TITLE,AUTHORS,YEAR,DESCRIPTION,ID,SUBJECT,PUBLISHER
Winner-Take-All Network Utilising Pseudoinverse Reconstruction Subnets Demonstrates Robustness on the Handprinted Character Recognition Problem,J. Körmendy-rácz S. Szabó J. Lörincz G. Antal G. Kovács A. Lörincz,1999,Wittmeyer’s pseudoinverse iterative algorithm is formulated as a dynamic connectionist Data Compression and Reconstruction (DCR) network and subnets of this type are supplemented by the winner-take-all paradigm. The winner is selected upon the goodness-of-fit of the input reconstruction. The network can be characterised as a competitive-cooperative-competitive architecture by virtue of the contrast enhancing properties of the pseudoinverse subnets. The network is capable of fast learning. The adopted learning method gives rise to increased sampling in the vicinity of dubious boundary regions that resembles the phenomenon of categorical perception. The generalising abilities of the scheme allow one to utilise single bit connection strengths. The network is robust against input noise and contrast levels shows little sensitivity to imprecise connection strengths and is promising for mixed VLSI implementation with on-chip learning properties. The features of the DCR network are demonstrated on the NIST database of handprinted characters.,10.1.1.1.1484,Correspondence and offprint requests to J. Kormendy-Rácz,Springer
DEEM: a Tool for the Dependability Modeling and Evaluation,A. Bondavalli I. Mura S. Chiaradonna S. Poli F. Sandrini,2000,Multiple-Phased Systems whose operational life can be partitioned in a set of disjoint periods called Â¿phasesÂ¿ include several classes of systems such as Phased Mission Systems and Scheduled Maintenance Systems. Because of their deployment in critical applications the dependability modeling and analysis of Multiple-Phased Systems is a task of primary relevance. However the phased behavior makes the analysis of Multiple-Phased Systems extremely complex. This paper is centered on the description and application of DEEM a dependability modeling and evaluation tool for Multiple Phased Systems. DEEM supports a powerful and efficient methodology for the analytical dependability modeling and evaluation of Multiple Phased Systems based on Deterministic and Stochastic Petri Nets and on Markov Regenerative Processes.,10.1.1.1.1485,Processes,IEEE Computer Society
Dynamical networks in function dynamics,Naoto Kataoka Kunihiko Kaneko,2003,As a first step toward realizing a dynamical system that evolves while spontaneously determining its own rule for time evolution function dynamics (FD) is analyzed. FD consists of a functional equation with a self-referential term given as a dynamical system of a one-dimensional map. Through the time evolution of this system a dynamical graph (a network) emerges. This graph has three interesting properties: (i) vertices appear as stable elements (ii) the terminals of directed edges change in time and (iii) some vertices determine the dynamics of edges and edges determine the stability of the vertices complementarily. Two aspects of FD are studied the generation of a graph (network) structure and the dynamics of this graph (network) in the system.,10.1.1.1.1486,Function dynamics Iterated map Self-reference Dynamical network,?
Simulation  Prototyping,Ingolf Ståhl,2002,A simulation model is successful if it leads to policy action i.e. if it is implemented. Studies show that for a model to be implemented it must have good correspondence with the mental model of the system held by the user of the model. The user must feel confident that the simulation model corresponds to this mental model. An understanding of how the model works is required. Simulation models for implementation must be developed step by step starting with a simple model the simulation prototype. After this has been explained to the user a more detailed model can be developed on the basis of feedback from the user. Software for simulation prototyping is discussed e.g. with regard to the ease with which models and output can be explained and the speed with which small models can be written.,10.1.1.1.1487,?,?
Hedging beyond duration and convexity,Jian Chen Michael C. Fu,2002,Hedging of fixed income securities remains one of the most challenging problems faced by financial institutions. The predominantly used measures of duration and convexity do not completely capture the interest rate risks borne by the holder of these securities. Using historical data for the entire yield curve we perform a principal components analysis and find that the first four factors capture over 99.99% of the yield curve variation. Incorporating these factors into the pricing of arbitrary fixed income securities via Monte Carlo simulation we derive perturbation analysis (PA) estimators for the price sensitivities with respect to the factors. Computational results for mortgage-backed securities (MBS) indicate that using these sensitivity measures in hedging provides far more protection against interest risk exposure than the conventional measures of duration and convexity.,10.1.1.1.1488,?,?
Designing for social friction: Exploring ubiquitous computing as means of cultural interventions in urban space,Rune Huvendick Jensen Tau Ulv Lenskjold,2004,As ubiquitous computing emerges in our lives and cities new opportunities for artistic and otherwise cultural interventions in urban space follow but so far not much work has been done in order to articulate the socio-cultural significance of these new opportunities. This paper is part of a general attempt to develop a coherent understanding of the implications and potentials of ubiquitous computing in the context of everyday city life. On a more specific level the paper examines how the notion of social friction can be helpful in the development and analysis of ubiquitous computing in relation to art and design. Social friction is articulated as a critical position which could be applied as a strategy for design. Our approach consists of a theoretical analysis and precedes concrete development and real-life experiments. As such the paper aims to establish a steppingstone from which to launch actual digital designs. We argue that by designing for the social friction which is an intrinsic characteristic of everyday life new forms of social and cultural potentials can be released. By means of discussing CityNova a vision for a possible use of ubiquitous computing in urban space we explore how this approach might lead to systems that create new ways of experiencing the city.,10.1.1.1.1489,everyday life urban space Situationism,?
Optimal Combination of Number of Taps and Coefficient Bit-Width for Low Power FIR Filter Realization,João Portela Eduardo Costa José Monteiro,2003,This paper addresses the optimization of FIR filters for low power. We propose a search algorithm to find the combination of the number of taps and coe#cient bit-width that leads to the minimum number of total partial sums and hence to the least power consumption. We show that the minimum number of taps does not necessarily lead to the least power consumption in fully parallel FIR filter architectures. This is particularly true if the reduction of the bit-width of the coe#cients is taken into account. We show that power is directly related to the total number of partial sums in the FIR filter which in turn is determined by the number of bits set to 1 in the coe#cients. We have developed a search algorithm that achieves up to 36% less power consumption when compared to an implementation using the minimum number of taps.,10.1.1.1.1490,?,?
The Influence of a Course on Direct and Activating Instruction upon Student Teachers Classroom Practice,Simon Veenman Eddie Denessen Ingrid Van Den Oord Ferdy Naafs,2003,Educational research has highlighted the importance of maintaining an orderly classroom environment and providing both clear and well-organized instruction tailored to the needs of individual students. Time spent on direct instruction and particularly the direct instruction of basic skills is associated with school learning (Wang Haertel  Walberg 1993). With the increased interest in constructivistic conceptions of learning and teaching today educators with constructivistic orientations contend that various forms of knowledge and skills are applied more generally when constructed by the learners themselves as opposed to explicitly taught: knowledge is made not acquired (Phillips 2000 p. 7). Such a view nevertheless often leads to an inclination to reject direct instruction by the teacher (see for example Brooks  Brooks 1993). It should be noted however that many of the discussions of constructivistic orientations to learning and instruction are at the level of slogan and clichÃ© (Duffy  Cunningham 1996 Finn  Ravitch 1996 Kozloff 1998). In addition the term constructivism has come to serve as an umbrella term for a diversity of views (Phillips 1995 2000).,10.1.1.1.1491,?,?
Multiplanar Applications and Multimodal Networks,S. Keshav,1999,We believe that a broad class of future applications will span both the Internet and the telephone network because such multiplanar applications have several economic and architectural advantages over conventional ones. We also envision the close interlinking of the telephone network and the Internet to form a multimodal network. In this paper we describe these applications and networks outline their architecture and present our experiences in constructing a prototype multiplanar application.,10.1.1.1.1492,Future applications network architecture,?
Free-Riding and Whitewashing in Peer-to-Peer Systems,Michal Feldman Christos Papadimitriou John Chuang  Ion Stoica,2004,We devise a simple model to study the phenomenon of free-riding and the effect of free identities on user behavior in peer-to-peer systems. At the heart of our model is a strategic user of a certain type an intrinsic and private parameter that reflects the users generosity. The user decides whether to contribute or free-ride based on how the current burden of contributing in the system compares to her type. We derive the emerging cooperation level in equilibrium and  quantify the effect of providing free-riders with degraded service on the emerging cooperation. We find that this penalty  mechanism is beneficial mostly when the generosity level of the society (i.e. the average type) is low. To quantify the social cost of free identities we extend the model to account for dynamic scenarios with turnover (users joining and leaving) and with whitewashers: users who strategically leave the system and re-join with a new identity. We find that the imposition of penalty on all legitimate newcomers incurs a significant social loss only under high turnover rates in conjunction with intermediate societal generosity levels.,10.1.1.1.1493,?,?
A Simple Algorithm for Complete Motion Planning of Translating Polyhedral Robots,Gokul Varadhan Shankar Krishnan T. V. N. Sriram Dinesh Manocha,2005,We present an algorithm for complete path planning for translating polyhedral robots in 3D. Instead of exactly computing an explicit representation of the free space we compute a roadmap that captures its connectivity. This representation encodes the complete connectivity of free space and allows us to perform exact path planning. We construct the roadmap by computing deterministic samples in free space that lie on an adaptive volumetric grid. Our algorithm is simple to implement and uses two tests: a complex cell test and a star-shaped test. These tests can be efficiently performed on polyhedral objects using max-norm distance computation and linear programming. The complexity of our algorithm varies as a function of the size of narrow passages in the configuration space. We demonstrate the performance of our algorithm on environments with very small narrow passages or no collision-free paths.,10.1.1.1.1494,?,Sage Publications Inc.
 Modeling Ship Arrivals in Ports,Eelco van Asperen Rommert Dekker Mark Polman Henk de Swaan Arons,2003,The model used in this report focuses on the analysis  of ship waiting statistics and stock fluctuations under different  arrival processes. However the basic outline is the  same: central to both models are a jetty and accompanying  tankfarm facilities belonging to a new chemical plant in the   Port of Rotterdam. Both the supply of raw materials and   the export of finished products occur through ships loading   and unloading at the jetty. Since disruptions in the plants  production process are very expensive buffer stock is  needed to allow for variations in ship arrivals and overseas  exports through large ships.   Ports provide jetty facilities for ships to load and unload  their cargo. Since ship delays are costly terminal operators  attempt to minimize their number and duration. Here simulation  has proved to be a very suitable tool. However in port  simulation models the impact of the arrival process of ships  on the model outcomes tends to be underestimated. This article  considers three arrival processes: stock-controlled   equidistant per ship type and Poisson. We assess how their  deployment in a port simulation model based on data from a  real case study affects the efficiency of the loading and  unloading process. Poisson which is the chosen arrival  process in many client-oriented simulations actually performs worst in terms of both ship delays and required storage capacity. Stock-controlled arrivals perform best with regard to ship delays and required storage capacity.   In the case study two types of arrival processes were  considered. The first type are the so-called stock-controlled  arrivals i.e. ship arrivals are scheduled in such a way that  a base stock level is maintained in the tanks. Given a base  stock level of a raw material or ...,10.1.1.1.1495,?,?
Cognitive Tools for . . .,Donald Sofge Dennis Perzanowski Marjorie Skubic Magdalena Bugajska J. Gregory Trafton Nicholas Cassimatis Derek Brock William Adams Alan Schultz,2004,The effective use of humanoid robots in space will depend upon  the efficacy of interaction between humans and robots. The key to  achieving this interaction is to provide the robot with sufficient skills for  natural communication with humans so that humans can interact with the  robot almost as though it were another human. This requires that a number  of basic capabilities be incorporated into the robot including voice  recognition natural language and cognitive tools on-board the robot to  facilitate interaction between humans and robots through use of common  representations and shared humanlike behaviors.,10.1.1.1.1496,Cognitive Systems Co-operative Control Speech Recognition Natural Language Human-Machine Interface Autonomous Mobile Robots,?
Exploiting Computer Automation to Improve the Interview Process and Increase Survey Cooperation,Jeffrey C. Moore Jeffrey C. Moore,2004,Couper (2002) outlines the challenges and opportunities of recent and stillemerging technological developments on the conduct of survey research. This paper focuses on one such development -- the use of computer-assisted survey instruments in place of paper-andpencil questionnaires -- and it focuses on one particular opportunity which this development presents: the ability to improve efficiency flow and naturalness and in general make the interview experience a more pleasant one for all participants while still controlling question wording and sequencing. Moral arguments can be raised in defense of such efforts the potential for important practical benefits including improved survey cooperation lends more mundane but perhaps more potent support. Although the research literature is surprisingly scant there is some evidence that improved instrument design can reduce nonresponse. A recent effort by the U.S. Census Bureau to redesign the core instrument for the Survey of Income and Program Participation (SIPP) offers additional support. Motivated in large measure by evidence of increasing unit nonresponse and attrition the primary goal of the SIPP redesign effort was to improve the interview process and in particular to seek ways to avoid violations of conversational norms (e.g. Grice 1975). A great many of the SIPP interview process improvements would not have been feasible without the computerization of the survey instrument. This paper briefly summarizes many of the technology-based changes implemented in the SIPP instrument and briefly describes a set of field experiments used to develop and refine the new procedures and to evaluate their success in achieving SIPPs redesign goals. Keywords: burden conversational norms efficiency flow nonresponse/...,10.1.1.1.1497,burden conversational norms efficiency flow nonresponse/attrition questionnaire design respondent-friendly I. In,?
Performance and Design Evaluation Of The Raid-II Storage Server,Peter M. Chen Edward K. Lee Ann L. Drapeau  Ken Lutz Ethan L. Miller Srinivasan Seshan Ken Shirriff David A. Patterson Randy H. Katz,1994,RAID-II is a high-bandwidth networkattached storage server designed and implemented at the University of California at Berkeley. In this paper we measure the performance of RAID-II and evaluate various architectural decisions made during the design process. We first measure the end-to-end performance of the system to be approximately 20 MB/s for both disk array reads and writes. We then perform a bottleneck analysis by examining the performance of each individual subsystem and conclude that the disk subsystem limits performance. By adding a custom interconnect board with a high-speed memory and bus system and parity engine we are able to achieve a performance speedup of 8 to 15 over a comparative system using only off-theshelf hardware.,10.1.1.1.1499,?,?
The Marinov Motor Notional Induction,Without Magnetic Field J. P Wesley,2001,Introduction  The force of induction F on a charge q is given by  FA=-qtcdd(1)  where A is the usual magnetic vector potential defined by  A r  rJr  rrc  -  s    (2)  where J is the current density. Slowly varying effects are assumed here where the basic theory may be given as a true relativity theory involving the separation distance between two charges and its time derivatives.  This force of induction Eq. (1) yields Faradays law of electromagnetic induction for the special case of an electromotive force (emf) around a fixed closed loop. In particular  emf  d  d  d  d  d        (  0  ) =-  =-  =-    s s s  sF  q  s  tc tc  an  tc  an  A  B    (3)  where F is the magnetic flux through the loop.  It is observed in the laboratory that an emf is also induced when =A tc 0  and the magnetic flux through the loop is changed by moving the loop so Faradays law becomes  emf = -      .-(4)  Francisco Mllers (1987) experiments show that induction occurs locally and that the force ,10.1.1.1.1500,?,?
Biometric Verification Based on Grip-Pattern Recognition,Raymond Veldhuis Asker Bazen Joost Kauffman Pieter Hartel,2004,This paper describes the design implementation and evaluation of a user-verification system for a smart gun which is based on grip-pattern recognition. An existing pressure sensor consisting of an array of 44    44 piezoresistive elements is used to measure the grip pattern. An interface has been developed to acquire pressure images from the sensor. The values of the pixels in the pressure-pattern images are used as inputs for a verification algorithm which is currently implemented in software on a PC. The verification algorithm is based on a likelihoodratio classifier for Gaussian probability densities. First results indicate that it is feasible to use grip-pattern recognition for biometric verification.,10.1.1.1.1501,Biometric verification likelihood ratio smart gun grip-pattern recognition,?
Relativistic Doppler Effect and the Principle of Relativity,W. Engelhardt,2003,The frequency shifts predicted by the `relativistic Doppler  e#ect are derived in the photon picture of light. It turns  out that in general the results do not depend exclusively  on the relative velocity between observer and light source.,10.1.1.1.1502,Relativity Doppler Effect Aberration a private address Fasaneriestrasse 8 D-80636 München,?
Differential Association Rule Mining for the Study of Protein-Protein Interaction Networks,Christopher Besemann  Anne Denton  Ajay Yekkirala  Ron Hutchison  Marc Anderson,2004,Protein-protein interactions are of great interest to biologists. A variety of high-throughput techniques have been devised each of which leads to a separate definition of an interaction network. The concept of differential association rule mining is introduced to study the annotations of proteins in the context of one or more interaction networks. Differences among items across edges of a network are explicitly targeted. As a second step we identify differences between networks that are separately defined on the same set of nodes. The technique of differential association rule mining is applied to the comparison of protein annotations within an interaction network and between different interaction networks. In both cases we were able to find rules that explain known properties of protein interaction networks as well as rules that show promise for advanced study.,10.1.1.1.1503,?,?
Combining Adaptive and Deterministic Routing: Evaluation of a Hybrid Router,Dianne Kumar Walid A. Najjar,1999,?,10.1.1.1.1504,?,Springer
Towards a More Complete Model of Role, Adrian Baldwin Cheh Goh Cheh Goh,1998,In order to manage the use of roles for the purpose of access control it is important to look at attributes beyond the consideration of capability assignment. Fundamentally a generic attribute description using a constraint-based approach will allow many of the important aspects of role such as scope activation and deactivation to be included. Furthermore the commonly accepted concept of role hierarchy is challenged from the point of view of subsidiarity in real organisations with the suggestion that role hierarchy has limited usefulness that does not seem to apply widely.,10.1.1.1.1505,?,?
Target Tracking with Distributed Sensors: The Focus of Attention Problem,Volkan Isler   Sanjeev Khanna  J. Spletzer Camillo J. Taylor ,2004,In this paper we consider the problem of assigning sensors to track targets so as to minimize the expected error in the resulting estimation for target locations. Specifically we are interested in how disjoint pairs of bearing or range sensors can be best assigned to targets in order to minimize the expected error in the estimates. We refer to this as the focus of attention (FOA) problem. In its,10.1.1.1.1506,?,?
Creating an Integrated Computer Assisted Learning and Assessment Experience in the School of European Languages and Cultures at the University of Edinburgh,John Hobbs John Hobbs  Marcus Duran Marcus Duran Eh Jx,2002,In the field of Computer-Aided anything acronyms abound. They are after all useful tools. However there is a risk that we become constrained by them and as a result fail to see beyond them.,10.1.1.1.1507,?,?
Web Structure Analysis for Information Mining,Lakshmi Vijjappu Ah-Hwee Ah-hwee Tan Chew-lim Tan,2001,Our approach to extracting information from the web analyzes the structural content of web pages through exploiting the latent information given by HTML tags. For each specific extraction task an object model is created consisting of the salient fields to be extracted and the corresponding extraction rules based on a library of HTML parsing functions. We derive extraction rules for both single-slot and multiple-slot extraction tasks which we illustrate through two sample domains.,10.1.1.1.1508,?,?
Bayesian Inference for Transductive Learning of Kernel Matrix Using the Tanner-Wong Data Augmentation Algorithm,Zhihua Zhang  Dit-Yan Yeung James T. Kwok,2004,In kernel methods an interesting recent development  seeks to learn a good kernel from  empirical data automatically. In this paper  by regarding the transductive learning  of the kernel matrix as a missing data  problem we propose a Bayesian hierarchical  model for the problem and devise the  Tanner-Wong data augmentation algorithm  for making inference on the model. The  Tanner-Wong algorithm is closely related to  Gibbs sampling and it also bears a strong resemblance  to the expectation-maximization  (EM) algorithm. For an e#cient implementation  we propose a simplified Bayesian hierarchical  model and the corresponding TannerWong  algorithm. We express the relationship  between the kernel on the input space  and the kernel on the output space as a  symmetric-definite generalized eigenproblem.,10.1.1.1.1509,?,?
Genetic Improvisation Model - a framework for real-time performance environments,Paul Nemirovsky Richard Watson,2003,This paper presents the current state in an ongoing development of the Genetic  Improvisation Model (GIM): a framework for the design of real-time improvisational  systems. The aesthetic rationale for the model is presented followed by  a discussion of its general principles. A discussion of the Emonic Environment  a networked system for audiovisual creation built on GIMs principles follows,10.1.1.1.1510,?,?
Mean-Variance Hedging under Additional Market Information ,Frank Thierbach,?,In this paper we analyse the mean-variance hedging approach in an incomplete market under the assumption of additional market information which is represented by a given finite set of observed prices of non-attainable contingent claims. Due to no-arbitrage arguments our set of investment opportunities increases and the set of possible equivalent martingale measures shrinks. Therefore we obtain a modified mean-variance hedging problem which takes into account the observed additional market information. Solving this by means of the techniques developed by Gourieroux Laurent and Pham (1998) we obtain an explicit description of the optimal hedging strategy and an admissible constrained variance-optimal signed martingale measure that generates both the approximation price and the observed option prices.,10.1.1.1.1511,JEL classification G11 G12,?
Sis-Prueba,Tool For Rapid Pedro Concejero Cerezo Juan José Rodríguez Soler Daniel Tapias Merino Telefónica Móviles España,?,SIS PRUEBA is a software tool to integrate usability and user-centred design principles in the development process of services within Telefnica Mviles Espaa (TME) the largest mobile telecommunications operator in Spain.,10.1.1.1.1512,?,?
Reducing the Computational Load of Energy Evaluations for Protein Folding,Eunice E. Santos Eugene Santos Jr.,?,Predicting the native conformation using computational protein models requires a large number  of energy evaluations even with simplified models such as hydrophobic-hydrophilic (HP)  models. Clearly energy evaluations constitute a significant portion of computational time. We  hypothesize that given the structured nature of algorithms that search for candidate conformations  such as stochastic methods energy evaluation computations can be cached and reused  thus saving computational time and e#ort. In this paper we present a caching approach and  apply it to 2D triangular HP lattice model. We provide theoretical analysis and prediction of  the expected savings from caching as applied this model. We conduct experiments using a sophisticated  evolutionary algorithm that contains elements of local search memetic algorithms  diversity replacement etc. in order to verify our hypothesis and demonstrate a significant level of savings in computational e#ort and time that caching can provide.,10.1.1.1.1513,protein folding triangular lattice HP energy model caching reuse evolutionary,?
Human-Robot Interactions in Active Sensor Networks,Alexei Makarenko  Tobias Kaupp  Ben Grocholsky Hugh Durrant-whyte,?,This paper considers the modes of interaction between one or several human operators and an active sensor network -- a fully decentralized network of sensors some or all of which have actuators and are in that sense active. The primary goal of this study is to investigate the conditions under which the human involvement will not jeopardize scalability of the overall system. Two aspects of human-robot interaction are considered: the ways in which the global view of the system may be conveyed to the operators and how the operators may influence the behavior of the system during the course of its operation. The results of analysis favor peer-topeer information-based interactions between the operators and the network whereby the humans act as extended sensors and communication nodes of the network itself. Experiments on an indoor active sensor network are described.,10.1.1.1.1514,?,?
Disjoint Sum of Product Minimization by Evolutionary Algorithms,Nicole Drechsler  Mario Hilgemeier Görschwin Fey  Rolf Drechsler,?,Recently an approach has been presented to minimize Disjoint Sumof  -Products (DSOPs) based on Binary Decision Diagrams (BDDs). Due  to the symbolic representation of cubes for large problem instances the  method is orders of magnitude faster than previous enumerative techniques.,10.1.1.1.1515,?,?
Peer-to-Peer Human-Robot Interaction for Space Exploration,Terrence Fong And Terrence Fong Illah Nourbakhsh,2004,NASA has embarked on a long-term program to develop  human-robot systems for sustained affordable space exploration.,10.1.1.1.1518,?,?
Survey  Taxonomy of Packet Classification Techniques,David E. Taylor,2004,Packet classification is an enabling function for a variety of Internet applications including Quality of Service security monitoring and multimedia communications. In order to classify a packet as belonging to a particular flow or set of flows network nodes must perform a search over a set of filters using multiple fields of the packet as the search key. In general there have been two major threads of research addressing packet classification: algorithmic and architectural. A few pioneering groups of researchers posed the problem provided complexity bounds and offered a collection of algorithmic solutions. Subsequently the design space has been vigorously explored by many offering new algorithms and improvements upon existing algorithms. Given the inability of early algorithms to meet performance constraints imposed by high speed links researchers in industry and academia devised architectural solutions to the problem. This thread of research produced the most widely-used packet classification device technology Ternary Content Addressable Memory (TCAM). New architectural research combines intelligent algorithms and novel architectures to eliminate many of the unfavorable characteristics of current TCAMs. We observe that the community appears to be converging on a combined algorithmic and architectural approach to the problem. Using a taxonomy based on the high-level approach to the problem and a minimal set of running examples we provide a survey of the seminal and recent solutions to the problem. It is our hope to foster a deeper understanding of the various packet classification techniques while providing a useful framework for discerning relationships and distinctions.,10.1.1.1.1519,?,?
Friscof Risco,Framework Of Information Eckhard D. Falkenberg Wolfgang Hesse Paul Lindgreen Björn E. Nilsson J. L. Han Oei Colette Rolland Ronald K. Stamper Frans J. M. Van Assche Alexander A. Verrijn-stuart Klaus Voss,1998,this report Paul Lindgreen as secretary and as editor of the interim report [Lin90a],10.1.1.1.1520,?,?
 Average performance of quasi Monte Carlo methods for global optimization,Hisham A. Al-Mharmah,1998,In this paper we compare the average performance of one class of low-discrepancy quasi-Monte Carlo sequences for global optimization. Weiner measure is assumed as the probability prior on all optimized functions. We show how to construct van der Corput sequences and we prove their consistency. Numerical experimentation shows that the van der Corput sequence in base 2 has a better average performance.,10.1.1.1.1521,?,?
The Virtual Ms Lyceum: A Consortium For Modeling And Simulation Technology,D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan Steven D. Farr Alex F. Sisti,1998,This paper addresses the opportunity to put into place a virtual consortium for modeling and simulation. While periodic conferences such as the Winter Simulation Conference are tremendously vital to the continued growth of modeling and simulation research they do not offer the day-to-day technical exchange that can now be made possible with matured collaborative technologies.,10.1.1.1.1522,?,?
Classification And Regression Trees Cart - A User Manual For Identifying Indicators Of Vulnerability To Famine And Chronic Food Insecurity,Auser Manualfor Yisehac Yohannes Patrick Webb,?,ue the Netherlands Norway the Philippines the Rockefeller Foundation the Rural Industries Research and Development Corporation (Australia) South Africa the Southern African Development Bank Spain Sweden Switzerland the United Kingdom the United Nations Childrens Fund the United States and the World Bank. CLASSIFIC ATION AND REGRESSION TREES CART^TM  A USER MANUAL FOR IDENTIFYING INDIC A TORS OF VULNERABILITY TO FAMINE AND CHRONIC FOOD INSECURITY YISEHAC YOHANNES PATRICK WEBB MICROCOMPUTERS IN POLICY RESEARCH   INTERNATIONAL FOOD POLICY RESEARCH INSTITUTE  CART is a registered trademark of California Statistical Software Inc. Copyright 1999 by the International Food Policy Research Institute 2033 K Street N.W. Washington D.C. 20006-1002 U.S.A. Library of Congress Cataloging-in-Publication Data available Yohannes Yisehac Classification and Regression Trees Cart^TM : A User Manual for Identifying Indicators of Vulnerability to Famine and Chronic Food Insecurity / Yise,10.1.1.1.1523,FAMINE AND CHRONIC FOOD INSECURITY YISE HAC YO HAN NES,?
An Approach for Locating Segmentation Points of Handwritten Digit Strings,Using Neural Network,?,An approach for segmentation of handwritten touching numeral strings is presented in this paper. A neural network has been designed to deal with various types of touching observed frequently in numeral strings. A numeral string image is split into a number of line segments while stroke extraction is being performed and the segments are represented with straight lines. Four types of primitive are defined based on the lines and used for representing the numeral string in more abstractive way and extracting clues on touching information from the string. Potential segmentation points are located using the neural network by active interpretation of the features collected from the primitives. Also the run-length coding scheme is employed for efficient representation and manipulation of images. On a test set collected from real mail pieces the segmentation accuracy of 89.1% was achieved in image level in a preliminary experiment. 1. ,10.1.1.1.1524,?,?
An Overview of JML Tools and Applications,Lilian Burdy Yoonsik Cheon David Cok Michael D. Ernst Joe Kiniry Gary T. Leavens K. Rustan M. Leino Erik Poll ,2003,The Java Modeling Language (JML) can be used to specify  the detailed design of Java classes and interfaces by adding annotations  to Java source files. The aim of JML is to provide a specification language  that is easy to use for Java programmers and that is supported by a wide  range of tools for specification type-checking runtime debugging static  analysis and verification. This paper,10.1.1.1.1525,formal specification Java runtime assertion checking static checking,?
Triage: Performance Isolation and Differentiation for Storage Systems,Magnus Karlsson  Christos Karamanolis Xiaoyun Zhu,2004,Ensuring performance isolation and differentiation among workloads that share a storage infrastructure is a basic requirement in consolidated data centers. Existing management tools rely on resource provisioning to meet performance goals they require detailed knowledge of the system characteristics and the workloads. Provisioning is inherently slow to react to system and workload dynamics and in the general case it is impossible to provision for the worst case.,10.1.1.1.1526,?,?
On-line Handwritten Japanese Text Recognition free from Constrains on Line,Direction And Character Masaki Nakagawa Motoki Onuma,?,This paper describes an on-line handwritten Japanese text recognition method that is liberated from constraints on writing direction (line direction) and character orientation. This method estimates the line direction and character orientation using the time sequence information of pen-tip coordinates and employs writingbox -free recognition with context processing combined. The method can cope with a mixture of vertical horizontal and skewed lines with arbitrary character orientations. It is expected useful for tablet PCs interactive electronic whiteboards and so on.,10.1.1.1.1527,?,?
Data Transformation for Warehousing Web Data,Yan Zhu Christof Bornhövd Alejandro P. Buchmann,2001,In order to analyze market trends and make reasonable business plans a companys local data is not sufficient. Decision making must also be based on information from suppliers partners and competitors. This external data can be obtained from the Web in many cases but must be integrated with the companys own data for example in a data warehouse. To this end Web data has to be mapped to the star schema of the warehouse. In this paper we propose a semi-automatic approach to support this transformation process. Our approach is based on the use a rooted labeled tree representation of Web data and the existing warehouse schema. Based on this common view we can compare source and target schemata to identify correspondences. We show how the correspondences guide the transformation to be accomplished automatically. We also explain the meaning of recursion and restructuring in mapping rules which are the core of the transformation algorithm.,10.1.1.1.1528,?,?
Discriminant Projections Embedding for Nearest Neighbor Classification.,Petia Radeva And Petia Radeva Jordi Vitrià,2004,In this paper we introduce a new embedding technique to  linearly project labeled data samples into a new space where the performance  of a Nearest Neighbor classifier is improved. The approach is  based on considering a large set of simple discriminant projections and  finding the subset with higher classification performance. In order to implement  the feature selection process we propose the use of the adaboost  algorithm. The performance of this technique is tested in a multiclass  classification problem related to the production of cork stoppers for wine  bottles.,10.1.1.1.1529,?,Springer Verlag
Vowel - Zero Alternations in Czech Prefixes,Tobias Scheer Tobias Scheer Clite E -e,1998,inchoative up    p#ed    16    48    before in front of    roz    80    295    inch. disperse/ break into pieces    nad    5    33    over    pod    26    74    under    od    41    253    distantiational movement    sum    195    762        TOTAL        957        (6) the secret must be found in the different status of stem-initial CC-clusters.    (7) stem-initial CCs observed with  a. prefixal-V only +e  b. prefixal - only -e  c. both mix     +e only: 17 CCs -e only: 38 CCs ct dn d# jm lstn mk pn ps rv #v sch sr v tn v# z# #r  bl b# cl cv #l f# fr hl hm hv chl chrchl km kr k# kv m# mr pl pt sh sv k n p r tl tr tv vd vr zbr zp zt #h #m ## #v  mix: 35 CCs br #t dm dr dv hn hr h# chv jd kd kl ml mn pj pr p# sk sl sm sn sp st l t t# v# vl v# v vz zd zl zn zv TOTAL nb CC: 90 (8) A given root belongs to one and only one of these three groups. (9)    CC mix represented by how many it,10.1.1.1.1530,e,?
Automatic Construction of Navigable Concept Networks Characterizing Text Databases,Claudio Carpineto Giovanni Romano Fondazione Ugo Bordoni,1995,In this paper we present a comprehensive approach to conceptual structuring and intelligent navigation of text databases. Given any collection of texts we first automatically extract a set of index terms describing each text. Next we use a particular lattice conceptual clustering method to build a network of clustered texts whose nodes are described using the index terms. We argue that the resulting network supports an hybrid navigational approach to text retrieval - implemented into an actual user interface - that combines browsing potentials with good retrieval performance. We present the results of an experiment on subject searching where this approach outperformed a conventional Boolean retrieval system.,10.1.1.1.1531,?,Springer-Verlag
µSleep: A Technique for Reducing Energy Consumption in Handheld Devices,Lawrence S. Brakmo Deborah A. Wallach Marc A. Viredaz,2004,Energy management has become one of the great challenges in portable computing. This is the result of the increasing energy requirements of modern portable devices without a corresponding increase in battery technology.  Sleep is a new energy reduction technique for handheld devices that is most effective when the handhelds processor is lightly loaded such as when the user is reading a document or looking at a web page. When possible rather than using the processors idle mode Sleep tries to put the processor in sleep mode for short periods (less than one second) without affecting the users experience. To enhance the perception that the system is on an image is maintained on the display and activity is resumed as a result of external events such as touch-screen and button activity. We have implemented Sleep on a prototype pocket computer where it has reduced energy consumption by up to 60%.,10.1.1.1.1532,?,?
Answers to the Top Ten Input Modeling Questions,Bahar Biller Barry L. Nelson,2002,In this tutorial we provide answers to the top ten inputmodeling questions that new simulation users ask point out common mistakes that occur and give relevant references. We assume that commercial input-modeling software will be used when possible and only suggest non-commercial options when there is little else available. Detailed examples will be provided in the tutorial presentation.,10.1.1.1.1533,?,?
A Simulation Study of an Automotive Foundry . . . ,Sang D. Choi Anil R. Kumar Abdolazim Houshyar,2002,This paper discusses the initial efforts to implement simulation modeling as a visual management and analysis tool at an automotive foundry plant manufacturing engine blocks. The foundry process was modeled using Pro Model to identify bottlenecks and evaluate machine performance cycle times and production data (total parts rejects throughput products/hr) essential for efficient production control. Results from the current system identified assembly machine work area as the bottleneck (although utilization was greater than 95% for two assembly machines) resulting in high work-in-process (WIP) inventory level low resource and machine utilization. Based on these results optimum numbers were identified through use of scenarios by varying the number of assembly machines and processing time of each machine. In addition to these scenarios strategies for production control involving buffer sizes were also made.,10.1.1.1.1534,?,?
A Sub-Quadratic Algorithm for Conjunctive and Disjunctive BESs,Jan Friso Groote Misa Keinänen,2004,We present an algorithm for conjunctive and disjunctive Boolean equation systems (BESs) which arise frequently in the verification and analysis of finite state concurrent systems. In contrast to the previously best known O(esup2) time solutions our algorithm computes the solution of such a fixpoint equation system with size e and alternation depth d in O(e log d) time.,10.1.1.1.1535,?,?
Innovations of the NetSolve Grid Computing System,Dorian C. Arnold  Henri Casanova Jack Dongarra,2002,This article is meant to provide the reader with details regarding the present state of the project describing the current architecture of the system its latest innovations and other systems 10  that make use of the NetSolve infrastructure. Copyright # 2002 John Wiley  Sons Ltd,10.1.1.1.1536,KEY WORDS Grid computing distributed computing heterogeneous network computing client--server,?
The InfoVis Toolkist,Jean-Daniel Fekete,2003,This report presents the InfoVis Toolkit designed to support the creation  extension and integration of advanced 2D Information Visualization components into interactive  Java Swing applications. The InfoVis Toolkit provides specific data structures to  achieve a fast action/feedback loop required by dynamic queries. It comes with a large  set of components such as range sliders and tailored control panels required to control and  configure the visualizations. These components are integrated into a coherent framework  that simplifies the management of rich data structures and the design and extension of  visualizations. Supported data structures currently include tables trees and graphs. Supported  visualizations include scatter plots time series Treemaps node-link diagrams for  trees and graphs and adjacency matrix for graphs. All visualizations can use fisheye lenses  and dynamic labeling. The InfoVis Toolkit supports hardware acceleration when available  through Agile2D an implementation of the Java Graphics API based on OpenGL achieving  speedups of 10 to 60 times. The report,10.1.1.1.1537,?,?
Complex Systems Modeling,Christophe Lecerf  et al.,2003,This paper addresses the simulation of the dynamics of complex systems by using hierarchical graph and multi-agent system. A complex system is composed of numerous interacting parts that can be described recursively. First we summarize the hierarchical aspect of the complex system. We then present a description of hierarchical graph as a data structure for structural modeling in parallel with dynamics simulation by agents. This method can be used by physiological modelers ecological modelers etc as well as in other domains that are considered as complex systems. An example issued from physiology will illustrate this approach.,10.1.1.1.1538,?,?
Automobile Manufacturing Supply Chain Simulation . . . ,Gary Tan Na Zhao Simon J. E. Taylor,2003,uses to deliver value to its customers. In todays competitive environment the globalization of markets has rapidly substituted the traditional integrated business. The competitive success of an organization no longer depends only on its own efforts but relies on the efficiency of the entire supply chain. Therefore building an effective supply chain is fast becoming paramount in todays marketplace. Distributed Supply Chain (DSC) Simulation has been identified as one of the best means to test and analyze the performance of supply chains. The Generic Runtime Infrastructure for Distributed Simulation (GRIDS) is a middleware that supports the reuse and interoperation of DSC simulations. This paper reports the experience on employing the GRIDS to support the distributed collaboration of an automobile manufacture supply chain simulation. Several advantages of GRIDS are also discussed here which make it an ideal middleware for DSC simulations.,10.1.1.1.1539,?,?
Multi-dimensional Visual Representations for Underwater Environmental Uncertainty,Greg S. Schmidt Sue-Ling Chen Greg S. Schmidt Sue-ling Chen Aaron N. Bryden  Mark A. Livingston Bryan R. Osborn  Lawrence J. Rosenblum,2004,this paper) and (2) develop a visual method for each characterization. The mariner community needs enhanced characterizations of environmental uncertainty now but the accuracy of the characterizations is still not sufficient enough and therefore formal user evaluations cannot take place at this point in development. We received feedback on the applicability of our techniques from domain experts. We used this in conjunction with previous results to compile a set of development guidelines (some obvious others not),10.1.1.1.1540,?,?
InstantGrid: A Framework for On-Demand Grid,Point Construction Roy Roy S. C. Ho K. K. Yin David C. M. Lee Daniel H. F. Hung Cho-li Wang Francis C. M. Lau,2004,This paper proposes the InstantGrid framework for on-demand  construction of grid points. In contrast to traditional approaches InstantGrid  is designed to substantially simplify software management in grid  systems and is able to instantly turn any computer into a grid-ready  platform with the desired execution environment. Experimental results  demonstrate that a 256-node grid point with commodity grid middleware  can be constructed in five minutes from scratch.,10.1.1.1.1541,?,?
Prototyping Proof Carrying Code,Martin Wildmoser Tobias Nipkow Gerwin Klein Sebastian Nanz,2004,We introduce a generic framework for proof carrying code developed and mechanically verified in Isabelle/HOL. The framework defines and proves sound a verification condition generator with minimal assumptions on the underlying programming language safety policy and safety logic. We demonstrate its usability for prototyping proof carrying code systems by instantiating it to a simple assembly language with procedures and a safety policy for arithmetic overflow.,10.1.1.1.1542,?,Kluwer
Proceedings of the Block Island Workshop on Cooperative Control,Springer-Verlag Series Lecture Wei Ren Al W. Beard Timothy W. Mclain,2004,this paper. Ref [15] addresses the knowledge consensus problem when teams of agents only have local communication between nearest neighbors. Since the set of nearest neighbors is constantly changing the overall system becomes a hybrid system. The paper shows that if the union over all bidirectional communication graphs is connected for finite periods of time then consensus is achieved. While the results in this paper are not as strong only unidirectional communication links are assumed,10.1.1.1.1543,?,Springer-Verlag
Hidden-Action in Multi-Hop Routing,Michal Feldman  John Chuang,2004,In any multi-hop routing scheme cooperation by the intermediate nodes are essential for the succesful delivery of traffic. However the effort exerted by the intermediate nodes are often unobservable by the source and/or destination nodes. We show it is possible to overcome this problem of hidden action by designing contracts in the form of payments to induce cooperation from the intermediate nodes. Interestingly the ability to monitor per-hop or per-path outcomes even if costless to implement may not improve the welfare of the participants or the performance of the network.,10.1.1.1.1544,?,?
EPTD DISCUSSION PAPER NO. 83 HOW AGRICULTURAL RESEARCH AFFECTS URBAN POVERTY IN DEVELOPING COUNTRIES: THE CASE OF CHINA,Shenggen Fan Cheng Fang Xiaobo Zhang,?,This paper develops a framework to measure the impact of agricultural research on urban poverty. Increased investments in agricultural RD can lower food prices by increasing food production and lower food prices benefit the urban poor because they often spend more than 60% of their income on food. Application of the framework to China shows that these food price effects are large and that the benefits for the urban poor have been about as large as the benefits for the rural poor. KEYWORDS: developing countries China agricultural research urban poverty ii  ACKNOWLEDGMENTS The authors are grateful for helpful comments received from Peter Hazell Robert Evanson and participants in a session at the American Agricultural Economics Association annual meeting in Chicago August 5-8 2001. iii  TABLE OF CONTENTS 1. ,10.1.1.1.1545,developing countries China agricultural research urban poverty i ACKNOWLEDGMENTS,?
Ontology-Based Query Refinement,For Multimedia Meta Sonja Zillner Werner Winiwarter,2004,To enable e#cient access to multimedia content the media data has to be augmented by semantic metadata and functionality. The semantic representation has to be integrated with domain ontologies to fully exploit domain-specific knowledge. This knowledge can be used for refining ambiguous user queries by closing the conceptual gap between the user and the information to be retrieved. In our previous research we have introduced Enhanced Multimedia Meta Objects (EMMOs) as a new approach for semantic multimedia meta modeling as well as the query algebra EMMA which is adequate and complete with regard to the EMMO model. This paper focuses on the refinement of EMMA queries by incorporating ontological knowledge.,10.1.1.1.1546,?,?
Computerising Natural History Card Archives,Downton Lucas And A. C. Downton S. M. Lucas G. Patoulas,2003,This paper summarises the achievements of a multidisciplinary Bioinformatics project which has the objective of providing a general mechanism for efficient computerisation of typewritten/hand-annotated archive card indexes of the type found in most museums archives and libraries. In addition to efficiently scanning recognising and databasing the content of the cards the original card images must be maintained as the ultimate source record and a flexible database structure is required to allow taxonomists to reorganise and update the resulting online archive. Implementation mechanisms for each part of the overall system are described and conversion performance for a demonstrator database of 27578 Pyralid moth archive cards is reported. The system is currently being used to convert the full NHM archive of Lepidoptera totalling 290886 cards.,10.1.1.1.1547,?,?
Genome-Wide Detection of Alternative Splicing in Expressed Sequences Using Partial Order Multiple Sequence Alignment Graphs,C. Grasso B. Modrek  Y. Xing C. Lee,2001,this paper we present a detailed examination of the technical problems we have encountered in undertaking high-throughput analyses of alternative splicing over the last four years and the specific solutions we have developed for these problems in seeking to minimize both false positive and false negative errors,10.1.1.1.1548,?,?
Adaptive Sampling for Environmental Robotics,Mohammad Rahimi Richard Pon  William J. Kaiser Gaurav S. Sukhatme Deborah Estrin  Mani Srivastava,2003,this paper we describe   ######################################## a new distributed   robotic sensor methodology developed for applications including  characterization of environmental structure and phenomena.  NIMS exploits deployed infrastructure that provides the benefits  of precise motion aerial suspension and low energy sustainable  operations in complex environments. NIMS nodes may explore a  three-dimensional environment and enable the deployment of  sensor nodes at diverse locations and viewing perspectives.  NIMS characterization of phenomena in a three dimensional  space must now consider the selection of sensor sampling points  in both time and space. Thus we introduce a new approach of  mobile node adaptive sampling with the objective of minimizing  error between the actual and reconstructed spatiotemporal  behavior of environmental variables while minimizing required  motion. In this approach the NIMS node first explores as an  agent gathering a statistical description of phenomena using a   ##################################approach. By iteratively   increasing sampling resolution guided adaptively by the  measurement results themselves this NIMS sampling enables  reconstruction of phenomena with a systematic method for  balancing accuracy with sampling resource cost in time and  motion. This adaptive sampling method is described analytically  and also tested with simulated environmental data. Experimental  evaluations of adaptive sampling algorithms have also been  completed. Specifically NIMS experimental systems have been  developed for monitoring of spatiotemporal variation of  atmospheric climate phenomena. A NIMS system has been  deployed at a field biology station to map phenomena in a 50m  width and 50m span transect in a forest environme...,10.1.1.1.1549,?,?
Enhanced Expressiveness in Scripting Using AnimalScript V2,Guido Rößling  Felix Gliesche Thomas Jajeh Thomas Widjaja,2004,this paper) is scripting. Here the user provides a simple ASCII file containing commands that steer the visualization. Typically the commands are held in plain English to make using the underlying scripting language easier. Typical examples for scripting-driven AV systems include JAWAA (Akingbade et al. 2003) JSamba (Stasko 1998) JHAV E (Naps et al. 2000) and Animal (Roling and Freisleben 2002),10.1.1.1.1550,?,?
Comparison of Clustering Algorithms in Speaker Identification,Tomi Kinnunen  Teemu Kilpelinen  Pasi FrÄnti,?,In speaker identification we match a given (unkown) speaker to the set of known speakers in a database. The database is constructed from the speech samples of each known speaker. Feature vectors are extracted from the samples by short-term spectral analysis and processed further by vector quantization for locating the clusters in the feature space. We study the role of the vector quantization in the speaker identification system. We compare the performance of different clustering algorithms and the influence of the codebook size. We want to find out which method provides the best clustering result and whether the difference in quality contribute to improvement in recognition accuracy of the system.,10.1.1.1.1551,Speech processing speaker identification vector,?
Towards a Generic Talking Head,Brar Bailly Chabanas,2003,We present here a framework for developing a generic talking head capable of reproducing the anatomy and the facial  deformations induced by speech movements with a set of a few parameters. We will show that the speaker-specific articulatory movements can be straightforward encoded into the normalized MPEG-4 Facial Animation Parameters and Facial Definition  Parameters.,10.1.1.1.1552,MPEG-4 Facial Animation Parameters and Facial Definition Parameters,?
Object-Relational Management of Multiply Represented Geographic Entities,Anders Friis-Christensen Christian S. Jensen,2003,Multiple representation occurs when information about the same geographic entity is represented electronically more than once. This occurs frequently in practice and it invariably results in the occurrence of inconsistencies among the different representations. We propose to resolve this situation by introducing a multiple representation management system (MRMS) the schema of which includes rules that specify how to identify representations of the same entity rules that specify consistency requirements and rules used to restore consistency when necessary. In this paper we demonstrate by means of a prototype and a realworld case study that it is possible to implement a multiple representation schema language on top of an objectrelational database management system. Specifically it is demonstrated how it is possible to map the constructs of the language used for specifying the multiple representation schema to functionality available in Oracle. Though some limitations exist Oracle has proven to be a suitable platform for implementing an MRMS.,10.1.1.1.1555,?,IEEE Computer Society
Word Searching in CCITT Group 4 Compressed Document Images,Yue Lu Chew Lim Tan,2003,In this paper we present a compressed pattern matching method for searching user queried words in the CCITT Group 4 compressed document images without decompressing. The feature pixels composed of black changing elements and white changing elements are extracted directly from the CCITT Group 4 compressed document images. The connected components are labeled based on a line-by-line strategy according to the relative positions between the changing elements of the current coding line and the changing elements of the reference line. Word boxes are bounded by merging the connected components. A two-stage matching strategy is constructed to measure the dissimilarity between the template image of the users query word and the words extracted from document images. Experimental results confirmed the validity of the proposed approach.,10.1.1.1.1558,?,?
Visualizing Multimedia Content on Paper Documents: Components of Key Frame Selection for Video Paper,Jonathan J. Hull Berna Erol  Jamey Graham Dar-shyang Lee,?,The components of a key frame selection algorithm for a paper-based multimedia browsing interface called Video Paper are described. Analysis of video image frames is combined with the results of processing the closed caption to select key frames that are printed on a paper document together with the closed caption. Bar codes positioned near the key frames allow a user to play the video from the corresponding times. This paper describes several component techniques that are being investigated for key frame selection in the Video Paper system including face detection and text recognition. The Video Paper system implementation is also discussed.,10.1.1.1.1559,?,?
Automatic Topic Identification,Using Ontology Hierarchy Sabrina Tiun Rosni Abdullah Tang Enya Kong,2001,This paper proposes a method of using ontology hierarchy in  automatic topic identification. The fundamental idea behind this work is to  exploit an ontology hierarchical structure in order to find a topic of a text. The  keywords which are extracted from a given text will be mapped onto their  corresponding concepts in the ontology. By optimizing the corresponding  concepts we will pick a single node among the concepts nodes which we  believe is the topic of the target text. However a limited vocabulary problem  is encountered while mapping the keywords onto their corresponding  concepts. This situation forces us to extend the ontology by enriching each of  its concepts with new concepts using the external linguistics knowledge-base  (WordNet). Our intuition of a high number keywords mapped onto the  ontology concepts is that our topic identification technique can perform at its  best.,10.1.1.1.1560,?,?
Module CAFCR course info logo TBD,Gerrit Muller,2004,This module provides the information about the CAFCR course: Multi-Objective Embedded Systems Design based on CAFCR. Distribution  This article or presentation is written as part of the Gaud project. The Gaud project philosophy is to improve by obtaining frequent feedback. Frequent feedback is pursued by an open creation process. This document is published as intermediate or nearly mature version to get feedback. Further distribution is allowed as long as the document remains complete and unchanged. All Gaud documents are available at:  http://www.extra.research.philips.com/natlab/sysarch/ version: 0 status: draft 5th July 2004 Contents 1 Multi-Objective Embedded Systems design based on CAFCR 1  1.1 ,10.1.1.1.1561,Contents,?
Partition Sampling for Active Video Database Annotation,Fabrice Souvannavong  Bernard Merialdo  Benoît Huet,2004,Annotating a video-database requires an intensive human effort that is time consuming and error prone. However this task is mandatory to bridge the gap between low-level video features and the semantic content. We propose a partition sampling active learning method to minimize human effort in labeling. Formally active learning is a process where new unlabeled samples are iteratively selected and presented to teachers. The major problem is then to find the best selection function that maximizes the knowledge gain acquired from new samples. In contrast with existing active learning approaches we focus on the selection of multiple samples. We propose to select samples such that their contribution to the knowledge gain is complementary and optimal. Hence at each iteration we ensure to maximize the knowledge gain. Our method offers many advantages among them the possibility to share the annotation effort among several teachers.,10.1.1.1.1562,?,?
Self-organized instability in . . . ,Ricard V. Solé David Alonso Alan McKane,2002,?,10.1.1.1.1563,scaling species-abundance distributions rarity species–area relations spatial dynamics,?
Learnability and the Statistical Structure of Language: Poverty of Stimulus Arguments Revisited,John D. Lewis Jeffrey L. Elman,2001,?,10.1.1.1.1564,?,Cascadilla Press
Discrete Event Simulation Experiments And Geographic Information Systems In Congestion Management Planning,Roy Brooks Wiley  Thomas Keyser White Dove Court,1998,A regional transportation system and the movement of large traffic volumes through it are characteristic of stochastic systems. The standard traffic management or transportation planning approach uses a slice in time view of the system. Static mean values of system variables are used for the basis of incident-caused congestion management decisions. By reason of the highly variable nature of transportation systems discrete event simulation is used in the planning process. The simulation model is highly dependent on the spatial accuracy of real world coordinates of nodes and the lengths of the roadway network links. Link travel times queue spill back and turn lane queue size are directly related to the magnitude of incident-caused congestion and the roadway systems ability to recover from it. The incorporation of accurate Geographic Information System (GIS) data with a powerful transportation simulation software package and properly designed data collection and analysis techniques are invaluable in support of transportation incident management decisions.,10.1.1.1.1566,?,?
P-RANK: Efficient Ranked Keyword Search Using P-tree,Fei Pan Imad Rahal Yue Cui William Perrizo,?,Nowadays XML is becoming the standard for electronic information representation and exchange in our lives. Access to information presented in hyperlinked XML documents and other formats have always been in demand by users. In this paper we describe the architecture implementation and evaluation of the P-RANK system built to address the requirement for efficient ranked keyword search over hyperlinked XML documents. Our contributions include presenting a new efficient keyword search system using a genuine data structure called the P-tree a novel ranking method based on dimension rank voting and a fast rank sorting method using the EIN-ring.,10.1.1.1.1567,?,?
Learning Partially Observable Action Models,Eyal Amir,?,In this paper we present tractable algorithms for learning a logical model of actions effects and preconditions in deterministic partially observable domains. These algorithms update a representation of the set of possible action models after every observation and action execution. We show that when actions are known to have no conditional effects then the set of possible action models can be represented compactly indefinitely. We also show that certain desirable properties hold for actions that have conditional effects and that sometimes those can be learned efficiently as well. Our approach takes time and space that are polynomial in the number of domain features and it is the first exact solution that is tractable for a wide class of problems. It does so by representing the set of possible action models using propositional logic while avoiding general-purpose logical inference. Learning in partially observable domains is difficult and intractable in general but our results show that it can be solved exactly in large domains in which one can assume some structure for actions effects and preconditions. These results are relevant for more general settings such as learning HMMs reinforcement learning and learning in partially observable stochastic domains.,10.1.1.1.1568,?,?
Reasoning about Time and Knowledge in Neural-Symbolic Learning Systems,Artur S. d’Avila Garcez   Luis C. Lamb ,2003,We show that temporal logic and combinations of temporal logics  and modal logics of knowledge can be effectively represented in artificial  neural networks. We present a Translation Algorithm from  temporal rules to neural networks and show that the networks  compute a fixed-point semantics of the rules. We also apply the  translation to the muddy children puzzle which has been used as a  testbed for distributed multi-agent systems. We provide a complete  solution to the puzzle with the use of simple neural networks capable  of reasoning about time and of knowledge acquisition through  inductive learning.,10.1.1.1.1569,?,?
Vowels in Infant- and Adult-Directed Speech,Joost Van De Weijer,2001,F1 and F2 frequencies of the vowels /i/ /a/ and /u/ were measured in speech directed to an infant and to adults. The vowels were taken from content words as well as function words. The results showed that the vowel triangles in speech to the infant were expanded compared to those in speech to adults but only in the content words. For function words the opposite pattern was found: adults produced more expanded vowels in adult-directed speech than in infant-directed speech.,10.1.1.1.1572,?,?
Stopping Criterion for Boosting-Based Data Reduction Techniques: from Binary to Multiclass Problems,Marc Sebban Richard Nock Stéphane Lallich E. Brodley Andrea Danyluk,2002,So far boosting has been used to improve the quality of moderately accurate learning algorithms  by weighting and combining many of their weak hypotheses into a final classifier with theoretically  high accuracy. In a recent work (Sebban Nock and Lallich 2001) we have attempted to adapt  boosting properties to data reduction techniques. In this particular context the objective was not  only to improve the success rate but also to reduce the time and space complexities due to the  storage requirements of some costly learning algorithms such as nearest-neighbor classifiers. In  that framework each weak hypothesis which is usually built and weighted from the learning set  is replaced by a single learning instance. The weight given by boosting defines in that case the  relevance of the instance and a statistical test allows one to decide whether it can be discarded  without damaging further classification tasks. In Sebban Nock and Lallich (2001) we addressed  problems with two classes. It is the aim of the present paper to relax the class constraint and  extend our contribution to multiclass problems. Beyond data reduction experimental results are  also provided on twenty-three datasets showing the benefits that our boosting-derived weighting  rule brings to weighted nearest neighbor classifiers.,10.1.1.1.1573,?,?
Removing Flicker from Old Movies,Francois Pitie,?,that are stored in a fragile state on a volatile medium. They require conservation and restoration. Automated tools for video restoration will be crucial in preserving our cultural heritage since manual image restoration is a tedious and time-consuming process.,10.1.1.1.1574,?,?
 An Optimization-Based Multi-Resolution . . . ,Darren T. Drewry Paul F. Reynolds Jr.  et al.,2002,The need for new approaches to the consistent simulation of related phenomena at multiple levels of resolution is great. While many fields of application would benefit from a complete and approachable solution to this problem such solutions have proven extremely difficult. We present a multi-resolution simulation methodology which uses numerical optimization as a tool for maintaining external consistency between models of the same phenomena operating at different levels of temporal and/or spatial resolution. Our approach follows from previous work in the disparate fields of inverse modeling and spacetime constraintbased animation. As a case study our methodology is applied to two environmental models of forest canopy processes that make overlapping predictions under unique sets of operating assumptions and which execute at different temporal resolutions. Experimental results are presented and future directions are addressed.,10.1.1.1.1575,?,?
Robust Ego-Motion Estimation and 3D Model Refinement Using Depth Based Parallax Model,Amit K Agrawal  Rama Chellappa,?,We present an iterative algorithm for robustly estimating the egomotion and refining and updating a coarse noisy and partial depth map using a depth based parallax model and brightness derivatives extracted from an image pair. Given a coarse noisy and partial depth map acquired by a range-finder or obtained from a Digital Elevation Map (DEM) we first estimate the ego-motion by combining a global ego-motion constraint and a local brightness constancy constraint. Using the estimated camera motion and the available depth map estimate motion of the 3D points is compensated. We utilize the fact that the resulting surface parallax field is an epipolar field and knowing its direction from the previous motion estimates estimate its magnitude and use it to refine the depth map estimate. Instead of assuming a smooth parallax field or locally smooth depth models we locally model the parallax magnitude using the depth map formulate the problem as a generalized eigen-value analysis and obtain better results. In addition confidence measures for depth estimates are provided which can be used to remove regions with potentially incorrect (and outliers in) depth estimates for robustly estimating ego-motion in the next iteration. Results on both synthetic and real examples are presented.,10.1.1.1.1576,?,?
Retrospective Digital Image Fusion of,Multidetector Ct And,2004,ion. In 5 patients additional pancreatic tumors or distant metastases only suspected during PET scanning were confirmed. Image fusion improved the sensitivity of malignancy detection from 76.6% (CT) and 84.4% (PET) to 89.1% (image fusion). Compared with CT alone image fusion increased the sensitivity of detecting tissue infiltration to 68.2% but at the cost of decreased specificity. Conclusion: The most important supplementary finding supplied by image fusion is a more precise correlation with focal tracer hot spots in PET. Image fusion improved the sensitivity of differentiating between benign and malignant pancreatic lesions with no significant change in specificity. All image modalities failed to stage lymph node involvement.  Key Words: PET CT spiral image manipulation or reconstruction pancreas computer applications detection  J Nucl Med 2004 45:1279--1286  With  an incidence rate of 10 cases per 100000 people per year cancer of the pancreas is the third most common ma,10.1.1.1.1578,?,?
The key to Czech vowel length (Arabic rule . . .,Tobias Scheer,2001,Arabic rule in Middle Europe)     contrastive vowel length in these languages. Czech vowel length has been extensively studied since the 19th century.  However no generalisation of any kind could be uncovered. Diachronically it does not relate to either Indo-European  or Common Slavic vowel length nor does it show any kinship with Baltic tones and East/ South Slavic accent.  Synchronically closed syllable shortening (krva vs. krav kravka cow NOMsg GENpl dim) appears to coexist with  closed syllable lengthening (n# vs. noe n#ky knife NOMsg GENsg scissors). In sum any attempt to propose a  regularity underlying this system seems desperate. Vowel length in Czech is therefore reputed to be anarchic and  unpredictable. This situation is mirrored in grammars by pages of amorphous lists of grammatical categories that exhibit  length or shortness.   Czech vowel length is driven by a simple mechanism that is known from other languages: templates. That is a  certain amount of vocalic space is associated to a given morphological and/ or semantic category. If concatenation of  underlying long and short vowels produces more morae than the specific category allows for shortening is observed. If  it produces less vocalic weight than the category at stake demands lengthening ensues. This kind of templatic structure  is a typical feature of Afro-Asiatic languages and I believe that the templatic regularities I present have not been  discovered before because nobody has ever looked at the relevant data through the prism of templates: these are  commonly held to be a typological pecularity of Afro-Asiatic absent from Indo-European.   In order to illustrate the preceding claim only a few of the instances of templatic activity that I have identified may  be quoted in t...,10.1.1.1.1579,?,?
Fake Palatalizations,Tobias Scheer  Philippe Segeral Université Nice Cnrs Umr N Coda,2001,below the skeleton   b. UP = processes driven by syllable structure. Consequences of syntagmatic  relations between syllabic constituents (e.g. lenition).  == trigger above the skeleton    2  c. DOWN           x x   | |   #   #   # #   #      UP   R   |   N Coda   | |   x x   | |   V   #   #   #        (4) Vulgar Latin [VL]: consonification of short (non-low) vowel in hiatus      a. {i e} - j / __ V b. {u o} - w / __ V    fiilia  filja fille vidua  wedwa veuve  viinea  winja vigne coagulaare  kwaglare cailler  (5) a. Lat. filia = 3 syll.VL. filja = 2 syll.   b. Cw/j clusters   c.  no original Cj/w preserved: Cj = palatalizations      mod. French [j] [z] [s] [#] [#] [] ([L])    (+j metathesis / fusion with the preceding vowel ratjoone  [##z]   (6) evolution of Cj:   a. classical view: all processes depend on segmental characteristics of C   b. our claim:    - there is just one (fundamentally) syllabic process    - segmental properties are secondary and never the cause ,10.1.1.1.1580,?,?
On Evaluating Loss Performance Deviation: A Simple Tool and Its Practical Implications,Ying Xu Roch Guérin,2003,The focus of this paper is on developing and evaluating a practical methodology for determining if and when  different types of traffic can be safely multiplexed within the same service class. The use of class rather than individual  service guarantees offers many advantages in terms of scalability but raises the concern that not all users within a class  see the same performance. Understanding when and why a user will experience performance that differs significantly  from that of other users in its class is therefore of importance. Our approach relies on an analytical model developed  under a number of simplifying assumptions which we test using several real traffic traces corresponding to different  types of users. This testing is carried out primarily by means of simulation to allow a comprehensive coverage of  different configurations. Our findings establish that although the simplistic model does not accurately predict the  absolute performance that individual users experience it is quite successful and robust when it comes to identifying  situations that can give rise to substantial performance deviations within a service class. As a result it provides a  simple and practical tool for rapidly characterizing real traffic profiles that can be safely multiplexed.,10.1.1.1.1581,?,?
Efficient Analysis of Rare Events Associated with . . . ,Ramya Dhamodaran et al.,2003,Over the last decade importance sampling has been a popular technique for the efficient estimation of rare event probabilities. This paper presents an approach for applying balanced likelihood ratio importance sampling to the problem of quantifying the probability that the content of the second buffer in a two node tandem Jackson network reaches some high level before it becomes empty. Heuristic importance sampling distributions are derived that can be used to estimate this overflow probability in cases where the first buffer capacity is finite or infinite. The proposed importance sampling distributions differ from previous balanced likelihood ratio methods in that they are specified as functions of the contents of the buffers. Empirical results indicate that the relative errors of these importance sampling estimators is bounded independent of the buffer size when the second server is the bottleneck and is bounded linearly in the buffer size otherwise.,10.1.1.1.1582,?,?
Agent-Based Modeling and . . . ,Anil Sawhney Howard Bashford Kenneth Walsh Ajith Rao Mulky,2003,Agent-based Modeling and Simulation (ABMS) is a relatively new development that has found extensive use in areas such as social sciences economics biology ecology etc. Can ABMS be effectively used in finding answers to complex construction systems? The focus of this paper is to provide some answers to this question. Initial experimentation is conducted to understand the advantages of using ABMS either in isolation or in combination with traditional simulation methodologies. The paper provides a summary of this experimentation conclusions and sets the agenda for future research in this area.,10.1.1.1.1583,?,?
To Search for Images on the Web,Look At The Ethan V. Munson,2001,this paper we want to argue that image pro-   This material is based upon work supported by the U. S. Department of Defense and by the National Science Foundation under Grant No. 9734102. Additional support was provided by Sun Microsystems,10.1.1.1.1584,?,?
Inferring White Matter Geometry from Diffusion Tensor MRI: Application to Connectivity Mapping,Christophe Lenglet  Rachid Deriche Olivier Faugeras,2004,We introduce a novel approach to the cerebral white matter  connectivity mapping from di#usion tensor MRI. DT-MRI is the  unique non-invasive technique capable of probing and quantifying the  anisotropic di#usion of water molecules in biological tissues. We address  the problem of consistent neural fibers reconstruction in areas of complex  di#usion profiles with potentially multiple fibers orientations. Our  method relies on a global modelization of the acquired MRI volume as a  Riemannian manifold M and proceeds in 4 majors steps: First we establish  the link between Brownian motion and di#usion MRI by using the  Laplace-Beltrami operator on M . We then expose how the sole knowledge  of the di#usion properties of water molecules on M is su#cient to  infer its geometry. There exists a direct mapping between the di#usion  tensor and the metric of M . Next having access to that metric we propose  a novel level set formulation scheme to approximate the distance  function related to a radial Brownian motion on M . Finally a rigorous  numerical scheme using the exponential map is derived to estimate the  geodesics of M  seen as the di#usion paths of water molecules. Numerical  experimentations conducted on synthetic and real di#usion MRI datasets  illustrate the potentialities of this global approach.,10.1.1.1.1585,?,Springer
Efficient Reasoning with Range and Domain Constraints,Dmitry Tsarkov Ian Horrocks,2004,We show how a tableaux algorithm for   that include range and domain axioms prove that the extended algorithm is still a decision   concepts w.r.t. such a role box and show how support for range and domian axioms can be exploited in order to add a new form of absorption optimisation called role absorption. We illustrate the effectiveness of the optimised algorithm by analysing the perfomance of our FaCT++  implementation when classifying terminologies derived from realistic ontologies. 1 ,10.1.1.1.1586,?,?
On Simple Oversampled A/D Conversion in Lsup2(R),Zoran Cvetkovic Martin Vetterli,2001,Accuracy of oversampled analog-to-digital (A/D) conversion the dependence of accuracy on the sampling interval and on the bit rate are characteristics fundamental to A/D conversion but not completely understood. These characteristics are studied in this paper for oversampled A/D conversion of band-limited signals in    ( ). We show that the digital sequence obtained in the process of oversampled A/D conversion describes the corresponding analog signal with an error which tends to zero as    in energy provided that the quantization threshold crossings of the signal constitute a sequence of stable sampling in the respective space of band-limited functions. Further we show that the sequence of quantized samples can be represented in a manner which requires only a logarithmic increase in the bit rate with the sampling frequency = ( log ) and hence that the error of oversampled A/D conversion actually exhibits an exponential decay in the bit rate as the sampling interval tends to zero.,10.1.1.1.1587,?,?
The BT-Tree: A Branched and Temporal Access Method,Linan Jiang Betty Betty Salzberg,2000,Temporal databases assume a single line of time  evolution. In other words they support timeevolving  data. However there are applications  which require the support of temporal data with  branched time evolution. With new branches created  as time proceeds branched and temporal  data tends to increase in size rapidly making the  need for efficient indexing crucial. We propose a  new (paginated) access method for branched and  temporal data: the BT-tree. The BT-tree is both  storage efficient and access efficient. Wehaveimplemented  the BT-tree and performance results  confirm these properties.,10.1.1.1.1588,?,Kaufmann
Biodiversity Informatics: The Challenge of Rapid Development Large Databases and Complex Data,Meredith A. Lane  James L. Edwards Ebbe S. Nielsen,2000,There are high expectations in all sectors of society for immediate access to biological knowledge of all kinds. To fully exploit and manage the value of biological resources society must have the intellectual tools to store retrieve collate analyze and synthesize organism-level and ecological scale information. However it currently is difficult to discover access and use biodiversity data because of the long history of bottom-up evolution of scientific biodiversity information the mismatch between the distribution of biodiversity itself and the distribution of the data about it and most importantly the inherent complexity of biodiversity and ecological data. This stems from among many factors numerous data types the nonexistence of a common underlying (binary) language and the multiple perceptions of different researchers/data recorders across spatial or temporal distance or both. The challenge presented to the computer science and information technology community by the biodiversity and ecological information domain is worthy of all the time and talent that can be brought to bear because the continued existence  of the species Homo sapiens depends upon  gaining an understanding of this spaceship Earth  and our fellow passengers upon it.,10.1.1.1.1589,?,Morgan Kaufmann
OCL as a Core UML Transformation Language,Wituml Position Paper Damien Pollet Didier Vojtisek Jean-marc Jézéquel,2002,Syntax Tree    *  Figure 2: Architecture diagram  UML repository The repository contains the model represented at the metamodel level (i.e. a class is represented by an object instance of the M2 concept named Class)  Bridge The OCL interpreter itself should not know anything of UML but rather manipulate it through a bridge pattern. This bridge maps manipulated MOF-compliant concepts to OCL types and properties.,10.1.1.1.1591,?,?
Thoughts and Musings on Simulation Education,Richard E. Nance Osman Balci,?,Proper education of a modeling and simulation professional meeting the extensive criteria imposed by the community poses significant challenges. In this paper we explore the formation of a university-based education in modeling and simulation to meet the challenges. We examine the factors affecting the composition of a modeling and simulation course. Based on the anticipated consequences we propose potential solutions.,10.1.1.1.1592,?,?
A Learning Approach to Improving Sentence-Level MT Evaluation,Alex Kulesza Stuart M. Shieber,2004,The problem of evaluating machine translation (MT) systems is more challenging than it  may first appear as diverse translations can often be considered equally correct. The task is  even more difficult when practical circumstances require that evaluation be done automatically  over short texts for instance during incremental system development and error analysis. While several,10.1.1.1.1593,?,?
Layered Animation of Captured Data,Wei Sun Adrian Hilton  Raymond Smith John Illingworth,2000,This paper proposes a novel technique for building layer animation models of real articulated objects  from 3D surface measurement data. Objects are scanned using a hand-held 3D sensor to acquire 3D  surface measurements. A novel geometric fusion algorithm is presented which enables reconstruction  of a single surface model from the captured data. This algorithm overcomes the limitations of previous  approaches which cannot be used for hand-held sensor data as they assume that measurements are on a  structured planar grid. The geometric fusion introduces the normal-volume representation of a triangle  to convert individual triangles to a volumetric implicit surface.,10.1.1.1.1594,?,?
On the Resolvability of Sinusoids with Nearby Frequencies in the Presence of Noise,Morteza Shahram And Morteza Shahram Peyman Milanfar,?,This paper develops statistical algorithms and performance limits for resolving sinusoids with nearby frequencies in the presence of noise. We address the problem of distinguishing whether the received signal is a single-frequency sinusoid or a double-frequency sinusoid with possibly unequal and unknown amplitudes and phases. We derive a locally optimal detection strategy that can be applied in a stand-alone fashion or as a refinement step for existing spectral estimation methods to yield improved performance. We further derive explicit relationships between the minimum detectable di#erence between the frequencies of two tones for any particular false alarm and detection rate and at a given SNR. # This work was supported in part by NSF CAREER Award CCR-9984246 and AFOSR grant F49620-03-1-0387.,10.1.1.1.1596,?,?
I In nn no ov va at ti io on n  g gr ro ow wt th h t th he eo or ry y  a an nd d t th he e r ro ol le e o of f k kn no ow w l le ed dg ge e s sp pi il ll lo ov ve er rs s,The Relationship Between,?,this article Professor Ajay Agrawal at Queens Universitys School of Business can be reached at aagrawal@business.queensu.ca. This paper represents the views of the author and does not necessarily reflect the opinions of Statistics Canada,10.1.1.1.1597,?,?
Loops in Reeb Graphs of 2-Manifolds,Kree Cole-McLaughlin   Herbert Edelsbrunner John Harer Vijay Natarajan Valerio Pascucci,2003,Given a Morse function f over a 2-manifold with or without boundary the Reeb graph is obtained by contracting the connected components of the level sets to points. We prove tight upper and lower bounds on the number of loops in the Reeb graph that depend on the genus the number of boundary components and whether or not the 2-manifold is orientable. We also give an algorithm that constructs the Reeb graph in time O(n log n) where n is the number of edges in the triangulation used to represent the 2-manifold and the Morse function.,10.1.1.1.1598,2-manifolds Morse functions level sets Reeb graphs loops algorithms,ACM Press
Hierarchical Web Caching Systems: Modeling Design and Experimental Results,Hao Che  Ye Tung  Zhijun Wang,2002,This paper aims at finding fundamental design principles for hierarchical web caching. An analytical modeling technique is developed to characterize an uncooperative twolevel hierarchical caching system where the least recently used (LRU) algorithm is locally run at each cache. With this modeling technique we are able to identify a characteristic time for each cache which plays a fundamental role in understanding the caching processes. In particular a cache can be viewed roughly as a low-pass filter with its cutoff frequency equal to the inverse of the characteristic time. Documents with access frequencies lower than this cutoff frequency have good chances to pass through the cache without cache hits. This viewpoint enables us to take any branch of the cache tree as a tandem of low-pass filters at different cutoff frequencies which further results in the finding of two fundamental design principles. Finally to demonstrate how to use the principles to guide the caching algorithm design we propose a cooperative hierarchical web caching architecture based on these principles. Both model-based and real trace simulation studies show that the proposed cooperative architecture results in more than 50% memory saving and substantial central processing unit (CPU) power saving for the management and update of cache entries compared with the traditional uncooperative hierarchical caching architecture.,10.1.1.1.1599,?,?
Low Overhead Encodings for Reduced Activity in Data and Address Buses,Paulo J. Ramos Arlindo L. Oliveira,1999,this paper require very little additional hardware and no extra bus lines achieving nonetheless a significant reduction of the activity level on the bus,10.1.1.1.1600,?,?
A Maximum Entropy Approach to Multiple Classifiers Combination,Francois Fouss Marco Saerens,2004,In this paper we present a maximum entropy (maxent) approach to the fusion  of experts opinions or classifiers outputs problem. The maxent approach is quite  versatile and allows us to express in a clear rigorous way the a priori knowledge  that is available on the problem. For instance our knowledge about the reliability  of the experts and the correlations between these experts can be easily integrated:  Each piece of knowledge is expressed in the form of a linear constraint.,10.1.1.1.1601,?,?
FCND DP No. 80 1 FCND DISCUSSION PAPER NO. 80 NONTRADITIONAL CROPS AND LAND ACCUMULATION AMONG GUATEMALAN SMALLHOLDERS: IS THE IMPACT SUSTAINABLE?,Calogero Carletto,?,Since the late 1970s dramatic economic changes have taken place in the agricultural sector in the highlands of Guatemala. The introduction of new export crops such as snow peas broccoli and miniature vegetables has led to yet another agro-export boom. Unlike earlier booms however this one has included all but the smallest farmers. The high rate of smallholder participation in the boom and the initial high profitability of nontraditional exports (NTXs) fueled initial optimism that NTX production could increase smallholders ability to accumulate land and so decrease the highly skewed distribution of land in Guatemala a country with one of the most unequal landholding patterns in all of Latin America. The picture that emerges from the analysis in this paper raises serious questions about the sustainability and equity effects of NTX crop adoption among smallholders in the long run. Two main findings illustrate the problems besetting NTX crop production. First the land accumulation rates of adopters have dropped dramatically in the 1990s. NTX crop adopters accumulated close to three times more land than non-adopters in the 1980s. Although adopters are still accumulating more land than non-adopters in the 1990s the gap between the two groups has narrowed substantially. Second smaller adopters are no longer accumulating land at higher rates than their larger counterparts. In the 1980s the landholdings of smaller adopters grew significantly faster than those of the larger adopters but this trend reversed itself in the iii 1990s. The advantages smallholders initially had in accumulating land may have been lost as a result of deteriorating agronomic conditions and volatile export markets. However given adequate policy support smallholders could indeed improve thei...,10.1.1.1.1602,?,?
Fort Lauderdale Florida July 11-14 2004,American Institute Of J. E. Bradford A. Charania B. St. Germain,?,This paper will describe the REDTOP-2 tool  and its capabilities. Sample results obtained from exercising the tool for a number of  different existing engine designs will be presented. Results from a multi-variable sensitivity  study on a LOX/LH2 fuel-rich single preburner staged-combustion engine will be  highlighted. Two sample applications involving vehicle designs will be discussed. The first  involves probabilistic/uncertainty analysis for an all-rocket vehicle design and the second the  rocket main propulsion system analysis of an airbreathing two-stage RLV concept with first  stage tail-rockets and all-rocket second stage propulsion. Finally future directions in the  development of REDTOP-2 will be discussed,10.1.1.1.1603,?,?
Subpixel Curvature Estimation of the Corpus Callosum via Splines and its Application to Autism,Thomas J. Hoffmann Moo K. Chung Kim D. Dalton  Andrew L. Alexander  Grace Grace Wahba Richard J. Davidson,2004,Introduction  Autism is a neurodevelopmental disorder with abnormal corpus callosum (CC) size [1]. Most previous studies used the area of predefined Witelson partition [5] as a morphometric measure but other shape metrics have not been considered. We present a new computational technique for curvature estimation via piecewise quintic splines and use it in both CC nonlinear dynamic time warping algorithm [4] and detecting the regions of curvature difference.  Figure 1: Left: level set segmentation showing  partial volume effect. Right: spline smoothing. A  similar approach has been taken in [6].  Methods  A group of 2D mid sagittal cross section images of the corpus callosum was taken from males of similar age 15 autistic and 12 normal controls. The level set method was used to extract the boundary # of the corpus callosum automatically by solving  ##  #t  + F|##| = 0  where F is the given boundary propagation velocity [2]. Then the pixelated CC contour was reconstructed into a rough ,10.1.1.1.1604,?,?
On Global Warming (Softening Global Constraints),Willem Jan Van Hoeve Gilles Pesant Louis-martin Rousseau,2004,We describe soft versions of the global cardinality constraint  and the regular constraint with e#cient filtering algorithms maintaining  domain consistency. For both constraints the softening is achieved by  augmenting the underlying graph. The softened constraints can be used  to extend the meta-constraint framework for over-constrained problems  proposed by Petit Regin and Bessiere.,10.1.1.1.1605,?,?
Issues in the Practical Use of Graph Rewriting,Dorothea Blostein Hoda Fahmy Ann Grbavec,1996,Graphs are a popular data structure and graph-manipulation  programs are common. Graph manipulations can be cleanly compactly and  explicitly described using graph-rewriting notation. However when a  software developer is persuaded to try graph rewriting several problems  commonly arise. Primarily it is difficult for a newcomer to develop a feel for  how computations are expressed via graph rewriting. Also graph-rewriting  is not convenient for solving all aspects of a problem: better mechanisms are  needed for interfacing graph rewriting with other styles of computation.,10.1.1.1.1606,?,Springer
Building Trust into OO Components Using a Genetic Analogy,Benoit Baudry Vu Le Hanh  Jean-Marc Jezequel Yves Le Traon,2000,Despite the growing interest for component-based systems few works tackle the question of the trust we can bring into a component.,10.1.1.1.1607,?,?
DiffServ and MPLS -- Concepts and Simulation,Raymond Law And Raymond Law Srihari Raghavan,?,Differentiated Services (DiffServ) is scalable for deployment in todays Internet and Multiprotocol Label Switching (MPLS) provides fast packet switching and the opportunity for traffic engineering. Thus the combination of DiffServ and MPLS presents a very attractive strategy to backbone network providers. This paper attempts to explain the concepts of DiffServ + MPLS and illustrate its effectiveness by performing a simulation using Network Simulator (ns-2). The results show the fast rerouting feature of MPLS and how it alleviates the problem of link failures in DiffServ networks.,10.1.1.1.1608,?,?
An Analytical Model of Adaptive Wormhole Routing with Time-Out,A. Khonsari H. Sarbazi-Azad M. Ould-Khaoua,?,Several studies have shown that the performance advantages of adaptive  routing over deterministic routing are reduced when the traffic contains  strong degree of communication locality. This paper proposes a new  analytical model of an adaptive routing algorithm proposed by Duato in  [Dua94]. The main feature of this algorithm is the use of a time-out  selection function for assigning virtual channels. This has the advantage  of reducing virtual channels multiplexing to improve the network  performance especially in the presence of communication locality.,10.1.1.1.1609,?,?
UEP for Video Transmission in Space-Time Coded,Ofdm Systems Guang-Hua,2004,In this paper we provide a sub-channel partitioning based unequal error protection (UEP) scheme for a space-time block coded orthogonal frequency division multiplexing (STBCOFDM) system. In such a scheme video data is partitioned into high-priority (HP) and low-priority (LP) layers according to the importance of the data. At the receiver side OFDM subchannels are partitioned into high-quality (HQ) and low-quality (LQ) groups according to the estimated channel qualities. Based on the feedback of sub-channel partitioning results the transmitter assigns HP and LP video data to the corresponding HQ and LQ sub-channels. Through theoretical analysis we show there is indeed a significant BER difference between the HQ and LQ sub-channels which can be exploited by UEP. Based on the analysis we provide a criterion for determining the appropriate transmission power. Through computer simulations we show that the proposed scheme offers significant performance gain compared to conventional methods. We also demonstrate that the scheme is the least sensitive to channel estimation errors among all compared schemes and is hardly influenced by the Doppler spread. The feedback overhead can also be reduced with almost no performance penalty by bundling several neighboring sub-channels together and assigning them to the same group.,10.1.1.1.1610,?,?
Pre-Provisioning Networks to Support Fast Restoration with Minimum Over-Build,Mansoor Alicherry  Randeep Bhatia,2004,Supporting fast restoration for general mesh topologies with minimal network over build is a technically challenging problem. Traditionally ring based SONET networks have offered 50ms restoration at the cost of requiring 100% over-build. Recently fast (local) reroute has gained momentum in the context of MPLS networks. Fast reroute when combined with preprovisioning of protection capacities and bypass tunnels comes close to providing fast restoration for mesh networks. Preprovisioning has the additional advantage of greatly simplifying network routing and signaling. Thus even for protected connections online routing can now be oblivious to the offered protection and may only involve single shortest path computations.,10.1.1.1.1611,?,?
 Initializing On-Line Simulations from the State of . . . ,Fernando G. Gonzalez Wayne J. Davis,1998,In this paper we address the complex task of initializing an on-line simulation to a current system state collected from an operating physical system. The paper begins by discussing the complications that arise when the system model employed by the controller and the planner are not the same. The benefits of using the same model for control and planning are then outlined. The paper then discusses a new simulation paradigm that models controller interactions and provides a single model that is capable of supporting planning and control functions. Next issues arising from performing a distributed simulation of the distributed control architecture that is being employed to manage the system are addressed. The definition of the state for the distributed system is then discussed and the collection of the real-time state information from the elements of this distributed system is outlined. Finally the procedure for initializing the distributed on-line simulation from the collected real-time state information is given.,10.1.1.1.1612,?,?
Monitoring Ethernet Connectivity,Thomas Rodeheffer Thomas L. Rodeheffer,2003,Although the Ethernet promises high probability packet delivery between all pairs of hosts defects in the installation can sometimes prevent some pairs of hosts from communicating very well. This paper describes a method that was developed and used at Carnegie Mellon University during 1984--1985 to monitor the connectivity between all pairs of hosts on the Ethernet. The method is based on sending test packets from a central station through various cyclic routes and relating the results to the likelihood of various defects via a system probability model. The method proved to be quite effective in practice and greatly assisted our support staff in maintaining our Ethernet.,10.1.1.1.1613,?,?
Dynamic Bandwidth Management for Single-hop Ad Hoc Wireless Networks,Samarth H. Shah   Kai Chen Klara Nahrstedt,2003,Distributed weighted fair scheduling schemes for QoS support in wireless networks have not yet become standard. In this paper we propose an Admission Control and Dynamic Bandwidth Management scheme that provides fairness in the absence of distributed link level weighted fair scheduling. In case weighted fair scheduling becomes available our system assists it by supplying the scheduler with weights and adjusting them dynamically as network and traffic characteristics vary. To obtain these weights we convert the bandwidth requirement of the application into a channel time requirement. Our Bandwidth Manager then allots each flow a share of the channel time depending on its requirement relative to the requirements of other flows in the network. It uses a max-min fairness algorithm with minimum guarantees. The flow controls its packet transmission rate so it only occupies the channel for the fraction of time allotted to it by the Bandwidth Manager. As available bandwidth in the network and the traffic characteristics of various flows change the channel time proportion allotted also dynamically varies. Our experiments show that at the cost of a very low overhead there is a high probability that every flow in the network will receive at least its minimum  requested share of the network bandwidth.,10.1.1.1.1614,?,?
EPTD Discussion Paper No. 114,Environment And Production Daniel Kaboré Chris Reij,?,This paper describes the emergence of improved traditional planting pits (za) in Burkina  Faso in the early 1980s as well as their advantages disadvantages and impact. The za emerged  in a context of recurrent droughts and frequent harvest failures which triggered farmers to start  improving this local practice. Despair triggered experimentation and innovation by farmers.  These processes were supported and complemented by external intervention. Between 1985 and  2000 substantial public investment has taken place in soil and water conservation (SWC). The  socio-economic and environmental situation on the northern part of the Central Plateau is still  precarious for many farming families but the predicted environmental collapse has not occurred  and in many villages indications can be found of both environmental recovery and poverty  reduction.      Keywords: soil fertility soil conservation water conservation  iii  TABLE OF CONTENTS     1. The Context In Which Za Emerged In The Yatenga Region 1  2. Development And Dissemination Of The Za Technology 3  3. Impact On Farm Households And On Farmland 11  4. Final Remarks 24  References 26      TRADITIONAL SOIL AND WATER CONSERVATION PRACTICE  IN BURKINA FASO     Daniel Kabor    and Chris Reij          1. THE CONTEXT IN WHICH ZA EMERGED IN THE YATENGA REGION   In the 1970s the densely populated northern part of the Central Plateau faced an  acute environmental crisis. Recurrent droughts led to frequent harvest failure. Between  1975 and 1985 this region witnessed substantial out-migration to less densely populated  regions with better soils and higher rainfall   . Women had to walk longer distances to  collect firewood. Vegetation was destroyed not only for firewood but even more to  expand cultivated land. Groundwater ...,10.1.1.1.1615,soil fertility soil conservation water conservation ii TABLE OF CONTENTS,?
Qwhuqdwlrqdo Rqihuhqfh Dqg ([klelwlrq Rq *hrjudsklf qirupdwlrq,Rqjuhvv Hqwhu Ri Giovanni Di Costanzo Adam M. Gadomski,?,Intelligent Agent and on its goal-oriented point of view.,10.1.1.1.1616,Decision Support Systems Emergency Management Intelligent Agent GIS Case Base Reasoning Artificial Intelligence Risk Assessment,?
per DoD Directive 5230.24 Authorized for public release distribution is unlimited,Cdrl June For Task Pv Cdrl A,1996,STARS Program Manager TASK: PV03 CDRL: A025 14 June 1996 Data Reference: STARS-VC-A025/001/00  Version 2.0 (Signatures on File)  Principal Author(s): Approvals:  Mark Simos Organon Motives Inc. Dick Creps Lockheed Martin Tactical Defense Systems  Date Teri F. Payton Lockheed Martin Tactical Defense Systems  Carol Klingler Lockeed Martin Tactical Defense Systems Date Larry Levine Organon Motives Inc. Date Dean Allemang Organon Motives Inc. Date Public reporting burden for this collection of information is estimated to average 1 hour per response including the time for reviewing instructions searching existing data sources gathering and maintaining the data needed and completing and reviewing the collection of information. Send comments regarding this burden estimate or any other aspect of this collection of information including suggestions for reducing this burden to Washington Headquarters Services Directorate for Information Operations and Reports 1215 Jefferson Davis Highway Suite 1204 Arlington VA 22202-4302 and to the Office of Management and Budget Paperwork Reduction Project (0704-0188) Washington DC 20503.,10.1.1.1.1617,?,?
L_p State Estimators for Power Systems,N. Logic E. Kyriakides G. T. Heydt,2002,this paper the case of 2  p is considered and alternative cases will be applied to power engineering estimation problems. The specific cases of parameter estimation and measurement noise are discussed,10.1.1.1.1618,?,?
Using Partial Differential Equations to Model TCP Mice and Elephants in Large IP Networks,M. Ajmone Marsan  M. Garetto  P. Giaccone E. Leonardi E. Schiattarella A. Tarello,2004,Fluid models of IP networks have been recently proposed as a way to break the scalability barrier of traditional discrete state-space models both simulative (e.g. ns-2) and analytical (e.g. queues and Markov chains). Fluid models adopt...,10.1.1.1.1619,?,?
Genome Informatics 14: 322--323 (2003) Features of Gene Extraction by Nonlinear Support,Vector Machines In Daisuke Komura Hiroshi Nakamura Shuichi Tsutsumi Hiroyuki Aburatani Sigeo Ihara,?,this paper we use the wrapper methods based on a nonlinear classification algorithm in order to extract the discriminative genes that di#cult to be extracted by conventional filter methods. RFE method based on nonlinear Support Vector Machines (SVMs) [2] is employed to this end because it is successfully applied to classification of gene expression data. We investigate the genes extracted by the RFE method based on SVMs with gaussian kernel function to indicate that it can extract discriminative genes which are not chosen by conventional filter methods,10.1.1.1.1620,Support Vector Machines DNA microarray feature selection Recurisve Feature Elimination,?
Space-Code Bloom Filter for Efficient Per-Flow Traffic Measurement,Abhishek Kumar  Jun (Jim) Xu Jia Wang Oliver Spatschek  Li (Erran) Li,2004,Per-flow traffic measurement is critical for usage accounting traffic engineering and anomaly detection. Previous methodologies are either based on random sampling (e.g. Ciscos NetFlow) which is inaccurate or only account for the elephants. We introduce a novel technique for measuring perflow traffic approximately for all flows regardless of their sizes at very high-speed (say OC768). The core of this technique is a novel data structure called Space Code Bloom Filter (SCBF). A SCBF is an approximate representation of a multiset each element in this multiset...,10.1.1.1.1621,Index Terms — Network Measurement Traffic Analysis Data Structures Statistical Inference Bloom Filter,?
The Role of Metamodeling in MDA,Colin Atkinson  Thomas Kühne,2002,There is general agreement that metamodeling will play a pivotal role in the realization of the MDA but less consensus on what the precise role of metamodeling should be and what form it should take. In this paper we first analyze the underlying motivation for metamodeling within the context of the MDA and derive a concrete set of requirements that an MDA supporting infrastructure should satisfy. We then present a number of concepts which we believe are best suited to providing technical solutions to the identified requirements. In particular we discuss why the traditional language definition view is insufficient for an optimal MDA foundation.,10.1.1.1.1622,?,?
Extending and Enriching WordNet with OntoLearn,Roberto Navigli Paola Paola Velardi Ro Cucchiarelli Francesca Neri,2004,OntoLearn is a system for word sense disambiguation used to automatically  enrich WordNet with domain concepts and to disambiguate WordNet glosses.,10.1.1.1.1623,?,Springer-Verlag
A Distributed and Measurement-Based Framework against Free Riding in Peer-to-Peer Networks,Murat Karakaya  Ibrahim Körpeoglu Özgür Ulusoy,2004,Peer-to-peer networks have attracted a significant amount of interest as a popular and successful alternative to traditional client-server networks for resource sharing and content distribution. However the existence of high degrees of free riding may be an important threat against P2P networks. In this paper     we propose a distributed and measurement-based method to reduce the degree of free riding in P2P networks. We primarily focus on developing schemes to locate free riders and on determining policies that can be used to take actions against them. We propose a model in which each peer monitors its neighboring peers makes decisions if they exhibit any kind of free-riding and takes appropriate actions if required. We specify three types of free riding and their symptoms observable from the activities of the neighboring peers. We employ simple formulas to determine if a peer exhibits any kind of free riding. The counter actions to be applied to the free riders are defined. We combine the mechanisms proposed to detect free riders and to take appropriate actions in an ECA rule and a state diagram.,10.1.1.1.1624,?,?
Optimizing Neighbor Table Accuracy of Position-Based Routing Algorithms,Marc Heissenbüttel  Torsten Braun,2005,In position-based routing protocols each node periodically transmits a short hello message (called beacon) to announce its presence and position. Receiving nodes list all known neighbor nodes with their position in the neighbor table and remove entries after they have failed to receive a beacon for a certain time from the corresponding node. Especially in highly dynamic networks the information stored in the neighbor table is often out-dated and does not reflect the actual topology of the network anymore such that retransmissions and rerouting are required which consume bandwidth and increase latency. Despite a considerable number of proposed position-based protocols almost no analysis has been performed on the impact of beacons and the out-dated and inaccurate neighbor tables. We show by analytical and simulation results that performance suffers especially in highly mobile ad-hoc networks and propose several mechanisms to improve the accuracy of neighborhood information. Extensive simulations show the effectiveness of the proposed schemes to improve the network performance.,10.1.1.1.1625,?,?
Effect Of Changing Patient Position From Supine To Prone On The Accuracy Of A Brown-Roberts-Wells Stereotactic Head Frame System,Torsten Rohlfing Calvin R. Maurer Department Of Neurosurgery Department Of Neurosurgery David Dean Ph. D Robert J. Maciunas Wells Stereotactic Head Frame System,2003,on and one in the prone position. The prone images were registered to the  respective supine images by use of an intensity-based registration algorithm once  using only the frame and once using only the head. The difference between the  transformations produced by these two registrations describes the movement of the  patients head with respect to the frame.  RESULTS: The maximum frame-based registration error between the supine and prone  positions was 2.8 mm it was more than 2 mm in two patients and more than 1.5 mm  in six patients. Anteroposterior translation is the dominant component of the difference  transformation for most patients. In general the magnitude of the movement increased  with brain volume which is an index of head weight.  CONCLUSION: To minimize frame-based registration error caused by a change in the  mechanical load on the frame stereotactic procedures should be performed with the  patient in the identical position during imaging and intervention.  KEY WOR,10.1.1.1.1627,TO PRONE ON THE ACCURACY OF A BROWN-ROBERTS,?
Stability of Data Networks under an Optimization-Based Bandwidth Allocation ,Heng-Qing Ye,2003,It is known that a data network may not be stable at the connection level under some  unfair bandwidth allocation policies even when the normal offered load condition is satisfied  i.e. the average traffic load at each link is less than its capacity. In this paper we show  that under the normal offered load condition a data network is stable when the bandwidth  of the network is allocated so as to maximize a class of general utility functions. Using the  microscopic model proposed by Kelly [9] for a TCP congestion control algorithm we argue  that the bandwidth allocation in the network dominated by this algorithm can be modelled  as our bandwidth allocation model and hence that the network is stable under the normal  offered load condition. This result may shed light on the stability issue of the Internet since  the majority of its data tra#c is dominated by the TCP.,10.1.1.1.1628,Data network bandwidth allocation TCP stability Lyapunov function,?
Experimental Comparison of Classification Uncertainty for Randomised and Bayesian Decision Tree Ensembles,V. Schetinin D. Partridge W. J. Krzanowski  R.M. Everson  J.E. Fieldsend T. C. Bailey  A. Hernandez,?,In this paper we experimentally compare the classification uncertainty  of the randomised Decision Tree (DT) ensemble technique and the Bayesian DT  technique with a restarting strategy on a synthetic dataset as well as on some  datasets commonly used in machine learning community. For quantitative  evaluation of classification uncertainty we use an Uncertainty Envelope dealing  with the class posterior distribution and a given confidence probability. Counting  the classifier outcomes this technique produces feasible evaluations of the  classification uncertainty. Using this technique in our experiments we found that  the Bayesian DT technique is superior to the randomised DT ensemble technique.,10.1.1.1.1629,?,?
Computer Supported Collaborative Learning Metacognition and Motivation,H. van der Meijden  J.D. Trimpe Drs J. D. Trimpe,1999,This paper describes the present results of introducing Computer Supported Collaborative Learning in a Dutch secondary school. The inquiry focuses on three main questions: 1. Does CSCL effect students metacognition and motivation? 2. Does the role of the teacher effect number and/or quality of the contributions in the database? 3. What opinions do both students and teachers have on CSCL? Method  The study is carried out in a secondary school in the Netherlands The Raayland College in Venray. The Raayland is a school that includes all types of secondary education: Gymnasium pre-university education (VWO) senior secondary education (HAVO) junior secondary education (MAVO) and preparatory vocational education (VBO). It is a school with 2.300 students and 158 teachers. The Raayland College is a so-called pioneering school. About 120 of 700 high schools in the Netherlands receive extra money from the Department of Education of the government to introduce computers in their curriculum. The aim of this initiative is that partner schools share their experiences with other schools which do not receive extra funding. The Raayland College is present on the World Wide Web. Participating in this project fits well in this context of a computer supported collaborative learning environment. Collaborative Learning with or without computers is not a common experience of students at Raayland College. Six classes of the Raayland College have applied collaborative learning supported by WebKnowledge Forum in one or two courses. Each course comprises of six lessons. WebKnowledge Forum is a software program that has been developed by Dr. Marlene Scardamalia and Dr. Carl Bereiter of the Ontario Institute for Studies in Education at the University of Toronto in succession to the Compu...,10.1.1.1.1630,?,?
Business Process Modeling towards Data Quality Assurance -- An Organizational . . . , n.n.,?,Data is produced and consumed everyday by information systems and its inherent quality is a fundamental aspect to operational and support business activities. However inadequate data quality often causes severe economic and social losses in the organizational context. The problem addressed in this paper is how to assure data quality both syntactically and semantically at information entity level. An information entity is a model representation of a real world business entity. To address this problem we have taken an organizational engineering approach consisting in using a business process-modeling pattern for describing at a high level of abstraction how to ensure and validate business object data. The pattern defines a conceptual data quality model with specific quality attributes. We use object-oriented concepts to take advantage of concepts such as inheritance and traceability. The concepts and notation we use are an extension to the Unified Modeling Language. A case study is detailed exemplifying the use of the proposed concepts.,10.1.1.1.1631,Data Quality Business Processes Object-Oriented Modeling UML,?
Two Ingredients for My Dinner with R2D2: Integration And Adjustable Autonomy,Dennis Perzanowski Alan C. Schultz Elaine Marsh William Adams,2000,While the tone of this paper is informal and tongue-incheek  we believe we raise two important issues in robotics  and multi-modal interface research namely how crucial  integration of multiple modes of communication are for  adjustable autonomy which in turn is crucial for having  dinner with R2D2. Furthermore we discuss how our multimodal  interface to autonomous robots addresses these issues  by tracking goals allowing for both natural and mechanical  modes of input and how our robotic system adjusts itself to  ensure that goals are achieved despite interruptions.,10.1.1.1.1632,?,AAAI Press
Human effectiveness issues in simulated . . . ,Sasanka V. Prabhala Jennie J. Gallimore S. Narayanan,2003,?,10.1.1.1.1633,?,?
Towards Utility-based Selection of Architecture-Modelling Concepts,H. A. Proper A. A. Verrijn-stuart  S.J.B.A. Hoppenbrouwers,2004,In this paper we are concerned with the principles underlying the utility of  modelling concepts in particular in the context of architecture-modelling. Firstly some  basic concepts are discussed in particular the relation between information language and  modelling. Our primary area of application is the modelling of enterprise architectures and  information system architectures where the selection of concepts used to model di#erent  aspects very much depends on the specific concerns that need to be addressed. The approach  is illustrated by a brief review of the relevant aspects of two existing frameworks for modelling  of (software intensive) information systems and their architectures.,10.1.1.1.1634,?,Australian Computer Society
Very Fast Simulated Re-Annealing,A L. Ingber Lester Ingber,1989,This paper contributes to this methodology by presenting an improvement over previous algorithms. Sections II and III give a short outline of previous Boltzmann annealing (BA) and fast Cauchy fast annealing (FA) algorithms. Section IV presents the new very fast algorithm. Section V enhances this algorithm with a re-annealing modification found to be extremely useful for multi-dimensional parameter-spaces. This method will be referred to here as very fast reannealing (VFR),10.1.1.1.1635,?,?
Web-Scale Information Extraction in KnowItAll,Oren Etzioni Michael Cafarella  Doug Downey  Stanley Kok  Ana-Maria Popescu  Tal Shaked Stephen Soderland Daniel S. Weld Alexander Yates,2004,Manually querying search engines in order to accumulate a large body of factual information is a tedious error-prone process of piecemeal search. Search engines retrieve and rank potentially relevant documents for human perusal but do not extract facts assess confidence or fuse information from multiple documents. This paper introduces KNOWITALL a system that aims to automate the tedious process of extracting large collections of facts from the web in an autonomous domain-independent and scalable manner.,10.1.1.1.1636,Mutual Information Search,?
Upper Bounds for American Option Prices using Regression with Martingale Basis Functions,N. P. Firth,2004,High dimensional American options have no analytic solution and are di#cult to  price numerically. Progress has been made in using Monte Carlo simulation to give both lower and  upper bounds on the price. Building on an idea of Glasserman and Yu we investigate the utility  of martingale basis functions in regression based approximation methods. Regression methods are  known to give lower bounds easily however upper bounds are usually computationally expensive.,10.1.1.1.1638,?,?
T h e E p h e m e r i s T h e E p h e m e r i s,Focus And Books,2001,orting life. Do not extinguish that element do not corrupt it learn that it is divine and do not substitute wretched scholastic feuds for the voice of nature. ---Essay on Tolerance Voltaire (1763).  We do not live very long. By the time a man has lived 20 years he may have begun to learn some of what was done in previous centuries. By the time a man has lived 30 years he may have begun to do something himself which was not done before. Yet by the time a man has lived 40 years he begins to doubt whether any of what was done before including his own work is of any real value!  If we lived much longer say for 100 or 200 years in good health some people would continue to learn and think and do original things all through their lifetimes. Those long-lived men and women would then go far beyond us in their thinking and knowledge. Indeed the simple-minded ideas which we follow in our philosophy and science and religion today might look meager and infantile to such superior bein,10.1.1.1.1639,?,?
Experiences with a Formal Method for Design and,Automatic Checking Of Ro Campi Eliseo Martinez Pierluigi San Pietro,2004,This paper addresses our experience in using and developing the VEG (Visual Event Grammars) toolkit for the formal specification verification design and implementation of graphical user interfaces,10.1.1.1.1640,?,?
Optimizing Search Strategies in k-d Trees,Neal Sample Matthew Haines  Mark Arnold Timothy Purcell,2001,K-d trees have been widely studied yet their complete advantages are often not realized due to ineffective search implementations and degrading performance in high dimensional spaces. We outline an effective search algorithm for k-d trees that combines an optimal depth-first branch and bound (DFBB) strategy with a unique method for path ordering and pruning. This technique was developed for improving nearest neighbor (NN) search but has also proven effective for k-NN and approximate k-NN queries.,10.1.1.1.1641,?,?
Intelligent Web Servers as Agents,Mauro Gaspari Nicola Dragoni Davide Guidi,2004,Software agents have been recognized as one of the main building blocks of the emerging infrastructure for the Semantic Web but their relationship with more standard components such as Web servers and clients is still not clear. At the server side a possible role for agents is to enhance the capabilities of servers using their intelligence to provide more complex services and behaviors. In this paper we explore the role of agents at the server side presenting an Open Service Architecture (OSA) which extends the centralized Internet Reasoning System (IRS-II) to a distributed scenario. The architecture uses a distributed facilitation protocol which integrates Web Services with agent communication languages. Finally we present an implementation which extends Tomcat with these features.,10.1.1.1.1642,?,?
ACKNOWLEDGMENTS,John Kerr Ganesh Pangare Vasudha Lokur Pangare P. J. George Shashi Kolavalli G. B. Singh Dayanatha Jha Numerous Investigators,?,Indias semi-arid tropical (SAT) region is characterized by seasonally concentrated rainfall low agricultural productivity degraded natural resources and substantial human poverty. The green revolution that transformed agriculture elsewhere in India had little impact on rainfed agriculture in the SAT. In the 1980s and 1990s agricultural scientists and planners aimed to promote rainfed agricultural development through watershed development. A watershed is an area from which all water drains to a common point making it an attractive unit for technical efforts to manage water and soil resources for production and conservation. Watershed projects are complicated however by the fact that watershed boundaries rarely correspond to human-defined boundaries. Also watershed projects often distribute costs and benefits unevenly with costs incurred disproportionately upstream typically among poorer residents and benefits realized disproportionately downstream where irrigation is concentrated and the wealthiest farmers own most of the land. Watershed projects take a wide variety of strategies ranging from those that are more technocratic to those that pay more attention to the social organization of watersheds. By the mid-1990s annual expenditure on watershed development in India approached $500 million but there was relatively little information available on the success of different project approaches. This study addresses three main research questions: 1) What projects are most successful in promoting the objectives of raising agricultural productivity improving natural resource management and reducing poverty? 2) What approaches enable them to succeed? 3) What nonproject factors also contribute to achieving these objectives? The major hypotheses are that participat...,10.1.1.1.1643,?,?
Controlled Fabrication System of Fabry-Perot Optical Fiber Sensors,Brian D. Woerner Wei Huo Wei Huo Anbo Wang Chairman,2000,i  Controlled Fabrication System of Fabry-Perot Optical Fiber Sensors  Wei Huo  The Bradley Department of Electrical and Computer Engineering Virginia Tech  (Abstract)  The use of optical fiber sensors is increasing widely in industry civil medicine defense and research. Among different categories of these sensors is the Extrinsic Fabry-Perot interferometer (EFPI) sensor which is inherently simple and requires only modest amount of interface electronics. These advantages make it suitable for many practical applications. Investigating a cost-effective reliable and repeatable method for optical fiber sensor fabrication is challenging work. In this thesis a system for controlled fabrication of FabryPerot optical fiber sensors is developed and presented as the first attempt for the long-term goal of automated EFPI sensor fabrication. The sensor fabrication control system presented here implements a real-time control of a carbon dioxide (CO 2 ) laser as sensor bonding power an optical fiber white light interferometric subsystem for real-time monitoring and measurement of the air gap separation in the Fabry-Perot sensor probe and real-time control of a piezoelectric (PZT) motion subsystem for sensor alignment. The design of optoelectronic hardware and computer software is included. A large number of sensors are fabricated using this system and are tested under high temperature and high pressure. This system as a prototype system shows the potential in automated sensor fabrication. Acknowledgements ii  Acknowledgements First and foremost I would like to thank Dr. Anbo Wang my advisor and graduate committee chair for his thoughtful guidance and constant encouragement and for giving me the opportunity to work at Photonics Lab as his graduate student. I am extremely gr...,10.1.1.1.1644,Acknowledgements Acknowledgements First and foremost I would like to thank Dr. Anbo Wang my advisor and graduate committee,?
Hydrogen Wishes,Winslow Burleson  Paul Nemirovsky  Dan Overholt,?,Hydrogen Wishes presented at MITs Center for Advanced Visual Studies explores the themes of wishes and peace. It dramatizes the intimacy and power of transforming ones breath and vocalized wishes into a floating sphere a bubble charged with hydrogen. The floating bubble represents transitory anticipation as a wish is sent on its trajectory toward fulfillment. Light heat sensors microphones projected imagery hydrogen and ordinary soap bubbles come together in this exploration of human aspiration. As in our lives many wishes escape but many others are catalyzed by the heat of the candle and become ethereal. The fulfilled wishes then become living artifacts within projected photographs of Earth cities as seen from outer space.,10.1.1.1.1645,?,?
Courage to Capital?,Model Of The Mark Carlson Galina Hale,?,With the rise of international bond markets in the 1990s the role of sovereign credit ratings  has become increasingly important. In the aftermath of Asian Crises a series of empirical studies  on the e#ects of sovereign ratings appeared. The theoretical literature on the topic however  remains rather scarce. We propose a model of rating agencies that is an application of global  game theory in which heterogeneous investors act strategically. The model is consistent with  the main findings by the empirical literature. In particular it is able to explain the independent  e#ect of sovereign ratings on the cost of debt and the failure of rating agencies to predict crises.,10.1.1.1.1646,Key words credit rating rating agency sovereign debt global game,?
An Efficient Method for . . . ,Wei Biao Wu et al.,2002,An efficient methodology for simulating paths of fractional stable motion is presented. The proposed approach is based on invariance principles for linear processes. A detailed analysis of the error terms involved is given and the performance of the method is assessed through an extensive simulation study.,10.1.1.1.1647,?,?
Bounded Rationality :: Bounded Models,Jocelyn Smith University,?,In economics and game theory agents are assumed to follow  a model of perfect rationality. This model of rationality  assumes that the rational agent knows all and will take  the action that maximizes her utility. We can find evidence  in the psychology and economics literature as well as in our  own lives that shows human beings do not satisfy this definition  of rationality. Thus there are many who look to study  some notion of bounded rationality. Unfortunately models  of bounded rationality suffer from the exact phenomena that  they attempt to explain. Specifically models of bounded rationality  are bounded. Understanding the limits of various  rationality models will make clearer their contribution and  place in the overall picture of rationality.,10.1.1.1.1648,?,?
An Efficient Approach to Decompose the Multidimensional Assignment Problem,H. W. de Waard Agostino Capponi,?,The primary contribution of this paper is the introduction of a new method to reduce significantly the computation time necessary to solve the multidimensional assignment (MDA) problem. In the first part of the track oriented method clusters are formed to reduce the amount of computation time necessary for correlation. For each formed target tree a mean track is formed. The different mean tracks are used to determine independent components. Each independent component corresponds with a cluster. In the second part of the method the original MDA problem is decomposed in smaller independent MDA problems using a root track label for each target tree.,10.1.1.1.1650,Multiple target tracking data-association MDA,?
Soft Error and Energy Consumption Interactions: A Data Cache Perspective,Lin Li  Vijay Degalahal N. Vijaykrishnan  Mahmut Kandemir Mahmut K Mary Jane Irwin,2004,Energy-e#ciency and reliability are two major design constraints influencing next generation system designs. In this work we focus on the interaction between power consumption and reliability considering the on-chip data caches. First  we investigate the impact of two commonly used architecturallevel  leakage reduction approaches on the data reliability. Our results indicate that the leakage optimization techniques can have very di#erent reliability behavior as compared to an original cache with no leakage optimizations. Next we investigate on providing data reliability in an energy-e#cient fashion in the presence of soft-errors. In contrast to current commercial caches that treat and protect all data using the same error detection/correction mechanism we present an adaptive error coding scheme that treats dirty and clean data cache blocks di#erently. Furthermore we present an early-write-back scheme that enhances the ability to use a less powerful error protection scheme for a longer time without sacrificing reliability. Experimental results show that proposed schemes when used in conjunction can reduce dynamic energy of error protection components in L1 data cache by 11% on average without impacting the performance or reliability.,10.1.1.1.1651,With shrinking feature sizes the,?
Distribution of Route Requests Using Dominating-Set Neighbor Elimination in an On-demand Routing Protocol,Marc Mosko  J.J. Garcia-Luna-Aceves,2003,We investigate the use of dominating-set neighbor elimination as an integral part of the distribution of route requests using the Ad hoc On-demand Distance Vector (AODV) protocol as an example of on-demand routing protocols. We use detailed simulations to show that simply applying dominant pruning (DP) to the distribution of route requests in AODV results in pruning too many route requests in the presence of mobility and cross-traffic. Accordingly we introduce several heuristics to compensate the effects of DP and show that the resulting AODV with Dominating Set heuristics (AODV-DS) has comparable or better delivery ratio network load and packet latency than the conventional AODV. AODV-DS exhibits over 70% savings on RREQ traffic than conventional AODV and in some situations AODV-DS may have a lower control overhead using Hello packets than conventional AODV without Hellos.,10.1.1.1.1652,?,?
A note by Zaman Akil introduced by Jean-Claude Pecker,Collge De France A Note Zaman Akil Introduced Jean-claude Pecker,2001,this paper. On January 2 1985 Zaman Akil sent the Academy of Sciences a short summary of a longer work. At his request the Perpetual Secretary of the Academy Prof. Paul Germain sent the letter to several members of the Academy including myself. I was the only one who agreed to discuss it with the author. His strange result was dismissed a priori by my colleagues as being a purely spurious relation without justification and which could not be understood since Akil equated a dimensionless quantity to a physical quantity of dimensions L        . A long correspondence then ensued between Mr. Akil and myself notwithstanding the difficulties created by the fact that Mr. Akil divides his time between London and Kuwait. This correspondence resulted in the paper published below (which was submitted to the Academy in 1988-1989) together with my note to the reader in defence of Akils peculiar results,10.1.1.1.1654,?,?
Apa: An Object Oriented System For Automatic Prosodic Analysis,Massimo Petrillo Massimo Petrillo Prof Giulio Iannello Prof Luigi P. Cordella Dott Francesco Cutugno,2004,Prosody is one of the challenges for experts of synthesis and recognition of the speech will be involved in the next years. Today?s speech synthesis systems are able to achieve better performancesthan older systems but the produced speech do not appear as natural as human voice. Those systems are already able to synthesize speech almost perfect on the segmental point of view: most of the artefact of former synthesizer are not present anymore. Further improvements can only come from a better implementation of prosody in future system. New systems have to be able to take under control intonation tempo and loudness of voice in order to obtain the most natural speech. Also automatic speech recognition systems make a poor use of prosodic features. Speaker independency and noise robustness are not the only challenge of future recognition systems. Further improvement can derive from a better processing of prosody: today?s systems require too much effort from the user to keep tempo and loudness constant. Those systems are thus not able to deal with spontaneous speech. In this work some prosodic processing tools will be shown. An application of these tools will be the extraction on prosodic features to be used as input in automatic recognition and the automatic prosodic labelling of corpora for speech synthesis purpose. In the first chapter of this thesis a very fast introduction to prosody will be given the most important similar systems described in literature will be shown and motivations for this work will be discussed. The second chapter will show original algorithms for prosodic analysis developed by the author. Most of the routines used in this work crucially rely on the proper choice of a number of parameter. While in many other similar works they are set empirically in the third chapter some tools are shown to effectively tune parameter. The problem is essentially reduced to a minimization of an n-variable function. Processing time of these tools will be reduced by using distributed computing. The fourth chapter will show the architecture of the proposed system it is essentially a library of classes able to model various prosodic entities. In the fifth chapter comparison between automatic and human analysis will be shown. In the same chapter parameter tuning tools will be compared and benefits from distributed computing will be also shown.,10.1.1.1.1656,?,?
Minimum Delay Spread TEQ Design in Multicarrier Systems,Roberto Lopez-Valcarce,2004,Recently a time-domain equalizer (TEQ) design for multicarrier-based systems has been proposed which claims to minimize the delay spread of the overall channel impulse response. We show that this is true only in an approximate sense depending on the channel considered the loss in delay spread with respect to the true minimum can be significant. An iterative algorithm to find this minimum is presented whose computational complexity is similar to that of standard TEQ designs like the MSSNR approach of Melsa et al. It is observed that the method iteratively and automatically seeks the time reference yielding best performance an advantage with respect to the MSSNR design which must compute several TEQs over a range of time references in order to select the optimum.,10.1.1.1.1657,?,?
Computationally Intelligent Methods for Mining 3D Medical Images Despina,Despina Kontos Vasileios Megalooikonomou Filia Makedon,2004,We present novel intelligent tools for mining 3D medical images. We  focus on detecting discriminative Regions of Interest (ROIs) and mining associations  between their spatial distribution and other clinical assessment. To  identify these highly informative regions we propose utilizing statistical tests to  selectively partition the 3D space into a number of hyper-rectangles. We apply  quantitative characterization techniques to extract k-dimensional signatures  from the highly discriminative ROIs. Finally we use neural networks for classification.,10.1.1.1.1658,data mining diagnosis information extraction knowledge discovery,Springer-Verlag
Imaging Below the Diffraction Limit: A Statistical Analysis,Morteza Shahram Peyman Milanfar,2004,The present paper is concerned with the statistical analysis of the resolution limit in a so-called diffraction-limited imaging system. The canonical case study is that of incoherent imaging of two closely-spaced sources of possibly unequal brightness. The objective is to study how far beyond the classical Rayleigh limit of resolution one can reach at a given signal to noise ratio. The analysis uses tools from statistical detection and estimation theory. Specifically we will derive explicit relationships between the minimum detectable distance between two closely-spaced point sources imaged incoherently at a given SNR. For completeness asymptotic performance analysis for the estimation of the unknown parameters is carried out using the Cramr-Rao bound. To gain maximum intuition the analysis is carried out in one dimension but can be well extended to the two-dimensional case and to more practical models.,10.1.1.1.1659,?,?
Female dominance and Social Structure In Alaotran gentle Lemurs,P.O. WAEBER  C.K. HEMELRIJK ,2003,?,10.1.1.1.1660,?,?
Loom2 - Intuitively Visualizing Usenet,Judith Donath Hyun-yeul Lee  danah boyd Jonathan Goler,2001,We are currently developing a system for visualizing Usenet newsgroups at a variety of scales. A macro/landscape view depicts many newsgroups and the relationships among them a medium view depicts the  interactions within a single group a close-up view depicts the individual in the context of the conversational situation.,10.1.1.1.1661,?,?
Circular Filters for Target Tracking in 3D,Dirk Tenne Tarunraj Singh,2004,This paper describes the development of a three dimensional geometrically constrained target tracker. This tracker combines the predictions of a circular prediction algorithm and a constant velocity filter by utilizing the Covariance Intersection. This combined prediction can be updated with the consequent measurement using the linear estimator. The proposed technique is illustrated on a benchmark trajectory including circular and straight line maneuvers.,10.1.1.1.1662,Circular filter tracking three dimensions hybrid,?
Intra-Operative 3D Ultrasound Augmentation,Stephen R. Aylward Julien Jomier  Jean-Philippe Guyon Susan Weeks,2002,We introduce an automated and accurate system for registering pre-operative 3D MR and CT images with intraoperative 3D ultrasound images based on the vessels visible in both. The clinical goal is to guide the radio-frequency ablation (RFA) of liver lesions using percutaneous ultrasound even when the lesions are not directly visible using ultrasound. The lesions locations and desired RFA sites are indicated on pre-operative images and those markings are made to appear within the intra-operative 3D ultrasound images.,10.1.1.1.1663,?,?
Modelling the Effects of Input Correlation in Iterative Software,A. Bondavalli S. Chiaradonna F. Di Giandomenico S. La Torre,?,This paper deals with the dependability evaluation of software programs of iterative  nature. In this work we define a model that is able to account for both dependencies  between input values of successive iterations and the effects of sequences of  consecutive software failures on the reliability of the controlled system. Differently  from previously proposed models some effort is devoted to address the problem  of how to get accurate estimates for the basic parameters. A model is thus proposed  that requiring the designers or users to provide information usually obtainable by  experimental techniques e.g. testing is more useful and more generally applicable. Then a ,10.1.1.1.1665,?,?
Photonic Data Services: Integrating Data Network and Path Services to Support Next Generation Data Mining Applications,Robert L. Grossman Yunhong Gu Dave Hanley Xinwei Hong Jorge Levera  Marco Mazzucco Dave Lillethun Joe Mambretti Jeremy Weinberger Future Directions H. Kargupta A. Joshi Y. Yesha Aaai Press,2004,We describe an architecture for next generation distributed data mining  systems which integrates data services to facilitate remote data analysis  and distributed data mining network protocol services for high performance  data transport and path services for optical paths. We also  present experimental evidence using geoscience data that this architecture  scales the remote analysis of Gigabyte size data sets over long haul  high performance networks.,10.1.1.1.1666,?,?
Adaptive Offloading Inference for Delivering Applications in Pervasive Computing Environments,Xiaohui Gu Klara Nahrstedt Alan Messer Dejan Milojicic Ira Greenberg Ira Greenberg Hewlett Packard Laboratories,2003,Pervasive computing allows a user to access an application on heterogeneous devices continuously and consistently. However it is challenging to deliver complex applications on resource-constrained mobile devices such as cell phones and PDAs. Different approaches such as application-based or system-based adaptations have been proposed to address the problem. However existing solutions often require degrading application fidelity. We believe that this problem can be overcome by dynamically partitioning the application and offloading part of the application execution to a powerful nearby surrogate. This will enable pervasive application delivery to be realized without significant fidelity degradation or expensive application rewriting. Because pervasive computing environments are highly dynamic the runtime offloading system needs to adapt to both application execution patterns and resource fluctuations. Using the Fuzzy Control model we have developed an offloading inference engine to adaptively solve two key decision-making problems during runtime offloading: (1) timely triggering of adaptive offloading and (2) intelligent selection of an application partitioning policy. Extensive trace-driven evaluations show the effectiveness of the offloading inference engine.,10.1.1.1.1667,Dejan Milojicic is affiliated with Hewlett Packard Laboratories Palo Alto CA. Email dejan @ hpl.hp.com,?
Automatic Classification of Nasals and Semivowels,Tarun Pruthi Carol Automatic Classification Of Nasals,2003,this paper we discuss acoustic parameters and a classifier we developed to distinguish between nasals (/m/ /n/ /ng/) and semivowels (/r/ /l/ /w/ /y/). Based on the literature and our own acoustic studies we use an onset/offset measure to capture the consonantal nature of nasals and an energy ratio a low spectral peak measure and a formant density measure to capture the nasal murmur,10.1.1.1.1668,?,?
An Investigation of Inter-Domain Control Aggregation Procedures,Rute Sofia  Roch Guérin  Pedro Veiga Roch Guérin Pedro Veiga,2002,Current Quality of Service models such as those embodied in the Differentiated Services proposal rely on data path aggregation to achieve scalability. Data path aggregation bundles into a single aggregate multiple flows with the same quality requirements hence decreasing the amount of state to be kept. A similar scalability concern exists on the control path where the state required to account for individual reservations needs to be minimized. There have been several proposals aimed at control path aggregation and the goal of this paper is to expand on these works in an attempt to gain a better understanding of the various parameters that influence the efficiency of different approaches. In particular we focus on inter-domain control aggregation and compare an Autonomous System (AS) sink-tree based approach with two examples of a shared AS segment based approach in terms of the amount of state kept both per AS and per edge router. Our main contributions are in providing a greater understanding into the design of efficient control path aggregation methods.,10.1.1.1.1669,?,?
Statistics and Causal Inference: A Review,Judea Pearl,2003,This paper aims at assisting empirical researchers benefit from recent advances in  causal inference. The paper stresses the paradigmatic shifts that must be undertaken  in moving from traditional statistical analysis to causal analysis of multivariate  data. Special emphasis is placed on the assumptions that underly all causal inferences  the languages used in formulating those assumptions and the conditional  nature of causal claims inferred from nonexperimental studies. These emphases  are illustrated through a brief survey of recent results including the control of  confounding the assessment of causal effects the interpretation of counterfactuals  and a symbiosis between counterfactual and graphical methods of analysis.,10.1.1.1.1670,Key Words Structural equation models confounding noncompliance graphical,?
Identification of PWARX Hybrid Models with Unknown and Possibly Different Orders,René Vidal,2004,We consider the problem of identifying the orders and the model parameters of PWARX hybrid models from noiseless input/output data. We cast the identification problem in an algebraic geometric framework in which the number of discrete states corresponds to the degree of a multivariate polynomial p and the orders and the model parameters are encoded on the factors of p. We derive a rank constraint on the input/output data from which one can estimate the coefficients of p. Given p we show that one can estimate the orders and the parameters of each ARX model from the derivatives of p at a collection of regressors that minimize a certain objective function. Our solution does not require previous knowledge about the orders of the ARX models (only an upper bound is needed) nor does it constraint the orders to be equal. Also the switching mechanism can be arbitrary hence the switches need not be separated by a minimum dwell time. We illustrate our approach with an algebraic example of a switching circuit and with simulation results in the presence of noisy data.,10.1.1.1.1671,?,?
Using ART1 Neural Networks to Determine,Clustering Tendency Louis Louis Massey,?,this paper is applicable to binary data inputs only investigation of the non-binary ART Pseudo-Random Vs Random  0  2  4  6  8  10  12  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1    pseudo random  Random 1  Random Vs Non-Random Data  0  2  4  6  8  10  12  0.002  0.1 0.3 0.5 0.7 0.9    Non-Random  random  Fig. 2a. Baseline pseudo-random data reaches maximal vigilance faster than nonrandom data. This indicates that clustering tendency is not caused by chance clustering Fig. 2b. True random data reach maximal vigilance faster than the baseline which is an indication that their clustering tendency is caused by mere chance,10.1.1.1.1672,?,?
Efficient Almost Wait-free Parallel Accessible Dynamic Hashtables,H. Gao     J. F. Groote W. H. Hesselink,2004,In multiprogrammed systems synchronization often turns out to be a performance bottleneck and the source of poor fault-tolerance. Wait-free and lock-free algorithms can do without locking mechanisms and therefore do not su#er from these problems. We present an e#cient almost wait-free algorithm for parallel accessible hashtables which promises more robust performance and reliability than conventional lock-based implementations. Our solution is as e#cient as sequential hashtables. It can easily be implemented using C-like languages and requires on average only constant time for insertion deletion or accessing of elements. Apart from that our new algorithm allows the hashtables to grow and shrink dynamically when needed. A true problem of lock-free algorithms is that they are hard to design correctly even when apparently straightforward. Ensuring the correctness of the design at the earliest possible stage is a major challenge in any responsible system development. Our algorithm contains 81 atomic statements. In view of the complexity of the algorithm and its correctness properties we turned to the interactive theorem prover PVS for mechanical support. We employ standard deductive verification techniques to prove around 200 invariance properties of our almost wait-free algorithm and describe how this is achieved using the theorem prover PVS.,10.1.1.1.1673,?,?
PAST: A large-scale persistent peer-to-peer storage utility,Peter Druschel  Antony Rowstron,2001,This paper sketches the design of PAST a large-scale Internet-based global storage utility that provides scalability high availability persistence and security. PAST is a peer-to-peer Internet application and is entirely selforganizing. PAST nodes serve as access points for clients participate in the routing of client requests and contribute storage to the system. Nodes are not trusted they may join the system at any time and may silently leave the system without warning. Yet the system is able to provide strong assurances efficient storage access load balancing and scalability.,10.1.1.1.1674,?,?
Selective Bitplane Encryption for Secure Transmission of Image Data in Mobile Environments,Martina Podesser Hans-peter Schmidt  Andreas Uhl,2002,We propose selective bitplane encryption to provide secure image transmission in low power mobile environments. Two types of ciphertext only attacks against this scheme are discussed and we use the corresponding results to derive conditions for a secure use of this technique.,10.1.1.1.1676,?,?
Hop-by-Hop Routing Algorithms for Premium-Class Traffic in DiffServ Networks,Jun Wang  Klara Nahrstedt,2002,Bear the provision of Quality of Service (QoS) in the Internet Differentiated Service (DiffServ) model has been  proposed as a cost-effective solution. Traffic is classified into several service classes with different priorities. The premium class traffic has the highest one. The routing algorithm used by the premium class service has significant effects not only on its own traffic but on all other classes of traffic as well. The shortest hopcount routing scheme used in current Internet turns out to be no longer sufficient in DiffServ networks. Based on,10.1.1.1.1677,?,?
Terrain Modelling Based on Contours and Slopes,Christopher Gold  Maciej Dakowicz,2003,Good quality terrain models are becoming more and more important as applications such as runoff modelling are being developed that demand better surface orientation information than is available from traditional interpolation techniques. A consequence is that poor-quality elevation grids must be massaged before they provide useable runoff models. This paper describes improved methods for extracting good quality terrain models from topographic contour maps which despite modern techniques are still the most available form of elevation information. Recent work on the automatic reconstruction of curves from point samples and the generation of medial axis transforms (skeletons) has greatly helped in the visualization of the relationships between sets of boundaries and families of curves. The insertion of skeleton points guarantees the elimination of all flat triangles. Additional assumptions about the local uniformity of slopes give us enough information to assign elevation values to these skeleton points. Various interpolation techniques were compared using visualization of the enriched contour data. Examination of the quality and consistency of the resulting maps indicates the required properties of the interpolation method in order to produce terrain models with valid slopes. The result provides us with a surprisingly realistic model of the surface - that is one that conforms well to our subjective interpretation of what a real landscape should look like.,10.1.1.1.1679,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,Given uncertainty in the input model and parameters of a simulation study the goal of the simulation study often becomes the estimation of a conditional expectation. The conditional expectation is expected performance conditional on the selected model and parameters. The distribution of this conditional expectation describes precisely and concisely the impact of input uncertainty on performance prediction. In this paper we estimate the density of a conditional expectation using ideas from the field of kernel density estimation. We present a result on asymptotically optimal rates of convergence and examine a number of numerical examples.,10.1.1.1.1680,?,?
Using Narrowing Approximations to Optimize Equational Logic Programs,M. Alpuente M. Falaschi M. J. Ramis G. Vidal,1993,Solving equations in equational theories is a relevant programming paradigm which  integrates logic and equational programming into one unified framework. Efficient methods  based on narrowing strategies to solve systems of equations have been devised. In  this paper we formulate a narrowing-based equation solving calculus which makes use of  a top-down abstract interpretation strategy to control the branching of the search tree. We define,10.1.1.1.1681,Abstract interpretation equational logic programming term rewriting systems,Springer-Verlag
Cross Document Ontology based Information Extraction for Multimedia Retrieval,Dennis Reidsma Jan Kuper Thierry Declerck  Horacio Saggion Hamish Cunningham,2003,This paper describes the MUMIS project which applies ontology  based Information Extraction to improve the results of Information  Retrieval in multimedia archives. It makes use of a domain specific  ontology multilingual lexicons and reasoning algorithms to automatically  create a semantic annotation of sources. The innovative aspect is  the use of a cross document merging algorithm that combines the information  extracted from separate textual sources to produce an integrated  more complete annotation of the material. This merging and unification  process uses ontology based reasoning and scenarios which are extracted  automatically from annotated sources.,10.1.1.1.1682,vector models site popularity,?
Resolving Implementation Convolution in Middleware Systems,Charles Zhang Hans-arno Jacobsen,2004,Middleware provides simplicity and uniformity for the development of distributed applications. However the modularity of the architecture of middleware is starting to disintegrate and to become complicated due to the interaction of too many orthogonal concerns imposed from a wide range of application requirements. This is not due to bad design but rather due to the limitations of the conventional architectural decomposition methodologies. We introduce the principles of horizontal decomposition (HD) to address this problem with a mixed-paradigm middleware architecture. HD provides guidance for the use of conventional decomposition methods to implement the core functionalities of middleware and the use of aspect orientation to address its orthogonal properties. Our evaluation of the horizontal decomposition principles focuses on refactoring major middleware functionalities into aspects in order to modularize and isolate them from the core architecture. New versions of the middleware platform can be created through combining the core and the flexible selection of middleware aspects such as IDL data types the oneway invocation style the dynamic messaging style and additional character encoding schemes. As a result the primary functionality of the middleware is supported with a much simpler architecture and enhanced performance. Moreover customization and configuration of the middleware for a wide-range of requirements becomes possible.,10.1.1.1.1684,?,?
Decentralized Algorithms for Sensor Registration,Valentino Crespi  George Cybenko,2003,In this paper   we investigate a problem arising in decentralized registration of sensors. The application we consider involves a heterogeneous collection of sensors - some sensors have on-board Global Positioning System (GPS) capabilities while others do not. All sensors have wireless communications capability but the wireless communication has limited effective range. Sensors can communicate only with other sensors that are within a fixed distance of each other. Sensors with GPS capability are self-registering. Sensors without GPS capability are less expensive and smaller but they must compute estimates of their location using estimates of the distances between themselves and other sensors within their radio range. GPS-less sensors may be several radio hops away from GPS-capable sensors so registration must be inferred transitively. Our approach to solving this registration problem involves minimizing a global potential or penalty function by using only local information determined by the radio range available to each sensor. The algorithm we derive is a special case of a more general methodology we have developed called Emergence Engineering.,10.1.1.1.1685,?,?
Working with Licensing Constraints,Jonathan Kaye Guangdong Jonathan Kaye,?,this paper I will discuss the central role of licensing constraints (henceforth LCs) in phonological systems and how they may be viewed as one of the principal engines of phonological events. LCs were originally designed to explain restrictions on the combinatorial properties of elements. Given a theory of phonological expressions (to be given below) the underlying assumption is that any syntactically well-formed combination of elements should be present in a phonological system unless explicitly excluded. Since as far as we know no language expresses the full range of theoretically possible combinations of elements LCs were proposed as language-specific constraints on such possibilities. A subset of a small set of possible LCs is sufficient to define the lexical set of say nuclear expressions of a given linguistic system. Recent work has shown that the usefulness of LCs extend far beyond their original raison dtre. In particular it is a pleasure to recognise the 2 seminal articles of Monik Charette  Asli Gksel (Charette and Gksel 1996) and (Charette and Gksel 1998) which have provided the leadership in this field and the inspiration for this present work. I will briefly review part of their work in a later section. In the following section I give a succinct summary of the element theory of phonological representations,10.1.1.1.1686,?,?
Why They Want to Teach: Factors Influencing Students to Become Technology Education Teachers,Michael D. Wright Rodney L. Custer,?,Introduction  Identifying and recruiting prospective technology education teachers has been an ongoing concern for more than two decades. Considerable research was conducted during the late 1970s and early 1980s relative to teacher recruitment (Craft 1979 Devier 1982). These studies were prompted by declining enrollments in university programs and reported shortages of industrial arts teachers in forty-one states (Miller 1980 Tomlinson 1982 Wright 1985). In some cases this shortage of teachers led to high school programs being closed or cut back the utilization of under-qualified personnel and the abandonment of planned expansion. Simultaneously university programs experienced significant drops in industrial arts teaching majors as students increasingly selected industrial technology or management options over teaching (Devier  Wright 1988). This trend of declining enrollments has continued and has now reached critical proportions (Volk 1997). Current data suggest that a,10.1.1.1.1687,?,?
Toward a Reusable and Generic Security Aspect Library,Minhuan Huang Chunlei Chunlei Wang Lufeng Zhang,?,Security is a good example for Aspect-Oriented Programming but there are few reusable software components at the level of aspects. We introduce an elementary implementation of a reusable and generic aspect library providing security functions. This aspect library is based on AspectJ and common Java security packages and includes typical security mechanisms. We describe the principle architecture and usage of the security aspect library and give a practical example of application in which security has been implemented using the aspects in the library. We also discuss the advantages and disadvantages of aspect library in reusability and generality and the future efforts we will focus on.,10.1.1.1.1688,?,?
Testing Nash-Bargaining Household Models With Time-Series Data,John Hoddinott Christopher Adam,1998,This paper uses a natural experiment in Canadian divorce law reform to discriminate empirically between unitary and Nash-bargained models of the household. Using time-series data from three Canadian provinces it demonstrates that following landmark divorce law reforms in the 1970s---reforms that led to improvements in womens expected settlement upon divorce in Ontario and British Columbia suicide rates for older married women in these provinces registered a sharp decline. Similar declines were not registered for younger unmarried women or men in Ontario and British Columbia nor for older married women in Quebec where the legal basis for divorce did not change. These results are consistent with Nash-bargained models of the household but not with the unitary model. ,10.1.1.1.1689,Acknowledgments.................................................... vii,?
A Linear Programming Formulation for Global Inference in Natural Language Tasks,Dan Roth  Wen-tau Yih,2004,The typical processing paradigm in natural language processing is the pipeline approach where learners are being used at one level their outcomes are being used as features for a second level of predictions and so one. In addition to accumulating errors it is clear that the sequential processing is a crude approximation to a process in which interactions occur across levels and down stream decisions often interact with previous decisions. This work develops a general...,10.1.1.1.1690,?,?
Simulation of Rare Events in Transportation Systems,Lori M. Kaufman Ted C. Giras,2001,Prior to the deployment of any new or replacement component within a transportation system it should be demonstrated that the modified system meets or exceeds the safety requirements of the original system. Since the occurrence of a mishap in such a system is a rare event it is neither cost nor time effective to build and to test a prototype in an actual system prior to deployment. The Axiomatic Safety-Critical Assessment Process (ASCAP) is a simulation methodology that models the complete system and analyzes the effects of equipment changes. By carefully constraining the amount of the overall system state space required for analyses it probabilistically determines the sequence of events that lead to mishaps. ASCAP is applicable to any transportation system that is governed by a well-defined operational environment.,10.1.1.1.1692,?,?
Cryptanalysis of a Pay-as-You-Watch System,Marc Joye,2003,In this paper we exhibit security flaws in MICROCAST payas  -you-watch system. From the sole knowledge of public parameters we  show how any intruder is able to forge a coin and so to freely get access  to the service.,10.1.1.1.1693,?,?
Includes CPF’s suggestions following RAM edits Training the Next Generation of Informaticians: The Impact of ‘BISTI ’ and,Charles P. Friedman Russ B. Altman Perry L. Miller Judy G. Ozbolt Edward H. Shortliffe,?,In 2002-2003 the American College of Medical Informatics (ACMI) undertook a study of the future of informatics training. This project capitalized on the rapidly expanding interest in the role of computation in basic biological research well characterized in the NIH BISTI report. The defining activity of the project was the three-day 2002 Annual Symposium of the College. A committee comprised of the authors of this report subsequently carried out activities including interviews with a broader informatics and biological sciences constituency collation and categorization of observations and generation of recommendations. The committee viewed biomedical informatics as an interdisciplinary field combining basic informational and computational sciences with application domains including health care biological research and education. Consequently effective training in informatics viewed from a national perspective should encompass four key elements: 1) curricula that integrate experiences in the computational sciences and application domains rather than just concatenating them 2) diversity among trainees with individualized interdisciplinary cross-training allowing each trainee to develop key competencies that he/she does not initially possess 3) direct immersion in research and development activities and 4) exposure across the wide range of basic informational and computational sciences. Informatics training programs that implement these features irrespective of their funding sources will meet and exceed the challenges raised by the BISTI report and optimally prepare their trainees for careers in a field that continues to evolve. ,10.1.1.1.1694,?,?
Models for Character Animation,Gordon Collins And Gordon Collins Adrian Hilton,2001,We present a review of methods for the construction and deformation of  character models. We consider both state of the art research and common  practice. In particular we review applications data capture methods manual  model construction polygonal parametric and implicit surface representations  basic geometric deformations free form deformations subdivision  surfaces displacement map schemes and physical deformation.,10.1.1.1.1695,?,?
Configuration Bitstream Compression for Dynamically,Reconfigurable Fpgas Ju Ju Hwa Pan Tulika Mitra Weng-fai Wong,?,Field Programmable Gate Arrays (FPGAs) holds the possibility of dynamic reconfiguration. The key advantages of dynamic reconfiguration are the ability to rapidly adapt to dynamic changes and better utilization of the programmable hardware resources for multiple applications. However with the advent of multi-million gate equivalent FPGAs configuration time is increasingly becoming a concern. High reconfiguration cost can potentially wipe out any gains from dynamic reconfiguration. One solution to alleviate this problem is to exploit the high levels of redundancy in the configuration bitstream by compression. In this paper we propose a novel configuration compression technique that exploits redundancies both within a configurations bitstream as well as between bitstreams of multiple configurations. By maximizing reuse our results show that the proposed technique performs 26.5--75.8% better than the previously proposed techniques. To the best of our knowledge ours is the first work that performs inter-configuration compression.,10.1.1.1.1697,?,?
Scalability of Peer Configuration Management in Partially Reliable and Ad Hoc Networks,Mark Burgess  Geoffrey Canright,?,Current interest in ad hoc and peer-to-peer networking technologies prompts a re-examination of models for configuration management within these frameworks. In the future network management methods may have to scale to millions of nodes within a single organization with complex social constraints. In this paper we discuss whether it is possible to manage the configuration of large numbers of network devices using well-known and no-so-well-known configuration models and we discuss how the special characteristics of ad hoc and peer-to-peer networks are reflected in this problem.,10.1.1.1.1699,Configuration management ad hoc networks peer,?
A Finite-Capacity Beam-Search-Algorithm for . . .,Ilka Habenicht Lars Mönch,2002,In this paper we describe a finite-capacity algorithm that can be used for production scheduling in a semiconductor wafer fabrication facility (wafer fab). The algorithm is a beam-search-type algorithm. We describe the basic features of the algorithm. The implementation of the algorithm is based on the ILOG-Solver libraries. We describe the simulation environment which is used to evaluate the performance of the proposed algorithm. We show some results from computational experiments with the algorithm and the simulation test-bed described.,10.1.1.1.1700,?,?
Simulation in . . . ,Jeremy Staum,2002,This paper presents an overview of the use of simulation algorithms in the field of financial engineering assuming on the part of the reader no familiarity with finance and a modest familiarity with simulation methodology but not its specialist research literature. The focus is on the challenges specific to financial simulations and the approaches that researchers have developed to handle them although the paper does not constitute a comprehensive survey of the research literature. It offers to simulation researchers professionals and students an introduction to an application of increasing significance both within the simulation research community and among financial engineering practitioners. ,10.1.1.1.1701,?,?
Using Influence Diagrams in Software Change Management,Colin J. Burgess Ilesh Dattani Gordon Hughes John H. R. May Kearton Rees,?,?,10.1.1.1.1702,in uence diagrams software change management risk-based modelling,?
Extending Ontology Tree Using NLP Technique,T. Sabrina  A. Rosni  T. Enyakong Pusat Pengajian Sains Komputer Universiti Sains Malaysia Pulau Pinang,?,This paper proposes a method of creating a web document representation using a web ontology concepts instead of `bag-ofwords . However since the web domain has a very small vocabulary we are unable to transform all or most of the keywords of the web document into web ontology concepts. This particular problem is solved by creating an extended part of the web ontology with words obtained from an external linguistics knowledgebase. The promising outcome as the result of Natural Language Processing (NLP) and Information Retrieval (IR) fields being merged together convinces us to create the extended ontology using NLP technique.,10.1.1.1.1703,Web ontology WordNet semantics relationships automatic,?
An Evaluation of the FIDAP Computational Fluid,Dynamics Code For D. A. Jones D. B. Clarke,?,U)   4. AUTHOR(S)   5. CORPORATE AUTHOR     506 Lorimer St   Fishermans Bend Victoria 3207 Australia   6a. DSTO NUMBER   6b. AR NUMBER     6c. TYPE OF REPORT   Technical Report   7. DOCUMENT DATE     8. FILE NUMBER   510/207/1295   9. TASK NUMBER   NAV 00/206   10. TASK SPONSOR   Navy- CANSG   11. NO. OF PAGES     12. NO. OF REFERENCES     ...,10.1.1.1.1704,?,?
Post-Release Analysis of Requirements Selection Quality - An Industrial Case Study,Lena Karlsson Björn Regnell Joachim Karlsson  Stefan Olsson,?,The process of selecting requirements for a release of a  software product is challenging as the decision-making is  based on uncertain predictions of issues such as market  value and development cost. This paper presents a method  aimed at supporting software product development organisations  in the identification of process improvement proposals  to increase requirements selection quality. The  method is based on an in-depth analysis of requirements  selection decision outcomes after the release has been  launched to the market and is in use by customers. The  method is validated in a case study involving real requirements  and industrial requirements engineering experts.,10.1.1.1.1705,?,?
Educational Technology Society 3(4) 2000 ISSN 1436-4522 101,Evaluating Information And Eileen Scanlon Ann Jones Jane Barnard Julie Thompson Judith Calder,2000,In this paper we will describe an approach to evaluating learning technology which we have developed over  the last twenty-five years outline its theoretical background and compare it with other evaluation  frameworks. This has given us a set of working principles from evaluations we have conducted at the Open  University and from the literature which we apply to the conduct of evaluations. These working practices  are summarised in the context interactions and outcomes (CIAO!) model. We describe here how we applied  these principles working practices and models to an evaluation project conducted in Further Education. We  conclude by discussing the implications of these experiences for the future conduct of evaluations.,10.1.1.1.1706,Further and higher education Distance education,?
Automatic Distribution of Java Byte-Code Based on Dependence Analysis,Roxana E. Diaconescu  Lei Wang  Michael Franz,?,One way to relieve resources when executing a program on constrained devices is to migrate parts of it to other machines in a distributed system. Ideally a system can automatically decide where to place parts of a program to satisfy resource constrains (CPU memory bandwidth battery power etc.). We describe a compiler and virtual machine infrastructure as the context for research in automatic program partitioning and optimization for distributed execution. We define program partitioning as the process of decomposing a program into multiple tasks. The main motivation for our design is to enable experimenting with optimizing program execution on resource-constrained devices with respect to memory consumption CPU time battery lifetime and communication.,10.1.1.1.1707,?,?
Speech Acts and Medical Records: The Ontological Nexus,  Lowell Vizenor Barry Smith,2004,?,10.1.1.1.1708,?,?
Bluetooth and Wi-Fi Wireless Protocols: A Survey and a Comparison,E. Ferro Erina Ferro  F. Potortì,2004,Bluetooth and IEEE 802.11 (Wi-Fi) are two communication protocol standards which  define a physical layer and a MAC layer for wireless communications within a short range (from a  few meters up to 100 meters) with low power consumption (from less than 1 mW up to 100 mW).,10.1.1.1.1709,?,?
Light Rather Than Iron Controls,Photosynthate Production And,2004,not found in spite of differences in phytoplankton  species composition: at the Antarctic Polar Front biomass was dominated by a diatom population  of Fragilariopsis kerguelensis whereas smaller cells including chrysophytes were relatively more  abundant in the Antarctic Circumpolar Current beyond the influence of frontal systems. Because  mixing was often in excess of 100 m in the latter region diatom cells may have been unable to fulfil  their characteristically high Fe demand at low average light conditions and thus became co-limited  by both resources. Using a model that describes the    C incorporation the consistency was  shown between the dynamics in the glucan pool in the field experiments and in laboratory  experiments with an Antarctic diatom Chaetoceros brevis. The glucan respiration rate was almost  twice as high during the dark phase as during the light phase which is consistent with the role of  glucan as a reserve supplying energy and carbon skeletons for conti,10.1.1.1.1710,?,?
Mining Short-Rule Covers In Relational Databases,Claudio Carpineto Giovanni Romano,2003,this paper is on IRs. We believe that a more widespread acceptance and utilization of this approach has been hindered so far by a shortage of theoretical and experimental evidence suggesting its utility and overall feasibility for practical data mining. The goal of this research is to contribute to fill this gap,10.1.1.1.1711,?,?
A Wavefront Sensing Method for Synthetic Aperture Sonar Autofocus,Callow Hayes And H. J. Callow M. P. Hayes P. T. Gough,2002,This paper outlines  a new autofocus procedure for improving SAS imagery based on wavefront sensing techniques from  the astronomical imaging field,10.1.1.1.1712,?,?
Automatic Classification of Nasals and Semivowels,Tarun Pruthi Carol Automatic Classification Of Nasals,2003,In this paper we discuss acoustic parameters and a classifier we developed to distinguish between nasals and semivowels. Based on the literature and our own acoustic studies we use an onset/offset measure to capture the consonantal nature of nasals and an energy ratio a low spectral peak measure and a formant density measure to capture the nasal murmur. These acoustic parameters are combined using Support Vector Machine based classifiers. Classification accuracies of 88.6% 94.9% and 85.0% were obtained for prevocalic postvocalic and intervocalic sonorant consonants respectively. The overall classification rate was 92.4% for nasals and 88.1% for semivowels. These results have been obtained for the TIMIT database which was collected from a large number of speakers and contains substantial coarticulatory effects.,10.1.1.1.1713,?,?
Adaptive and Quality Quadrilateral/Hexahedral Meshing from Volumetric Imaging Data,Yongjie Zhang  Chandrajit Bajaj,2006,This paper describes an algorithm to extract adaptive and quality quadrilateral/hexahedral meshes directly from volumetric imaging data. First a bottom-up surface topology preserving octree-based algorithm is applied to select a starting octree level. Then the dual contouring method is used to extract a preliminary uniform quad/hex mesh which is decomposed into finer quads/hexes adaptively without introducing any hanging nodes. The positions of all boundary vertices are recalculated to approximate the boundary surface more accurately. Mesh adaptivity can be controlled by a feature sensitive error function the regions that users are interested in or finite element calculation results. Finally the relaxation based technique is deployed to improve mesh quality. Several demonstration examples are provided from a wide variety of application domains. Some extracted meshes have been extensively used in finite element simulations.,10.1.1.1.1715,quadrilateral/hexahedral mesh topology preservation mesh adaptivity quality mesh,?
An Adaptive Cache Structure for Future High-Performance Systems,Changkyu Kim  Doug Burger Stephen W. Keckler,?,On-chip cache sizes are likely to continue to grow over the next decade as working sets available chip capacity and memory latencies all increase. Traditional cache architectures with fixed sizes and discrete latencies lock one organization down at design time which will provide inferior performance across a range of workloads. In addition expected increases in on-chip communication delays will make the time to retrieve data in a cache a function of the datas physical location. Consequently cache access times will become a continuum of latencies rather than a single one. This non-uniformity will make static organizations particularly limited for single-chip servers in which multiple processors will be different distances from the cache controller. In this paper we propose a set of adaptive high-performance cache design called Non-Uniform Cache Architectures (NUCAs). We extend these physical designs with logical policies that allow important data to migrate closer to the processor within the same cache. We show that these adaptive level-two NUCA designs provide 1.6 times the performance of a Uniform Cache Architecture of any size and that the adaptive NUCA scheme outperforms static NUCA schemes by 9% for multi-megabyte on-chip server caches with large numbers of banks.,10.1.1.1.1716,?,?
Precise Modeling of Design Patterns,Alain Le Guennec Gerson Sunyé Jean-marc Jézéquel,2000,Design Patterns are now widely accepted as a useful concept  for guiding and documenting the design of object-oriented software  systems. Still the UML is ill-equipped for precisely representing design  patterns. It is true that some graphical annotations related to parameterized  collaborations can be drawn on a UML model but even the most  classical GoF patterns such as Observer Composite or Visitor cannot  be modeled precisely this way. We thus propose a minimal set of modifications  to the UML 1.3 meta-model to make it possible to model design  patterns and represent their occurrences in UML opening the way for  some automatic processing of pattern applications within CASE tools.,10.1.1.1.1717,?,Springer Verlag
Comparing Fusors within a Category of Fusors,Steven Thorsen Mark Mark E. Oxley,?,Category Theory is used to describe a category of fusors. The category is formed from a model of a process begining with an event and leading to the final labeling of the event. Although many techniques of fusing information have been developed the inherent relationships among different types of fusion techniques (fusors) have not yet been fully explored. In this paper a foundation of fusion is presented definitions developed and a method of measuring the performance of fusors is given. Functionals on receiver operating characteristic (ROC) curves are developed to form a partial ordering of a set of classifier families. The functional also induces a category of fusion rules. The treatment includes a proof of how to find the Bayes optimal classifier (or Bayes Optimal fusor if available) from a ROC curve.,10.1.1.1.1718,information fusion fusors ROC ROC curves Bayes Optimal,?
Encoding Volumetric Grids For Streaming Isosurface Extraction,Ajith Mascarenhas Martin Isenburg Valerio Pascucci  Jack Snoeyink,2004,Gridded volumetric data sets representing simulation or tomography output are commonly visualized by displaying a triangulated isosurface for a particular isovalue. When the grid is stored in a standard format the entire volume must be loaded from disk even though only a fraction of the grid cells may intersect the isosurface.,10.1.1.1.1719,?,?
Model-Based Design and New User Interfaces: Current Practices and Opportunities,José Pascual José Pascual Molina Massó Pascual González López,2004,In conventional applications it is easy to find detailed and structured practices that make use of models in order to describe almost every aspect of the user interface. On the other hand new user interfaces such as those used in virtual and augmented applications are usually designed and developed in an ad hoc fashion or following a rather simple systematic approach. There are however a few notable efforts to develop model-based design methods for these new interfaces. Current practices research efforts and holes that are still to be addressed in the development of new user interfaces are reviewed in this paper.,10.1.1.1.1720,?,?
Teachers Professional Development: . . . ,  Mieke Clement et al.,2000,There exists nowadays consensus on the importance of teachers professional development. Also most authors agree that the schools workplace conditions can exert great influence on this development. In this paper the impact of two workplace conditions autonomy and collegiality on elementary school teachers professional development is analysed. The qualitative research reported makes clear that this in#uence should be thought of in a balanced way. Certain forms of autonomy and collegiality -- and more specifically certain combinations of both workplace conditions -- have a far more positive influence on teachers professional development than others. ,10.1.1.1.1722,Professional development Collegiality Autonomy Learning opportunities Learning space Learning experiences Qualitative research School organisation,?
Mapping Ground Video to Aerial DEMs,Amit K. Agrawal  Chandra Shekhar  Philip David  Jeff DeHart,?,We present an approach for registering an aerial Digital Elevation Model (DEM) with a color intensity image obtained using a camera mounted on a mobile robot. An approximate measurement of the camera pose is obtained using auxiliary sensors on-board the robot. The DEM is transformed into a depth map in the cameras coordinate system using this initial pose. The problem is now simplified to the alignment of two images one containing intensity information and the other depth. Region boundaries in the intensity image are matched with discontinuities in the depth map using a robust directed Hausdorff distance. This cost function is minimized with respect to the six parameters defining the camera pose. Due to the highly non-linear nature of cost function with multiple local minima a stochastic algorithm based on the downhill simplex principle is employed for minimization. Results on real data are presented.,10.1.1.1.1723,Video Registration Depth Map Simulated Annealing Simplex algorithm Hausdorff Distance Color Segmentation,?
Properties and Benefits of Calibrated Classifiers,Ira Cohen Moises Goldszmidt,2004,A calibrated classifier provides reliable estimates of the true  probability that each test sample is a member of the class of interest.,10.1.1.1.1724,?,Springer
Long Baseline Precision Navigation System for Synthetic Aperture Sonar,Edward N. Pilbrow  Michael P. Hayes  Peter T. Gough,2002,A two transponder long baseline positioning system to measure the sway of a free towed Synthetic Aperture Sonar (SAS) is proposed. A Matlab simulation predicts a worst case sway accuracy of    cm over a 150 m long tow path with an update rate of 14 Hz. The sway is measured with respect to freely deployed transponders which remain stationary on the seabed connected via cables to floating buoys housing GPS timing receivers. Sway information is completely independent for each sonar ping and allows the deblurring of the SAS images by post processing.,10.1.1.1.1725,?,?
Real-Time Skin Rendering on Graphics Hardware,Pedro Sander David Pedro V. S,?,We present a real-time algorithm for skin rendering which was used in the real-time animation Ruby: The DoubleCross appearing in this years SIGGRAPH animation festival. Our approach approximates the appearance of subsurface scattering by blurring the diffuse illumination in texture space using graphics hardware. This approach based on the offline skin rendering technique proposed by Borshukov and Lewis gives a realistic look and is both efficient and easy to implement. We describe algorithms to efficiently implement this technique in real-time using graphics hardware as well as several enhancements to improve quality.,10.1.1.1.1726,?,?
An Overview of Quality-of-Service Routing for the Next Generation High-Speed Networks: Problems and Solutions ,Shigang Chen  Klara Nahrstedt ,?,The up-coming Gbps high-speed networks are expected to support a wide range of communication-intensive real-time multimedia applications. The requirement for timely delivery of digitized audio-visual information raises new challenges for the next generation integrated-service broadband networks. One of the key issues is the Quality-of-Service (QoS) routing. It selects network routes with sufficient resources for the requested QoS parameters. The goal of routing solutions is two-fold: (1) satisfying the QoS requirements for every admitted connection and (2) achieving the global efficiency in resource utilization. Many unicast/multicast QoS routing algorithms were published recently and they work with a variety of QoS requirements and resource constraints. Overall they can be partitioned into three broad classes: (1) source routing (2) distributed routing and (3) hierarchical routing algorithms. In this paper we give an overview of the QoS routing problem as well as the existing solutions. We present the strengths and the weaknesses of different routing strategies and outline the challenges. We also discuss the basic algorithms in each class classify and compare them and point out possible future directions in the QoS routing area.,10.1.1.1.1727,?,?
Two-phased stød vowels – a cognitive reality?,Nina Grønnum A Hans Basbøll B,2003,Introduction  The pertinent facts leading up to this latest experiment about acoustic and perceptual properties of Danish std have been reported and discussed in Grnnum  Basbll (2001a 2001b 2002a 2002b). Here is the briefest possible summary: Consonants with std are not systematically longer than consonants without std and they may be shorter as well. Vowels with std are as long as long vowels without std and both are 50-70% longer than short vowels. Std vowels are also found to equal long vowels perceptually though this similarity may be overshadowed by the similarity between syllables with std irrespective of vowel length.  2. Std onset timing and cognitive reality  Variability in the onset (when it can be determined at all) of the laryngealization which is the std measured from vowel onset is very considerable with time lags ranging between 10 and 130ms. It averages around 60ms cf. Grnnum  Basbll (2001a). We need now to know whether and how this onset is perceived. Wh,10.1.1.1.1729,?,?
An Experimental Study of the Autonomous Helicopter Landing Problem,Srikanth Saripalli Gaurav Gaurav S. Sukhatme James F. Montgomery,2002,this paper we propose and experimentally investigate a vision-based technique for autonomously landing a robotic helicopter. We model the solution to the landing problem discretely using a finite state machine responsible for detecting the landing site navigating toward it and landing on it. Data from a single on-board camera are combined with attitude and position measurements from an on-board inertial navigation unit. These are the inputs to the on-board control system: a set of controllers running in parallel which are responsible for controlling the individual degrees of freedom of the helicopter. The resulting hybrid control system is simple yet effective as shown experimentally by trials in nominal and perturbed conditions,10.1.1.1.1730,?,?
FCND DP No.143,Fcnd Discussion Paper Mary Arimond Marie T. Ruel,?,Summary indicators for measuring and assessing infant and child feeding  practices are needed for research communication and advocacy and program evaluation.  This paper reports on progress in developing a summary measure of infant and child  feeding practices that addresses the following two challenges: infant and child feeding is  multidimensional and appropriate practices vary by age of the child. Much previous  research in the area of infant and child feeding has focused on single practices over a  narrow age range and so has not addressed the determinants and impact of adequate or  optimal infant and child feeding.  Using data from the Ethiopia Demographic and Health Survey an infant and child  feeding index is constructed summarizing a range of key practices including  breastfeeding bottle use feeding frequency and diet diversity. Because it provides agespecific scoring and incorporates various practices the index is a useful analytic tool.  The index is associated with an indicator of child growth (height-for-age) in  bivariate and multivariate analyses. Examination of individual indicators shows that this  association is driven by a strong positive association between one componentdiet  diversityand height-for-age. Further work is required to establish the nature of the  relationship between infant and child feeding indicators nutrient adequacy growth and  other outcomes. But because it can be used to illustrate the association between a set of  recommended practices and growth the index may serve as a communication tool with  policymakers.    iii Simulations show that the index accurately reflects an averaging of changes in  individual component practices and so it may also be of use to program managers who  seek a summary measure for assessing p...,10.1.1.1.1732,?,?
Unsynchronized Parallel Discrete Event Simulation,Dhananjai Madhava Rao  Narayanan V. Thondugulam  Radharamanan Radhakrishnan  Philip A. Wilsey D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,1998,Distributedsynchronizationforparallelsimulationisgenerallyclassifiedasbeingeitheroptimisticorconservative. Whileconsiderableinvestigationshavebeenconducted toanalyzeandoptimizeeachofthesesynchronization strategiesverylittlestudyonthedefinitionandstrictness ofcausalityhavebeenconducted.Dowereallyneed topreservecausalityinalltypesofsimulations?This paperattemptstoanswerthisquestion.Wearguethat significantperformancegainscanbemadebyreconsideringthisdefinitiontodecideiftheparallelsimulation needstopreservecausality.Weinvestigatethefeasibility ofunsynchronizedparallelsimulationthroughtheuseof severalqueuingmodelsimulationsandpresentacomparativeanalysisbetweenunsynchronizedandTimeWarp simulation.,10.1.1.1.1733,?,?
Subordinated Advection-Dispersion Equation for Contaminant Transport,Boris Baeumer David A. Benson Mark M. Meerschaert Stephen W. Wheatcraft,2000,A mathematical method called subordination broadens the applicability of the  classical advection-dispersion equation for contaminant transport. In this method the time  variable is randomized to represent the operational time experienced by different  particles. In a highly heterogeneous aquifer the operational time captures the fractal  properties of the medium. This leads to a simple parsimonious model of contaminant  transport that exhibits many of the features (heavy tails skewness and non-Fickian growth  rate) typically seen in real aquifers. We employ a stable subordinator that derives from  physical models of anomalous diffusion involving fractional derivatives. Applied to a onedimensional  approximation of the MADE-2 data set the model shows excellent  agreement.,10.1.1.1.1734,?,?
Restless bandit marginal productivity indices II: Multi-project case . . . ,José Niño-mora,2004,This paper develops a framework based on convex optimization and economic ideas to  formulate and solve approximately a rich class of dynamic and stochastic resource  allocation problems fitting in a generic discrete-state multi-project restless bandit  problem (RBP). It draws on the single-project framework in the authors companion  paper Restless bandit marginal productivity indices I: Single-project case and optimal  control of a make-to-stock M/G/1 queue based on characterization of a projects  marginal productivity index (MPI). Our framework significantly expands the scope of  Whittle (1988)s seminal approach to the RBP. Contributions include: (i) Formulation  of a generic multi-project RBP and algorithmic solution via single-project MPIs of a  relaxed problem giving a lower bound on optimal cost performance (ii) a heuristic  MPI-based hedging point and index policy (iii) application of the MPI policy and  bound to the problem of dynamic scheduling for a multiclass combined MTO/MTS  M/G/1 queue with convex backorder and stock holding cost rates under the LRA  criterion and (iv) results of a computational study on the MPI bound and policy  showing the latters near-optimality across the cases investigated,10.1.1.1.1735,shadow wage,?
MAF : un Protocole de Multicast Fiable,Prom Eth Ee,2003,This paper describes the design and implementation of a novel reliable multicast protocol totally reliable and scalable to large number of receivers. MAF relies on Active Networks technology: active routers in the multicast tree store senders transmissions in order to be able to later retransmit them to repair downstream losses. To address scalability MAF organizes those active routers into a hierarchical structure obtained by dividing the multicast tree into subtrees. Since a sender initiated approach is used within each of those subtrees MAF has the particularity of operating correctly with finite buffers. This paper also describes the implementation of MAF over the active network platform deployed by the RNRT project AMARRAGE. Index Terms--- totally reliable multicast active networks hierarchical structure aggregated ACK finite buffers.,10.1.1.1.1736,?,?
Optimization Problems in Telecommunications and the Internet,Carlos A. S. Oliveira,2004,ix 1 ,10.1.1.1.1737,ACKNOWLEDGMENTS......................... iii LIST OF TABLES............................. vii LIST OF,?
 Distributed Symmetric Key Management for Mobile Ad hoc Networks,Aldar C-f. Chan,2004,Key management is an essential cryptographic primitive upon which other security primitives are built. However none of the existing key management schemes are suitable for ad hoc networks. They are either too inefficient not functional on an arbitrary or unknown network topology or not tolerant to a changing network topology or link failures. Recent research on distributed sensor networks suggests that key pre-distribution schemes (KPS) are the only practical option for scenarios where the network topology is not known prior to deployment. However all of the existing KPS schemes rely on trusted third parties (TTP) rendering them inapplicable in many ad hoc networking scenarios and thus restricting them from wide-spread use in ad hoc networks. To eliminate this reliance on TTP we introduce distributed key pre-distribution scheme (DKPS) and construct the first DKPS prototype to realize fully distributed and selforganized key pre-distribution without relying on any infrastructure support. DKPS overcomes the main limitations of the previous schemes namely the needs of TTP and an established routing infrastructure. It minimizes the requirements posed on the underlying networks and can be easily applied to the ad hoc networking scenarios where key pre-distribution schemes were previously inapplicable. Finally DKPS is robust to changing topology and broken links and can work before any routing infrastructure has been established thus facilitating the widespread deployment of secure ad hoc networks.,10.1.1.1.1738,?,?
Testing SoC Interconnects for Signal Integrity Using Extended JTAG Architecture,Mohammad H. Tehranipour  Nisar Ahmed  Mehrdad Nourani,2003,As technology shrinks and working frequency reaches multi gigahertz range designing and testing interconnects are no longer trivial issues. In this paper we propose an enhanced boundary scan architecture to test high-speed interconnects for signal integrity. This architecture includes: a) a modified driving cell that generates patterns according to multiple transitions fault model and b) an observation cell that monitors signal integrity violations. To fully comply with conventional JTAG two new instructions are used to control cells and scan activities in the integrity test mode.,10.1.1.1.1739,Boundary Scan Test Integrity Loss Interconnect Testing JTAG Standard Signal Integrity System-on-Chip,Aix-enProvence
Order Statistics Approach for Detecting a Transient Signal of Unknown Arrival Time in Noise,Eran Fishler Hagit Messer,?,Detecting a transient signal of unknown arrival time in noise is actually a binary hypothesis test problem where the null hypothesis (noise only) is a simple one while the alternative hypothesis is composite. The generalized likelihood ratio test (GLRT) is a common tool to solve such problems. In this paper we show how order statistics (OS) approach can be used to solve the same problem. We show that the two hypothesis becomes simple using the OS approach so a likelihood ratio test (LRT) can be applied and we discuss the trade-offs between the two solutions. In particular we point out cases where the OS detector outperforms the GLRT.,10.1.1.1.1740,?,?
Face Appearance Factorization For Expression Analysis And Synthesis,Bouchra Abboud Franck Franck Davoine,?,Facial expression interpretation recognition and analysis is a key issue in visual communication and man to machine interaction. In this paper we present a factorization technique which decomposes the appearance parameters coding a natural image. This technique is then used to perform facial expression synthesis on unseen faces showing any undetermined facial expression as well as facial expression recognition.,10.1.1.1.1741,?,?
Experimental Results on Fusion of Multiple Fingerprint Matchers,Gian Luca Marcialis Fabio Roli,2003,Fingerprints are widely used in automatic identity verification  systems. The core of such systems is the verification algorithm to match two  fingerprints. So far various method for fingerprint matching have been  proposed but few works investigated the fusion of two or more matching  algorithms. In this paper various methods for fusing such algorithms have been  investigated. Experimental results showed that such fusion can outperform the  best individual verification algorithm and increase the discrimination between  genuine and impostor classes.,10.1.1.1.1742,?,?
A Client Side Approach to Building the Semantic Web,Erik Larson,?,In this paper I describe an alternative approach to building a semantic web that addresses some known challenges to existing attempts. In particular powerful information extraction techniques are used to identify concepts of interest in Web pages. Identified concepts are then used to semi-automatically construct assertions in a computer-readable markup reducing manual annotation requirements. It is also envisioned that these semantic assertions will be constructed specifically by communities of users with common interests. The structured knowledge bases created will then contain content that reflects the uses they were designed for thereby facilitating effective automated reasoning and inference for real-world problems.,10.1.1.1.1743,?,?
Union-Find and Congruence Closure Algorithms that Produce Proofs,Robert Nieuwenhuis Albert Oliveras,2004,Congruence closure algorithms are nowadays central in many modern applications in automated deduction and verification where it is frequently required to recover the set of merge operations that caused the equivalence of a given pair of terms. For this purpose we study from the algorithmic point of view the problem of extracting such small proofs.,10.1.1.1.1744,?,?
Geometric Shortest Path Containers,Dorothea Wagner Thomas Willhalm Christos Zaroliagis,2004,In this paper we consider Dijkstras algorithm for the single source single target shortest  path problem in large sparse graphs. The goal is to reduce the response time for on-line  queries by using precomputed information. Due to the size of the graph preprocessing space  requirements can be only linear in the number of nodes. We assume that a layout of the  graph is given. In the preprocessing we determine from this layout a geometric object for  each edge containing all nodes that can be reached by a shortest path starting with that edge.,10.1.1.1.1745,Graph algorithms,?
Student Views of Formative and Summative CAA,D. OHare Kedleston Rd,2001,Over the past two years students taking two biology modules at the University of Derby have been assessed using computer assessments with TRIADs (Tripartite Interactive Assessment Delivery System) in both their formal end of module examinations and for scored formative assessments. We were keen to establish the student views of the use of computer assessment and thus over this period in addition to the overall evaluation of the modules the students were also given the opportunity to evaluate these assessments. In the first instance an open ended approach was taken and students were given the opportunity to anonymously write comments on the computer examinations. The results of this were encouraging in that only a minority of students (~5%) made non-positive comments on CAA with the majority of students being very positive on their CAA experiences. In addition a range of useful comments in relation to the application of CAA were provided by students pertaining to comparability with traditional examinations and student learning strategy these are also discussed.,10.1.1.1.1747,?,?
A Framework for Protein Classification,Anand Kumar Barry Smith,2003,It is widely understood that protein functions can be exhaustively described in terms of  no single parameter whether this be amino acid sequence or the three-dimensional  structure of the underlying protein molecule. This means that a number of different  attributes must be used to create an ontology of protein functions. Certainly much of the  required information is already stored in databases such as Swiss-Prot Protein Data  Bank SCOP and MIPS. But the latter have been developed for different purposes and  the separate data-structures which they employ are not conducive to the needed data  integration. When we attempt to classify the entities in the domain of proteins we find  ourselves faced with a number of cross-cutting principles of classification. Our question  here is: how can we bring together these separate taxonomies in order to describe  protein functions? Our proposed answer is: via a careful top-level ontological analysis  of the relevant principles of classification combined with a new framework for the  simultaneous manipulation of classifications constructed for different purposes.,10.1.1.1.1748,?,Belleville Verlag
Impact of Flow Dynamics on Traffic Engineering Design Principles,Konstantina Papagiannaki Nina Taft Christophe Diot,2004,A common traffic engineering design principle is to select a small set of flows that account for a large fraction of the overall traffic to be differentially treated inside the network so as to achieve a specific performance objective. In this paper we illustrate that one needs to be careful in implementing such an approach because there are tradeoffs to be addressed that arise due to traffic dynamics. We demonstrate that Internet flows are very volatile in terms of volume and may substantially change the volume of traffic they transmit as time evolves. Currently proposed schemes for flow classification although attractive due to their simplicity face challenges due to this property of flows. Bandwidth volatility impacts the amount of load captured in a set of flows which usually drops both significantly and quickly after flow classification is performed. Thus if the goal is to capture a large fraction of traffic consistently over time flows will need to be reselected often. Our first contribution is in understanding the impact of flow volatility on the classification schemes employed in a traffic engineering context. Our second contribution is to propose a classification scheme that is capable of addressing the issues identified above by incorporating historical flow information. Using actual Internet data we demonstrate that our scheme outperforms previously proposed schemes and reduces both the impact of flow volatility on the load captured by the selected set of flows and the required frequency for its reselection.,10.1.1.1.1749,?,Hong-Kong
Panel Session: The Future Of The Winter Simulation Conference,S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Daniel T. Brunner Ricki G. Ingalls Barry L. Nelson,2003,The Winter Simulation Conference (WSC) is traditionally known as the most important annual conference serving the discrete event simulation community. The purpose of this panel session is to generate discussion about the nature of WSC in the future and about its future role in the overall simulation community. There are many reasons to do this. It is important to the communities currently served by WSC critical to the conference itself and in a broad sense significant to the future of simulation itself. In keeping with the track theme of discussing the future of simulation it makes sense to discuss the future of the most important discrete-event simulation event.,10.1.1.1.1751,?,?
Context Based Identification of User Communities From Internet Chat,Ata Kaban  Xin Wang,?,We study the temporal connectivity structure of single-channel Internet-based chat participation streams. Somewhat similar to bibliometric analysis and complementary to topic-analysis we base our study solely on context information provided by the temporal order of participants contributions. Experimental results obtained by employing both networkanalysis indicators and an aggregate Markov modelling approach indicate the existence of distinguishable communities in the about one day worth real-world chat dynamics analysed.,10.1.1.1.1752,?,?
GAMBL Genetic Algorithm Optimization of Memory-Based WSD,Bart Decadt And Bart Decadt Véronique Hoste Walter Daelemans Antal Van Den Bosch,2004,GAMBL is a word expert approach to WSD in which each word expert is trained using memorybased learning. Joint feature selection and algorithm parameter optimization are achieved with a genetic algorithm (GA). We use a cascaded classifier approach in which the GA optimizes local context features and the output of a separate keyword classifier (rather than also optimizing the keyword features together with the local context features). A further innovation on earlier versions of memorybased WSD is the use of grammatical relation and chunk features. This paper presents the architecture of the system briefly and discusses its performance on the English lexical sample and all words tasks in SENSEVAL-3.,10.1.1.1.1753,classifier (rather than also optimizing the,?
Anthropomorphic visualization: Depicting . . . ,Ethan Lewis Perry,2004,Anthropomorphic visualization is a new approach to presenting information about participants in online spaces using the human form as the basis for the visualization. Various data about an individuals online behavior are mapped to different parts of a humanoid yet abstract form. I hypothesized that using a humanoid form to visualize data about people in online social spaces could serve two purposes simultaneously: communicate statistics about the individuals and evoke a social response. Using the,10.1.1.1.1754,?,?
Agent-Based Service Composition through Simultaneous Negotiation in Forward and Reverse Auctions, Andrew Byde Claudio Bartolini Chris Preist Chris Preist,2003,Service composition is the act of taking several component products or services and bundling them together to meet the needs of a given customer. In the future service composition will play an increasingly important role in e-commerce and automation will be desirable to improve speed and efficiency of customer response. In this paper we consider a service composition agent that both buys components and sells services through auctions. It buys component services by participating in many English auctions. It sells composite services by participating in Request-for-Quotes reverse auctions. Because it does not hold a long-term inventory of component services it must take risks it must make offers in reverse auctions prior to purchasing all the components needed and must bid in English auctions prior to having a guaranteed customer for the composite good. We present algorithms that is able to manage this risk by appropriately bidding/offering in many auctions and reverse auctions simultaneously. The algorithms will withdraw from one set of possible auctions and move to another set if this will produce a better-expected outcome but will effectively manage the risk of accidentally winning outstanding bids/offers during the withdrawal process. We illustrate the behavior of these algorithms through a set of worked examples.,10.1.1.1.1755,?,?
Migration of Service and Customer Data in Intelligent Network Applications Anders Rosn,Anders Rosen Telia Supervisor Lars Planelid Examiner Monika Danielsson Anders Rosén Examensarbete Dv,?,this paper most of the contents of this section (1.2) is taken,10.1.1.1.1756,Contents Contents 1.0 Intelligent Networks,?
Design Implementation and Evaluation of IPv4+4,Zoltan Turanyi  Andras Valko  Anrew Campbell,?,In this paper we present and evaluate the 4+4 architecture. 4+4 extends the IPv4 address space without requiring changes to existing routers. It builds on the existence of NATs and multiple address realms but it does not use address translation and provides end-to-end address transparency. Existing address translation is used only as a transition tool. The paper also presents an implementation of 4+4 and related experimental results. We conclude that 4+4 is simple to introduce and may represent a mediumterm solution if IPv6 transition does not take off quickly enough. The source code of our implementation can be downloaded from http://ipv44.comet.columbia.edu.,10.1.1.1.1757,?,?
Limited Evolution of Segregation Distortion: Potential for a High Degree of Polymorphism,M van Boven  F Weissing,1998,this paper is as follows. We present a model for selection and segregation distortion in an infinitely large randomly mating population with one sex. To fix ideas we first consider the competition between the wildtype and two distorter alleles. We then show how the analysis can be extended to the competition between a large number of distorters. We start by assuming that the amount of complementation is the same for all combinations of distorter alleles. In this case each parameter configuration results in a unique stable polymorphism. We give an analytical characterization of this equilibrium and show that it typically involves many alleles. Subsequently we show by means of a simple example that the outcome of competition may be contingent on the initial conditions if the degree of complementation di#ers between distorters. Finally we study the competition between segregation distorters in case that there is a negative trade-o# between distorting e#ciency and complementing ability,10.1.1.1.1758,?,?
Mobile Agent-based Performance Management for the,Virtual Home Environment C. Bohoris G. Pavlou A. Liotta,2003,The Virtual Home Environment (VHE) encompasses the deployment and management of adaptable services that retain any personalized service aspects irrespective of terminal network and geographic location. We assert that the dynamic nature of the VHE requires management capabilities that can be suitably provided through the use of mobile agent technology. In this direction we examine four different engineering solutions for the realization of a VHE performance management component that allows service adaptation in relation to the available network Quality of Service (QoS). The mobile agent approach is compared with competing technologies in order to identify the benefits of this novel application of mobile agents discuss its drawbacks and finally focus on the lessons learned from our prototype system. Although mobile agents are typically associated with increased performance costs it is through agent migration that we were able to address the VHE requirements of universality dynamic programmability and network technology independence.,10.1.1.1.1760,?,?
A Simple Polynomial Time Framework for Reduced-Path Decomposition in Multi-Path Routing,Vahab S. Mirrokni Marina Thottan  Huseyin Uzunalioglu Sanjoy Paul,2004,The recent reduction in telecommunications spending has increased the importance of network planning to improve the return on investment on the existing network infrastructures. Therefore tools that help in maximizing the bandwidth efficiency of the network at a minimum cost are essential. Previous work in this area focused on increasing bandwidth efficiency and reliability. In this work in addition to increasing the bandwidth efficiency we address the complexity of network management and operations. This issue is explicitly addressed by our novel framework a simple polynomial time algorithm (SimPol)that  achieves optimum network performance (in terms of congestion or bandwidth consumption) using only a small number of paths. The problem formulation is based on splittable multicommodity flows. Using SimPol we show that the total number of paths is at most k + mwherek and m are the numbers of demands and edges in the network respectively. We extend the basic framework into an integer programming formulation to address the tradeoff between network congestion and the total number of paths. We also use SimPol to address the problem of implementing path/link policies such as bandwidth-limited paths. The performance of SimPol is evaluated through extensive simulations. We find that for large number of demands the LPbased framework provides a near-optimal solution of almost one path per demand. Using the integer programming approach we can get exactly one path while losing about 10% to 50% in congestion depending on the number of demands. This congestion is however far better than the traditional shortest path routing. The framework is general and can be used in capacity planning for transport networks such as MPLS and ATM.,10.1.1.1.1762,?,?
Recognition of Cursive Roman Handwriting - Past Present and Future,Horst Bunke,2003,This paper review the state of the art in o#-line Roman cursive han dw iting recognition. The input provided to an o#-line han iting recognition system is an image of a digit aw ord or - more generally - some text and the system produces as output an ASCII transcription of the input. This taskinvolves a number of processing steps some of w ich are quite di#cult. Typically preprocessing normalization feature extraction classification and postprocessing operations are required. Well survey the state of the art analyze recent trends and try to identify challenges for future research in this field.,10.1.1.1.1763,digit string,?
Laboratory-Scale Test of de Broglies Tired-Photon Model,Croca Departamento De J. R. Croca,2001,this paper I wish to present the model proposed some years ago by Louis de Broglie [2] for the tired photon. The problem with most alternative explanations for the cosmological redshift arises from the fact that they result from ad hoc assumptions. The model of de Broglie has none of the ad hoc character of which most tired-light mechanisms are accused: it follows from considerations at the fundamental level of his quantum theory [3]. It is only a corollary of his causal double solution theory which stands almost side by side with the orthodox non causal theory for explanation and prediction of quantum phenomena. Another major advantage of this model is that it can be tested on a laboratory scale,10.1.1.1.1764,?,?
Semantic Agent Technologies for Tactical Sensor Networks,Guofei Jiang  Wayne Chung  George Cybenko,?,Recent advances in wireless communication and microelectronics have enabled the development of low-cost sensor devices leading to interest in large-scale sensor networks for military applications. Sensor networks consist of large numbers of networked sensors that can be dynamically deployed and used for tactical situational awareness. One critical challenge is how to dynamically integrate these sensor networks with information fusion processes to support real-time sensing exploitation and decision-making in a rich tactical environment. In this paper we describe our work on an extensible prototype to address the challenge. The prototype and its constituent technologies provide a proof-of-concept that demonstrates several fundamental new approaches for implementing next generation battlefield information systems. Many cutting-edge technologies are used to implement this system including semantic web web services peer-to-peer network and content-based routing. This prototype system is able to dynamically integrate various distributed sensors and multi-level information fusion services into new applications and run them across a distributed network to support different mission goals. Agent technology plays a role in two fundamental ways: resources are described located and tasked using semantic descriptions based on ontologies and semantic services tracking fusion and decision-making logic is implemented using agent objects and semantic descriptions as well.,10.1.1.1.1765,Sensor network information fusion peer-to-peer network DAML semantics dynamic integration web service content-based,?
Advection And Dispersion In Time And Space,B. Baeumer D. A. Benson M. M. Meerschaert,2004,Previous work showed how moving particles that rest along their trajectory lead to time-nonlocal advection-dispersion equations. If the waiting times have infinite mean the model equation contains a fractional time derivative of order between 0 and 1. In this article we develop a new advection-dispersion equation with an additional fractional time derivative of order between 1 and 2. Solutions to the equation are obtained by subordination. The form of the time derivative is related to the probability distribution of particle waiting times and the subordinator is given as the first passage time density of the waiting time process which is computed explicitly. Preprint submitted to Elsevier Science 19 July 2004 Key words: Anomalous Di#usion Continuous Time Random Walks First Passage Time Fractional Calculus Subdi#usion Power laws 1 ,10.1.1.1.1766,Key words Anomalous Diffusion Continuous Time Random Walks First Passage Time Fractional Calculus Subdiffusion Power laws,?
New Horizons: Telecommunications Policy in Israel in the 21st Century,Neil Gandal,2002,The telecommunications industry in Israel has changed significantly in recent years. This paper examines key issues that will arise in Israel as a result of these major changes and argues that the major changes in the telecommunications industry require significant changes in the regulatory structure. The paper first provides important background material on the current structure in the various sectors of the telecommunications industry in Israel. The paper then discusses the current regulatory environment and makes recommendations regarding the future regulatory structure in Israel and the scope for regulation.,10.1.1.1.1767,?,?
A Formalism for Consistency and Partial Replication,Marc Shapiro Karthikeyan Bhargavan Yek Chong Youssef Hamadi,2004,?,10.1.1.1.1768,?,?
Templatic Structure in Czech: Vowel-final Prefixes,Tobias Scheer Université De Nice Leipzig Im Dezember E -e,1999,n Beschlagnahme pfndbar zabavit -ovat beschlagnahmen drh zdr#ka  zdr#n  zdrh   zadrhl  Stockung  Sperr-  Schlinge  verwickelt   zadrhnout-vat   zadrhovat   zadr#et-ovat  scheuern reiben  verknoten  aufhalten  duch zducha  zdus  zdusn  zdusn   zadusen   zadusen   zadchan  Atemnot  Kirchengut  Kirchen-  asthmatisch  Ersticken  erstickt  stickig   zadusit   zadusovat se   zadychat  ersticken  beteuern  anhauchen  hyb zhyb   zahynut   zahnut  Falte Krmmung  Untergang  gebogen   zahnout   zahbat   zahynout  umbiegen  rtteln  untergehen  h# zh#evn   zah#at   zah#vac   zah#va#   zah#vadlo  Wrme-  Erwrmen  Wrme-  Vorwrmer     zah#t-vat erwrmen  chod zchod   zachzen   zachzka  Klosett  Umgang  Umweg   zachzet einbiegen  untergehen  chran zchrana  zchrann   zachrnce   zachrnkyn#   zachrn#n   zachra#ovac  Rettung  Rettungs-  Retter  Retterin  Rettung  Rettungs-   zachrnit   zachra#ovat  (er-) retten    klad zklad  zkladka  zkladna  zkladn   zakladac   zakladatel   zakladatelka  Grundla,10.1.1.1.1769,ZA- Nouns Verbs ? VV V VV V bav zábava,?
Simple Identity-Based Cryptography with Mediated RSA,Xuhua Ding Gene Tsudik,?,Identity-based public key encryption facilitates easy introduction of  public key cryptography by allowing an entitys public key to be derived from  an arbitrary identification value such as name or email address. The main practical  benefit of identity-based cryptography is in greatly reducing the need for  and reliance on public key certificates. Although some interesting identity-based  techniques have been developed in the past none are compatible with popular  public key encryption algorithms (such as El Gamal and RSA). This limits the  utility of identity-based cryptography as a transitional step to full-blown public  key cryptography. Furthermore it is fundamentally difficult to reconcile finegrained  revocation with identity-based cryptography.,10.1.1.1.1770,?,Springer
A Simple Traffic Independent Scheme for Enabling Restoration Oblivious . . . ,Murali Kodialam T. V. Lakshman Sudipta Sengupta,2004,Fast restoration is an important feature of both MPLS and optical networks. The main mechanism for achieving fast restoration is by locally routing around failures using pre-setup detour paths. Signaling and routing protocol extensions to implement this local bypass ability are currently being standardized. To make use of this ability dynamic schemes that jointly route primary paths and all link detours for links used by the primary paths have been previously proposed. These schemes also permit sharing of reserved restoration capacity for achieving efficiency. However this joint computation places a significantly larger computational load on the network elements than that imposed by the shortest path computation variants typically used for unprotected network connection routing. In this paper we propose a new scheme that is operationally much simpler shares capacity used for restoration and permits the network to route the primary paths in a manner that is oblivious to restoration needs. Restoration of all carried traffic is guaranteed by a new link capacity partitioning scheme that maximizes the working capacity of the network without requiring any knowledge of the traffic that will be imposed on the network. Being traffic independent for a priori link capacity partitioning and being oblivious to restoration needs for on-line network routing makes this scheme operationally simple and desirable in the sense of placing no additional routing load on the constrained computing resources at the network nodes. To compute the link capacity partitions we develop a fast combinatorial algorithm that uses only iterative shortest path computations and is a fully polynomial time approximation scheme (FPTAS)  i.e. it achieves a (1 + #)-factor approximation for any #0 and ru...,10.1.1.1.1771,?,?
Educational Goal Preferences among Novice and Veteran Teachers of . . .,Y. Rich Yisrael Rich Malka Almozlino,1999,Does teaching experience di!erentially shape the thinking of teachers of di!erent academic disciplines regarding schooling issues incidentally related to subject matter instruction? This question was addressed by examining the broad schooling goals established for students by novice and veteran teachers of humanistica and scientica subjects. Participants were 44 Israeli female teachers of grades 7}9. Frequency and intensity of goal preferences were assessed in a semi-structured interview. Results demonstrated that: (1) novices and veterans expressed di!erent goal preferences as did humanities versus science teachers (2) experienced humanities teachers preferred academic goals less than other teachers and (3) the overall order of goal preference was academicsocialpersonal. The signicance of the interaction between teacher experience and discipline taught is discussed. # 1999 Elsevier Science Ltd. All rights reserved.,10.1.1.1.1772,Teacher goals Teacher experience Subject matter,?
Verification Via Structure Simulation,N. Immerman A. Rabinovich T. Reps M. Sagiv G. Yorsh,2004,Interpretation  The abstract-interpretation technique [2] allows conservative automatic verification of partial correctness to be conducted by identifying sound over-approximations to loop invariants. An iterative computation is carried out to determine an appropriate abstract value for each program point. The result at each program point is an abstract value that summarizes the sets of reachable concrete states at that point.,10.1.1.1.1773,?,Springer
Modeling the cytotoxic T cell response,Paul Helman Miller Alan Perelson Lance Williams Dennis Lai Chao Dennis Lai Chao Dennis Lai Chao Dennis Lai Chao,2004,This work describes a computer model of the immune system s response to infection specifically the cytotoxic T lymphocyte (CTL) response. CTLs play an important role in the control of infectious agents and they are essential components of our defense against HIV cancer and other diseases of great public interest. Immunologists are interested in manipulating and enhancing the CTL response to these diseases whether by vaccination or drug therapy but the process can be difficult and ad hoc. A combination of animal experimentation limited human testing and simple mathematical models have been the primary sources of guidance in the efforts to address these diseases. Computer models provide an alternative strategy for exploring immune system therapies. Recently developed laboratory techniques that have revealed and quantified many aspects of CTL behavior provide an unprecedented opportunity to develop detailed models. The model used in this work integrates many of these new findings into a coherent system that simulates an immune response to viral infection. This model reproduces many of the phenomena seen in CTL responses but not captured by other mathematical or computer models and can be used to explore vaccination strategies. The value of modeling goes beyond simply making predictions. It allows one to perform experiments difficult or even impossible to perform in the laboratory. For example in a computer model one can replicate experiments exactly or choose to allow stochastic fluctuations to influence the outcome. In biological systems achieving this level of control is impossible. Model-building can also be used as a vehicle for hypothesis testing by formulating one s assumptions about a system s behavior as a model. If the model s behavior does not match real-world experimental results the initial assumptions can be changed and a new model built. The model presented here is the result of a series of such choices.,10.1.1.1.1774,?,?
Modeling the Performance of Wireless Sensor Networks,C.-F. Chiasserini  M. Garetto,2004,A critical issue in wireless sensor networks is represented by the limited availability of energy within network nodes therefore making good use of energy is a must. A widely employed energy-saving technique is to place nodes in sleep mode corresponding to a low-power consumption as well as to reduced operational capabilities. In this work we develop a Markov model of a sensor network whose nodes may enter a sleep mode and we use this model to investigate the system performance in terms of energy consumption network capacity and data delivery delay. Furthermore the proposed model enables us to investigate the trade-offs existing between these performance metrics and the sensor dynamics in sleep/active mode. Analytical results present an excellent matching with simulation results for a large variety of system scenarios showing the accuracy of our approach.,10.1.1.1.1775,?,?
Lexical Similarity based on Quantity of Information Exchanged - Synonym Extraction,Ngoc-Diep Ho  Fairon Cédrick,2004,There are a lot of approaches for measuring semantic similarities between words. This paper proposes a new method based on the analysis of a monolingual dictionary. We can view the word definitions of a dictionary as a network: its nodes are the headwords found in the dictionary and its edges represent the relations between a headword and the words present in its definition. In this view the meaning of a word is defined by the total quantity of information in which each element of its definition contributes. The similarity between two words is defined by the maximal quantity of information exchanged between them through the network.,10.1.1.1.1776,Information Exchanged- Synonym Extraction,?
Effective Implementation of Cycle Time Reduction . . . ,Joerg Domaschke Steven Brown et al.,1998,Using discrete-event simulation models a study was conducted to evaluate the current production practices of a high-volume semiconductor back-end operation. The overall goal was to find potential areas for productivity improvement that would collectively yield a 60% reduction in manufacturing cycle time. This paper presents the simulation methodology and findings pertaining to analysis of the Assembly Burn-In and Test operations. Many of the recommendations identified can be implemented at no additional cost to the factory. The most significant opportunities for improvement are in the Test area the system constraint. Additionally the model is extremely sensitive to changes in operator staffing levels an accurate reflection of many back-end operations. The model shows that the cumulative impact of these recommendations is a 41% reduction in average cycle time a significant contribution to the overall goal.,10.1.1.1.1777,?,?
Market InstitutionsTransaction Costs and Social Capital in the Ethiopian Grain Market,Eleni Z. Gabre-madhin Eleni Z. Gabre-madhin Figures Vii Foreword Ix,?,this report may be reproduced without the express  permission of but with acknowledgment to the International Food Policy Research Institute,10.1.1.1.1778,?,?
P2P the Gorilla in the Cable,Alexandre Gerber Joseph Re Gerber Joseph Houle Han Nguyen Matthew Roughan Subhabrata Sen,2003,There is considerable interest in Peer-topeer (P2P) traffic because of its remarkable increase over the last few years. By analyzing flow measurements at the regional aggregation points of several cable operators we are able to study its properties. It has become a large part of broadband traffic and its characteristics are different from older applications such as the Web. It is a stable balanced traffic: the peak to valley ratio during a day is around 2 and the Inbound/Outbound traffic balance is close to one. Although P2P protocols are based on a distributed architecture they dont show strong signs of geographical locality. A cable subscriber is not much more likely to download a file from a close region than from a far region.,10.1.1.1.1779,?,?
Dynamic Allocation Indices For Restless Projects And Queueing Admission Control: A Polyhedral Approach,Jose Nino-Mora,2002,This paper develops a polyhedral approach to the design analysis and computation of dynamic allocation indices for scheduling binary-action (engage/rest) Markovian stochastic projects which can change state when rested (restless bandits (RBs)) based on partial conservation laws (PCLs). This extends previous work by the author [J. Nino-Mora (2001): Restless bandits partial conservation laws and indexability. Adv. Appl. Probab. 33 76--98] where PCLs were shown to imply the optimality of index policies with a postulated structure in stochastic scheduling problems under admissible linear objectives and they were deployed to obtain simple sufficient conditions for the existence of Whittles (1988) RB index (indexability) along with an adaptive-greedy index algorithm. The new contributions include: (i) we develop the polyhedral foundation of the PCL framework based on the structural and algorithmic properties of a new polytope associated with an accessible set system (J   (F-extended polymatroid) (ii) we present new dynamic allocation indices for RBs motivated by an admission control model which extend Whittles and have a significantly increased scope (iii) we deploy PCLs to obtain both sufficient conditions for the existence of the new indices (PCL-in-  dexability) and a new adaptive-greedy index algorithm (iv) we interpret PCL-indexability as a form of the classic economics law of diminishing marginal returns and characterize the index as an optimal marginal cost rate we further solve a related optimal constrained control problem (v) we carry out a PCL-indexability analysis of the motivating admission control model under time-discounted and long-run average criteria this gives under mild conditions a new index characterization of optimal threshold...,10.1.1.1.1780,?,?
Feedback Controlled Software Systems,William B. Dunbar   Eric Klavins Stephen Waydo,2003,Software systems generally suffer from a certain fragility in the face of disturbances  such as bugs unforeseen user input unmodeled interactions with other software components and  so on. A single such disturbance can make the machine on which the software is executing  hang or crash. We postulate that what is required to address this fragility is a general means of using feedback to stabilize these systems. In this paper we develop a preliminary dynamical systems model of an arbitrary iterative software process along with the conceptual framework for stabilizing it in the presence of disturbances. To keep the computational requirements of the  controllers low randomization and approximation are used. We describe our initial attempts to  apply the model to a faulty list sorter using feedback to improve its performance. Methods by  which software robustness can be enhanced by distributing a task between nodes each of which are  capable of selecting the best input to process are also examined and the particular case of a  sorting system consisting of a network of partial sorters some of which may be buggy or even  malicious is examined.,10.1.1.1.1781,?,?
Polarization Rotation over Cosmological Distances as a Probe to New Physics,C. Wolf,2001,Recent studies in the rotation of the plane of polarization of electromagnetic waves over...,10.1.1.1.1782,?,?
Automated Service Integration for Crisis Management,Alan Berfield Panos Panos K. Chrysanthis Ros Labrinidis,2004,The integration and coordination of different emergency service personnel is crucial to Crisis Management.,10.1.1.1.1783,?,?
Almost ASAP Semantics: From Timed Models to Timed Implementations,Martin De Wulf Laurent Doyen Jean-françois Raskin,2003,In this paper we introduce a parametric semantics for timed controllers called  the Almost ASAP semantics. This semantics is a relaxation of the usual ASAP semantics (also  called the maximal progress semantics) which is a mathematical idealization that can not be  implemented by any physical device no matter how fast it is. On the contrary any correct  Almost ASAP controller can be implemented by a program on a hardware if this hardware is  fast enough. We study the properties of this semantics show how it can be analyzed using the  tool HyTech and illustrate its practical use on examples.,10.1.1.1.1784,?,Springer
The Formation of Networks with Transfers among Players,Francis Bloch Matthew O. Jackson,2004,We examine the formation of networks among a set of players whose payoffs depend  on the structure of the network. We focus on games where players may bargain by  promising or demanding transfer payments when forming links. We examine several  variations of the transfer/bargaining aspect of link formation. One aspect is whether  players can only make and receive transfers to other players to whom they are directly  linked or whether they can also subsidize links that they are not directly involved  in. Another aspect is whether or not transfers related to a given link can be made  contingent on the full resulting network or only on the link itself. A final aspect  is whether or not players can pay other players to refrain from forming links. We  characterize the networks that are supported under these variations and show how each  of the above aspects is related either to accounting for a specific type of externality or  to dealing with the combinatorial nature of network payoffs.,10.1.1.1.1785,Networks Network Games Network Formation Game Theory Efficient Networks Side Payments Transfers Bargaining Externalities,?
Time Patterns in Visual Reception and Written Phrase Production,Philip Cummins Boris Gutbrod  Rüdiger Weingarten,?,In previous studies we could show that linguistic word structures correlate closely with the time  course of written word production. In the present study we investigate whether there are also  correlations between the syntactic structures of phrases and the time course of their production.,10.1.1.1.1786,?,?
ASAP2: An Improved . . . ,Natalie M. Steiger Christos Alexopoulos David Goldsman et al.,2002,We introduce ASAP2 an improved variant of the batchmeans algorithm ASAP for steady-state simulation output analysis. ASAP2 operates as follows: the batch size is progressively increased until the batch means pass the ShapiroWilk test for multivariate normality and then ASAP2 delivers a correlation-adjusted confidence interval. The latter adjustment is based on an inverted Cornish-Fisher expansion for the classical batch means t-ratio where the terms of the expansion are estimated via a first-order autoregressive time series model of the batch means. ASAP2 is a sequential procedure designed to deliver a confidence interval that satisfies a prespecified absolute or relative precision requirement. When used in this way ASAP2 compares favorably to ASAP and the well-known procedures ABATCH and LBATCH with respect to close conformance to the precision requirement as well as coverage probability and mean and variance of the half-length of the final confidence interval.,10.1.1.1.1787,?,?
The ways to improve intelligence of interacting agents,Supervisor Prof Aaron Sloman Marek Kopicki Marek Kopicki,2004,The path planning is not a trivial problem of artificial intelligence. An agent has to find a path from one state (or position) to another whilst avoiding contact with obstacles. The configuration space used for representation of all agent states is usually continuous which makes the problem even more complex. Skeletonisation is one of approaches which discretises continuous space and reduces it to a graph search problem.,10.1.1.1.1788,?,?
Stratum Approaches to Temporal DBMS Implementation,Kristian Torp Christian S. Jensen,1998,Previous approaches to implementing temporal DBMSs have assumed that a temporal DBMS must be built from scratch employing an integrated architecture and using new temporal implementation techniques such as temporal indexes and join algorithms. However this is a very large and time-consuming task. This paper explores approaches to implementing a temporal DBMS as a stratum on top of an existing non-temporal DBMS rendering implementation more feasible by reusing much of the functionality of the underlying conventional DBMS. More specifically the paper introduces three stratum meta-architectures each with several specific architectures. Based on a new set of evaluation criteria advantages and disadvantages of the specific architectures are identified. The paper also classifies all existing temporal DBMS implementations according to the specific architectures they employ. It is concluded that a stratum architecture is the best short medium and perhaps even longterm approach to implementing a temporal DBMS.,10.1.1.1.1789,Temporal databases database systems architectures,?
Understanding Ontologies in Scholarly Disciplines,Brian R Gaines,?,Description logics are valuable for modeling the conceptual structures of scientific and engineering research because the underlying ontologies generally have a taxonomic core. Such structures have natural representations through semantic networks that mirror the underlying description logic graph-theoretic structures and are more comprehensible than logical notations to those developing and studying the models. This article reports experience in the development of visual language tools for description logics with the objective of making research issues past and present more understandable.,10.1.1.1.1790,?,?
The Finite Ridgelet Transform for Image Representation,Minh N. Do Martin Vetterli,2003,The ridgelet transform [6] was introduced as a sparse expansion for functions on continuous spaces that are smooth away from discontinuities along lines. In this paper we propose an orthonormal version of the ridgelet transform for discrete and finite -size images. Our construction uses the finite Radon transform (FRAT) [11] [20] as a building block. To overcome the periodization effect of a finite transform we introduce a novel ordering of the FRAT coefficients. We also analyze the FRAT as a frame operator and derive the exact frame bounds. The resulting finite ridgelet transform (FRIT) is invertible nonredundant and computed via fast algorithms. Furthermore this construction leads to a family of directional and orthonormal bases for images. Numerical results show that the FRIT is more effective than the wavelet transform in approximating and denoising images with straight edges.,10.1.1.1.1791,?,?
Query Plans for Conventional and Temporal Queries Involving Duplicates and Ordering,Giedrius Slivinskas  Christian S. Jensen Richard T. Snodgrass,2000,Most real-world database applications contain a substantial portion of time-referenced or temporal data. Recent advances in temporal query languages show that such database applications could benefit substantially from builtin temporal support in the DBMS. To achieve this temporal query representation optimization and processing mechanisms must be provided. This paper presents a general algebraic foundation for query optimization that integrates  conventional and temporal query optimization and is suitable for providing temporal support both via a stand-alone temporal DBMS and via a layer on top of a conventional DBMS. By capturing duplicate removal and retention and order preservation for all queries as well as coalescing for temporal queries this foundation formalizes and generalizes existing approaches.,10.1.1.1.1792,?,?
  Types and Roles of Ontologies in Web Information Extraction,Martin Labsky Vojt?ch Svátek Ondrej Sváb ,2004, We discuss the diverse types and roles of ontologies in web information extraction and illustrate them on a small study from the product offer domain. Attention is mainly paid to the impact of domain ontologies presentation ontologies and terminological taxonomies. ,10.1.1.1.1793,?,?
Genome Informatics 14: 238--249 (2003) Docking Unbound Proteins with MIAX: A Novel,Algorithm For Protein-Protein Carlos A. Del Carpio Muñoz Tobias Peissker Atsushi Yoshimori Eiichiro Ichiishi,?,We propose a new methodology for soft docking unbound protein molecules (reported at the isolated state). The methodology is characterized by its simplicity and easiness of embedment in any rigid body docking process based on point complementarity. It is oriented to allow limited free but not unrealistic interpenetration of the side chains of protein surface amino acid residues. The central step to the technique is a filtering process similar to those in image processing. The methodology assists in deletion of atomic-scale details on the surface of the interacting monomers leading to the extraction of the most characteristic flattened shape for the molecule as well as the definition of a soft layer of atoms to allow smooth interpenetration of the interacting molecules during the docking process. Although the methodology does not perform structural or conformational rearrangements in the interacting monomers results output by the algorithm are in fair agreement with the relative position of the monomer in experimentally reported complexes. The algorithm performs especially well in cases where the complexity of the protein surfaces is high that is in hetero dimmer complex prediction. The algorithm is oriented to play the role of a fast screening engine for proteins known to interact but for which no information other than that of the structures at the isolated state is available. Consequently the importance of the methodology will increase in structural-function studies of thousand of proteins derived from large scale genome sequencing projects being executed all around the globe  Keywords: protein-protein interaction docking soft docking filtering  1 ,10.1.1.1.1794,protein-protein interaction docking soft docking filt,?
Low-Complexity Video Coding for Receiver-Driven Layered Multicast,Steven Mccanne Martin Vetterli  Van Jacobson,1997,In recent years the Internet Multicast Backbone or MBone has risen from a small research curiosity to a largescale and widely used communications infrastructure. A driving force behind this growth was the development of multipoint audio video and shared whiteboard conferencing applications. Because these real-time media are transmitted at a uniform rate to all of the receivers in the network a source must either run at the bottleneck rate or overload portions of its multicast distribution tree. We overcome this limitation by moving the burden of rate adaptation from the source to the receivers with a scheme we call receiver-driven layered multicast or RLM. In RLM a source distributes a hierarchical signal by striping the different layers across multiple multicast groups and receivers adjust their reception rate by simply joining and leaving multicast groups. In this paper we describe a layered video compression algorithm which when combined with RLM provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. In addition to a layered representation our coder has low complexity (admitting an efficient software implementation) and high loss resilience (admitting robust operation in loosely controlled environments like the Internet) . Even with these constraints our hybrid DCT/wavelet-based coder exhibits good compression performance. It outperforms all publicly available Internet video codecs while maintaining comparable run-time performance. We have implemented our coder in a real application---the UCB/LBL videoconferencing tool vic. Unlike previous work on layered video compression and transmission we have built a fully operational system that is currently being deployed on a very large scale over the MBone.,10.1.1.1.1795,MBone,?
Congestion Control via Online Sampling,Gang Wu  Edwin K. P. Chong  Robert Givan,2001,We consider the congestion-control problem in a communication network with multiple traffic sources each modeled as a fullycontrollable stream of fluid traffic. The controlled traffic shares a common bottleneck node with high-priority cross traffic described by a Markovmodulated fluid (MMF). Each controlled source is assumed to have a unique round-trip delay. We wish to maximize a linear combination of the throughput delay traffic loss rate and a fairness metric at the bottleneck node. We introduce an online sampling-based burst-level congestioncontrol scheme capable of performing effectively under rapidly-varying cross traffic by making explicit use of the provided MMF model of that variation. The control problem is posed as a finite-horizon Markov decision process and is solved heuristically using a technique called Hindsight Optimization. We provide a detailed derivation of our congestion-control algorithm based on this technique. The distinguishing feature of our scheme relative to conventional congestion-control schemes is that we exploit a stochastic model of the cross traffic. Our empirical study shows that our control scheme significantly outperforms the conventional proportionalderivative (PD) controller achieving higher utlization lower delay and lower loss under reasonable fairness. The performance advantage of our scheme over the PD scheme grows as the rate variance of cross traffic increases underscoring the effectiveness of our control scheme under variable cross traffic.,10.1.1.1.1796,?,?
Building Polygonal Maps from Laser Range Data,Longin Jan Latecki  Rolf Lakaemper  Xinyu Sun  Diedrich Wolter,2004,This paper presents a new approach to the problem of building a global map from laser range data utilizing shape based object recognition techniques originally developed for tasks in computer vision. In contrast to classical approaches the perceived environment is represented by polygonal curves (polylines) possibly containing rich shape information yet consisting of a relatively small number of vertices. The main task besides segmentation of the raw scan point data into polylines and denoising is to find corresponding environmental features in consecutive scans to merge the polylinedata to a global map. The correspondence problem is solved using shape similarity between the polylines. The approach does not require any odometry data and is robust to discontinuities in robot position e.g. when the robot slips. Since higher order objects in the form of polylines and their shape similarity are present in our approach it provides a link between the necessary low-level and the desired high-level information in robot navigation. The presented integration of spatial arrangement information illustrates the fact that high level spatial information can be easily integrated in our framework.,10.1.1.1.1797,?,?
Storage and Retrieval of First Order Logic Terms In a Database, Peter Gursky,2004,In this paper we present a storage method for sets of first  order logic terms in a relational database using function symbols based  indexing method of Discrimination trees. This is an alternative method  to a published one based on attribute indexing. This storage enables  e#ective implementation of several retrieval operations: unification generalization  instantation and variation of a given query term in the language  of first order predicate calculus. In our solution each term has  unique occurrence in the database. This is very useful when we need to  store a large set of terms that have identical many subterms.,10.1.1.1.1799,?,?
Signal Processing With Factor Graphs: Examples,Hans-andrea Loeliger  Justin Dauwels Volker M. Koch  Sascha Korl,2004,this paper we outline three examples of ongoing work of this type. For an introduction to factor graphs we refer to [1] and [2]. We will use the notation of [2],10.1.1.1.1800,?,?
Teachers Perceptions of Professional Identity: An Exploratory Study From a Personal Knowledge Perspective,Douwe Beijaard Nico Verloop Jan D. Vermunt,2000,The purpose of this study was to investigate experienced secondary school teachers (N80) current and prior perceptions of their professional identity. A questionnaire was used to explore the way teachers see (and saw) themselves as subject matter experts didactical experts and pedagogical experts. The teachers currently see their professional identity as consisting of a combination of the distinct aspects of expertise. Most teachers current perceptions of their professional identity reportedly di!er signicantly from their prior perceptions of this identity during their period as beginning teachers. On the basis of their current perceptions of their professional identity ve groups of teachers could be distinguished. These groups had di!erent learning experiences throughout their careers for each aspect of expertise. Also teachers from di!erent subject areas did not undergo the same changes in their perceptions of their professional identity. The di!erences among the groups in teachers current perceptions of professional identity were not related to contextual experiential and biographical factors that might in#uence these perceptions. ,10.1.1.1.1801,content knowledge (cf. Fenstermacher 1994 Hoyle,?
Layered MPEG4 Video Signals for Real-time Mobile Streaming Applications Authors:,Francesco G. B De Natale Claudio Sacchi Claudio Sacchi Nicola Conci Nicola Conci Giovanni Berl Giovanni Berl A Scorza A Scorza Francesco G. B. De,?,this report a novel methodology for the efficient multiplexing and transmission of MPEG4coded video signals over wireless networks will be presented and discussed. The proposed approach relies on the joint exploitation of variable-bit-rate (VBR) multicarrier code-division multiplexing (MC-CDM) together with MPEG4 coding with Fine-Grain-Scalability (FGS) in order to provide unequal error protection to the transmitted video stream. The innovative scheme proposed employs a shared bandwidth partitioned into orthogonal sub-channels in order to multiplex different layers of MPEG-4-coded signals. The highest number of subchannels (and hence an increased frequency diversity) is assigned to the lowest-bit-rate base layer and the lowest number of sub-channels is assigned to the highest bit-rate enhancement layer. In such a way base layer information contents are more protected against channel degradations than information contained in FGS enhancement layers which can only yield a refinement of the quality of the decoded streams. A 2GHz LEO multicast satellite transmission to mobile users has been regarded as the application testbed for the proposed method. Results achieved in terms of PSNR point out that the VBR MC-CDM technique can provide better results than a conventional MPEG-4 single-layer MC-SS transmission. In the framework of a full-digital implementation of reconfigurable multimedia transceivers the proposed VBR MCCDM technique may be regarded as an interesting solution for reliable multimedia transmissions in mobile environments,10.1.1.1.1802,?,?
Analog Integrated Circuits and Signal Processing 30 69--81 2002,An Mhz Th-Order Hanspeter Schmid,2001,This paper is a practical guide to building higher-order filters with single-amplifier biquadratic MOSFET--C sections. Theory design guidelines and measurement electronics are discussed by example of a 7th-order current-mode filter built to the specifications of a 1 DVD read channel filter. The 7th-order filter was fabricated with the double-poly 0.6-micron CMOS process by AMS. It is continuously tunable from 4.5 MHz up to 10 MHz covers a chip area of only 0.24 mm     and consumes 49 mW from a 3.3-V supply. The SNR at    of harmonic distortion is between 48 dB and 50 dB over the whole tuning range. The comparatively low power consumption and chip area could be achieved by using single-amplifier biquadratic building blocks implemented as MOSFET--C filters and generating the control voltage of the MOSFET resistors with an on-chip charge pump. The technique is with a small loss of SNR also applicable on fabrication processes where only gate-oxide capacitors are available.,10.1.1.1.1803,Key Words MOSFET-C filter single-amplifier biquad current-mode filter current conveyor charge pump,?
December 2000 CSTR-00-018,University Of Bristol Peter A. Flach Peter A. Flach,2001,This paper reviews a number of recent books related to current developments  in machine learning. Some (anticipated) trends will be sketched. These include:  a trend towards combining approaches that were hitherto regarded as distinct and  were studied by separate research communities a trend towards a more prominent  role of representation and a tighter integration of machine learning techniques  with techniques from areas of application such as bioinformatics. The intended  readership has some knowledge of what machine learning is about but brief tutorial  introductions to some of the more specialist research areas will also be given.,10.1.1.1.1805,?,?
Drift-Controlled Scalable Video Coding In Over-Complete Wavelet Domain,Vidhya Seran  Lisimachos P. Kondi,2004,In this work we propose a novel scheme to minimize drift in scalable wavelet based video coding which gives a balanced performance between compression efficiency and quality. Our drift control mechanism maintains two frame buffers in the encoder and decoder one for the base layer and the other for the enhancement layer. Drift control is achieved by switching between these two buffers for motion compensation and prediction. In the encoder the residues are coded using the embedded zerotree wavelet (EZW) algorithm. Our prediction is based on the enhancement layer which inherently introduces drift in the system if part of the enhancement layer is not available at the receiver. A measure of drift is computed based on channel information and a threshold is set. When the measure exceeds the threshold i.e. when drift becomes significant we switch the prediction to be based on the base layer which is always available to the receiver.,10.1.1.1.1806,?,?
Limit Theorems For Continuous Time Random Walks With Infinite Mean Waiting Times,Mark M. Meerschaert Hans-Peter Scheffler,2003,A continuous time random walk is a simple random walk subordinated to a renewal process used in physics to model anomalous diffusion. In this paper we show that when the time between renewals has infinite mean the scaling limit is an operator Levy motion subordinated to the hitting time process of a classical stable subordinator. Density functions for the limit process solve a fractional Cauchy problem the generalization of a fractional partial differential equation for Hamiltonian chaos. We also establish a functional limit theorem for random walks with jumps in the strict generalized domain of attraction of a full operator stable law which is of some independent interest.  ,10.1.1.1.1807,?,?
Conceptual Modeling of Time-Varying Information, Heidi Gregersen Christian S. Jensen,1998,A wide range of database applications manage information that varies over time. Many of the underlying  database schemas of these were designed using one of the several versions with varying syntax and  semantics of the Entity-Relationship (ER) model. In the research community as well as in industry it is  common knowledge that the temporal aspects of the mini-world are pervasive and important but are also  difficult to capture using the ER model. Not surprisingly several enhancements to the ER model have  been proposed in an attempt to more naturally and elegantly support the modeling of temporal aspects of  information. Common to the existing temporally extended ER models few or no specific requirements  to the models were given by their designers. With the,10.1.1.1.1808,?,?
Comments Received on DRAFT ANS X9.82 Random Number Generation,,?,In this paper we examine the sources of random numbers used in signal processing. We also hope to present some interesting solutions to modern application problems using random numbers and  to provide methods in which to test the integrity of random number sequences for use in a variety of applications.,10.1.1.1.1809,?,?
Simulation Modeling at . . . ,P. Benjamin et al.,1998,The purpose of this paper is to characterize the problem of multiple levels of abstraction in simulation modeling and to develop an approach that addresses the problem. In this paper we describe the notion of abstraction and the technical problems associated with multiple levels of abstraction how abstractions affect different activities during the simulation modeling process a preliminary approach for addressing the problems associated with multiple levels of abstraction the conceptual architecture of a simulation modeling environment that implements the proposed approach and a summary of the research on questions of abstraction in simulation.,10.1.1.1.1812,?,?
Quality of Service Adaptation in Data Stream Management Systems: A Control-Based Approach,Yi-Cheng Tu Yuni Xia Sunil Prabhakar,?,Unlike snapshot queries in traditional  databases the processing of continuous  queries in Data Stream Management Systems  (DSMSs) needs to satisfy user-specified QoS  requirements. In this paper we focus on  three major QoS parameters in a DSMS environment:   processing delay querying frequency  and loss tolerance. To minimize processing  delays the Earliest Deadline First (EDF)  CPU scheduling policy is recommended.,10.1.1.1.1813,?,?
Business process modelling and . . . ,Vlatka Hlupic Stweart Robinson,1998,Globalisation and competitive pressure urge many organisations to radically change business processes. Although this approach can provide significant benefits such as reducing costs or improving efficiency there are substantial risks associated with it. Using simulation for modelling and analysis of business processes can reduce that risk and increase the chance for success of Business Process Re-engineering projects. This paper investigates the potential of simulation modelling to be used for modelling business processes and supports the case for a wider use of simulation techniques by the business community. Following a discussion on business process modelling methods and tools the usability of simulation modelling for evaluating alternative business process strategies is investigated. Examples of simulation models representing business processes are presented and discussed.,10.1.1.1.1814,?,?
Individuality of Numerals,Sargur Srihari Catalin Sargur N. Srihari Catalin I. Tomai Bin Zhang Sangjik Lee,2003,The analysis of handwritten documents from the viewpoint of determining their writership has great bearing on the criminal justice system. In many cases only a limited amount of handwriting is available and sometimes it consists of only numerals. Using a large number of handwritten numeral images extracted from about 3000 samples written by 1000 writers a study of the individuality of numerals for identification/verification purposes was conducted. The individuality of numerals was studied using cluster analysis. Numerals discriminability was measured for writer verification. The study shows that some numerals present a higher discriminatory power and that their performances for the verification/identification tasks are very different.,10.1.1.1.1815,?,IEEE Computer Society
Corpus-Based Terminology Extraction Applied to Information Access,Anselmo Penas Felisa Verdejo Julio Gonzalo,2001,This paper presents an application of corpus-based terminology extraction in interactive information retrieval. In this approach the terminology obtained in an automatic extraction procedure is used without any manual revision to provide retrieval indexes and a browsing by phrases facility for document accessing in an interactive retrieval search interface. We argue that the combination of automatic terminology extraction and interactive search provides an optimal balance between controlled-vocabulary document retrieval (where thesauri are costly to acquire and maintain) and free text retrieval (where complex terms associated to domain specific concepts are largely overseen).,10.1.1.1.1816,?,?
Experimental Studies of Data Transport and Data,Access Of Earth Robert L. Grossman Yunhong Gu David Hanley Xinwei Hong Parthasarathy Krishnaswamy,?,Although the amount of earth science data is growing rapidly as is  the availability of high performance networks our ability to access large  remote earth science data sets is still very limited. This is particularly  true of networks with high bandwidth delay products (BDP) such as  those between the US and Europe. Recently several network protocols  have emerged that improve the situation and hold the promise of  being much more e#ective than striped TCP. (In striped TCP data  is striped across multiple TCP streams). In this paper we report on  experimental studies using one of these new protocols called UDT and  compare UDT to other approaches. In addition we consider the effectiveness  of these new protocols when reading and writing data from  disk over high BDP networks. We also consider the problem of accessing  remote data by attribute over these same networks. We show that  with the appropriate protocol accessing data across the Atlantic can  be improved significantly. We note that the UDT protocol used here  can be deployed as an application library for earth science applications  and neither requires upgrades to existing network infrastructure such  as routers nor to the Linux kernels on the servers involved.,10.1.1.1.1817,?,?
Retrieving Japanese specialized terms and corpora from the World Wide Web,Marco Baroni  Motoko Ueyama,2004,The BootCaT toolkit (Baroni and Bernardini 2004) is a suite of perl programs implementing a procedure to bootstrap specialized corpora and terms from the web using minimal knowledge sources. In this paper we report ongoing work in which we apply the BootCaT procedure to a Japanese corpus and term extraction task in the hotel terminology domain. The results of our experiments are very encouraging indicating that the BootCaT procedure can be successfully applied with relatively small modifications to a language very different from English and the other Indo-European languages on which we tested the procedure originally.,10.1.1.1.1819,?,?
Energy-Balanced Task Allocation for Collaborative Processing in Wireless Sensor Networks,Yang Yu Viktor K. Prasanna,2005,We propose an energy-balanced allocation of a real-time application onto a single-hop cluster of homogeneous  sensor nodes connected with multiple wireless channels. An epoch-based application consisting of a set of communicating  tasks is considered. Each sensor node is equipped with discrete dynamic voltage scaling (DVS). The time and  energy costs of both computation and communication activities are considered. We propose both an Integer Linear  Programming (ILP) formulation and a polynomial time 3-phase heuristic. Our simulation results show that for small  scale problems (with # ## tasks) up to 5x lifetime improvement is achieved by the ILP-based approach compared  with the baseline where no DVS is used. Also the 3-phase heuristic achieves up to 63% of the system lifetime  obtained by the ILP-based approach. For large scale problems (with 60 - 100 tasks) up to 3.5x lifetime improvement  can be achieved by the 3-phase heuristic. We also incorporate techniques for exploring the energy-latency tradeoffs of  communication activities (such as modulation scaling) which leads to 10x lifetime improvement in our simulations.,10.1.1.1.1820,?,?
A Model-driven Development Environment for Composing and Validating Distributed Real-time and Embedded Systems: A Case Study,Gabriele A. Trombetti Aniruddha Gokhale Douglas C. Schmidt,2005,Model-driven development (MDD) processes are increasingly being used to develop component middleware and applications for distributed real-time and embedded (DRE) systems in various domains. DRE applications are often missioncritical and have stringent quality of service (QoS) requirements such as timeliness predictability and scalability. MDD software techniques are well suited for validating the operation of DRE applications since they offer a higher-level of abstraction than conventional third-generation programming languages. The state-of-the-art in model-driven DRE application development is still maturing however. For example conventional MDD development environments for DRE application do not yet provide seamless integration of development capabilities and model checking capabilities.,10.1.1.1.1821,Distributed Real-time and Embedded Systems Component Middleware Model-driven Systems Model checking. ? Submitted to Model-driven Software Development- Volume II of,Springer-Verlag
Finding Optimal Views for 3D Face Shape Modeling,Jinho Lee Baback Jinho Lee Baback Moghaddam Hanspeter Pfister Raghu Machiraju,2004,A fundamental problem in multi-view 3D face modeling is the determination of the set of optimal views required for accurate 3D shape estimation for a generic face. There is no analytical solution to this problem instead (partial) solutions require (near) exhaustive combinatorial search hence the inherent computational difficulty. We build on our previous modeling framework which uses an efficient contour-based silhouette method and extend it by aggressive pruning of the view-sphere with view clustering and various imaging constraints. A multi-view optimization search is performed using both model-based (eigenheads) and data-driven (visual hull) methods yielding comparable best views. These constitute the first reported set of optimal views for silhouette-based 3D face shape capture and provide useful empirical guidelines for the design of 3D face recognition systems.,10.1.1.1.1822,?,?
Generic Simulation Models of Reusable Launch Vehicles,E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Martin Steele,2002,Analyzing systems by means of simulation is necessarily a time consuming process. This becomes even more pronounced when models of multiple systems must be compared. In general and even more so in todays fast-paced environment competitive pressure does not allow for waiting on the results of a lengthy analysis. That competitive pressure also makes it more imperative that the processing performance of systems be seriously considered in the system design. Having a generic model allows one model to be applied to multiple systems in a given domain and provides a feedback mechanism to systems designers as to the operational impact of design decisions.,10.1.1.1.1824,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,The concept of web services represent the next generation of architectures for interoperability between software applications based on software industry standards. Presented here is an overview of web services a discussion of the use of web services in the context of simulation and a demonstration of the use of web services for simulation as implemented in the Microsoft .Net software development and execution framework. The paper focuses on the vital role of industry standards in the definition and implementation of web services and relates this to the opportunities and challenges for similar standards and benefits for interoperability in simulation software.,10.1.1.1.1825,SIMULATION WEB SERVICES WITH.NET TECHNOLOGIES,?
Blow-up and stability of semilinear PDEs with gamma generator,Jose Alfredo Lopez-Mimbela  Nicolas Privault,2004,We investigate finite-time blow-up and stability of semilinear partial differential  equations of the form @w t =@t = w t +t      t  w 0 (x) = (x)  0 x 2 R+   where is the generator of the standard gamma process and   0  2 R   0 are constants. We show that any initial value satisfying c 1 x     (x)  x  x 0 for some positive constants x 0  c 1  a 1  yields a non-global solution if  a 1   1 +  or if a 1   = 1 +  and   1. If (x)  c 2 x     x  x 0  where  x 0  c 2  a 2  0 and a 2   1 +  then the solution w t is global and satis  es  0  w t (x)  Ct     x  0 for some constant C  0. This extends the results  previously obtained in the case of -stable generators. Systems of semilinear  PDEs with gamma generators are also considered.,10.1.1.1.1826,?,?
A New GPCA Algorithm for Clustering Subspaces by Fitting Differentiating and Dividing Polynomials,Rene Vidal Yi Ma Jacopo Piazzi,2004,We consider the problem of clustering data lying on multiple subspaces of unknown and possibly different dimensions. We show that one can represent the subspaces with a set of polynomials whose derivatives at a data point give normal vectors to the subspace associated with the data point. Since the polynomials can be estimated linearly from data subspace clustering is reduced to classifying one point per subspace. We do so by choosing points in the data set that minimize a distance function. A basis for the complement of each subspace is then recovered by applying standard PCA to the set of derivatives (normal vectors) at those points. The final result is a new GPCA algorithm for subspace clustering based on simple linear and polynomial algebra. Our experiments show that our method outperforms existing algebraic algorithms based on polynomial factorization and provides a good initialization to iterative techniques such as K-subspace and EM. We also present applications of GPCA on computer vision problems such as vanishing point detection face clustering and news video segmentation.,10.1.1.1.1827,?,?
Performance Investigation of an On-Line,Auction System Jane Jane Hillston Leïla Kloul,2001,The standard design of on-line auction systems places most of the computational  load on the server and its adjacent links resulting in a bottleneck in  the system. In this paper we investigate the impact in terms of the performance  of the server and its adjacent links of introducing active nodes into the  network. The performance study of the system is done using the stochastic  process algebra formalism PEPA.,10.1.1.1.1829,?,?
A Performance Comparison of NFS and iSCSI for IP-Networked Storage,Peter Radkov  Li Yin  Pawan Goyal Prasenjit Sarkar Prashant Shenoy,2004,IP-networked storage protocols such as NFS and  iSCSI have become increasingly common in today  s LAN environments. In this paper we experimentally  compare NFS and iSCSI performance  for environments with no data sharing across machines.,10.1.1.1.1830,?,?
A Comparative Analysis Of Two Approaches Using The Road,Network For Tracking Stéphane Gattein Patrick Vannoorenberghe,?,This paper examines two multiple ground target tracking methods. Their specificity is that they use the road network as additional prior geographical information to further refine the targets state estimation. The first method is based on belief functions theory for associating measurements to predictions as well as for determining the road segment relative to an existing target. The second method uses a Variable Structure Interacting Multiple Model method integrated in a Multiple Hypothesis Tracking framework (MHT VS-IMM). Finally both approaches are compared suggesting the possibility of using the advantages of the evidential approach inside the well established MHT framework.,10.1.1.1.1831,Information fusion ground target tracking road network prior,?
Long Range Contacts in Overlay Networks with Unbalanced Node Distribution,Filipe Araujo Filipe Araújo  Luis Rodrigues Luís Rodrigues,2004,A fundamental aspect in the design of overlay networks is the path length/node degree  trade-o#. Previous research has shown that it is possible to achieve logarithmic path lengths  for logarithmic or even constant node degree. While nearby contacts with nodes that have  close identifiers ensure a connected lattice of nodes short path lengths demand for the use  of long range contacts. In this respect previous work exhibits limitations in scenarios where  node distribution is unbalanced: either short path length properties do not hold or may require  node degree and/or signaling to grow with respect to the virtual identification space  instead of the number of nodes (which is usually several order of magnitudes smaller).,10.1.1.1.1832,?,?
Transaction Patterns,Collection Of Four Figure Pattern Map,?,This paper contains some transaction related patterns from my forthcoming book Patterns in Java Volume 3: Design Patterns for Enterprise and Distributed Applications. A transaction is a sequence of operations that change the state of an object or collection of objects in a well defined way. Transactions are useful because they satisfy constraints about what the state of an object must be before after or during a transaction. For example a particular type of transaction may satisfy a constraint that an attribute of an object must be greater after the transaction than it was before the transaction. Sometimes the constraints are unrelated to the objects that the transactions operate on. For example a transaction may be required to take place in less than a certain amount of time. The patterns in this chapter provide guidance in selecting and combining constraints for common types of transactions. Figure 1 shows how the patterns in this chapter build on each other. Composite Transaction ACID Transaction Two Phase Commit Audit Trail Figure 1: Pattern Map  The first and most fundamental pattern to read is the ACID Transaction pattern. It describes how to design transactions that never have inconsistent or unexpected outcomes. The Composite pattern describes how to compose a complex transaction from simpler transactions. The Two Phase commit pattern describes how to ensure that a composite transaction is atomic. The Audit Trail pattern describes how to maintain an historical of ACID transactions. You may notice the lack of code examples in this paper. It is the authors opinion that the patterns in this paper are too high level for concrete code examples to be useful. The application of these transaction related patterns can be readily understood at the design level. How...,10.1.1.1.1833,?,?
On the Adequateness of Emergency Exit Panel And Corridor . . . ,E. Lazkano A. Astigarraga B. Sierra I. Rañó,2004,There are different approaches to mobile robot navigation. Landmark-based  localization has shown to be the alternative to simple dead-reckoning but often landmarks  are environmental specific and recognition algorithms are computationally very  expensive. This paper presents an approach to landmark-based navigation using emergency  exit pannels and corridors as cues without odometric information. Experiments  are carried out to verify appart each landmark identification subsystem and both behaviors  are combined together in a complete path through the environment.,10.1.1.1.1835,Robot Navigation Landmark Recognition Behavior-Based Systems Neural nets Autonomous Systems,?
A General Theory for the Evolution of Application Models,H.A. Proper  Th.P. van der Weide ,1995,In this article we focus on evolving information systems. First a delimitation of the concept of  evolution is provided resulting in a first attempt to a general theory for such evolutions. The theory,10.1.1.1.1836,?,?
Exploring Case-Based Bayesian Networks and Bayesian Multi-nets for Classification,Ahmed Hussein  Eugene Santos Jr.,2004,Recent work in Bayesian classifiers has shown that a better and more flexible representation of domain knowledge results in better classification accuracy. In previous work [1] we have introduced a new type of Bayesian classifier called Case-Based Bayesian Network (CBBN)  classifiers. We have shown that CBBNs can capture finer levels of semantics than possible in traditional Bayesian Networks (BNs). Consequently our empirical comparisons showed that CBBN classifiers have considerably improved classification accuracy over traditional BN classifiers. The basic idea behind our CBBN classifiers is to intelligently partition the training data into semantically sound clusters. A local BN classifier can then be learned from each cluster separately. Bayesian Multi-net (BMN) classifiers also try to improve classification accuracy through a simple partitioning of the data by classes. In this paper we compare our CBBN classifiers to BMN classifiers. Our experimental results show that CBBN classifiers considerably outperform BMN classifiers. 1 ,10.1.1.1.1837,?,?
Diagnosing Network-Wide Traffic Anomalies,Anukool Lakhina  Mark Crovella  Christophe Diot,2004,Anomalies are unusual and significant changes in a networks traffic levels which can often span multiple links. Diagnosing anomalies is critical for both network operators and end users. It is a difficult problem because one must extract and interpret anomalous patterns from large amounts of high-dimensional noisy data.,10.1.1.1.1838,Measurement Performance Security,?
IEEE COMMUNICATIONS LETTERS VOL. 3 NO. 3 MARCH 1999 57 Average SNR of a Generalized Diversity,Selection Combining Scheme Ning Kong Laurence B. Milstein,1998,The average signal-to-noise ratio (SNR) of a generalized selection combining scheme in which the  m  diversity branches (m  L    L  is the total number of diversity branches available) with the largest instantaneous SNRs are selected and coherently combined is derived. A Rayleigh fading channel is assumed and a simple closed-form expression for the SNR is found which is upper bounded by the average SNR of maximal ratio combining and lower bounded by average SNR of conventional selection combining.,10.1.1.1.1840,?,?
Improving Spatial Reuse of IEEE 802.11 Based,Ad Hoc Networks,?,In this paper we evaluate and suggest methods to improve the performance of IEEE 802.11 based ad hoc networks from the perspective of spatial reuse. Since 802.11 employs virtual carrier sensing to reserve the medium prior to a packet transmission the relative size of the spatial region it reserves for the impending traffic significantly affects the overall network performance. We show that the space reserved by 802.11 for a successful transmission is far from optimal and depending on the one hop distances between the sender and the receiver we can have three scenarios with very different spatial reuse characteristics. We also introduce a new quantitative measure the spatial reuse index to evaluate the efficiency of the medium reservation accomplished by 802.11 virtual carrier sensing. We also propose an improved virtual carrier sensing mechanism for wireless LAN scenarios and using analysis and simulation results show that it can significantly increase the spatial reuse and network throughput.,10.1.1.1.1841,?,?
An Experimental Analysis Of Cryptographic Overhead In,Performance-Critical Systems William William Freeman Ethan Miller,1999,This paper studies the performance implications of using cryptographic controls in performance-critical systems. Full cryptographic controls beyond basic authentication are considered and experimentally validated in the concept of network file systems. This paper demonstrates that processor speeds have recently become fast enough to support cryptographic controls in many performance-critical systems. Integrity and authentication using keyed-hash and RSA as well as confidentiality using RC5 are tested. This analysis demonstrates that full cryptographic controls are feasible in a distributed network file system by showing the performance overhead for including signature hash and encryption algorithms on various embedded and workstation computers. The results from these experiments are used to predict the performance impact using three proposed network disk security schemes.,10.1.1.1.1842,?,?
Informedia at PDMC,Wei-Hao Lin Whlin Wei-hao Lin Alexander Hauptmann,2004,Introduction  Our Digial Human Memory project (Lin  Hauptmann 2002) aims to collect and index every aspect of human daily experiences in digital form. By wearing a spy camera microphones and a BodyMedia armband the wearer can collect rich records in a unobtrutive fashion and many applications can build on top of such multimodal collections. For example digital human memory can serve as a memory prosthesis to help the wearer recall past events the habits or anomalies of the wearer can be analyzed from digital human memory. The physiological recordings recorded by a Bodymedia armband provides complementary dimensions of the wearers experiences and play an important role in identifying wearers context and activities. In this year Physiological Data Modeling Contest we build a baseline system that models the gender and context tasks as simple binary classification problems using only unambiguous annotations. In addition we explore two issues. First instead of ignoring ambiguo,10.1.1.1.1843,?,?
Team Dynamo-Pavlov Uppsala,Paul Pettersson Olle Gällmo Pahram Azimi Rani Khalil Martin Tillenius Arsenij Vodjanov Samuel Waxin,?,Team Dynamo-Pavlov of Uppsala is an e#ort at the Department  of Information Technology at Uppsala University in Sweden to  establish a soccer team in the four legged league of Robocup. The core  develoment team of the project is a group of 4th year computer science  students taking a project course in the fall of 2002. In 2003 a smaller  group of students have been working with the code to compete in German  Open and Robocup 2003.,10.1.1.1.1845,?,?
Spectral LPM: An Optimal Locality-Preserving Mapping using the Spectral (not Fractal) Order,Mohamed Mokbel Walid Walid G. Aref Ananth Grama,?,For the past two decades fractals (e.g. the Hilbert and Peano space-filling curves) have been considered the natural method for providing a locality-preserving mapping. The idea behind a locality-preserving mapping is to map points that are nearby in the multi-dimensional space into points that are nearby in the one-dimensional space. In this paper we argue against the use of fractals in locality-preserving mapping algorithms and present examples with experimental evidence to show why fractals produce poor locality-preserving mappings. In addition we propose an optimal locality-preserving mapping algorithm termed the Spectral Locality-Preserving Mapping algorithm (Spectral LPM for short) that makes use of the spectrum of the multi-dimensional space. We give a mathematical proof for the optimality of Spectral LPM and also demonstrate its practical use.,10.1.1.1.1846,?,?
Human Evaluation of Kea an Automatic Keyphrasing System,Steve Jones  Gordon W. Paynter,2001,This paper describes an evaluation of the Kea automatic keyphrase extraction algorithm. Tools that automatically identify keyphrases are desirable because document keyphrases have numerous applications in digital library systems but are costly and time consuming to manually assign. Keyphrase extraction algorithms are usually evaluated by comparison to author-specified keywords but this methodology has several well-known shortcomings. The results presented in this paper are based on subjective evaluations of the quality and appropriateness of keyphrases by human assessors and make a number of contributions. First they validate previous evaluations of Kea that rely on author keywords. Second they show Keas performance is comparable to that of similar systems that have been evaluated by human assessors. Finally they justify the use of author keyphrases as a performance metric by showing that authors generally choose good keywords.,10.1.1.1.1847,Algorithms Performance Experimentation. Keywords keyphrase extraction author keyphrases digital libraries subjective evaluation user interface,?
Mapping physical artifacts to their Web counterparts: A Case Study,Greg Murdoch  Nicholas Kushmerick,2004,directories etc---exist in both a physical (paper) and virtual (Web) form. Few approaches to knowledgment management and digital libraries fully exploit the opportunities a#orded by this fact. Motivated by the goal of seamless integration of physical artifacts and their Web counterparts we describe a large-scale case study of one aspect of this relationship. Based on a corpus of hundreds of real-world product catalogs we measure the e#ectiveness of hand-held scanner /OCR devices for the task of automatically retrieving a catalogs authoritative Web counterpart (the vendors home page). We find that despite OCR errors text fragments scanned from product catalogs can serve as reasonably effective queries for retrieving the Web counterparts. Furthermore the e#ectiveness of the technique increases with multiple scanned text fragments. Our main technical contribution is a novel machine learning approach to adaptively merging the retrieved documents from multiple scans.,10.1.1.1.1848,?,?
A Multiple-objectives Evolutionary Perspective to Interdomain Traffic Engineering,Steve Uhlig,2004,We present an application of multiple-objectives evolutionary optimization to the problem of engineering the distribution of the interdomain traffic in the Internet. We show that this practical problem requires such a heuristic due to the potential conflicting nature of the traffic engineering objectives. Furthermore having to work on the parameters space of the real problem makes such techniques as evolutionary optimization very easy to use. We show the successful application of our algorithm to two important problems in interdomain traffic engineering.,10.1.1.1.1849,?,?
Enabling Knowledge Representation on the Web by Extending RDF Schema,Jeen Broekstra Michel Klein Stefan Decker Dieter Fensel Frank van Harmelen Ian Horrocks,2001,Recently there has been a wide interest in using ontologies on the Web. As a basis for this RDF Schema (RDFS) provides means to define vocabulary structure and constraints for expressing metadata about Web resources. However formal semantics are not provided and the expressivity of it is not enough for full-fledged ontological modeling and reasoning. In this paper we will show how RDFS can be extended in such a way that a full knowledge representation (KR) language can be expressed in it thus enriching it with the required additional expressivity and the semantics of this language. We do this by describing the ontology language OIL as an extension of RDFS. An important benefit of our approach is that it ensures maximal sharing of meta-data on the Web: even partial interpretation of an OIL ontology by less semantically aware processors will yield a correct partial interpretation of the meta-data. We conclude that our method of extending is equally applicable to other KR formalisms.,10.1.1.1.1850,?,?
Resilience for Autonomous Agents,Matthew M. Williamson Miranda Mowbray A Mowbray Matthew Williamson,2003,In this paper we show how the resilience approach can give a generic  solution to the problems of looping and high-bandwidth output in autonomous  agents. A resilient approach to looping is for the agent to delay responding again  to a source that has recently triggered a task. A resilient approach to high-bandwith  output is for the agent to delay output when the overall noise level in the environment  is high. The conditions under which the delays are triggered may be  determined by data on past system behaviour. Our generic approach allows agents  to limit themselves without requiring them to perform semantic analyses.,10.1.1.1.1851,?,?
Systematic Change Management in Dimensional Data Warehousing,R. Bliujute S. Saltenis G. Slivinskas C. S. Jensen,1998,With the widespread and increasing use of data warehousing in industry the design of effective  data warehouses and their maintenance has become a focus of attention. Independently of this  the area of temporal databases has been an active area of research for well beyond a decade. This,10.1.1.1.1852,?,?
Construction of Equiangular Signatures for Synchronous CDMA Systems,Robert W. Heath Jr.  Joel A. Tropp et al.,2004,Welch bound equality (WBE) signature sequences maximize the uplink sum capacity in direct-spread synchronous code division multiple access (CDMA) systems. WBE sequences have a nice interference invariance property that typically holds only when the system is fully loaded and the signature set must be redesigned and reassigned as the number of active users changes to maintain this property. An additional equiangular constraint on the signature set however maintains interference invariance. Finding such signatures requires imposing equiangular side constraints on an inverse eigenvalue problem. This paper presents an alternating projection algorithm that can design WBE sequences that satisfy equiangular side constraints. The proposed algorithm can be used to find Grassmannian frames as well as equiangular tight frames. Though one projection is onto a closed but non convex set it is shown that this algorithm converges to a fixed point and these fixed points are partially characterized.,10.1.1.1.1853,?,?
Genome Informatics 14: 553--554 (2003) 553 A Consensus Transmembrane Topology Prediction,Method Of High-Reliability Jun-xiong Xia Toshio Shimizu,?,Introduction  It has been revealed that the function of transmembrane (TM) proteins (20-30% in most genomes [1]) can be classified and identified with the information of its TM topologies i.e. the number of TM segments (TMSs) the position of TMS and the orientation of the TMS to the membrane lipid bilayer [6]. Therefore developing the TM topology prediction method with high reliability is critical task for the elucidation of TM protein functions. Although many TM topology prediction methods have been proposed the prediction accuracies of these methods are still not high enough i.e. at most 50-60% as to whole TM topology [3]. In this study we propose a new consensus approach (ConPred elite) with reliabilities of 0.98 and 0.95 for prokaryotic and eukaryotic TM protein sequences respectively by combining the results from five currently used TM topology prediction methods. We applied this method to TM proteins extracted from 87 prokaryotic and 12 eukaryotic proteomes.  2 Material,10.1.1.1.1855,transmembrane protein transmembrane topology prediction consensus approach high reliability genome-wide,?
Papyrus: A System for Data Mining over Local and Wide Area Clusters and Super-Clusters,S. Bailey  Robert Grossman A. Ramu B. Malhi  H. Sivakumar H. Sivakumar  A. Turinsky A. Turinsky Papyrus A,1999,this paper we introduce a system called Papyrus for distributed data mining over commodity and high performance networks and give some preliminary experimental results about its performance. We are particularly interested in data mining over clusters of workstations distributed clusters connected by high performance networks (super-clusters) and distributed clusters and super-clusters connected by commodity networks (meta-clusters),10.1.1.1.1856,?,?
Spacewalker: Automated Design Space Exploration for,Embedded Computer Systems Greg Snider,2001,This paper addresses the problem of automated design of a  computer system for an embedded application. The computer  system to be designed consists of a VLIW processor and/or a  customized systolic array along with a cache subsystem  comprising a data cache instruction cache and second-level  unified cache. Several algorithms for walking the design space  are described and experimental results of custom designed  systems for two applications are presented,10.1.1.1.1857,s,?
Blind Iterative Decision Feedback Equalizers for Block QAM Transmission Systems,Roberto Lopez-Valcarce,?,A novel blind initialization procedure for iterative decision feedback equalizers in block-based transmission systems is proposed and investigated. It relies on an initial stage using Regalias blockbased Constant Modulus iterative algorithm for the blind computation of a linear equalizer then a switch to decision feedback mode is performed. It is shown how the building blocks of the decision feedback equalizer (feedforward and feedback filters automatic gain control and phase rotation) can be blindly estimated. Due to the unknown lag introduced by the blind linear equalizer delay synchronization of the feedforward and feedback filters is also required. These filters are then refined over successive decision feedback iterations. This approach can also be used as a blind channel identifier for other block receiver designs such as soft ISI cancelers and decoder-aided (i.e. turbo) equalizers. 1. ,10.1.1.1.1858,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,AweSim# is a general-purpose simulation system which  takes advantage of Windows# technology to integrate programs  and provide componentware. AweSim includes the   Visual SLAM# simulation language to build network   subnetwork discrete event and continuous models. Network  models require no programming yet allow user-coded  inserts in Visual Basic or C. Discrete event and continuous  models can be created using the object-oriented technology  of Visual Basic C or Visual C++ and can be combined  with network models. This tutorial will demonstrate the  process of using AweSims componentware describe examples  of user interfaces that allow integration with other   applications and present a sample model.   1 ,10.1.1.1.1859,?,?
Predictable Configuration Management in a Randomized Scheduling Framework,Mark Burgess  Frode Eika Sandnes Frode Eika S,2001,Configuration management is an essential...This article addresses security in configuration management systems and proposes strategies for increasing security by randomized scheduling of actions constrained by a set of precedence relations...,10.1.1.1.1860,Configuration management security scheduling randomization,?
Geometric Travel Planning,Stefan Edelkamp  Shahid Jabbar Thomas Willhalm ,2003,This paper provides a novel approach for optimal route planning making efficient use of the underlying geometrical structure. It combines classical AI exploration with computational geometry. Given a set,10.1.1.1.1862,?,?
Rate Quantization and Service Quality over Single Crossbar Switches,Can Emre Koksal  Robert G. Gallager Charles E. Rohrs,2004,We study the provision of deterministic rate guarantees over single crossbar switches. Birkhoff decomposition yields a general approach for this problem but the required complexity can be very high and the quality of service can be unsatisfactory for practical traffic sources.,10.1.1.1.1863,?,?
Beyond Prototypes: Challenges in Deploying Ubiquitous Systems,Nigel Davies Hans-werner Gellersen,2002,developments such as the increasingly widespread acceptance of video surveillance in public places. However the decades most striking developments (with respect to ubiquitous computing) have undoubtedly been the emergence of the Web as a global information and service resource and the widespread adoption of digital mobile telephony letting users experience nearly ubiquitous wireless communications.  The World Wide Web  The Webs emergence has fundamentally changed the way many people interact with computers. It has also created a culture that is substantially more amenable to the deployment of ubiquitous computing environments than that which existed when Weiser first articulated his vision.  Most obviously the Web has created a nearly ubiquitous information and communications infrastructure. We can now access a huge wealth of knowledge and services from almost any computer including low-power mobile devices such as smart phones and PDAs. However the Web has had other more subtl,10.1.1.1.1864,?,?
Retrieving ClipArt Images by Content,Manuel Fonseca Barroso Manuel J. Fonseca B. Barroso P. Ribeiro Joaquim A. Jorge,2004,Nowadays there are a lot of vector drawings available for inclusion into documents which tend to be achieved and accessed by categories. However to find a drawing among hundreds of thousands is not easy. While text-driven attempts at classifying image data have been recently supplemented with query-by-image content these have been developed for bitmap-type data and cannot handle vectorial information. In this paper we present an approach to index and retrieve ClipArt images by content using topological and geometric information automatically extracted from drawings. Additionally we introduce a set of simplification heuristics to eliminate redundant information and useless elements.,10.1.1.1.1865,?,Springer-Verlag
dPAM: A Distributed Prefetching Protocol for Scalable Asynchronous Multicast in P2P Systems,Abhishek Sharma Azer Bestavros Ibrahim Matta,2004,We leverage the buffering capabilities of end-systems to achieve scalable asynchronous delivery of streams in a peer-to-peer environment. Unlike existing cache-and-relay schemes we propose a distributed prefetching protocol where peers prefetch and store portions of the streaming media ahead of their playout time thus not only turning themselves to possible sources for other peers but their prefetched data can allow them to overcome the departure of their source-peer. This stands in sharp contrast to existing cache-and-relay schemes where the departure of the source-peer forces its peer children to go the original server thus disrupting their service and increasing server and network load. Through mathematical analysis and simulations we show the effectiveness of maintaining such asynchronous multicasts from several source-peers to other children peers and the efficacy of prefetching in the face of peer departures. We confirm the scalability of our dPAM protocol as it is shown to significantly reduce server load.,10.1.1.1.1866,?,?
Efficient Simulations for . . . ,Jeremy Staum,2003,This paper presents an overview of techniques for improving the efficiency of option pricing simulations including quasiMonte Carlo methods variance reduction and methods for dealing with discretization error.,10.1.1.1.1867,?,?
An In-Silico Method for Prediction of Polyadenylation Signals in Human Sequences,Huiqing Liu Hao Han Jinyan Li Limsoon Wong,2003,This paper presents a machine learning method to predict polyadenylation signals (PASes) in  human DNA and mRNA sequences by analysing features around them. This method consists of  three sequential steps of feature manipulation: generation selection and integration of features. In  the first step new features are generated using k-gram nucleotide acid or amino acid patterns. In  the second step a number of important features are selected by an entropy-based algorithm. In the  third step support vector machines are employed to recognize true PASes from a large number of  candidates. Our study shows that true PASes in DNA and mRNA sequences can be characterized  by di#erent features and also shows that both upstream and downstream sequence elements are  important for recognizing PASes from DNA sequences. We tested our method on several public  data sets as well as our own extracted data sets. In most cases we achieved better validation  results than those reported previously on the same data sets. The important motifs observed are  highly consistent with those reported in literature.,10.1.1.1.1869,polyadenylation signals machine learning feature selection support vector machines,?
Using Formal Tools to Study Complex Circuits Behaviour,Paul Amblard Tima-Cmp Paul Amblard Fabienne Lagnier Michel Lévy Université Joseph Fourier,2002,We use a formal tool to extract Finite State Machines (FSM) based representations (lists of states and transitions) of sequential circuits described by flip-flops and gates. These complete and optimized representations helps the designer to understand the accurate behaviour of the circuit. This deep understanding is a prerequisite for any verification or test process. An example is fully presented to illustrate our method. This simple pipelined processor comes from our experience in computer architecture and digital design education. ([2])  1. ,10.1.1.1.1871,?,?
Estimation of DeltaSigma converter spectrum,Emilia Nunzi Paolo Carbone Dario Petri E. Nunzi P. Carbone D. Petri,?,Effects of the windowing process widely investigated by the scientific literature for narrow--band components embedded in white noise is not sufficiently detailed when signals are corrupted by colored noise. Such a phenomenon can  heavily affect the spectral parameters estimation of the noisy signal. In this paper effects of the windowing on the output of analog--to--digital converters with ## topology which present a spectrally shaped quantization noise is analyzed. In particular the spectral leakage of both narrow-- and wide-- band components is investigated and a criterion for choosing the most appropriate window for any given modulator resolution is given. The proposed analysis validates the use of the Hanning sequence as the optimum two term cosine window to be employed for characterizing low order ## modulators.,10.1.1.1.1872,?,?
Uncertain Reasoning and Forecasting,Paul Dagum  Adam Galper Eric Horvitz Adam Seiver,1995,We develop a probability forecasting model through a synthesis of Bayesian beliefnetwork  models and classical time-series analysis. By casting Bayesian time-series analyses  as temporal belief-network problems weintroduce dependency models that capture richer  and more realistic models of dynamic dependencies. With richer models and associated  computational methods we can movebeyond the rigid classical assumptions of linearityin  the relationships among variables and of normality of their probability distributions.,10.1.1.1.1873,probability forecasting Bayesian belief networks critical care,?
Detection of Matrices and Segmentation of Matrix Elements,In Scanned Images Kanahori Toshihiro,?,We proposed a method for recognizing matrices which contain abbreviation symbols and a format for representing the structure of matrices and reported experimental results in our paper [1]. The method consisted of 4 processes detection of matrices segmentation of elements construction of networks and analysis of the matrix structure. In the paper our work was described with a focus on the construction of networks and the analysis of the matrix structure. However we concluded that improvements in the other two processes were very important for obtaining a high accuracy rate for recognition. In this paper we describe the two improved processes the detection of matrices and the segmentation of elements and we report the experimental results.,10.1.1.1.1875,?,?
Symbolic Modeling of Structural Relationships in the Foundational Model of Anatomy,Jose L.V. Mejino  Jr.  Cornelius Rosse D. Sc,2004,The need for a sharable resource that can provide deep anatomical knowledge and support inference for biomedical applications has recently been the driving force in the creation of biomedical ontologies. Previous attempts at the symbolic representation of anatomical relationships necessary for such ontologies have been largely limited to general partonomy and class subsumption. We propose an ontology of anatomical relationships beyond class assignments and generic part-whole relations and illustrate the inheritance of structural attributes in the Digital Anatomist Foundational Model of Anatomy. Our purpose is to generate a symbolic model that accommodates all structural relationships and physical properties required to comprehensively and explicitly describe the physical organization of the human body.,10.1.1.1.1876,Ontology Knowledge representation Spatial reasoning Mereotopology Partonomy Anatomy 1,?
Mayday: Distributed Filtering for Internet Services,David G. Andersen  ,2003,Mayday is an architecture that combines overlay networks with lightweight packet filtering to defend against denial of service attacks. The overlay nodes perform client authentication and protocol verification and then relay the requests to a protected server. The server is protected from outside attack by simple packet filtering rules that can be efficiently deployed even in backbone routers. Mayday generalizes,10.1.1.1.1877,?,?
Improving Throughput and Maintaining Fairness Using Parallel Tcp,Thomas J. Hacker  Brian D. Noble  Brian D. Athey,2004,Applications that require good network performance often use parallel TCP streams and TCP modifications to improve the effectiveness of TCP. If the network bottleneck is fully utilized this approach boosts throughput by unfairly stealing bandwidth from competing TCP streams. Improving the effectiveness of TCP is easy but improving effectiveness while maintaining fairness is difficult. In this paper we describe an approach we implemented that uses a long virtual round trip time in combination with parallel TCP streams to improve effectiveness on underutilized networks. Our approach prioritizes fairness at the expense of effectiveness when the network is fully utilized. We compared our approach with standard parallel TCP over a wide-area network and found that our approach preserves effectiveness and is fairer to competing traffic than standard parallel TCP.,10.1.1.1.1878,?,?
Specialized Search in Linguistics and Languages,Zhiping Zheng And Zhiping Zheng Gregor Erbach,2002,Seven Tones    ([13]) is a search engine specialized in linguistics and  languages. Its current database which is stored on a single machine contains  approximately 240000 indexed web pages about linguistics and languages.,10.1.1.1.1879,intelligent crawling specialized search engine information retrieval automated,?
Dynamic Coupling of Binary Components and its Technical Support,Dirk Heuzeroth Ralf H. Reussner,1999,The aim of todays software development is to build applications by the reuse of binary components. This requires the composition of components and as special cases component enhancement as well as adaption. We demonstrate how to deal with these cases by furnishing components with a type consisting of two protocols --- a call and a use protocol. We model these protocols by finite automata and show how those reflect component enhancement and adaption. This mechanism allows for automatic adaption of components in changing environments. In order to,10.1.1.1.1880,?,?
Agriculture Diversification in South Asia: Patterns Determinants and Policy Implications,P.K. Joshi Ashok Gulati Pratap S. Birthal Laxmi Tewari,1999,The South Asian countries are gradually diversifying with some inter-country variation in favor of high value commodities namely fruits vegetables livestock and fisheries. Agricultural diversification is strongly influenced by price policy infrastructure development (especially markets and roads) urbanization and technological improvements. Rainfed areas have benefited more as a result of agricultural diversification in favor of high value crops by substituting inferior coarse cereals. Agricultural diversification is also contributing to employment opportunities in agriculture and increasing exports. The need is to suitably integrate production and marketing of high value commodities through appropriate institutions. Market reforms in developing and strengthening desired institutions through required legal changes would go a long way in boosting agricultural growth augmenting income of small farm holders and promoting exports.,10.1.1.1.1881,?,?
Steps Towards a Cognitive Vision System,H.-H. Nagel,2004,An adequate natural language description of developments in a real-world scene may  be taken as a proof of `understanding what is going on. An algorithmic system which  generates natural language descriptions from video recordings of road tra#c scenes may  be said to `understand its input to the extent the algorithmically generated text is acceptable  to humans judging it. A Fuzzy Metric-Temporal Horn Logic (FMTHL) provides  a formalism to represent both schematic and instantiated conceptual knowledge about  the depicted scene and its temporal development. The resulting conceptual representation  mediates in a systematic manner between the spatio-temporal geometric descriptions  extracted from video input and a module which generates natural language text. This  contribution outlines a thirty years e#ort to create such a `cognitive vision system indicates  its current status summarizes lessons learned along the way and discusses open  problems against this background.,10.1.1.1.1882,Computer Vision conceptual processing fuzzy metric-temporal logic image sequence evaluation model-based tracking optical flow system aspects text generation,Springer-Verlag
Report on the TREC 2003 Experiment: Genomic Track,Patrick Ruch Patrick Ruch Ab  Christine Chichester  Gilles Cohen  Giovanni Coray  Frederic Ehrler  Hatem Ghorbel  Henning Müller  Vincenzo Pallotta,?,this report mostly focuses on the information extraction task (task II),10.1.1.1.1883,?,?
Parameter Estimation In Pairwise Markov Fields,Dalila Benboudjema Wojciech Pieczynski,2005,Hidden Markov fields (HMF) which are widely applied in various problems arising in image processing have recently been generalized to Pairwise Markov Fields (PMF). Although the hidden process is no longer necessarily a Markov one in PMF models they still allow one to recover it from observed data. We propose in this paper two original methods of parameter estimation in PMF based on general Stochastic Gradient (SG) and Iterative Conditional Estimation (ICE) principles respectively. Some experiments concerning unsupervised image segmentation based on Bayesian Maximum Posterior Mode (MPM) are also presented.,10.1.1.1.1885,?,?
Web Data Integration for E-Commerce Applications,Wilhelm Hasselbring,2002,This article discusses  the problems and  proposes a top-down  approach to  overcome some of  the problems. A  combined yo-yo  approach aims to  exploit both  strategies benefits,10.1.1.1.1886,?,?
Achieving Proportional Delay Differentiation in Wireless LAN via Cross-Layer Scheduling,Yuan Xue Kai Chen Klara Nahrstedt,2004,Providing service differentiation in wireless networks has attracted much attention in recent research. Existing studies so far have focused on the design of differentiated media access algorithms. Some QoS metrics such as queueing delay can not be completely addressed by these approaches. Moreover without a formalized service differentiation goal that quantifies the outcome of differentiation the performance of most approaches fluctuates especially in short time-scales. This paper addresses above problems by introducing the concept of proportional service differentiation to the domain of wireless network and focuses on providing proportional delay differentiation in wireless LANs. Due to the unique characteristic of distributed medium sharing the 1 scheduling algorithm employed in wireline networks can not be applied directly to the context of wireless LANs. We argue that delay differentiation in wireless LAN can only be achieved through a joint packet scheduling at the network layer and distributed coordination at the MAC layer. Therefore we present a cross-layer waiting time priority scheduling (CWTP) algorithm. CWTP consists of two tiers: an intra-node WTP scheduler at the network layer and an inter-node distributed coordination function at the MAC layer. These two tiers coordinate via a mapping function which maps the normalized waiting time at the network layer to the backoff time at the MAC layer. Two mapping schemes namely linear mapping and piecewise linear mapping are presented and evaluated in this paper. Extensive simulation results show that the CWTP algorithm can effectively achieve proportional delay differentiation in wireless LANs.,10.1.1.1.1887,Service Differentiation Wireless LAN 2,?
Solving Factored MDPs with Continuous and Discrete Variables,Carlos Guestrin  Milos Hauskrecht Branislav Kveton,2004,Although many real-world stochastic planning problems are more naturally formulated by hybrid models with both discrete and continuous variables current state-of-the-art methods cannot adequately address these problems. We present the first framework that can exploit problem structure for modeling and solving hybrid problems efficiently. We formulate these problems as hybrid Markov decision processes (MDPs with continuous and discrete state and action variables) which we assume can be represented in a factored way using a hybrid dynamic Bayesian network (hybrid DBN). This formulation also allows us to apply our methods to collaborative multiagent settings. We present a new linear program approximation method that exploits the structure of the hybrid MDP and lets us compute approximate value functions more efficiently. In particular we describe a new factored discretization of continuous variables that avoids the exponential blow-up of traditional approaches. We provide theoretical bounds on the quality of such an approximation and on its scale-up potential. We support our theoretical arguments with experiments on a set of control problems with up to 28-dimensional continuous state space and 22-dimensional action space.,10.1.1.1.1888,?,?
Multiscale analysis of the healthcare and public health system: Organizing for achieving both effectiveness and efficiency,Yaneer Bar-Yam,2004,this paper for enabling the healthcare system to improve its capability is to unbind the large scale and complex tasks so efficient and effective organizations can be formed around these distinct tasks. Specifically we argue for two very different systems: an efficient system to deal with health issues that affect entire populations (and that can be made efficient on a large scale) and a system to address the complexities of individual medical care in an effective and error-free way. By separating simple large scale health care from complex individualized medical care we relieve physicians of tasks that can be addressed with a much higher efficiency enabling them to focus their attention on the complex tasks for which they are uniquely trained. Not only does this create a more cost-effective health care system but it also allows for a more effective and error-free medical system,10.1.1.1.1889,?,?
Reducing TCB size by using untrusted components -- small kernels versus virtual-machine monitors,Michael Hohmuth Michael Peter Hermann Härtig  Jonathan S. Shapiro,2004,Secure systems are best built on top of a small trusted operating system: The smaller the operating system the easier it can be assured or verified for correctness. In this,10.1.1.1.1890,?,ACM Press
Eulerian Derivation Of The Fractional Advection-Dispersion Equation,Rina Schumer  David A. Benson  Mark M. Meerschaert  Stephen W. Wheatcraft,2001,Z. A fractional advection--dispersion equation ADE is a generalization of the classical ADE in which the second-order derivative is replaced with a fractional-order derivative. In contrast to the classical ADE the fractional ADE has solutions that resemble the highly skewed and heavy-tailed breakthrough curves observed in field and laboratory studies. These solutions known as a-stable distributions are the result of a generalized central limit theorem which describes the behavior of sums of finite or infinite-variance random variables. We use this limit theorem in a model which sums the length of particle jumps during their random walk through a heterogeneous porous medium. If the length of solute particle jumps is not constrained to a representative elementary Z. volume REV  dispersive flux is proportional to a fractional derivative. The nature of fractional derivatives is readily visualized and their parameters are based on physical properties that are measurable. When a fractional Ficks law replaces the classical Ficks law in an Eulerian evaluation of solute transport in a porous medium the result is a fractional ADE. Fractional ADEs are ergodic equations since they occur when a generalized central limit theorem is employed. q 2001 Elsevier Science B.V. All rights reserved.,10.1.1.1.1891,Solute transport Heterogeneity Dispersivity Power law Stochastic processes Statistical distribution Corresponding author,?
Sequence Types for the pi-calculus,Sergio Maffeis,2004,We introduce channel sequence types to study finitary polymorphism in the context of mobile processes modelled in the #-calculus. We associate to each channel a set of exchange types and we require that output processes send values of one of those types and input processes accept values of all the types in the set. Our type assignment system enjoys subject reduction and guarantees the absence of communication errors. We give several examples of polymorphism and we encode the #-calculus with the strict intersection type discipline.,10.1.1.1.1892,Union Types,?
Proceedings of the 1998 Winter Simulation Conference,Ed Medeiros Watson,?,This paper describes the Visual Simulation Environment (VSE) software product. VSE has been developed under $1.3 million research funding primarily from the U.S. Navy for over a decade. It enables discrete-event generalpurpose object-oriented picture-based component-based visual simulation model development and execution. This advanced environment can be used for solving complex problems in areas such as air traffic control and space systems business process reengineering and workflows complex system design evaluation computer and communication networks computer performance evaluation education and training health care systems manufacturing systems military/combat systems satellite and wireless communications systems service systems supply chain management and transportation systems.,10.1.1.1.1893,?,?
Optimal CDMA Signatures: A Finite-Step Approach,Joel A. Tropp  Inderjit. S. Dhillon,2004,A description of optimal sequences for direct-spread code division multiple access is a byproduct of recent characterizations of the sum capacity. This papers restates the sequence design problem as an inverse singular value problem and shows that it can be solved with finite-step algorithms from matrix analysis. Relevant algorithms are reviewed and a new one-sided construction is proposed that obtains the sequences directly instead of computing the Gram matrix of the optimal signatures. I. ,10.1.1.1.1894,?,?
Signal Integrity: Fault Modeling and Testing in High-Speed SoCs , Mehrdad Nourani Amir Attarha ,2002,As we approach 100nm technology the interconnect issues are becoming one of the main concerns in the testing of gigahertz system-onchips. Voltage distortion (noise) and delay violations (skew) contribute to the signal integrity loss and ultimately functional error performance degradation and reliability problems. In this paper we first define a model for integrity faults on the high-speed interconnects. Then we present a BIST-based test methodology that includes two special cells to detect and measure noise and skew occurring on the interconnects of the gigahertz system-on-chips. Using an inexpensive test architecture the integrity information accumulated by these special cells can be scanned out for final test and reliability analysis.,10.1.1.1.1895,?,?
Studying Cooperation and Conflict between Authors with History Flow Visualizations,Fernanda B. Viégas Martin Wattenberg Kushal Dave,2004,The Internet has fostered an unconventional and powerful style of collaboration: wiki web sites where every visitor has the power to become an editor. In this paper we investigate the dynamics of Wikipedia a prominent thriving wiki. We make three contributions. First we introduce a new exploratory data analysis tool the history flow visualization which is effective in revealing patterns within the wiki context and which we believe will be useful in other collaborative situations as well. Second we discuss several collaboration patterns highlighted by this visualization tool and corroborate them with statistical analysis. Third we discuss the implications of these patterns for the design and governance of online collaborative social spaces. We focus on the relevance of authorship the value of community surveillance in ameliorating antisocial behavior and how authors with competing perspectives negotiate their differences.,10.1.1.1.1897,revision history visualization collaboration document,ACM Press
Geometrical and Performance Analysis of,Gmd And Chase Eran Fishler Student Member Ofer Amrani Senior Member,?,The overall number of nearest neighbors in bounded distance decoding (BDD) algorithms is given by N oeff = No + NBDD  where NBDD denotes the number of additional noncodeword neighbors that are generated during the (suboptimal) decoding process. We identify and enumerate the nearest neighbors associated with the original Generalized Minimum Distance (GMD) and Chase decoding algorithms. After careful examination of the decision regions of these algorithms we derive an approximated probability ratio between the error contribution of a noncodeword neighbor (one of NBDD points) and a codeword nearest neighbor. For Chase Algorithm 1 it is shown that the contribution to error probability of a noncodeword nearest neighbor is a factor of 2  d01  less than the contribution of a codeword while for Chase Algorithm 2 the factor is  2  dd=2e01   d being the minimum Hamming distance of the code. For Chase Algorithm 3 and GMD a recursive procedure for calculating this ratio which turns out to be nonexponential in d is presented. This procedure can also be used for specifically identifying the error patterns associated with Chase Algorithm 3 and GMD. Utilizing the probability ratio we propose an improved approximated upper bound on the probability of error based on the union bound approach. Simulation results are given to demonstrate and support the analytical derivations.,10.1.1.1.1898,?,?
© 2003 The Company of Biologists Ltd,Although The Systemic P. V. Skov J. F. Steffensen,?,igin these anastomoses coil extensively over 200--300 m before re-anastomosing with neighbouring vessels to form progressively larger secondary arteries (Olson 1996). In the skipjack tuna Katsuwonis pelamis and the Atlantic cod Gadus morhua the SCS forms capillary beds (Dewar et al. 1994 Burne 1929) which are assumed to be typical of water breathing teleosts (Vogel 1985a) before draining into the primary venous system. However in Salaria pavo (prev. Blennius) and Zosterisessor ophiocephalus it fails to do so (Lahnsteiner et al. 1990).  The distribution and volume of the SCS has been widely discussed. To date it has been shown that secondary vessels supply secondary capillary beds in the body surface the fins the buccal cavity the pharynx and the peritoneum and it may 591 The Journal of Experimental Biology 206 591-599   2003 The Company of Biologists Ltd  doi:10.1242/jeb.00113  The volume of the primary (PCS) and secondary (SCS) circulatory system in the Atlantic cod ,10.1.1.1.1899,?,?
The Management and Mining of Multiple Predictive Models Using the Predictive Modeling Markup Language (PMML),Robert Grossman National Robert Grossman Stuart Bailey Ashok Ramu Balinder Malhi Philip Hallstrom Ivan Pulleyn Xiao Qin,1999,Keywords: data mining predictive modeling data interchange formats XML SGML ensemble learning partitioned learning distributed learning We introduce a markup language based upon XML for working with the predictive models produced by data mining systems. The language is called the Predictive Model Markup Language (PMML) and can be used to define predictive models and ensembles of predictive models. It provides a flexible mechanism for defining schema for predictive models and supports model selection and model averaging involving multiple predictive models. It has proved useful for applications requiring ensemble learning partitioned learning and distributed learning. In addition it facilitates moving predictive models across applications and systems.,10.1.1.1.1900,data mining predictive modeling data interchange formats XML SGML ensemble learning,?
A Biospi Model Of Lymphocyte-Endothelial,Interactions In Inflamed P. Lecca C. Priami C. Laudanna G. Constantin,2004,This paper presents a stochastic model of the lymphocyte recruitment in inflammed  brain microvessels. The framework used is based on stochastic process algebras for  mobile systems. The automatic tool used in the simulation is the BioSpi. We  compare our approach with classical hydrodinamical specifications,10.1.1.1.1903,?,?
A Practical Learning-Based Approach for Dynamic Storage Bandwidth Allocation,Vijay Sundaram Prashant Shenoy,2003,In this paper we address the problem of dynamic allocation of storage  bandwidth to application classes so as to meet their response time requirements.,10.1.1.1.1904,?,?
Maximizing Throughput for Optical Burst Switching Networks,Jikai Li  Chunming Qiao Jinhui Xu Dahai Xu,2004,A key problem in Optical Burst Switching (OBS) is to schedule as many bursts as possible on wavelength channels so that the throughput is maximized and the burst loss is minimized. Currently most of the research on OBS (e.g. burst scheduling and assembly algorithms) has been concentrated on reducing burst loss in an average-case sense. Little effort has been devoted to understanding the worst-case performance. Since OBS itself is an open-loop control system it may often exhibit a worst-case behavior when adversely synchronized thus a poor worst-case performance can lead to an unacceptable system-wide performance. In this paper we use competitive analysis to analyze the worstcase performance of a large set of scheduling algorithms called best-effort online scheduling algorithms for OBS networks and establish a number of interesting upper and lower bounds on the performance of such algorithms. Our analysis shows that the performance of any best-effort online algorithm is closely related to a few factors such as the range of offset time burst length ratio scheduling algorithm and number of data channels. A surprising discovery is that the worst-case performance of any best-effort online scheduling algorithm is primarily determined by the maximum to minimum burst length ratio followed by the range of offset time. Furthermore if all bursts have the same burst length and offset time all best-effort online scheduling algorithms generate the same optimal solution regardless how different they may look like. Our analysis can also be extended to some non-besteffort online scheduling algorithms such as the well-known Horizon algorithm and establish similar bounds. Based on the analytic results we give guidelines for several widely discussed OBS problems inclu...,10.1.1.1.1905,?,?
Routing Complexity of Faulty Networks,Omer Angel  Itai Benjamini Eran Ofek  Udi Wieder,2004,One of the fundamental problems in distributed computing is how to efficiently perform routing in a faulty network in which each link fails with some probability. This paper investigates how big the failure probability can be before the capability to efficiently find a path in the network is lost. Our main results show tight upper and lower bounds for the failure probability which permits routing both for the hypercube and for the d-dimensional mesh. We use tools from percolation theory to show that in the d-dimensional mesh once a giant component appears --- efficient routing is possible. A different behavior is observed when the hypercube is considered. In the hypercube there is a range of failure probabilities in which short paths exist with high probability yet finding them must involve querying essentially the entire network. Thus the routing complexity of the hypercube shows an asymptotic phase transition. The critical probability with respect to routing complexity lies in a different location then that of the critical probability with respect to connectivity. Finally we show that an oracle access to links (as opposed to local routing) may reduce significantly the complexity of the routing problem. We demonstrate this fact by providing tight upper and lower bounds for the complexity of routing in the random graph G np .,10.1.1.1.1906,?,?
Efficient and Flexible Parallel Retrieval Using Priority Encoded Transmission,Ramaprabhu Janakiraman  Lihao Xu,?,Many applications including web transfers software distribution video-on-demand and peer-to-peer data downloads require the retrieval of structured documents consisting of multiple components like images video and text. Large systems using these applications may be made more scalable by using efficient data distribution techniques like multicast and by enabling clients to retrieve data from multiple servers in parallel.,10.1.1.1.1907,?,?
The Impact of Concurrency Gains on the Analysis and Control of Multi-threaded Internet Services,Hani Jamjoom Chun-ting Chou Kang G. Shin,2004,With the proliferation of Internet services many solutions have emerged to provide Quality-of-Service (QoS) guarantees when the demands for the hosted services exceed the servers capacity. In this paper we take an analytical approach to answering key questions in the design and performance of application-level QoS techniques especially those that are based on the multi-threading or multi-processing abstraction. Key to our analysis is the integration of the effects of concurrency into the interactions between multi-threaded services. To this end we extend traditional time-sharing models to develop the multi-threaded round-robin (MTRR) servers a more accurate model of operation of typical multi-threaded Internet services. For this model we first develop powerful yet computationallyefficient mathematical relationships that describe the performance (in terms of throughput and response time) of multithreaded services. We then apply optimization techniques to derive the optimal allocation of threads given specific QoS objective functions. Using realistic workloads on a typical web server we show the efficacy and accuracy of the proposed new methodology.,10.1.1.1.1908,?,?
Exploiting the Cache Capacity of a Single-Chip Multi-Core Processor with Execution Migration,Pierre Michaud,2004,We propose to modify a conventional single-chip multicore so that a sequential program can migrate from one core to another automatically during execution. The goal of execution migration is to take advantage of the overall onchip cache capacity. We introduce the affinity algorithm a method for distributing cache lines automatically on several caches. We show that on working-sets exhibiting a property called splittability it is possible to trade cache misses for migrations. Our experimental results indicate that the proposed method has a potential for improving the performance of certain sequential programs without degrading significantly the performance of others.,10.1.1.1.1909,?,?
Robustness of Class-Based Path-Vector Systems,Aaron D. Jaggard  Vijay Ramachandran,2004,Gri#n Jaggard and Ramachandran introduced in [4] a framework for understanding the design principles of path-vector protocols such as the Border Gateway Protocol (BGP) which is used for inter-domain routing on the Internet. They described as an application of their framework a study of Hierarchical-BGP-like systems where routing at a node is determined by the relationship with the next-hop node on a path (e.g. an ISPpeering relationship) and some additional scoping rules (e.g. the use of backup routes). These systems are called class-based path-vector systems. The robustness of these systems depends on the presence of a global constraint on the system but an adequate constraint has not yet been given. In this paper we give the best-known su#cient constraint that guarantees robust convergence. We show how to generate this constraint from the design specification of the path-vector system. We also give centralized and distributed algorithms to enforce this constraint discuss applications of these algorithms and compare them to algorithms given in previous work on path-vector protocol design.,10.1.1.1.1910,?,?
CODEX: A Robust and Secure Secret Distribution System,Michael A. Marsh  Fred B. Schneider,2003,CODEX (COrnell Data EXchange) stores secrets for subsequent access by authorized clients. It also is a vehicle  for exploring the generality of a relatively new approach to  building distributed services that are both fault-tolerant and attack-tolerant. Elements of that approach include: embracing the asynchronous (rather than synchronous) model of computation use of Byzantine quorum systems for storing state and  employing proactive secret sharing with threshold cryptography for implementing confidentiality and authentication of service responses. Besides explaining the CODEX protocols experiments to measure their performance are discussed.,10.1.1.1.1911,Index Terms — Distributed systems Fault tolerance Access,?
Identifying Good Predictions of RNA Secondary Structure,M. E. Nebel,2004,Predicting the secondary structure of RNA molecules from the knowledge  of the primary structure (the sequence of bases) is still a challenging  task. There are algorithms that provide good results e.g. based on  the search for an energetic optimal configuration. However the output  of such algorithms does not always give the real folding of the molecule  and therefore a feature to judge the reliability of the prediction would be  appreciated. In this paper we present results on the expected structural  behavior of LSU rRNA derived using a stochastic context-free grammar  and generating functions. We show how these results can be used to  judge the predictions made for LSU rRNA by any algorithm. In this  way it will be possible to identify those predictions which are close to  the natural folding of the molecule with a probability of 97% of success.,10.1.1.1.1913,?,?
Exact Power Estimation Using Word Level Transition Probabilities,Ana T. Freitas  Arlindo L. Oliveira  Jose C. Monteiro  Horacio C. Neto,1999,We propose a model and an algorithm to perform exact power estimation taking  into account all temporal and spatial correlations of the input signals. The proposed  methodology is able to accurately model temporal and spatial correlations at the logic  level with the input signal correlations being specified at the word level using a simple  but effective formulation.,10.1.1.1.1914,?,?
A Study about Trade-off between Performance and Security in an Internet Audio Mechanism,Alessandro Aldini Roberto Gorrieri,?,We study the nature of the relationship between performance measures and privacy guarantees in the case study of an adaptive protocol for the secure transmission of real-time audio over the Internet. The analysis is conducted on a...,10.1.1.1.1915,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,A number of network simulators are now capable of simulating systems with millions of devices at the IP packet level. With this ability comes a need for realistic network descriptions of commensurate size. This paper describes our effort to build a detailed model of the U.S. Internet backbone based on measurements taken from a variety of mapping sources and tools. We identify key attributes of a network design that are needed to use the model in a simulation describe which components are available and which must be modeled and discuss the pros and cons of this approach as compared to synthetic generation. As for attributes that we have to model we also briefly discuss some measurement efforts that can potentially provide the missing pieces and thus improve the fidelity of the model. Finally we describe the resulting network model of the U.S. Internet backbone which is being made publicly available. 1 ,10.1.1.1.1916,?,?
Investigating Swirl and Tumble Flow with a Comparison of Visualization Techniques,Robert S. Laramee  Daniel Weiskopf  Jürgen Schneider Helwig Hauser,2004,We investigate two important common fluid flow patterns from computational fluid dynamics (CFD) simulations namely swirl and tumble motion typical of automotive engines. We study and visualize swirl and tumble flow using three different flow visualization techniques: direct geometric and texture-based. When illustrating these methods side-by-side we describe the relative strengths and weaknesses of each approach within a specific spatial dimension and across multiple spatial dimensions typical of an engineer s analysis. Our study is focused on steady-state flow. Based on this investigation we offer perspectives on where and when these techniques are best applied in order to visualize the behavior of swirl and tumble motion.,10.1.1.1.1917,and Modeling Simulation Output Analysis Keywords Flow visualization computational fluid dynamics (CFD swirl flow tumble flow visualization systems engine simulation in-cylinder flow,IEEE Computer Society
The KGP Model of Agency,Antonis Kakas  Paolo Mancarella Fariba Sadri Kostas Stathis Francesca Toni,2004,This paper presents a new model of agency called the KGP (Knowledge Goals and Plan) model. This draws from the classic BDI model and proposes a hierarchical agent architecture with a highly modular structure that synthesises various reasoning and sensing capabilities of the agent in an open and dynamic environment. The novel features of the model include: its innovative use of Computational Logic (CL) in a way that facilitates both the formal analysis of the model and its computational realisability directly from the high-level specification of the agents (a first prototype for the development of KGP agents exists based upon a correct computational counterpart of the model) the modular separation of concerns and flexibility afforded by the model in designing heterogeneous agents and in developing independently the various components of an agent and the declarative agent control provided through a context-sensitive cycle CL theory component that regulates the agents operational behaviour according to the current circumstances of operation thus breaking away from the conventional one-size-fits-all control of operation.,10.1.1.1.1918,?,IOS Press
Verification of Parallel Systems via Decomposition,Jan Friso Groote Faron Moller,1992,Recently Milner and Moller have presented several decomposition results for processes. Inspired by these we investigate decomposition techniques for the verification of parallel systems. In particular we consider those of the form       q j (I) where p i and q j are (finite) state systems. We provide a decomposition procedure for all p i and q j and give criteria that must be checked on the decomposed processes to see whether (I) does or does not hold. We analyse the complexity of our procedure and show that it is polynomial in n m and the sizes of p i  and q j if there is no communication. We also show that with communication the verification of (I) is co-NP hard which makes it very unlikely that a polynomial complexity bound exists. But by applying our decomposition technique to Milners cyclic scheduler we show that verification can become polynomial in space and time for practical examples where standard techniques are exponential. Note: The authors are supported by the European Communities under ESPRIT Basic Research Action 3006 (CONCUR).,10.1.1.1.1919,?,Springer
International Affairs Portal: A Semantic Web Application,J.  Contreras    V. R. Benjamins  et al.,?,This paper describes a semantic portal on the domain of International  Affairs. This application is an integration of several technologies in the field of  the Semantic Web in a complex project. We describe an approach tools and  techniques that allow building a semantic portal where access is based on the  meaning of concepts and relations of the International Affairs domain. The  approach comprises an automatic ontology-based annotator a semantic search  engine with a natural language interface a web publication tool allowing  semantic navigation and a 3D visualization component. The portal is being  deployed in the Royal Institute Elcano    (Real Instituto Elcano) in Spain which  is a prestigious independent political institute whose mission is to comment on  the political situation in the world focusing on its relation to Spain. As part of  its dissemination strategy it operates a public website. The online content can  be accessed by navigating through categories or by a keyword-based full text  search engine. The work described in this paper aims at improving access to the  content. The semantic portal is currently being tested by the Institute.,10.1.1.1.1920,?,?
Referencing Objects in FIPA SL: An Analysis and Proposal,Stephen Cranefield  Martin Purvis,?,Although the syntax and semantics of mainstream agent content languages are based on those of predicate logic the popularity of the Java programming language the availability of various free Java-based agent development toolkits and the use of frame-based ontology modelling languages have meant that many developers of  multi-agent systems are accustomed to conceptualising their problem domain in terms of classes and objects.,10.1.1.1.1921,?,?
Towards More Effective Techniques for Automatic Query Expansion,Claudio Carpineto Giovanni Romano,1999,Techniques for automatic query expansion from top retrieved documents have recently shown promise for improving retrieval effectiveness on large collections but there is still a lack of systematic evaluation and comparative studies. In this paper we focus on term-scoring methods based on the differences between the distribution of terms in (pseudo-)relevant documents and the distribution of terms in all documents seen as a complement or an alternative to more conventional techniques. We show that when such distributional methods are used to select expansion terms within Rocchios classical reweighting scheme the overall performance is not likely to improve. However we also show that when the same distributional methods are used to both select and weight expansion terms the retrieval effectiveness may considerably improve. We then argue based on their variation in performance on individual queries that the set of ranked terms suggested by individual distributional methods can be combined to further improve mean performance by analogy with ensembling classifiers and present experimental evidence supporting this view. Taken together our experiments show that with automatic query expansion it is possible to  achieve performance gains as high as 21.34% over non-expanded query (for non-interpolated average precision). We also discuss the effect that the main parameters involved in automatic query expansion such as query difficulty number of selected documents and number of selected terms have on retrieval effectiveness.,10.1.1.1.1922,?,?
Rainbow: Distributed Database System for Classroom Education And Experimental Research,Abdelsalam (Sumi) Helal Hua Li,2000,?,10.1.1.1.1923,Rainbow GUI allows the user to a) configure a,?
A Tool for Writing and Debugging Algebraic Specifications,J. Henkel A. Diwan,2004,Despite their benefits programmers rarely use formal specifications because they are difficult to write and they require an up front investment in time. To address these issues we present a tool that helps programmers write and debug algebraic specifications. Given an algebraic specification our tool instantiates a prototype that can be used just like any regular Java class. The tool can also modify an existing application to use the prototype generated by the interpreter instead of a hand-coded implementation. The tool improves the usability of algebraic specifications in the following ways: (i) A programmer can “run ” an algebraic specification to study its behavior. The tool reports in which way a specification is incomplete for a client application. (ii) The tool can check whether a specification and a hand-coded implementation behave the same for a particular run of a client application. (iii) A prototype can be used when a hand-coded implementation is not yet available. Two case studies demonstrate how to use the tool. 1.,10.1.1.1.1924,?,IEEE Computer Society Press
Commander Behavior and Course of Action . . . ,Deborah Vakas John Prince H. Ric Blacksten Chuck Burdick,2001,The Joint Warfare System (JWARS) is being equipped with a Commander Model (CM) to perform situation assessment and Course of Action (COA) selection and a Commander Behavior Model (CBM) to bias decisions with a commanders leadership style. The CM is a hybrid artificial intelligence system that models doctrine through the use of fuzzy rule sets together with a tree-based lookahead algorithm for the strategy. The CBM employs behaviorbased fuzzy rule sets to augment the CM in assessing the situation and in biasing the COA selection criteria. Extending from Myers-Briggs personality traits the CBM links personality traits to military attitudes consequences and values. Employing the fuzzy rule sets the resulting sets of values are combined to select a specific COA with an auditable trail. Users will have the ability to modify both the input parameters and the underlying rules. The CM/CBM is applicable to decisions at multiple echelons.,10.1.1.1.1925,?,?
Study of an Ergodicity . . . ,John B. Gilmer Jr. Frederick J. Sullivan,2001,Multitrajectory Simulation allows random events in a simulation to generate multiple trajectories. Management techniques have been developed to manage the choices of trajectories to be continued as combinatorial explosion and limited resources prevents continuing all of them. One of the seemingly most promising methods used trajectory probability as a criterion so that higher probability trajectories were preferentially continued resulting in a more even distribution of (surviving) trajectory probabilities and better than stochastic approximation to a reference outcome. It was also found that this management technique introduced a failed ergodicity assumption. The higher and lower probability trajectories behave differently to a significant extent. The effect is to limit the number of trajectories which can usefully be applied to the problem such that additional runs would fail to converge further toward the definitive reference outcome set. This may be a useful model for understanding other simulation modeling limitations.,10.1.1.1.1926,?,?
A New Proof for the Stability of Equation-Error Models,Roberto Lopez-Valcarce Student Member  Soura Dasgupta,1999,Some recent works have shown that under an autoregressive constraint on the input signal least-squares equationerror methods provide stable models of the estimated transfer function. Here we present an alternative proof of this fact which allows to increase the order of the autoregressive input by one for both the monic and unit-norm approaches.,10.1.1.1.1928,?,?
Is Increased Diversity in Genetic Programming Beneficial? An Analysis of Lineage Selection,Edmund K. Burke  Steven Gustafson  Graham Kendall  Natalio Krasnogor Edmund K. Burke Steven Gustafson,2003,This paper presents an analysis of increased diversity in genetic programming. A selection strategy based on genetic lineages is used to increase genetic diversity. A genetic lineage is defined as the path from an individual to individuals which were created from its genetic material. The method is applied to three problem domains: Artificial Ant Even-5-Parity and symbolic regression of the Binomial-3 function. We examine how increased diversity affects problems differently and draw conclusions about the types of diversity which are more important for each problem. Results indicate that diversity in the Ant problem helps to overcome deception while elitism in combination with diversity is likely to benefit the Parity and regression problems.,10.1.1.1.1929,?,IEEE Press
Statistical Region Merging,Richard Nock  Frank Nielsen,2004,This paper explores a statistical basis for a process often described in computer vision: image segmentation by region  merging following a particular order in the choice of regions. We exhibit a particular blend of algorithmics and statistics whose  segmentation error is as we show limited from both the qualitative and quantitative standpoints. This approach can be efficiently  approximated in linear time/space leading to a fast segmentation algorithm tailored to processing images described using most  common numerical pixel attribute spaces. The conceptual simplicity of the approach makes it simple to modify and cope with hard  noise corruption handle occlusion authorize the control of the segmentation scale and process unconventional data such as spherical  images. Experiments on gray-level and color images obtained with a short readily available C-code display the quality of the  segmentations obtained.,10.1.1.1.1930,?,?
A Unified Approach to Discrete and Continuous High-Gain Adaptive Controllers Using Time Scales,Ian A. Gravagne  John M. Davis Jeffrey  Jeffrey J. Dacunha,?,It has been known for some time that proportional output feedback  will stabilize certain classes of linear time-invariant systems under an  adaptation mechanism that drives the feedback gain su#ciently high. More  recently it was demonstrated that discrete implementations of the high-gain  adaptive controller also require adaptation of the sampling rate. In this paper  we use recent advances in the mathematical field of dynamic equations on time  scales to unify the discrete and continuous versions of the high-gain adaptive  controller. A novel proof method is presented based on time scales as is a  brief tutorial on the subject of time scales.,10.1.1.1.1931,Contents,?
Constructive Induction Using,Non-Greedy Strategy For Arlindo L. Oliveira,1992,We present a method for feature construction  and selection that finds a minimal set of conjunctive  features that are appropriate to perform  the classification task. For problems where this  bias is appropriate the method outperforms other  constructive induction algorithms and is able to  achieve higher classification accuracy. The application  of the method in the search for minimal  multi-level boolean expressions is presented and  analyzed with the help of some examples.,10.1.1.1.1932,?,Morgan Kaufmann
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Bridges Using Discrete-event Simulation Srinath Devulapalli Julio C. Martinez Jesus M. De La Garza,?,The complexities and costs associated with preserving the nations bridge infrastructure demand innovative approaches to analysis of data and prediction of future bridge conditions. Several Bridge Management systems (BMS) have come into existence following the ISTEA act of 1991. The policy analysis module of BMS systems developed is restricted to analytical methods. With the availability of modern infrastructure realistic simulation models are being developed in several fields. This leads to the question of whether reasonably realistic and practical discrete event simulation (DES) based policy analysis tools can be developed ? A DES model was developed for the Salem district of Virginia using a simulation language STROBOSCOPE. This simulation model can be used to simulate the bridge network behavior under different policies and observe the impact on the health of the network making it a useful tool for decision-making. The tool enables the formulation and testing of different bridge maintenance policies.,10.1.1.1.1934,?,?
Achieving Privacy Preservation When Sharing Data for Clustering,Stanley R. M. Oliveira Osmar R. Zaïane,2004,In this paper we address the problem of protecting the underlying  attribute values when sharing data for clustering. The challenge is how  to meet privacy requirements and guarantee valid clustering results as well.,10.1.1.1.1936,?,TorontoCanada
A Bayesian Blackboard for Information Fusion,Charles Sutton Clayton Morrison Paul R. Cohen Joshua Moody Jafar Adibi,2004,A Bayesian blackboard is just a conventional knowledge-based blackboard system in which knowledge sources modify Bayesian networks on the blackboard. As an architecture for intelligence analysis and data fusion this has many advantages: The blackboard is a shared workspace or corporate memory for collaborating analysts analyses can be developed over long periods of time with information that arrives in dribs and drabs the computers contribution to analysis can range from data-driven statistical algorithms up to domain-specific knowledge-based inference and perhaps most important the control of intelligence-gathering in the world and inference on the blackboard can be rational that is grounded in probability and utility theory. Our Bayesian blackboard architecture called AIID serves both as a prototype system for intelligence analysis and as a laboratory for testing mathematical models of the economics of intelligence analysis.,10.1.1.1.1937,?,?
The Coda Mirror,Philippe Segeral Tobias Scheer,1999,?,10.1.1.1.1938,?,?
Reliable Objects: a Lightweight Approach Applied to Java,Jean-Marc Jezequel  Daniel Deveaux  Yves Le Traon,2001,Small scale software developments need specific low cost and lowoverhead methods and  tools to deliver quality products within tight time and budget constraints. This is particularly  true of testing because of its cost and impact on final product reliability. We propose  a lightweight approachtoembed tests into components making them self testable. We also  propose a method to evaluate testing efficiency based on mutation techniques which ultimately  provides an estimation of a components quality. This allows the software developer  to consciously trade reliability for resources. Our methodology has been implemented in the  Eiffel Java C++ and Perl languages. The Java implementation built on top of iContract is  outlined here.,10.1.1.1.1939,?,?
More Things Than Are Dreamt of in Your Biology: Information-processing in biologically-inspired robots,A. Sloman  R.L. Chrisley,2004,Animals and robots perceiving and acting in a world require an ontology that accommodates entities processes states of a#airs etc. in their environment. If the perceived environment includes information-processing systems the ontology should reflect that. Scientists studying such systems need an ontology that includes the first-order ontology characterising physical phenomena the second-order ontology characterising perceivers of physical phenomena and a (recursive) third order ontology characterising perceivers of perceivers including introspectors. We argue that second- and third-order ontologies refer to contents of virtual machines and examine requirements for scientific investigation of combined virtual and physical machines such as animals and robots. We show how the CogA# architecture schema combining reactive deliberative and meta-management categories provides a first draft schematic third-order ontology for describing a wide range of natural and artificial agents. Many previously proposed architectures use only a subset of CogA# including subsumption architectures contention-scheduling systems architectures with `executive functions and a variety of types of `Omega architectures.,10.1.1.1.1940,?,?
Probing-Based Preprocessing Techniques for Propositional Satisfiability,Inês Lynce  João Marques-Silva,2003,Preprocessing is an often used approach for solving hard instances of propositional satisfiability (SAT). Preprocessing can be used for reducing the number of variables and for drastically modifying the set of clauses either by eliminating irrelevant clauses or by inferring new clauses. Over the years a large number of formula manipulation techniques has been proposed that in some situations have allowed solving instances not otherwise solvable with stateof -the-art SAT solvers. This paper proposes probing-based preprocessing an integrated approach for preprocessing propositional formulas that for the first time integrates in a single algorithm most of the existing formula manipulation techniques. Moreover the new unified framework can be used to develop new techniques. Preliminary experimental results illustrate that probing-based preprocessing can be effectively used as a preprocessing tool in state-of-theart SAT solvers.,10.1.1.1.1941,?,?
A Framework for Providing Electronic Payment Services,Martina Kannen  Martin Leischner Torsten Stein,2003,In this paper we propose a process and service oriented framework which offers a structural and conceptual orientation in the field of electronic payment. It renders possible an integral view on electronic payment that goes beyond the frame of an individual system. To do this we have generalized the systems-oriented approaches to a phase-oriented payment model. Using this model requirements and supporting services for electronic payment can be sorted systematically and described from both the customers and the merchants viewpoint. Providing integrated payment processes and services is proving to be a difficult task. With this paper we would like to outline the necessity for a Payment Service Provider to act as a mediator for suppliers and users of electronic payment systems.,10.1.1.1.1942,?,?
Finding Optimal Pairs of Patterns,Hideo Bannai Heikki Hyyrö Ayumi Shinohara Masayuki Takeda Kenta Nakai  Satoru Miyano,2004,We consider the problem of finding the optimal pair of string patterns for discriminating between two sets of strings i.e. finding the pair of patterns that is best with respect to some appropriate scoring function that gives higher scores to pattern pairs which occur more in the strings of one set but less in the other. We present an O(Nsup2) time algorithm for finding the optimal pair of substring patterns where N is the total length of the strings. The algorithm looks for all possible Boolean combination of the patterns e.g. patterns of the form p and notq which indicates that the pattern pair is considered to match a given string s if p occurs in s AND q does NOT occur in s. The same algorithm can be applied to a variant of the problem where we are given a single set of sequences along with a numeric attribute assigned to each sequence and the problem is to find the optimal pattern pair whose occurrence in the sequences is correlated with this numeric attribute. An e#cient implementation based on suffix arrays is presented and the algorithm is applied to several nucleotide sequence datasets of moderate size combined with microarray gene expression data aiming to find regulatory elements that cooperate complement or compete with each other in enhancing and/or silencing certain genomic functions.,10.1.1.1.1943,?,?
Protein Secondary Structure: Entropy Correlations And Prediction,Gavin E. Crooks Steven E. Brenner,2004,Motivation: Is protein secondary structure primarily determined by local interactions between residues closely spaced along the amino acid backbone or by non-local tertiary interactions ? To answer this question we measure the entropy densities of primary and secondary structure sequences and the local inter-sequence mutual information density.,10.1.1.1.1944,?,?
Spontaneous Branching in a Polyp Oriented,Model Of Stony Alfons Hoekstra Jaap Ka Peter Sloot,2002,A three-dimensional model of di#usion limited coral growth  is introduced. As opposed to previous models in this model we take a  polyp oriented approach. Here coral morphogenesis is the result of the  collective behaviour of the individual coral polyps. In the polyp oriented  model branching occurs spontaneously as opposed to previous models  in which an explicit rule was responsible for branching. We discuss the  mechanism of branching in our model. Also the e#ects of polyp spacing  on the coral morphology are studied.,10.1.1.1.1945,?,Springer-Verlag
Query Brokers for Distributed and Flexible Query Evaluation,Tuyet-Trinh Vu  Christine Collet,2003,This paper presents our work on supporting flexible query evaluation over large distributed heterogeneous and autonomous sources. Flexibility means that the query evaluation process can be configured according to application contextspecific resources constraints and also can interact with its execution environment.,10.1.1.1.1947,?,?
Learning a Factorized Segmental Representation of Far-Field Tracking Data,Chris Stauffer,2004,There are many useful observable characteristics of the state of a tracked object. These characteristics could include normalized size normalized speed normalized direction object color position and object shape among other characteristics. Although these characteristics are by no means completely independent of each other it is desirable to determine a separate compact description of each of each of these aspects. Using this compact factored description different aspects of individual sequences can be estimated and described without overwhelming computational or storage costs. In this work we describe Factored Latent Analysis (FLA) and its application to deriving factored models for segmenting sequences in each of K separate characteristics. This method exploits temporally local statistics within each of the latent aspects and their interdependencies to derive a model that allows segmentation of each of the observed characteristics. This method is data driven and unsupervised. Activity classification results for multiple challenging environments are shown.,10.1.1.1.1948,?,?
Notions of Upward Compatibility of Temporal Query Languages,John Bair Michael H. Böhlen Christian S. Jensen Richard T. Snodgrass,1997,Migrating applications from conventional to temporal database management technology has received  scant mention in the research literature. This paper formally defines three increasingly restrictive notions  of upward compatibility which capture properties of a temporal SQL with respect to conventional SQL  that when satisfied provide for a smooth migration of legacy applications to a temporal system. The  notions of upward compatibility dictate the semantics of conventional SQL statements and constrain the  semantics of extensions to these statements. The paper evaluates the seven extant temporal extensions to  SQL all of which are shown to complicate migration through design decisions that violate one or more  of these notions. We then outline how SQL--92 can be systematically extended to become a temporal  query language that satisfies all three notions.,10.1.1.1.1949,?,?
Evaluating Quality of Text Clustering with ART1,L. Massey  ,2003,Self-organizing large amounts of textual data in accordance to some topics structure is an increasingly important application of clustering. Adaptive Resonance Theory (ART) neural networks possess several interesting properties that make them appealing in this area. Although ART has been used in several research works as a text clustering tool the level of quality of the resulting document clusters has not been clearly established yet. In this paper we present experimental results with binary ART that address this issue by determining how close clustering quality is to an upper bound on clustering quality.,10.1.1.1.1950,?,?
NFS Tricks and Benchmarking Traps,Daniel Ellard   Margo Seltzer,2003,We describe two modifications to the FreeBSD 4.6 NFS server to increase read throughput by improving the read-ahead heuristic to deal with reordered requests and stride access patterns. We show that for some stride access patterns our new heuristics improve end-to-end NFS throughput by nearly a factor of two. We also show that benchmarking and experimenting with changes to an NFS server can be a subtle and challenging task and that it is often difficult to distinguish the impact of a new algorithm or heuristic from the quirks of the underlying software and hardware with which they interact. We discuss these quirks and their potential effects.,10.1.1.1.1952,?,?
The Lightspace Change Constraint Equation (LCCE) with practical application to estimation of the projectivity+gain transformation between multiple pictures of the same subject matter,S. Mann  C. Manders J. Fung,2003,For many years the Brightness Constancy Constraint Equation (BCCE) has been used for optical flow and related computer vision computations. However almost all cameras have some kind of automatic exposure feature such as Automatic Gain Control (AGC) so that the overall exposure level of the image varies as the camera is aimed at brighter or darker portions of a scene. Moreover because most cameras have some kind of unknown nonlinear response function the change due to AGC cannot be captured by merely applying a multiplicative constant to the pixels of each image. We propose therefore a Lightspace Change Constraint Equation (LCCE) that accounts for exposure change (AGC) together with the nonlinear response function of the camera. The response function can be automatically learned by an intelligent image processing system presented with differently exposed capture of the same subject matter in overlapping regions of registered images. Most importantly a Logarithmic Lightspace Change Constraint Equation (LLCCE) is shown to have a very simple mathematical formulation. The LCCE (and Log LCCE) is applied to the estimation of the projective coordinate transformation between pairs of images in a sequence and is compared with examples where the BCCE fails.,10.1.1.1.1954,?,?
Static Placement Dynamic Issue (SPDI) Scheduling for EDGE Architectures,Ramadass Nagarajan  etal. Sundeep K. Kushwaha Doug Burger Kathryn S. Mckinley Calvin Lin Stephen W. Keckler,2004,Technology trends present new challenges for processor architectures and their instruction schedulers. Growing transistor density will increase the number of execution units on a single chip and decreasing wire transmission speeds will cause long and variable on-chip latencies. These trends will severely limit the two dominant conventional architectures: dynamic issue superscalars and static placement and issue VLIWs. We present a new execution model in which the hardware and static scheduler instead work cooperatively called Static Placement Dynamic Issue (SPDI). This paper focuses on the static instruction scheduler for SPDI. We identify and explore three issues SPDI schedulers must consider---locality contention and depth of speculation. We evaluate a range of SPDI scheduling algorithms executing on an Explicit Data Graph Execution (EDGE) architecture. We find that a surprisingly simple one achieves an average of 5.6 instructions-per-cycle (IPC) for SPEC2000 64-wide issue machine and is within 80% of the performance without on-chip latencies. These results suggest that the compiler is effective at balancing on-chip latency and parallelism and that the division of responsibilities between the compiler and the architecture is well suited to future systems. 1,10.1.1.1.1955,?,?
Adaptive Process Control in Rubber Industry,Rüdiger W. Brause  Ulf Pietruschka,1998,This paper describes the problems and an adaptive solution for process control in rubber industry. We show that the human and economical benefits of an adaptive solution for the approximation of process parameters are very attractive. The,10.1.1.1.1956,?,?
Overlay and Peer-to-Peer Multimedia Multicast with Network-Embedded FEC,Hayder Radha Mingquan Wu,2004,Under traditional IP multicast application-level FEC can only be implemented on an end-to-end basis between the sender and the clients. Emerging overlay and peer-to-peer (p2p) networks open the door for new paradigms of network FEC. The deployment of FEC within these emerging networks has received very little attention (if any). In this paper we analyze and optimize the impact of Network-Embedded FEC (NEF) in overlay and p2p multimedia multicast networks. Under NEF we place FEC codecs in selected intermediate nodes of a multicast tree. The NEF codecs detect and recover lost packets within FEC blocks at earlier stages before these blocks arrive at deeper intermediate nodes or at the final leaf nodes. This approach significantly reduces the probability of receiving undecodable FEC blocks. In essence the proposed NEF codecs work as signal regenerators in a communication system and can reconstruct most of the lost data packets without requiring retransmission. We develop an optimization algorithm for the placement of NEF codecs within random multicast trees. Our theoretical analysis and simulation results show that a relatively small number of NEF codecs placed in (sub-)optimally selected intermediate nodes of a network can improve the throughput and overall reliability dramatically.,10.1.1.1.1957,?,?
Network Motifs in Natural and Artificial Transcriptional Regulatory Networks,Wolfgang Banzhaf  P. Dwight Kuo,2004,We show that network motifs found in natural regulatory networks may also be found in  an artificial regulatory network model created through a duplication / divergence process. It  is shown that these network motifs exist more frequently in a genome created through the  aforementioned process than in randomly generated genomes. These results are then compared  with a network motif analysis of the gene expression networks of Escherichia Coli and  Saccharomyces cerevisiae. In addition it is shown that certain individual network motifs may  arise directly from the duplication / divergence mechanism.,10.1.1.1.1958,?,?
Incremental Density Approximation and Kernel-Based Bayesian Filtering for Object Tracking,Bohyung Han Dorin Comaniciu Ying Zhu Larry Davis,2004,Statistical density estimation techniques are used in many computer vision applications such as object tracking background subtraction motion estimation and segmentation. The particle filter (Condensation) algorithm provides a general framework for estimating the probability density functions (pdf) of general non-linear and non-Gaussian systems. However since this algorithm is based on a Monte Carlo approach where the density is represented by a set of random samples the number of samples is problematic especially for high dimensional problems. In this paper we propose an alternative to the classical particle filter in which the underlying pdf is represented with a semi-parametric method based on a mode finding algorithm using mean-shift. A mode propagation technique is designed for this new representation for tracking applications. A quasi-random sampling method [14] in the measurement stage is used to improve performance and sequential density approximation for the measurements distribution is performed for efficient computation. We apply our algorithm to a high dimensional colorbased tracking problem and demonstrate its performance by showing competitive results with other trackers. 1,10.1.1.1.1960,?,?
Why a Static Interpretation is Not Sufficient in Spatial Communication,John A. Bateman  Kerstin Fischer  Thora Tenbrink,2003,This paper proposes a research methodology  for attacking the problem of  providing fluent and natural discourse  about space and spatially situated tasks  between nave users and robots. We suggest  flexible and adaptive ontology mediation  parameterized according to  empirically determined discourse and  contextual factors as a suitable architecture  with clear applications for the treatment  of natural human-human dialog  also.,10.1.1.1.1961,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,In this paper we present an overview of classical results about the variance reduction technique of control variates. We emphasize aspects of the theory that are of importance to the practitioner as well as presenting relevant applications. 1 ,10.1.1.1.1962,?,?
Understanding BGP Behavior through a Study of DoD Prefixes,Xiaoliang Zhao Dan Dan Massey S. Felix Wu,2003,BGP is the de-facto inter-domain routing protocol and it is essential to understand how well BGP performs in the Internet. As a step toward this understanding this paper studies the routing performance of a sample set of prefixes owned by the U.S. Department of Defense (DoD). We examine how reliably the sample set is connected to the Internet and how it affects the rest of the Internet. We show that our sample set receives reliable connectivity with the exception of a few prefixes. We also show that on average the sample set has minimal impact on global routing but certain BGP features used by DoD routers result in periods of excessive routing overhead. During some stressful periods our sample set only 0.2% of all prefixes contributed over 80% of a particular BGP update class. We explain how the BGP design allows certain local changes to propagate globally and amplifies the impact of our sample prefixes.,10.1.1.1.1963,?,?
Cache Conscious Indexing for Decision-Support in Main Memory ,Jun Rao Kenneth A. Ross,1999,We study indexing techniques for main  memory including hash indexes binary  search trees T-trees B+-trees interpolation  search and binary search on arrays. In a ,10.1.1.1.1964,?,?
Taking Advantage of the Symbiotic Relationship between Tools and Processes to Support Executable Process Models,Ralf Buschermöhle Oldenburger Forschungs- Und Entwicklungsinstitut,2003,An approach for tight coupling of process models and software development tools --- with the metaphor of component-based software development environments --- supporting eXecutable Process Models (XPM) is presented. In this paper we focus on the direction from the components of a software development environment towards the process models in order to automatically acquire process model information solving various drawbacks compared to a manual acquisition of this information. Requirements on a process modeling language for using this information are discussed.,10.1.1.1.1965,?,?
FCNDP No. 181,Fcnd Discussion Paper Stuart Gillespie,?,While many community-driven development (CDD) initiatives may be  successful their impact is often limited by their small scale. Building on past and  ongoing work on CDD this study addresses the fundamental question: how can CDD  initiatives motivate and empower the greatest number of communities to take control of  their own development? What are the key contextual factors institutional arrangements  capacity elements and processes related to successful scaling-up of CDD and  conversely what are the main constraints or limiting factors in different contexts?  Drawing upon recent literature and the findings from five case studies key lessons on  how best to stimulate facilitate and support the scaling-up of CDD in different  situations along with some major challenges are highlighted.  Lessons include the need for donors and supporters of CDD including  governments to think of the process beyond the project and of transformation or  transition rather than exit. Donor push and community pull factors need to be balanced to  prevent supply-driven demand-driven development. Overall capacity is pivotal to  successful CDD and its successful scaling-up over time. Capacity is more than simply  resources however it also includes motivation and commitment which in turn require  appropriate incentives at all levels. Capacity development takes time and resources but  it is an essential upfront and ongoing investment with the capacity and commitment of  facilitators and local leaders being particularly important. A learning by doing  cultureone that values adaptation flexibility and openness to changeneeds to be  fostered at all levels with time horizons adjusted accordingly. The building of a library  of well-documented context-specific experiences th...,10.1.1.1.1966,?,?
Towards an Information Systems Engineering Body of Knowledge,H.A. Proper Iris Group  S.J.B.A. Hoppenbrouwers  R.D.T. Janssen H. Bosma,2000,Though there may be millions of professionals worldwide acting as a designer architect or engineer in the design realisation and implementation of information systems there is not yet a well established and clearly identified body of knowledge that can be said to define the profession.,10.1.1.1.1967,?,?
Content Extraction from HTML Documents,Rahman Alam And A. F. R. Rahman H. Alam R. Hartono,2001,In recent times the way people access information from the web has undergone a transformation. The demand for information to be accessible from anywhere anytime has resulted in the introduction of Personal Digital Assistants (PDAs) and cellular phones that are able to browse the web and can be used to find information using wireless connections. However the small display form factor of these portable devices greatly diminishes the rate at which these sites can be browsed. This shows the requirement of efficient algorithms to extract the content of web pages and build a faithful reproduction of the original pages with the important content intact.,10.1.1.1.1968,?,?
Termination,As The Example,?,proof. Let us examine why.       #M  1 :A 2#A 1      2 :A 2  #E.    M 2 :A 1  We can make the following inferences.    V 1 =  #x:A 2 .M # 1 By type preservation and inversion   At this point we cannot proceed: we need a derivation of  [V 2 /x]M # 1 ## V for some V  to complete the derivation of M 1    M 2 ## V . Unfortunately the induction hypothesis does not tell us anything about [V 2 /x]M # 1 . Basically we need to extend it so it makes a statement about the result of evaluation (    #x:A 2 .M # 1 inthis  case).  Sticking to the case of linear application for the moment we call a term M good if it evaluates to a good value V .AvalueVis good if it is a function  #x:A 2 .M # 1 and if substituting a good value V 2 for x in M # 1 results in a good term. Note that this is not a proper definition since to see if V is good we may need to substitute any good value V 2 into it possibly including V itself. We can make this definition inductive if we observe that the value,10.1.1.1.1969,?,?
How to Describe Physical,Reality Jean-Claude Pecker Jean-claude Pecker,2001,to 100 km/sec per Mpc. The most likely value for the deceleration parameter q o is  which corresponds to a flat universe. But all measurements are in fact quite dispersed around this value and seem now to indicate an open universe.  Two other cosmological facts are related to the Big Bang theory. The second cosmological fact often quoted and extensively discussed by Rees is that on earth we are immersed in a cosmic microwave background radiation like being in a furnace kept at a temperature of t 0 = 2.7 Kelvin. This accidental discovery seemed to confirm the socalled Big Bang model for theorists. The third cosmological fact depends on the measurement of elementary abundances in the universe and it seems that the proportions of hydrogen deuterium helium lithium etc. have changed little since their formation at the time of the Big Bang.  Needless to say when one discovers several facts which fit within the same theory one is tempted not to go beyond and to relegate all o,10.1.1.1.1970,?,?
Avoiding Detection in a Dynamic Environment,Ashley Tews  Maja Mataric  Gaurav Sukhatme,2004,Remaining elusive while navigating to a goal in a dynamic environment containing an observer requires taking advantage of opportunistic cover as it occurs. A reactive navigation approach is needed that recognizes the utility of environment features in offering protective cover. We present an approach that allows stealthy traverses in unknown environments containing dynamic objects. It is a frontier-based method that allows a robot to follow in the obscuring shadow of objects despite their dynamics and take advantage of more opportunistic cover if it becomes available. An analysis of our approach in off-line modeling and experiments conducted in simulation and outdoor environments demonstrate its effectiveness in achieving high quality solutions for stealthy navigation.,10.1.1.1.1971,?,?
Deployment and Connectivity Repair of a Sensor Net with a Flying Robot,P. Corke S. Hrabar R. Peterson D. Rus S. Saripalli G. Sukhatme,2004,We consider multi-robot systems that include sensor nodes and aerial or ground robots networked together. Such networks are suitable for tasks such as large-scale environmental monitoring or for command and control in emergency situations. We present a sensor network deployment method using autonomous aerial vehicles and describe in detail the algorithms used for deployment and for measuring network connectivity and provide experimental data collected from field trials. A particular focus is on determining gaps in connectivity of the deployed network and generating a plan for repair to complete the connectivity. This project is the result of a collaboration between three robotics labs (CSIRO USC and Dartmouth.)  1 ,10.1.1.1.1972,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,Airports are an ideal application area for simulation. The processes are in a continuous state of change are complex and stochastic involve many moving objects and require a good performance that can be measured in several different performance indicators. Within airports but also between airports the same kind of questions are answered over and over again. Often however new simulation models are built for each question if possible copying some parts of previous models. Structured reuse of simulation components is rarely seen. This paper shows an approach for airport terminal modeling that departs from the assumption that reusable simulation building blocks can form the core of a powerful airport modeling tool which is able to answer different questions at airports better and faster than traditional models. The building blocks have been implemented in the commercially available simulation language eM-Plant. Several studies carried out with this library were very successful.,10.1.1.1.1974,?,?
CATS 2.0 User Guide,Galen Andrew,?,dist dist flag described in section 3.1 can also be used in place of -d.  The number of goods and bids must also be specified for each run. If every instance is to have the same number of goods and bids the -goods and -bids flags are used to provide these numbers. It is also possible to choose the numbers of goods and bids separately for each instance from a uniform distribution over a specified range. This is done with the -random goods and -random bids flags. Both are followed by two integers specifying the minimum and maximum values of the range.  If the -default hard flag is used (see section 3.5) all of the above parameters take on default values and are not required. A specific distribution can still be chosen but the number of bids and goods if they are (redundantly) entered must be 1000 and 256 respectively since our hardness models are based on this problem size. The 2.1 release of CATS may allow variable problem sizes.    L1 and L5 are excluded because it is impossib,10.1.1.1.1975,?,?
Ad Hoc Networks Security,Pietro Michiardi Refik Molva,2003,Countermeasures against node misbehavior and selfishness are mandatory requirements in mobile ad hoc networks. Selfishness that causes lack of node activity cannot be solved by classical security means that aim at verifying the correctness and integrity of an operation. In this paper we outline an original security mechanism (CORE) based on reputation that is used to enforce cooperation among the nodes of a MANET. We then investigate on its robustness using an original approach: we use game theory to model the interactions between the nodes of the ad hoc network and we focus on the strategy that a node can adopt during the network operation. As a first result we obtained the guidelines that should be adopted when designing a cooperative security mechanism that enforces mobile nodes cooperation. Furthermore we were able to show that when no countermeasures are taken against misbehaving nodes network operation can be heavily jeopardized. We then showed that the CORE mechanism is compliant with guidelines provided by the game theoretic model and that under certain conditions it assures the cooperation of at least half of the nodes of a MANET.,10.1.1.1.1976,?,Press Wiley
An Integrated Architecture for Exploring Wrapping Mediating and Restructuring Information from the Web,Wolfgang May,2000,The goal of information extraction from the Web is to provide an integrated view on heterogeneous information sources. A main problem with current wrapper/mediator approaches is that they rely on very different formalisms and tools for wrappers and mediators thus leading to an impedance mismatch between the wrapper and mediator level. Additionally most approaches currently are tailored to access information from a fixed set of sources.,10.1.1.1.1977,?,?
Nonlinear Estimation of the Fundamental Matrix with Minimal Parameters,Adrien Bartoli Peter Sturm Ieee Computer Society,2004,The purpose of this paper is to give a very simple method for  nonlinearly estimating the fundamental matrix using the minimum number of seven parameters. Instead of minimally parameterizing it we rather update what we call its orthonormal representation which is based on its singular value decomposition. We show how this method can be used for efficient bundle adjustment of point  features seen in two views. Experiments on simulated and real data show that this implementation performs better than others in terms of computational cost i.e.  convergence is faster although methods based on minimal parameters are more likely to fall into local minima than methods based on redundant parameters.,10.1.1.1.1978,?,?
Potential Maximization and Coalition Government Formation,Rod Garratt James E. Parco Cheng-Zhong Qin AMNON RAPOPORT,2003,A model of coalition government formation is presented in which inefficient nonminimal winning coalitions can form in Nash equilibrium. Predictions for five games are presented and tested experimentally. The experimental data support potential maximization as a refinement of Nash equilibrium. In particular the data support the prediction that non-minimal winning coalitions occur when the distance between policy positions of the parties is small relative to the value of forming the government. These conditions hold in games 1 3 4 and 5 where subjects played their unique potential-maximizing strategies 91 52 82 and 84 percent of the time respectively. In the remaining game (Game 2) experimental data support the prediction of a minimal winning coalition. Players A and B played their unique potential-maximizing strategies 84 and 86 percent of the time respectively and the predicted minimal-winning government formed 92 percent of the time (all strategy choices for player C conform with potential maximization in Game 2). In Games 1 2 4 and 5 over 98 percent of the observed Nash equilibrium outcomes were those predicted by potential maximization. Other solution concepts including iterated elimination of dominated strategies and strong/coalition proof Nash equilibrium are also tested.,10.1.1.1.1979,JEL Classification C72 C78 D72,?
Ontology-based Integration for Sharing,Knowledge Over The D. Bianchini V. De Antonellis,2004,In this paper we propose a methodology developed in the  framework of the VISPO project for engineering a three-layer ontology  based on the conceptualization integration synthesis and categorization  of XML data descriptions provided by a number of sources in a virtual  district where di#erent enterprises cooperate for business purposes. Ontologies  are proposed as an unifying framework for di#erent viewpoints  by providing a shared understanding in a subject domain. Our methodology  generates an ontology organized into concepts and concept relationships  at di#erent levels of detail to provide multiple unified views of  the datasources containing heterogeneous information about the domain  of interest.,10.1.1.1.1980,?,?
Is the Coda Mirror a phonological object?,Philippe Segeral  Tobias Scheer,?,ss affecting a segment because of its position in a string Coda V__V devoicing typical highly improbable deaspiration (C  h  --C) typical highly improbable velarisation (ln--##) typical highly improbable   s-debuccalisation (s--h) typical highly improbable   liquid gliding (rl--j) typical highly improbable    depalatalisation (#--n) typical highly improbable    l-vocalisation (#--w/o) typical highly improbable   r-vocalisation/ loss ([kaad] card) typical highly improbable   [NC] hom : homorganisation of nasals typical highly improbable spirantisation (bdg--###) highly improbable typical voicing (t--d) highly improbable typical rhotacism (z--r) highly improbable typical c. only solution when using the familiar model of syllabic structure: criterion based on {__# __.C V__V} = postvocalic pure adjacence V__V = flanked by vowels pure adjacence {__# __.C} = Coda pure position d. contradiction: the superset is defined in pure terms of adjacence. Hence one of its subsets ,10.1.1.1.1981,?,?
A Comparison Of Fast Factorised Back-Projection And Wavenumber Algorithms,For Sas Image A. J. Hunter M. P. Hayes P. T. Gough,2003,The Fast Factorised Back-Projection (FFBP) algorithm has received considerable attention recently for SAS image reconstruction. The FFBP algorithm provides a means of trading image quality and/or resolution for a reduction in computational cost over standard Back-Projection. In this paper we describe FFBP for SAS image reconstruction and compare it to the Wavenumber algorithm in terms of computational cost and image quality.,10.1.1.1.1982,?,?
Workshop on Enduser Development,Henry Lieberman  Fabio Paternò Henry Lieberman Fabio Paternò Alexander Repenning Volker Wulf Michael Amberg Jens Wehrmann Lawrence Bergman Tessa Lau Vittorio Castelli Daniel Oblinger,2003,opportunity for equipping private households with inexpensive smart devices for controlling and  automating various tasks in our daily lives. Networking technology and standards have an important role  in driving this development. The omnipresence of the Internet via phone lines TV cable power lines and  wireless channels facilitates ubiquitous networks of smart devices that will significantly change the way  we interact with home appliances. Home networking is considered to become one of the fastest growing  markets in the area of information technology. However interoperability and flexibility of embedded  devices are key challenges for making Smart Home technology accessible for a broad audience. In  particular the software programs that determine the behavior of the smart home must facilitate  customizability and extensibility. Unlike industrial applications that are typically engineered by highly  skilled programmers control and automation programs for the smart home should be understandable to  laypeople. In this article we discuss how recent technological progress in the areas of visual  programming languages component software and connection-based programming can be applied to  programming the smart home. Our research is carried out in tight collaboration with a corporate partner  in the area of embedded systems.,10.1.1.1.1983,?,?
Semantic Web Services Languages and Technologies: Comparison and Discussion,Rohit Aggarwal,2004,this paper is to survey the current semantic Web services languages and modeling frameworks by outlining their features and capabilities. We will then compare the approaches and identify the deficient features which need to be overcome to meet the requirements of the industry and the SWSL in developing a formal language/technology for supporting semantic Web services,10.1.1.1.1984,?,?
Estimation Of The Long-Range Dependence Parameter . . . ,Houssain Kettani,2003,... In this paper we consider the case when the process is assumed to be fractional ARIMA and show that the new method still possesses the aforementioned qualities,10.1.1.1.1985,?,?
On the ill-conditioning of subspace . . . ,Alessandro Chiuso Giorgio Picci,2003,There is experimental evidence that the performance of standard subspace algorithms from the literature (e.g. the  N4SID method)  may be surprisingly poor in certain experimental conditions. This happens typically when the past signals (past inputs  andoutputs)  and future input spaces are nearly parallel. In this paper we argue that the poor behavior may be attributed to a form of ill-conditioning of the underlying multiple regression problem which may occur for nearly parallel regressors. An elementary error analysis of the subspace identification problem shows that there are two main possible causes of ill-conditioning. The first has to do with near collinearity of the state and future input subspaces. The second has to do with the dynamical structure of the input signal and may roughly be attributed to lack of excitation. Stochastic realization theory constitutes a natural setting for analyzing subspace identification methods. In this setting we undertake a comparative study of three widely used subspace methods (N4SID Robust N4SID and  PO-MOESP)  The last two methods are proven to be essentially equivalent and the relative accuracy regarding the estimation of the (A C) parameters is shown to be the same.,10.1.1.1.1986,Subspace identi cation Exogenous inputs Numerical conditioning Collinearity Oblique projections State-space identi cation,?
Specification and Validation of a Real-Time Parallel Kernel using LOTOS,Supported By Fapesp Cléver R. Guareis De Farias Luís Ferreira Pires,2001,This paper presents and discusses the LOTOS specification of a real-time parallel kernel. The purpose of this specification exercise has been to evaluate LOTOS with respect to its capabilities to model real-time features with a realistic industrial product. LOTOS was used to produce the formal specification of TRANS-RTXC which is a real-time parallel kernel developed by Intelligent Systems International. This paper shows that although timing constraints cannot be explicitly represented in LOTOS the language is suitable for the specification of co-ordination of real-time tasks which is the main functionality of the real-time kernel. This paper also discusses the validation process of the kernel specification and the role of tools in this validation process. We believe that our experience (use of structuring techniques use of validation methods and tools etc) is valuable for designers who want to apply formal models in their design or analysis tasks.,10.1.1.1.1987,?,?
 Gene-Distribution Patterns on Cyanobacterial Genomes,Nobuyoshi Sugaya  Hiroo Murakami Makihiko Satoh Sachiyo Aburatani Katsuhisa Horimoto,2003,?,10.1.1.1.1988,genome size gene distribution gene-location distance cyanobacteria,?
DTDs versus XML Schema: A Practical Study,Geert Jan Bex  Frank Neven  Jan Van den Bussche,2004,Among the various proposals answering the shortcomings of Document Type Definitions (DTDs) XML Schema is the most widely used. Although DTDs and XML Schema Defintions (XSDs) di#er syntactically they are still quite related on an abstract level. Indeed freed from all syntactic sugar XML Schemas can be seen as an extension of DTDs with a restricted form of specialization. In the present paper we inspect a number of DTDs and XSDs harvested from the web and try to answer the following questions: (1) which of the extra features/expressiveness of XML Schema not allowed by DTDs are e#ectively used in practice and (2) how sophisticated are the structural properties (i.e. the nature of regular expressions) of the two formalisms. It turns out that at present real-world XSDs only sparingly use the new features introduced by XML Schema: on a structural level the vast majority of them can already be defined by DTDs. Further we introduce a class of simple regular expressions and obtain that a surprisingly high fraction of the content models belong to this class. The latter result sheds light on the justification of simplifying assumptions that sometimes have to be made in XML research.,10.1.1.1.1989,?,?
Multidatabase Languages,Paolo Missier Marek Rusinkiewicz  W. Jin,?,Introduction  Database systems based on SQL are well suited for homogeneous databases  -- either centralized or distributed. Most traditional database architectures however seem inadequate to handle differenttypes of heterogeneity.Interoperability at the system level can be achieved to some degree byinterposing an additional interface layer between a database system and the application as in the ODBC solution [Mic94] and more recently in the analogous Java-based JDBC proposal [HC96]. Other vendor-specific solutions provide network and protocol transparency by standardizing their SQL interface.  The problem of dataorsemantic heterogeneityhowever still remains. Different systems that own different pieces of data maycomeinto conflict when they need to agree at least in part on the meaning of each others data. This situation is common in loosely coupled database federations where private data from a common domain of discourse is shared and yet each local system insists on ma,10.1.1.1.1990,?,?
HapticFlow: PDE-Based Mesh Editing with Haptics,Ye Duan  Jing Hua Hong Qin,2004,This paper presents HapticFlow a haptics-based direct mesh editing system founded upon the concept of PDE-based geometric  surface flow. The proposed flow-based approach for direct geometric manipulation offers a unified design paradigm that  can seamlessly integrate implicit distance-field based shape modeling with dynamic physics-based shape design. HapticFlow  provides an intuitive haptic interface and allows users to directly manipulate 3D polygonal objects with ease. To demonstrate  the effectiveness of our new approach we developed a variety of haptics-based mesh editing operations such as embossing  engraving sketching as well as force-based shape manipulation operations,10.1.1.1.1991,PDE surface flow distance field sketching haptics interaction techniques,?
Lossless Turbo Source Coding with Decremental Redundancy,Joachim Hagenauer  Joao Barros Andrew Schaefer,2004,Recent results indicate that the same turbo principle which delivers near to optimal strategies for channel coding can be used to obtain very efficient source coding schemes. We investigate this issue applying ten Brinks EXIT chart analysis and show how this technique can be used to select the most efficient match of component codes and puncturing matrices to compress discrete memoryless sources. Aiming at perfect reconstruction at the decoder i.e. lossless source coding we present an encoding algorithm which gradually removes the redundancy while checking the decodability of the compressed bit stream. This concept of decremental redundancy is dual to the principle of incremental redundancy that characterizes hybrid ARQ (Type II) communication protocols. Both principles can be combined when the channel is noisy.,10.1.1.1.1992,?,?
Corresponding author. Tel.: 44-29-20-876909.,Mail Address Selwynne Neil Selwyn Lyn Dawes Neil Mercer,2000,The C1 billion government drive to integrate information and communications technology (ICT) into UK schools and colleges has been rmly focused on the technological transformation of the teaching profession. In particular the establishment of a National Grid for Learning (NGfL) remains dependent on the successful selling of ICT to teachers many of whom have previously proved unwilling to use computers. In practice much of this task has been left to IT rms eager to promote their products to a potentially lucrative educational marketplace. From this basis the present paper takes a detailed examination of educational computing advertising material currently being produced by IT rms in the UK. In particular it concentrates on how advertisements construct both the process of education and the teacher as a potential user of ICT. Four dominant themes emerge from this analysis: ICT as problematic for teachers ICT as a problem solver for teachers ICT as a futuristic form of education and ICT as a traditional form of education. Despite the con#icting and often contra-factual nature of these four discourses the paper argues that educational computing advertising is consistent in its disempowering portrayal of the teacher at the expense of both the computer and IT rm. This demotion of the teacher is likely to have negative e!ects on the way that teachers approach ICT as part of their professional routine running contrary to the underlying aims of the National Grid for Learning initiative. # 2000 Elsevier Science Ltd. All rights reserved.,10.1.1.1.1993,?,?
AMVA Techniques for High Service Time Variability,Derek L. Eager   Daniel J. Sorin Mary K. Vernon,2000,Motivated by experience gained during the validation of a recent Approximate Mean Value Analysis (AMVA) model of modern shared memory architectures this paper re-examines  the standard AMVA approximation for non-exponential FCFS queues. We find that this approximation is often inaccurate for FCFS queues with high service time variability. For such queues we propose and evaluate: (1) AMVA estimates of the mean residual service time at an arrival instant that are much more accurate than the standard AMVA estimate (2) a new AMVA technique that provides a much more accurate estimate of mean center residence time than the standard AMVA estimate and (3) a new AMVA technique for computing the mean residence time at a downstream queue which has a more bursty arrival process than is assumed in the standard AMVA equations. Together these new techniques increase the range of applications to which AMVA may be fruitfully applied so that for example the memory system architecture of shared memory systems with complex modern processors can be analyzed with these computationally efficient methods.,10.1.1.1.1994,?,?
Enhancing Visual Comparisons in Interactive Graphs,Mika Käki,2000,Bar and line graphs are a good medium when trying to understand overall trends and general relationships between data items. Sometimes it is however desirable to make more detailed comparisons between data items. In this case good tools are valuable especially when examining a dense graph. This paper introduces two techniques that can be used in such tools. Spatial grouping and visual landmarks can be applied in a way that takes full advantage of the attributes of the human attention mechanism to facilitate visual comparisons.,10.1.1.1.1995,?,?
A Distributed Complete Method for Multi-Agent Constraint Optimization,Adrian Petcu Boi Faltings,2004,We present in this paper a new complete method for distributed constraint optimization. This is a utility-propagation method inspired by the sum-product algorithm. The original algorithm requires fixed message sizes linear memory and is time-linear in the size of the problem. However it is correct only for tree-shaped constraint networks. In this paper we show how to extend the algorithm to arbitrary topologies using cycle cutsets while preserving the linear message size and memory requirements. We present some preliminary experimental results on randomly generated problems. The algorithm is formulated for optimization problems but can be easily applied to satisfaction problems as well.,10.1.1.1.1996,?,?
Applications of Multiple Trust Authorities in Pairing Based Cryptosystems,Liqun Chen Keith Keith Harrison David Soldera Nigel Smart L. Chen K. Harrison D. Soldera N. P. Smart Filton Road,2003,We investigate a number of issues related to the use of multiple trust authorities and multiple identities in the type of identifier based cryptography enabled by the Weil and Tate pairings. An example of such a system is the Boneh and Frank9I encryption scheme. We present various applications of multiple trust authorities. In particular we focus on how one can equate a trust authority with a way to add contextual information to an identity. 1 ,10.1.1.1.1997,?,Springer-Verlag
FCND DP No. 113 FCND DISCUSSION PAPER NO. 113 MEASURING POWER,Elizabeth Frankenberg Duncan Thomas,?,There is a longstanding interest in how decisions about resource allocations are made within households and how those decisions affect the welfare of household members. Much empirical work has approached the problem from the perspective that if preferences differ welfare outcomes will depend on the power of individuals within the household to exert their own preferences. Measures of power are therefore a central component of quantitative empirical approaches to understanding how differences in preferences translate into different welfare outcomes. Following most of the empirical studies in this genre this paper focuses on dynamics within couples although we recognize that dynamics among extended family members and across generations are of substantial interest. A number of different measures of power have been used in the literature. Because control over economic resources is seen as an important source of power individual labor income which one earns and so presumably controls to some degree is one potential measure of power. However whether and how much one works is a choice that is not likely to be independent of ones power in the household. Non- labor income has also been used as a measure of power but even if non- labor income does not reflect contemporaneous choices it likely does reflect past choices particularly labor supply choices and so is also a function of power. Levels of resources brought to the marriage by each spouse over which they may individually retain control are even less proximate to the current choices of household members but nevertheless reflect ones taste in iii partners and therefore may not be exogenous to power. (In some instances resources brought to the marriage may reflect decisionmaking by the couples parents dependi...,10.1.1.1.1998,?,?
Compact Propositionalizations of First-Order Theories,Deepak Ramachandran  Eyal Amir,?,We present new insights and algorithms for converting reasoning problems in monadic First-Order Logic (includes only 1place predicates) into equivalent problems in propositional logic. Our algorithms improve over earlier approaches in two ways. First they are applicable even without the unique-names and domain-closure assumptions and for possibly infinite domains. Therefore they apply for many problems that are outside the scope of previous techniques. Secondly our algorithms produce propositional representations that are significantly more compact than earlier approaches provided that some structure is available in the problem. We examined our approach on an example application and discovered that the number of propositional symbols that we produced is smaller by a factor of f # 50 than traditional techniques when those techniques can be applied. This translates to a factor of about 2  f  increase in the speed of reasoning for such structured problems.,10.1.1.1.1999,?,?
 Simulation of a  large-scale . . . ,K. Heinz Weigl,1998,This paper describes a simulation model of a large beverage distribution center. The brewery distribution center has a volume of 71600 cubic meters and contains about 8000 pallets. Every day 1800 pallets are handled in or out of the system and the object of this study was to verify the functionality of the automated storage and retrieval system and integrated conveyor system -- including elevators connecting five levels of the distribution center. The complex system is modeled with the powerful simulation software Arena. A brief discussion of the results is also given.,10.1.1.1.2000,?,?
Determinants of Poverty in Egypt: 1997,Gaurav Datt  Dean Jolliffe,1999,Poverty profiles are a useful way of summarizing information on the levels of poverty and the characteristics of the poor in a society. They also provide us with important clues to the underlying determinants of poverty. However important as they are poverty profiles are limited by the bivariate nature of their informational content. The bivariate associations typical in a poverty profile can sometimes be misleading they beg the obvious question of the effect of a particular variable conditional on the other potential determinants. While there may be certain contexts where unconditional poverty profiles are relevant to a policy decision (see Ravallion 1996) often one would be interested in the conditional poverty effects of proposed policy interventions. It is not surprising therefore that empirical poverty assessments in recent years have seen a number of attempts at going beyond the poverty profile tabulations to engage in a multivariate analysis of living standards and poverty. This study for Egypt has a similar motivation. For Egypt while there has been some work on a descriptive analysis of the characteristics of the poor to our knowledge there is no precursor to an empirical modeling of the determinants of poverty using nationally representative data. To a large extent this has been due to the nonavailability of unit-record data from the Household Income Expenditure and Consumption Survey (HIECS) the primary source of data on iii 1997 Egypt Integrated Household Survey (EIHS). Using the EIHS data it is now possible to conduct a household-level multivariate analysis of living standards. The EIHS being an integrated multimodule survey also offers the potential of a richer analysis of this issue than may have been possible from other data sources. In t...,10.1.1.1.2001,?,?
Journal of Magnetic Resonance 149 271--275 (2001),Doi Jmre Available J. J. Warren P. B. Moore,?,INTRODUCTION  Dipolar coupling data are potentially of great use to NMR spectroscopists since they contain long range information (as opposed to NOE and scalar couplings). Since however the dipolar coupling of an isotropically tumbling molecule averages to zero useful dipolar coupling data was until recently only available for the small number of paramagnetic proteins (1) and protein-- DNA complexes (2) that align spontaneously in strong magnetic fields. The recent introduction of liquid crystal media that induce tunable levels of physical alignment such as phospholipid mixtures  (3) filimentous phage (4 5) and purple membranes (6) should allow dipolar coupling data to be collected from essentially all nucleic acids and proteins.  The dipolar coupling between two nuclei is given by  DPQ (##)    a [(3 cos      1)    1.5R sin    # cos 2#] [1] where D  a subsumes the gyromagnetic ratios of the two nuclei To whom correspondence should be addressed at Department of Chemistry ,10.1.1.1.2003,?,?
Fft benchmarking for digital signal processing technologies,Fabrizio Stefani Antonio Moschitta David Macii Dario Petri F. Stefani A. Moschitta D. Macii D. Petri,2003,An appropriate choice of the computing devices employed in digital signal processing applications requires to characterize and to compare various technologies so that the best component in terms of cost and performance can be used in a given system design. In this paper a benchmark strategy is presented to measure the performances of various types of digital signal processing devices. Although different metrics can be used as performance indexes Fast Fourier Transform (FFT) computation time and Real-Time Bandwidth (RTBW) have proved to be excellent and complete performance parameters. Moreover a new index measuring the architectural efficiency in computing FFT is introduced and explained. Both parameters can be used to compare several digital signal processing technologies thus guiding designers in optimal component selection.,10.1.1.1.2004,Fast Fourier Transform (FFT digital signal processing kernel,?
Can Shortest-path Routing and TCP Maximize Utility,Jiantao Wang   Lun Li Steven H. Low John C. Doyle,2003,TCP-AQM protocols can be interpreted as distributed primal-dual algorithms over the Internet  to maximize aggregate utility over source rates. In this paper we study whether TCP-AQM  together with shortest-path routing can maximize utility over both rates and routes. We show that  this is generally impossible because the addition of route maximization makes the problem NP-hard. We exhibit,10.1.1.1.2005,?,?
The Large Error First (LEF) Scheduling Policy for Real-Time Control Systems,Jos Ypez Pau,?,Most of the real-time scheduling algorithms are based on open-loop strategies that do not take application demands into account. This precludes the scheduler to dynamically adjust task executions in order to optimize  performance. To overcome this limitation we have focused  our work on scheduling techniques that are able to take  scheduling decisions based on continuous feedback information of the performance delivered by each task. Focusing on control applications we present an early specification of a novel scheduling technique: Large Error  First (LEF). It uses feedback information from each controlled plant in order to assign priorities to each control task. For a given simulation set-up comparing the performance of LEF versus open loop classical scheduling  techniques encouraging simulation results have been  obtained.,10.1.1.1.2006,?,?
Communication Systems: A Unified Model of Socially Intelligent Systems,Matthias Nickles Michael Rovatsos Wilfried Brauer Gerhard Weiß,2004,This paper introduces communication systems (CS) as a unified model  for socially intelligent systems. This model derived from sociological systems  theory combines the empirical analysis of communication in a social system with  logical processing of social information to provide a general framework for computational  components that exploit communication processes in multiagent systems.,10.1.1.1.2007,?,Springer Verlag
Self-Similar Traffic and Network Dynamics,Ashok Erramilli Matthew Roughan Darryl Veitch  Walter Willinger,2002,One of the most significant findings... This paper reviews what is currently known about network traffic self-similarity and its significance. We then consider a matter of current research namely the manner in which network dynamics (specifically the dynamics of transmission control protocol (TCP) the predominant transport protocol used in todays Internet) can affect the observed self-similarity. To this end we first discuss some of the pitfalls associated with applying traditional performance evaluation techniques to highly-interacting large-scale networks such as the Internet. We then present one promising approach based on chaotic maps to capture and model the dynamics of TCP-type feedback control in such networks. Not only can appropriately chosen chaotic map models capture a range of realistic source characteristics but by coupling these to network state equations one can study the effects of network dynamics on the observed scaling behavior. We consider several aspects of TCP feedback and illustrate by examples that while TCP-type feedback can modify the self-similar scaling behavior of network traffic it neither generates it nor eliminates it.,10.1.1.1.2009,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Thorsten S. Daum,?,We investigate the use of XML as an open cross-platform and extendable file format for the description of hierarchical simulation models including their graphical representations initial model conditions and model execution algorithms. We present HiMASS-x an XML-centered suite of software applications that allows for cross-platform distributed modeling and execution of hierarchical componentized and reusable simulation models.,10.1.1.1.2010,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Jerry Banks Sanjay Jain,?,It has become a matter of survival that many companies improve their supply chain efficiency. This presents an opportunity for simulation. However there are many challenges that must be overcome for simulation to be a contributor to play an effective role. Four contributors discuss the opportunities that they see for simulation to play a meaningful role in the area of supply chain management.,10.1.1.1.2011,?,?
TOASTER and KROONDE: High-Resolution and High-Speed Real-Time Sensor Interfaces,Thierry Coduys  Cyrille Henry  Arshia Cont Director La Kitchen,2004,High capacity of transmission lines (Ethernet in particular) is much higher than what imposed by MIDI today. So it is possible to use capturing interfaces with high-speed and high-resolution thanks to the OSC protocol for musical synthesis (either in realtime or non real-time). These new interfaces offer many advantages not only in the area of musical composition with use of sensors but also in live and interactive performances. In this manner the processes of calibration and signal processing are delocalized on a personal computer and augments possibilities of processing. In this demo we present two hardware interfaces developed in La kitchen with corresponding processing to achieve a high-resolution high-speed sensor processing for musical applications.,10.1.1.1.2012,Sensors Calibration Precision OSC Pure Data Max/MSP,?
FCND DP No. 88 FCND DISCUSSION PAPER NO. 88 THE DETERMINANTS OF EMPLOYMENT STATUS IN EGYPT,Ragui Assaad Fatma El-hamidi Akhter U. Ahmed,?,Egyptian labor market is moving from a period of high overall unemployment to one where unemployment is increasingly concentrated among specific groups whose access to the private-sector labor market is limited. Educated young women are more adversely affected than their male counterparts by the transition to a private-sector-led economy. There is no systematic link between youth unemployment among new entrants and poverty unless it is the head of the household who is unemployed. An economic policy environment that is favorable for labor-intensive export-oriented industries would help absorb the new entrants into the labor market and the prospect is particularly good for young female workers. Policymakers should consider a reduction in the femalespecific employer mandates (such as the existing provision for a generous maternity leave) that raise the cost of hiring women. iv v CONTENTS Acknowledgments.......................................................................................................... ix Executive Summary ....................................................................................................... xi 1. ,10.1.1.1.2013,Acknowledgments.....................................................................................,?
Adaptive Methods for Activity Monitoring of Streaming Data,Vasundhara Puttagunta Konstantinos Kalpakis,2004,Activity monitoring deals with monitoring data (usually streaming data) for interesting events. It has several applications such as building an alarm or an alert system that triggers when outliers or change points are detected. We discuss,10.1.1.1.2014,streaming data recursive least squares regression recursive computations,?
Implementing An,Electronic Portfolio Assessment El-marie Mostert Johan G Knoetze Prof Johan G Knoetze,2001,The implementation of a portfolio assessment strategy in the education and training environment is a time consuming process that should be performed within a specific framework structure or model to accommodate diverse learners.,10.1.1.1.2015,Electronic portfolios Assessment Evaluation Internet Portfolio Assessment,?
The fusion machine (Extended Abstract),Philippa Gardner Cosimo Laneve Lucian Wischik,2002,We present a new model for the distributed implementation of pi-like calculi. This model is a closemos h to a variety of calculi and so perm02 strong correctness results that are easy to prove. In particular we describe a distributed  abstractms hine called the fusion machnq . In it only channels exist at runtim0 It uses aform of concurrent constraints called fusions---equations  on channelnaml#0#05 h it stores as trees of forwarders between channels. We imH`B2# t in the fusionms hine a solos calculus with explicit fusions. There are encodings into this calculusfrom the pi calculus and the explicit fusion calculus. We quantify the e#ciency of the latter bymz2# of (co-)locations.  ,10.1.1.1.2016,?,Springer-Verlag
Shadowplay – Lighting in different computer game genres,Sara Jacobsson,2004,This paper discusses the nature and significance of artificial illumination in computer games. It examines different game genres and finds their essence in order to be able to locate a specific game typical to each genre. Games that existed prior to the computer are shown use light in a much more functional way as opposed to digital games which use illumination primarily for creating reality or aesthetic pleasure. Copyright 2004  KEYWORDS: Lighting design Illumination Shadows Computer games Game genres.,10.1.1.1.2017,Lighting design,?
A QoS-Aware Transcoding Proxy Using On-demand Data Broadcasting,Jiun-long Huang Ming-syan Chen Hao-ping Hung,2004,The high diversity in the capabilities of various mobile de-vices such as display capabilities and computation power makes the design of mobile information systems more challenging. A transcoding proxy is placed between a client and an information server to coordinate the mismatch be-tween what the server provides and what the client prefers. However most research works in transcoding proxies in mo-bile computing environments are under the traditional client-server architecture and do not employ the data broadcast technique which is has been deemed a promising technique to design a power conservation high scalable and high band-width utilization. In addition the issue of QoS provision is also not addressed. In view of this we design in this paper a QoS-aware transcoding proxy by utilizing the on-demand broadcasting technique. We first propose a QoS-aware transcoding proxy architecture abbreviated as QTP and model it as a queueing network. By analyzing the queueing network several theoretical results are derived. We then propose a version decision policy and a service admission control scheme to provide QoS in QTP. The derived results are used to guide the execution of the proposed version decision policy and service admission control scheme to achieve the given QoS requirement. To measure the performance of QTP several experiments are conducted. Experimental results show that the proposed scheme is more scalable than traditional client-server systems. In addition the proposed scheme is able to effectively control the system load to attain the desired QoS.,10.1.1.1.2018,?,?
User Modelling and Mobile Learning,Susan Bull,2003,This paper describes a study investigating the potential for two user modelling systems: a location-aware user modelling system providing easy access to applications files and course materials commonly used by an individual student in different locations,10.1.1.1.2019,?,Springer-Verlag
Towards the global GIS,Christopher Gold   Mir Abolfazl Mostafavi  ,2003,This paper outlines the concept of a Global GIS and defines various aspects of its  development as well as various options and decisions that must be made. The emphasis is on  the advantages and disadvantages of maintaining a global topological structure and whether  topology should be generated on the fly in response to a specific query. We first define  what we mean by space in this context followed by a description of topological structures  and how we may use them in the context of graph traversal problems. We then describe some  appropriate data structures. After mentioning some of the real-world problems associated with polygon construction problems we touch on how graphs may represent change over time. A global,10.1.1.1.2020,GIS topology data structures globe Voronoi diagrams,?
Proceedings of the 2003 Winter Simulation Conference,S. Chick P. J. Sánchez D. Ferrin D. J. Morris,?,Simulation models and business application software as they  are used for decision support in enterprise management are  both representations of an enterprises actual operations.  This paper describes a unified simulation and application  framework where it is possible to represent the entire performance process along a supply chain in a unified business  model improve its performance with discrete event simulation technology and then generate and implement the corresponding business application software from the same unified model based on a so-called framework-based  application technology which allows implementation of  changes derived from simulation analysis with minimal effort and time. This enables a company to optimise not only  operational processes such as shopfloor or warehouse operations but also business processes such as planning order  management and scheduling through simulation.   1 ,10.1.1.1.2021,INTEGRATION OF DISCRETE EVENT SIMULATION MODELS WITH FRAMEWORK-BASED BUSINESS APPLICATIONS,?
Keyframe Selection for Camera Motion and Structure Estimation from Multiple Views,Thorsten Thormaehlen  Hellward Broszio  Axel Weissenfeld,2004,Estimation of camera motion and structure of rigid objects  in the 3D world from multiple camera images by bundle adjustment  is often performed by iterative minimization methods due to their low  computational e#ort. These methods need a robust initialization in order  to converge to the global minimum. In this paper a new criterion for  keyframe selection is presented. While state of the art criteria just avoid  degenerated camera motion configurations the proposed criterion selects  the keyframe pairing with the lowest expected estimation error of initial  camera motion and object structure. The presented results show that the  convergence probability of bundle adjustment is significantly improved  with the new criterion compared to the state of the art approaches.,10.1.1.1.2022,?,?
Sources of Funds and Investment Activities of Venture Capital Funds:,Evidence From Germany Colin Mayer Koen Schoors Yishay Yafeh Saul Lach Sophie Manigart Alan Morrison Kristian Rydqvist Juro Teranishi Naoyuki Yoshino,?,Using a newly constructed data set we compare sources of funds and investment activities of venture capital (VC) funds in Germany Israel Japan and the UK. Sources of VC funds differ significantly across countries e.g. banks are particularly important in Germany corporations in Israel insurance companies in Japan and pension funds in the UK. VC investment patterns also differ across countries in terms of the stage sector of financed companies and geographical focus of investments. We find that these differences in investment patterns are related to the variations in funding sources - for example bank and pension fund backed VC firms invest in later stage activities than individual and corporate backed funds -- and we examine various theories concerning the relation between finance and activities. We also report that the relations differ across countries for example bank backed VC firms in Germany and Japan are as involved in early stage finance as other funds in these countries whereas they tend to invest in relatively late stage finance in Israel and the UK. We consider the implication of this for the influence of financial systems on relations between finance and activities.,10.1.1.1.2023,?,?
Capitalization of Nouns in German Sentences,Said Sahel Ruediger Weingarten Boris Gutbrod Philip Cummins,?,German orthography has the somewhat unique property of systematically marking nouns by  capitalizing their first letter. This gives the reader additional information with respect to the  syntactic structure of a sentence but also burdens the writer with the task of making this structure  explicit. In some older studies the benefits of this information have been demonstrated for the  reading process it still remains unclear though how the writer accomplishes this task. Two  different processes are conceivable: The information is either delivered by the Orthographic  Output Lexicon or is syntactically generated whilst the sentence to be written is constructed. In a  series of experiments evidence is provided for an interactive exchange between lexical and  syntactic processing dealing with the question of when capitalization should occur.,10.1.1.1.2024,?,?
Functional anatomy of pitch memory---an fMRI study,With Sparse Temporal Nadine Gaab A Christian Gaser B Tino Zaehle A Lutz Jancke Gottfried Schlaug A,?,Auditory functional magnetic resonance imaging tasks are challenging since the MR scanner noise can interfere with the auditory stimulation. To avoid this interference a sparse temporal sampling method with a long repetition time (TR # 17 s) was used to explore the functional anatomy of pitch memory. Eighteen right-handed subjects listened to a sequence of sine-wave tones (4.6 s total duration) and were asked to make a decision (depending on a visual prompt) whether the last or second to last tone was the same or different as the first tone. An alternating button press condition served as a control. Sets of 24 axial slices were acquired with a variable delay time (between 0 and 6 s) between the end of the auditory stimulation and the MR acquisition. Individual imaging time points were combined into three clusters (0 --2 3-- 4 and 5-- 6 s after the end of the auditory stimulation) for the analysis. The analysis showed a dynamic activation pattern over time which involved the superior temporal gyrus supramarginal gyrus posterior dorsolateral frontal regions superior parietal regions and dorsolateral cerebellar regions bilaterally as well as the left inferior frontal gyrus. By regressing the performance score in the pitch memory task with task-related MR signal changes the supramarginal gyrus (left#right) and the dorsolateral cerebellum (lobules V and VI left#right) were significantly correlated with good task performance. The SMG and the dorsolateral cerebellum may play a critical role in short-term storage of pitch information and the continuous pitch discrimination necessary for performing this pitch memory task.,10.1.1.1.2025,Pitch memory Music Temporal lobe Supramarginal gyrus Cerebellum Performance,?
Proceedings of the 3rd Hawaii International Conference on Statistics Mathematics and Related Fields,Honolulu Hawaii June,2004,We consider the problem of converting a decimal number to a base b number. We present a conversion function that relates each digit in the base b system to the decimal value that is equal to the base b number in question. Thus each base b digit of the related base b number can be obtained directly from the corresponding decimal number without the requirement of knowing any other base b digit.,10.1.1.1.2026,for j = n n ? 1? ?m + 1 ?m and “. ” is,?
Synthesized Strings for String Players,Cornelius Poepel,2004,A system is introduced that allows a string player to control a synthesis engine with the gestural skills he is used to. The implemented system is based on an electric viola and a synthesis engine that is directly controlled by the unanalysed audio signal of the instrument and indirectly by control parameters mapped to the synthesis engine. This method offers a highly string-specific playability as it is sensitive to the kinds of musical articulation produced by traditional playing techniques. Nuances of sound variation applied by the player will be present in the output signal even if those nuances are  beyond traditionally measurable parameters like pitch amplitude or brightness. The relatively minimal hardware requirements make the instrument accessible with little expenditure.,10.1.1.1.2027,instrument design,?
A Set Theoretic Framework For Enumerating,Matches In Surveys Richard G. Clegg,?,This paper describes a method for enumerating the ways in which combinations of vehicles can be observed at di#erent survey points. The framework described is quite general and can be applied to a variety of problems where matches are to be found in data surveyed at a number of locations (or at a single location over a number of days). As an example the framework is applied to the problem of false matches in licence plate survey data.,10.1.1.1.2028,?,?
Reliable Data Transport: A Critical Service for the Grid,William Allcock Ian Ian Foster Ravi Madduri,2004,this paper we discuss the various XML schema [1516] the port types defined and some of our experiences building RFT,10.1.1.1.2029,?,?
Service Adaptive Multicast for Media Distribution Networks,Sujata Banerjee Zhichen Xu Sung-Ju Lee Chunqiang Tang,2003,multimedia content service delivery. Its efficiency is maximized when all the service recipients have identical needs. In reality however the end users may have a heterogeneous set of requirements for different service levels as well as different service components depending on their system and network capabilities. We propose the notion of Service Adaptive Multicast (SAM) that balances the tradeoffs between providing individualized service to each client and maintaining an efficient overlay multicast tree structure. The novel aspects of our approach are (a) the ability to augment and transform existing paths into service paths with the desired attributes and (b) integration of two tree maintenance processes: a receiver-initiated just-in-time adaptation of the multicast service tree driven by application/user perceived QoS and a demand-driven tree maintenance process geared towards long-term tree quality. We demonstrate the performance of our approach using simulations of large client population.,10.1.1.1.2030,?,?
Performance study of a COTS Distributed DBMS adapted for multilevel security,Moses Garuba Royal Holloway,2004,butes security levels and the page size  were varied for a Selection and Join query. We were particularly interested in  the relationship between performance degradation and changes in the quantity  of these properties. The performance of each scheme was measured in  terms of its response time.  The response times for the element level fragmentation scheme increased  as the numbers of tuples attributes security levels and the page size were increased  more significantly so than when the number of tuples and attributes  were increased. The response times for the attribute level fragmentation  scheme was the fastest suggesting that the performance of the attribute level  scheme is superior to the tuple and element level fragmentation schemes. In  the context of assurance this research has also shown that the distribution of  fragments based on security level is a more natural approach to implementing  security in MLS/DBMS systems because a multilevel database is analogous  to a,10.1.1.1.2031,?,?
Genetic Programming for Guiding Branch and Bound Search,Konstantinos Kostikas  Charalambos Fragakis,2004,We propose how Genetic Programming (GP) can be used  for developing in real time problem-specific heuristics for Branch and  Bound (BB) search. A GP run embedded into the BB process exploits  the characteristics of the particular problem being solved evolving  a problem-specific heuristic expression. The evolved heuristic replaces  the default one for the rest of the BB search. The application of our  method to node selection for BB based Mixed Integer Programming  is illustrated by incorporating the GP node selection heuristic generator  into a BB MIP solver. The hybrid system compares well with the unmodified  solver utilizing DFS BFS or even the advanced Best Projection  heuristic when confronted with hard MIP problems from the MIPLIB3  benchmarking suite.,10.1.1.1.2032,?,Springer
Quantitative Study of Differentiated Service Model Using Ultrasan,Jun Wang Ying Wang Klara Nahrstedt,2001,In todays Internet only best-effort service is provided. With up-coming Quality of Service (QoS) requirements  raised by a wide range of communication-intensive real-time multimedia applications the best-effort service is no  longer sufficient. As a result Differentiated Service Model (DiffServ) has been proposed as a cost-effective way to  provision QoS in the Internet.,10.1.1.1.2033,?,?
Cluster-Based Scalable Network Services,Armando Fox   Steven D. Gribble Yatin Chawathe Eric A. Brewer Paul Gauthier,1997,This paper has benefited from the detailed and perceptive comments of our reviewers especially our shepherd Hank Levy. We thank Randy Katz and Eric Anderson for their detailed readings of early drafts of this paper and David Culler for his ideas on TACCs potential as a model for cluster programming. Ken Lutz and Eric Fraser configured and administered the test network on which the TranSend scaling experiments were performed. Cliff Frost of the UC Berkeley Data Communications and Networks Services group allowed us to collect traces on the Berkeley dialup IP network and has worked with us to deploy and promote TranSend within Berkeley. Undergraduate researchers Anthony Polito Benjamin Ling and Andrew Huang implemented various parts of TranSends user profile database and user interface. Ian Goldberg and David Wagner helped us debug TranSend especially through their implementation of the rewebber,10.1.1.1.2034,?,?
Genetic Programming for Object Detection,Jay Winkeler Electrical Jay F. Winkeler,?,This paper examines genetic programming  as a machine learning technique  in the context of object detection.,10.1.1.1.2035,?,Morgan Kaufmann
Distributed Perimeter Detection in Wireless Sensor Networks,Fernando Martincic Loren Schwiebert,2004,This paper introduces a distributed localized algorithm where sensor nodes determine if they are located along the perimeter of a wireless sensor network. The algorithm works correctly in su#ciently dense wireless sensor networks with a minimal requisite degree of connectivity. Using 1-hop and 2-hop neighbour information nodes determine if they are surrounded by neighbouring nodes and consequently if they are located within the interior of the wireless sensor network. The algorithm requires minimal communication between nodes - a desirable property since energy reserves are generally limited and non-renewable.,10.1.1.1.2036,wireless sensor network distributed algorithms perimeter detection,?
Sonoelastography using Compensated Power Doppler,Stephen J. McKenna   Stuart Dickson Ian W. Ricketts et al.,2002,Sonoelastography is the visualisation of elastic properties using ultrasound. It can enable tumours to be detected and localised based on their elasticity when they are less elastic than the surrounding soft tissue. In vibration sonoelastography the target tissues are vibrated while simultaneously recording ultrasound images. A technique for imaging relative elastic properties is proposed that uses a standard ultrasound machine. It combines B-scan and power Doppler signals to produce images of relative vibration amplitude. Preliminary results using simulations and liver phantoms are presented and the potential of the method to highlight areas of differing elasticity within an organ such as the breast is mentioned. The possibility of combining such a method with freehand 3D scanning enabling B-scan and power Doppler signals to simultaneously populate a voxel array for subsequent visualisation is discussed.,10.1.1.1.2037,Doppler ultrasound,?
XCS and the Monks Problems,Shaun Saxon   Alwyn Barry,1999,It has been known for some time that Learning  Classifier Systems (Holland 1986) have potential  for application as Data Mining tools. Parodi and  Bonelli (1990) applied the Boole LCS (Wilson  1985) to a Lymphography data set and reported  82% classification rates. More recent work such as  GA-Miner (Flockhart 1995) has sought to extend  the application of LCS to larger commercial data  sets introducing more complex attribute encoding  techniques static niching and hybrid genetic  operators in order to address the problems  presented by large search spaces. Despite these  results the traditional LCS formulation has shown  itself to be unreliable in the formation of accurate  optimal generalisations which are vital for the  reduction of results to a human readable form. XCS  (Wilson 1995 1998) has been shown to be capable  of generating a complete and optimally accurate  mapping of a test environment (Kovacs 1996) and  therefore presents a new opportunity for the  application of Learning Classifier Systems to Data  Mining. As part of a continuing research effort this  paper presents some first results in the application  of XCS to a Data Mining task. It demonstrates that  XCS is able to produce a classification  performance and rule set which exceeds the  performance of most current Machine Learning  techniques when applied to the Monks problems  (Thrun 1991).,10.1.1.1.2038,?,?
A Low-Footprint Class Loading Mechanism for Embedded Java Virtual Machines,Christophe Rippert  Alexandre Courbot Re Courbot  Gilles Grimaud,?,This paper shows that it is possible to dramatically reduce the memory consumption of classes loaded in an embedded Java virtual machine without reducing its functionalities. We describe how to pack the constant pool by deleting entries which are only used during the class loading process. We present some benchmarks which demonstrate the efficiency of this mechanism. We finally suggest some additional optimizations which can be applied if some restrictions to the functionalities of the virtual machine can be tolerated.,10.1.1.1.2039,?,Press
A Conceptual Model of Information Supply,Van Gils Proper B. Van Gils H. A. Proper,2003,In this paper we introduce a conceptual model for information supply which abstracts from enabling technologies such as file types transport protocols and rdf and daml+oil. Rather than focusing on technologies that may be used to actually implement information supply we focus on the question: what is information supply and how does it relate to the data (resources) found on the Web today. By taking a high level of abstraction we can gain more insight in the information market compare di#erent views on it and even present the architecture of a prototype retrieval system (Vimes ) which uses transformations to deal with the heterogeneity of information supply.,10.1.1.1.2040,Engineering,?
E-Learning: An Opportunity To Support The Individual The Group And Thecommunity, Joaquim Borges Gouveia O Pessoa Cerem Joaquim Borges Gouveia,?,The authors proposed a content management approach to develop a Webbased learning platform that were implemented and used to support both presential and distance education. The project named EFTWeb focus on the need to support both content and context. It provided the basis for the current research concerning the impact of new learning approaches. This paper presents current research extending EFTWeb to provide a broader environment that takes advantage of e-learning concepts by augmenting the framework to include beyond content and context the experience dimension. The augmented framework relates education activities with the individual the group and the community addressing how e-learning can be used to support learning experiences. ?  1. ,10.1.1.1.2041,?,?
Study of a Highly Accurate and Fast Protein-Ligand Docking Algorithm,Based On Molecular M. Taufer M. Crowley D. Price A. A. Chien C. L. Brooks Iii,2004,Few methods use molecular dynamics simulations based on atomically detailed force fields to study the proteinligand docking process because they are considered too time demanding despite their accuracy. In this paper we present a docking algorithm based on molecular dynamics simulations which has a highly flexible computational granularity. We compare the accuracy and the time required with well-known commonly used docking methods like AutoDock DOCK FlexX ICM and GOLD. We show that our algorithm is accurate fast and because of its flexibility applicable even to loosely coupled distributed systems like desktop grids for docking.,10.1.1.1.2042,Force field based methods,?
Realizing Human Centered Systems via Socially Deliberating Agents,G.A. Vouros  I. Partsakoulakis  V. Kourakos-Mavromichalis,?,Human centered systems must focus attention in roles users and tasks aiming to making the full potential of computing ubiquitous. The paper proposes a generic design pattern for such systems incorporating digital assistants and human representatives. These agents collaborate with people and deliberate socially for helping them to (a) participate in numerous physical and social contexts consistently and coherently (b) build explicit social structures governed by social laws (i.e. agents values permissions preferences contextual constraints) (c) deal with the dynamics of the activitiesenvironment and (d) manage the distributivity of the activities and environment.,10.1.1.1.2043,?,?
High-Order Balanced Multiwavelets: Theory Factorization and Design,Jérôme Lebrun Martin Vetterli,2001,This paper deals with multiwavelets and the different properties of approximation and smoothness associated with them. In particular we focus on the important issue of the preservation of discrete-time polynomial signals by multifilterbanks. We introduce and detail the property of balancing for higher degree discrete-time polynomial signals and link it to a very natural factorization of the refinement mask of the lowpass synthesis multifilter. This factorization turns out to be the counterpart for multiwavelets of the well-known zeros at condition in the usual (scalar) wavelet framework. The property of balancing also proves to be central to the different issues of the preservation of smooth signals by multifilterbanks the approximation power of finitely generated multiresolution analyses and the smoothness of the multiscaling functions and multiwavelets. Using these new results we describe the construction of a family of orthogonal multiwavelets with symmetries and compact support that is indexed by increasing order of balancing. In addition we also detail for any given balancing order the orthogonal multiwavelets with minimum-length multifilters.,10.1.1.1.2044,?,?
Improved High-Definition Video by Encoding at an Intermediate Resolution,Andrew Segall  Michael Elad  Peyman Milanfar  Richard Webb  Chad Fogg,2004,In this paper we consider the compression of high-definition video sequences for bandwidth sensitive applications. We show that down-sampling the image sequence prior to encoding and then up-sampling the decoded frames increases compression efficiency. This is particularly true at lower bit-rates as direct encoding of the high-definition sequence requires a large number of blocks to be signaled. We survey previous work that combines a resolution change and  compression mechanism. We then illustrate the success of our proposed approach through simulations. Both MPEG-2 and H.264 scenarios are considered. Given the benefits of the approach we also interpret the results within the context of traditional spatial scalability.,10.1.1.1.2046,?,?
Tailored Compression of Java Class Files,R. Nigel Horspool  Jason Corless,1998,Java class files can be transmitted more efficiently over a network if they are compressed. After an...,10.1.1.1.2047,?,?
FCNDP No. 166,Fcnd Discussion Paper Futoshi Yamauchi,?,This paper models the assimilation process of migrants and shows evidence of the  complementarity between their destination experience and upon-arrival human capital.  Bayesian learning and dynamics of matching are modeled and empirically assessed using  panel data of wages from the Bangkok labor market in Thailand. The analysis  incorporates (1) the heterogeneity of technologies and products characteristic of urban  labor markets (2) imperfect information on migrants types and skill demanded in the  markets and (3) migrants optimal learning over time. Returns to destination experience  emerge endogenously. Estimation results which control migrants selectivity by firstdifferencing procedures show that (1) schooling returns are lower for migrants than for  natives (2) the accumulation of destination experience raises wages for migrants (3) the  experience effect is greater for more-educated agents i.e. education and experience are  complementary and (4) the complementarity increases as destination experience  accumulates. The results imply that more-educated migrants have higher learning  efficiency and can perform tasks of greater complexity ultimately yielding higher wage  growth in the destination market. Simulations show that due to the complementarity  wages for different levels of upon-arrival human capital diverge in the migrants  assimilation process.#  iii Contents   Acknowledgments............................................................................................................... v    1. ,10.1.1.1.2048,1. Introduction.....................................................................................,?
Mirror Image Learning for Autoassociative Neural Networks,Shusaku Shimizu Wataru Wataru Ohyama Tetsushi Wakabayashi Fumitaka Kimura,?,for the autoassociative neural networks and evaluates the performance by handwritten numeral recognition test. Each of the autoassociative networks is first trained independently for each class using the feature vector of the class. Then the mirror image learning algorithm is applied to enlarge the learning sample of each class by mirror image patterns of the confusing classes to achieve higher recognition accuracy.,10.1.1.1.2049,?,?
User Modeling in the Design of Interactive Interface Agents,Michael Fleming Robin Cohen,1999,This paper presents a model for more interactive interface agents. This more  interactive style of agents aims to increase the trust and understanding between user and  agent by allowing the agent under certain conditions to solicit further input from the user  about his preferences and desires. With the user and agent engaging in specific clarification  dialogues the users input is employed to adjust the agents model of the user. Moreover  the user is provided with an ability to view this user model under certain well defined  circumstances. Since both the agent and user can take the initiative to interact basic issues  regarding mixed-initiative systems arise. These issues are addressed in our model which  also takes care to restrict the agents interaction with the user to avoid bothering the user  unduly. We illustrate our design for more interactive interface agents by including some  examples in the domain of electronic mail.,10.1.1.1.2050,user modeling agents personalized and adaptive informationassistants mixed-initiative,?
Gaussian Importance Sampling  . . . ,Paul Glasserman et al.,1998,This paper deals with efficient algorithms for simulating performance measures of Gaussian random vectors. Recently we developed a simulation algorithm which consists of doing importance sampling by shifting the mean of the Gaussian random vector. Further variance reduction is obtained by stratification along a key direction. A central ingredient of this method is to compute the optimal shift of the mean for the importance sampling. The optimal shift is also a convenient and in many cases an effective direction for the stratification. In this paper after giving a brief overview of the basic simulation algorithms we focus on issues regarding the computation of the optimal change of measure. A primary application of this methodology occurs in computational finance for pricing path dependent options.,10.1.1.1.2051,?,?
The Added Value of Written Knowledge Building in a Three-Dimensional Virtual World,M. B. Ligorio H. Van Der Meijden,2001,Introduction  The concept of knowledge building (Scardamalia  Bereiter 1994) is closely related to the notion of constructivism (Papert 1991). Both assume that learners construct knowledge by interpreting their perceptual experiences in terms of prior knowledge current mental structures and existing beliefs (Jonassen  McAleese 1993). Constructivism implies that learning is the personal interpretation of the world situated in a rich context. Learners involvement in the process of knowledge construction development and evaluation aims at the development of their reflective awareness. Collaboration is used to encourage the construction of an understanding from multiple viewpoints.  In this project it is assumed that learning occurs by building a virtual world both under the physical point of view building virtual houses and objects and under the cultural point of view by exchanging discussing and generating ideas knowledge and specific content for each virtual house. The stu,10.1.1.1.2052,?,?
Buddy Tracking -- Efficient Proximity Detection Among Mobile Friends, Arnon Amir  Alon Efrat  Jussi Myllymaki  Kevin Wampler  et al.,2004,Global positioning systems (GPS) and mobile phone networks are making it possible to track individual users with an increasing accuracy. It is natural to ask whether one can use this information to maintain social networks. Here each user wishes to be informed whenever one of a list of other users called the users friends appears in the users vicinity. In contrast to more traditional positioning based algorithms the computation here depends not only on the users own position on a static map but also on the dynamic position of the users friends. Hence it requires both communication and computation resources. The computation can be carried out either between the individual users in a peer-to-peer fashion or by centralized servers where computation and data can be collected at one central location. In the peer-to-peer model a novel algorithm for minimizing the number of location update messages between pairs of friends is presented. We also present an efficient algorithm for the centralized model based on region hierarchy and quadtrees. The paper provides an analysis of the two algorithms compares them with a naive approach and evaluates them using the IBM City Simulator system.,10.1.1.1.2053,Strips algorithm location based services social networks global positioning systems dynamic nearest neighbors,?
Military Simulation Worlds And Organizational Learning,Michael D. Proctor  Justin C. Gubler,1998,The operational benefits of having a learning organization include at the very minimum increased organizational competitiveness and responsiveness in a given realm of competition. Military simulation worlds have served and continue to serve as practice fields for organizational learning. Organizational learning mechanisms like the simulation debriefing session have been linked to organizational learning through a taxonomy for rare events. This research provides both descriptive and prescriptive findings for military interactive simulation and debriefing systems. Some suggestions for simulation system design are made based on the research.,10.1.1.1.2054,?,?
Simulation Software Component Architecture For Simulation-Based Enterprise Applications,Charles R. Harrell  Donald Hicks,1998,This paper examines trends and technologies leading towards simulation-based enterprise applications. Component internet and distributed computing technologies are presented as enablers of simulation-based enterprise applications. Examples are given of typical applications that can take advantage of distributed simulation components. The goal of this paper is to present a high level component architecture that will work in current enterprise information technology (IT) environments,10.1.1.1.2055,?,?
Visualization in Resource Allocation Tasks,Pearl Pu George George Melissargos,1997,This paper presents an application of information visualization techniques in the resource re-allocation domain and in particular flight rescheduling. In collaboration with Swissair our work concentrates on human-computer problem solving and how visualization techniques can help users perceive the entire solution space in four abstraction models in order to make the right decision. We present a technique called coordinated visualization,10.1.1.1.2056,?,?
Efficient Integration of Behavioral Synthesis within Existing Design Flows,Cesrio Sugar Moussa W. O. Cesário Z. Sugar I. Moussa A. A. Jerraya,?,This paper analyzes the reasons why behavioral synthesis was never widely accepted by designers and then we propose a practical solution to this problem. The main breakthrough of this new approach is the redefinition of the synthesis flow at the behavioral level to better profit from the powerful of RTL and FSM synthesis tools. The effectiveness of this new methodology is illustrated with two large design examples: a 2-million-transistor ATM shaper design and a motion estimator for a video codec (H261 standard).,10.1.1.1.2057,?,?
Input Modeling Techniques For Discrete-Event Simulations,Lawrence Leemis,2001,Most discrete-event simulation models have stochastic elements that mimic the probabilistic nature of the system under consideration. A close match between the input model and the true underlying probabilistic mechanism associated with the system is required for successful input modeling. The general question considered here is how to model an element (e.g. arrival process service times) in a discrete-event simulation given a data set collected on the element of interest. For brevity it is assumed that data is available on the aspect of the simulation of interest. It is also assumed that raw data is available as opposed to censored data grouped data or summary statistics. This example-driven tutorial examines introductory techniques for input modeling. Most simulation texts (e.g. Law and Kelton 2000) have a broader treatment of input modeling than presented here. Nelson and Yamnitsky (1998) survey advanced techniques.,10.1.1.1.2058,?,Piscataway
Property P for Knots admitting Certain Gabai Disks,Oliver T. Dasbach Tao Li,?,We show that if a knot has a minimal spanning surface that admits certain Gabai  disks then this knot has Property P. As one of the applications we extend and simplify  a recent result of Menasco and Zhang that closed 3-braid knots have Property P. Other  applications are given.,10.1.1.1.2059,?,?
Automatic Generation Including Fast Timed Simulation Models of Operating Systems in Multiprocessor SoC Communication Design,Sungjoo Yoo Gabriela Nicolescu Lovic Gauthier Ahmed A. Jerraya,2002,To enable fast and accurate evaluation of HW/SW implementation choices of on-chip communication we present a method to automatically generate timed OS simulation models. The method generates the OS simulation models with the simulation environment  as a virtual processor. Since the generated OS simulation models use real OS code the presented method can mitigate the OS code equivalence problem. The generated model also simulates different types of processor exceptions. This approach provides two orders of magnitude higher simulation speedup compared to the simulation using instruction set simulators for SW simulation.,10.1.1.1.2060,?,?
Optimization Of Multiclass Queueing Networks  with Changeover Times via the Achievable Region Approach:  Part I  The Single-station Case,Dimitris Bertsimas José Niño-Mora,1999,?,10.1.1.1.2063,?,?
A Generalized Maximum Entropy Approach to Bregman Co-clustering and Matrix Approximation,Arindam Banerjee Inderjit Dhillon Joydeep Ghosh Srujana Merugu  Dharmendra S. Modha,2004,Co-clustering is a powerful data mining technique with varied applications such as text clustering microarray analysis and recommender systems. Recently an informationtheoretic co-clustering approach applicable to empirical joint probability distributions was proposed. In many situations co-clustering of more general matrices is desired. In this paper we present a substantially generalized co-clustering framework wherein any Bregman divergence can be used in the objective function and various conditional expectation based constraints can be considered based on the statistics that need to be preserved. Analysis of the coclustering problem leads to the minimum Bregman information principle which generalizes the maximum entropy principle and yields an elegant meta algorithm that is guaranteed to achieve local optimality. Our methodology yields new algorithms and also encompasses several previously known  clustering and co-clustering algorithms based on alternate minimization.,10.1.1.1.2064,Categories and Subject Descriptors I.2.6 [Artificial Intelligence Learning General Terms Algorithms Keywords Co-clustering Matrix Approximation Bregman,?
Active Authorization as High-level Control,Daniel Cvrcek,2000,The paper introduces several issues that have one common target - secure cooperation of autonomous information systems. We show that Active authorization model may be an abstract layer that allows simple efficient and secure management of heterogeneous systems security properties.,10.1.1.1.2065,?,?
Data Cleaning Methods,William Winkler,2003,Data Cleaning methods are used for finding duplicates within a  file or across sets of files. This overview provides background on  the Fellegi-Sunter model of record linkage. The Fellegi-Sunter  model provides an optimal theoretical classification rule. Fellegi  and Sunter introduced methods for automatically estimating   optimal parameters without training data that we extend to many  real world situations.   Keywords   EM Algorithm string comparator unsupervised learning.   1. ,10.1.1.1.2066,string comparator unsupervised learning,?
Beacon Vector Routing: Scalable Point-to-Point in Wireless Sensornets,Rodrigo Fonseca Rodrigo Fonseca Sylvia Ratnasamy Sylvia Ratnasamy  David Culler David Culler  Scott Shenker Scott Shenker Ion Stoica Ion Stoica,2004,This paper proposes a practical and scalable technique for point-to-point routing in wireless sensornets. This method called Beacon Vector Routing (BVR) assigns coordinates to nodes based on the vector of distances (hop count) to a small set of beacons and then defines a distance metric on these coordinates. Packets are routed greedily being forwarded to the next hop that is the closest (according to this beacon vector distance metric) to the destination. This approach is evaluated through both simulation and a prototype implementation on motes.,10.1.1.1.2067,?,?
Communicative Aspects of Human-Robot Interaction,Thora Tenbrink,2001,How do we communicate wirh robots?... This paper will outline some basic aspects of what characterizes human-robot interaction in contrast to other kinds of interaction such as communication with children or foreigners. Here the robots looks -- humanoid or not -- will not play a major role. The question at hand is rather whether or to what degree humans expect a robot to behave linguistically like a human being...,10.1.1.1.2068,?,?
Collapse-to-Zoom: Viewing Web Pages on Small Screen Devices by Interactively Removing Irrelevant Content,Patrick Baudisch Xing Xie Chong Wang Wei-ying Ma,2004,Overview visualizations for small-screen web browsers were designed to provide users with visual context and to allow them to rapidly zoom in on tiles of relevant content. Given that content in the overview is reduced however users are often unable to tell which tiles hold the relevant material which can force them to adopt a time-consuming hunt-and-peck strategy. Collapse-to-zoom addresses this issue by offering an alternative exploration strategy. In addition to allowing users to zoom into relevant areas collapse -to-zoom allows users to collapse areas deemed irrelevant such as columns containing menus archive material or advertising. Collapsing content causes all remaining content to expand in size causing it to reveal more detail which increases the users chance of identifying relevant content. Collapse-to-zoom navigation is based on a hybrid between a marquee selection tool and a marking menu called marquee menu. It offers four commands for collapsing content areas at different granularities and to switch to a full-size reading view of what is left of the page.,10.1.1.1.2069,screen device PDA pen overview fisheye zooming,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Thomas J. Schriber,?,This paper provides simulation practitioners and consumers with a grounding in how discrete-event simulation software works. Topics include discrete-event systems entities resources control elements and operations simulation runs entity states entity lists and entity-list management. The implementation of these generic ideas in AutoMod SLX and Extend is described. The paper concludes with several examples of why it matters for modelers to know how their simulation software works including coverage of SIMAN (Arena) ProModel and GPSS/H as well as the other three tools.,10.1.1.1.2071,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Jui-hua Li Joanne Holliday,?,This paper presents a methodology of decision-making for embedded I/O buffer sizes in a single-bus shared-memory system. The decision is made with the aid of a queuing model simulation and the proposed algorithm. The generalized queueing model is simulated to cover two cases: independent processing units and pipelined processing units in a shared-memory environment. The objective is to obtain the best performance with the optimized embedded buffers in the system. Therefore an algorithm is developed to find the optimal solution efficiently by exploring the correlation between buffers and system performance. The local optimum is guaranteed. The method can be widely applied to many applications.,10.1.1.1.2072,?,?
A Routing Scheme for Content-Based Networking,Antonio Carzaniga   Matthew J. Rutherford Alexander L. Wolf,2004,This paper proposes a routing scheme for contentbased networking. A content-based network is a communication network that features a new advanced communication model where messages are not given explicit destination addresses and where the destinations of a message are determined by matching the content of the message against selection predicates declared by nodes. Routing in a content-based network amounts to propagating predicates and the necessary topological information in order to maintain loop-free and possibly minimal forwarding paths for messages. The routing scheme we propose uses a combination of a traditional broadcast protocol and a contentbased routing protocol. We present the combined scheme and its requirements over the broadcast protocol. We then detail the content-based routing protocol highlighting a set of optimization heuristics. We also present the results of our evaluation showing that this routing scheme is effective and scalable.,10.1.1.1.2073,?,?
Grounding Knowledge of Engineering Applications in Systematic Terms,Ying Liu  Jin Yu,2004,In the main research of internet-computing enabled knowledge management we use some of the most advanced research scenarios arguing that we critically need a system approach to question where knowledge comes from. In particular within a given engineering domain we synthesis the problems and reveal that the knowledge is embraced by interactions among systems system observers observables engineering objects and instruments that the complex system interactions must be dispatched into infrastructural layers based on physicsontologies that the ontologies must be dedicated to human and data communications. Such a synthesis would impact on knowledge technologies for solving engineering problems in scalabilities as well as in collective vocabularies that must associate with the communication crossing the layers in the problem solving environment.,10.1.1.1.2074,?,?
Photon Mapping on Programmable Graphics Hardware,Timothy J. Purcell Craig Donner Mike Cammarano Henrik Wann Jensen Pat Hanrahan,2003,We present a modified photon mapping algorithm capable of running entirely on GPUs. Our implementation uses  breadth-first photon tracing to distribute photons using the GPU. The photons are stored in a grid-based photon  map that is constructed directly on the graphics hardware using one of two methods: the first method is a multipass  technique that uses fragment programs to directly sort the photons into a compact grid. The second method uses  a single rendering pass combining a vertex program and the stencil buffer to route photons to their respective  grid cells producing an approximate photon map. We also present an efficient method for locating the nearest  photons in the grid which makes it possible to compute an estimate of the radiance at any surface location in the  scene. Finally we describe a breadth-first stochastic ray tracer that uses the photon map to simulate full global  illumination directly on the graphics hardware. Our implementation demonstrates that current graphics hardware  is capable of fully simulating global illumination with progressive interactive feedback to the user.,10.1.1.1.2075,Programmable Graphics Hardware Global Illumination Photon Mapping,?
Solar: Building a Context Fusion Network for Pervasive Computing,Guanling Chen,2004,  The complexity of developing context-aware pervasive-computing applications calls for distributed software infrastructures that assist applications to collect aggregate and disseminate contextual data. In this dissertation we present a Context Fusion Network (CFN) called Solar which is built with a scalable and self-organized service overlay. Solar is flexible and allows applications to select distributed data sources and compose them with customized data-fusion operators into a directed acyclic information flow graph. Such a graph represents how an application computes high-level understandings of its execution context from low-level sensory data. To manage application-specified operators on a set of overlay nodes called Planets Solar provides several unique services such as application-level multicast with policy-driven data reduction to handle buffer overflow context-sensitive resource discovery to handle environment dynamics and proactive monitoring and recovery to handle common failures. Experimental results show that these services perform well on a typical DHT-based peer-to-peer routing substrate. In this dissertation we also discuss experience insights and lessons learned from our quantitative analysis of the input sensors a detailed case study of a Solar application and development of other applications in different domains.,10.1.1.1.2076,?,?
The Effects of Partial Observability in SLAM,Juan Andrade-Cetto  Alberto Sanfeliu,2004,In this article we show that partial observability hinders full reconstructibility of the state space in SLAM making the final map estimate dependent on the initial observations and not guaranteeing convergence to a positive semi-definite covariance matrix. By characterizing the form of the total Fisher information we are able to determine the unobservable state space directions. To overcome this problem we formulate new fully observable measurement models that make SLAM stable.,10.1.1.1.2077,?,?
On Low Bit-Rate Coding Using the Contourlet Transform,Ramin Eslami Hayder Radha,2003,In this work we study and analyze the contourlet transform for low bit-rate image coding. This image-based geometrical transform has been recently introduced to efficiently represent images with a spars set of coefficients. In order to explore the potentiality of this new transform as a tool for image coding we developed a direct coding scheme that is based on using non-linear approximation of images. We code the quantized transform coefficients as well as the significance map of an image in the contourlet transform domain. Based on the proposed approach we analyzed the rate-distortion curves for a set of images and concluded that this coding approach despite its redundancy is visually competitive with a direct wavelet transform coder and in particular it is visually superior to wavelet coding for images with textures and oscillatory patterns.,10.1.1.1.2078,?,?
On the Nature of the Redshift in the Standard Model of Cosmology,V. S. Troitsky,2001,Introduction  It is shown in the present paper that the standard model of cosmology owing to its mathematical structure is actually basedontheconcept of a variation of light velocity with time due to whichthe redshift is observed. First we recall the fundamental statements of the standard cosmology.  The generally accepted Big Bang cosmology is based on the space-time metric:  d d d d d s c t a t r f r o  2 2 2 2 2 2 2 2 2    q q j sin (1)  Here a(t) is the radius of the Universe or otherwise the  scale dimension of space defined by the solution of the  Einstein gravity equation j q are the angular coordinates  of galaxies and r is the relative constant radial  coordinate. To simplify the expression we shall consider  the case of plane space for which f(r) =  r. In this case  themetric distance up to galaxies detectedbythe station-  ary length standard will be according to (1)R(t)=a(t)r.  This signifies that the Universe is a sphere of radiusa(t)  filled with galaxies th,10.1.1.1.2079,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Tim Baines Linda Hadfield Steve Mason,?,Discrete Event Simulation of manufacturing systems has become widely accepted as an important tool to aid the design of such systems. Often however it is applied by practitioners in a manner which largely ignores an important element of industry namely the workforce. Workers are usually represented as simple resources often with deterministic performance values. This approach ignores the potentially large effect that human performance variation can have on a system. A long-term data collection exercise is described with the aim of quantifying the performance variation of workers in a typical automotive assembly plant. The data are presented in a histogram form which is immediately usable in simulations to improve the accuracy of design assessment. The results show levels of skewness and range which are far larger than anticipated by current researchers and practitioners in the field.,10.1.1.1.2080,?,?
Protocol Behavior: More Effort More Gains?,Mamatas And Tsaoussidis,2004,We investigate the behavior of TCP(##) protocols in the presence of wireless networks. We seek an answer to strategic issues of maximizing energy and bandwidth exploitation without damaging the dynamics of multipleflow equilibrium. Our perspective is novel indeed: What is the return of the effort that a protocol expends? Can we achieve more gains with less effort? We study first the design assumptions of TCP(##) protocols and discuss the impact of equation-based modulation of # and # on protocol efficiency. We introduce two new metrics to capture protocol behavior: The Extra Energy Expenditure and the Unexploited Available Resource Index. We confirm experimentally that in general smoothness and responsiveness constitute a tradeoff,10.1.1.1.2081,?,?
Automatic Classification of Audio Data,Carlos H. L. Costa  Jaime D. Valle Jr.  Alessandro L. Koerich Ro L. Koerich,2004,In this paper a novel content--based musical genre classification approach that uses combination of classifiers is proposed. First musical surface features and beat-- related features are extracted from different segments of digital music in MP3 format. Three 15--dimensional feature vectors are extracted from three different parts of a music clip and three different classifiers are trained with such feature vectors. At the classification mode the outputs provided by the individual classifiers are combined using a majority vote rule. Experimental results show that the proposed approach that combines the output of the classifiers achieves higher correct musical genre classification rate than using single feature vectors and single classifiers.,10.1.1.1.2082,Audio classification musical genre classification information fusion classifier,?
Faster Deterministic Broadcasting in ad hoc Radio Networks,Dariusz R. Kowalski Andrzej Pelc,2003,We consider radio networks modeled as directed graphs. In  ad hoc radio networks every node knows only its own label and a linear  bound on the size of the network but is unaware of the topology of the  network or even of its own neighborhood. The fastest currently known  deterministic broadcasting algorithm working for arbitrary n-node ad  hoc radio networks has running time O(n log    n). Our main result is a  broadcasting algorithm working in time O(n log n log D) for arbitrary n-  node ad hoc radio networks of eccentricity D. The best currently known  lower bound on broadcasting time in ad hoc radio networks  is    hence our algorithm is the  rst to shrink the gap between bounds on  broadcasting time in radio networks of arbitrary eccentricity to a logarithmic  factor. We also show a broadcasting algorithm working in time  O(n log D) for complete layered n-node ad hoc radio networks of eccentricity   D. The latter complexity is optimal.,10.1.1.1.2083,?,Springer-Verlag
EPTD DISCUSSION PAPER NO. 91 WHY TVES HAVE CONTRIBUTED TO INTERREGIONAL IMBALANCES IN CHINA,Junichi Ito,?,The major objectives of this paper are to shed some light on the mechanism that generates interregional economic imbalances among communities in rural China. Central to this issue is the development of township and village enterprises (TVEs) because the presence of secondary industry is closely associated with the economic welfare of the people residing in rural communities. In rural Jiangsu for example spatial disparities have become more pronounced over the past two decades. This fact suggests that the influence of initial conditions---historical and geographical advantages of industrial frontrunners---has not been erased but rather continues to persist. This is attributed to a variety of factors including the less efficient use of TVE resources in poor areas the decentralized fiscal system and agglomeration economies. In short the socialist regime of self-reliance that still lingers in Chinas rural society traps less advanced areas in poverty. KEYWORDS: economic imbalance rural China past-dependency institution allocation efficiency agglomeration economies ii  ACKNOWLEDGMENTS The author acknowledges the general assistance of staff from the Chinese Academy of Agricultural Sciences Jiangsu Academy of Social Sciences Nanjing Agricultural University and Policy Research Institute (MAFF Japan) and financial support from the Government of Japan. The author is grateful for helpful comments from Katsuji Nakagane Zongshun Bao Hao Hu Funing Zhong Peter Hazell and other participants at various seminars. iii  TABLE OF CONTENTS 1. ,10.1.1.1.2084,TABLE OF CONTENTS,?
The Architecture of Complex Systems,Vito Latora Massimo Marchiori,2002,INTRODUCTION  At the present time the most commonly accepted definition of a complex system is that of a system containing many interdependent constituents which interact nonlinearly    . Therefore when we want to model a complex system the first issue has to do with the connectivity properties of its network the architecture of the wirings between the constituents. In fact we have recently learned that the network structure can be as important as the nonlinear interactions between elements and an accurate description of the coupling architecture and a characterization of the structural properties of the network can be of fundamental importance also to understand the dynamics of the system.  The definition may seem somewhat fuzzy and generic: this is an indication that the notion of a complex system is still not precisely delineated and di#ers from author to author. On the other side there is complete agreement that the ideal complex systems are the biological ones especially,10.1.1.1.2085,?,?
ESPRIT Project 20716,Generic Upgradable Architecture David Powell Christophe Rabéjac Andrea Bondavalli,1977,Contents  1. Notation and definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 2. Heuristics for a-counts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 3. Interactive consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 3.1 Consolidation of a-counts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 3.2 Consolidation of binary accusations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 4. Diagnosis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9  5. Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 6. References,10.1.1.1.2086,?,?
The Spatial Distribution of Poverty in Vietnam and the Potential for Targeting,N. Minot  B. Baulch Contact Candice Cohen Contact Candice Cohen,2002,This paper combines household survey and census data to construct a provincial poverty map of Vietnam and evaluate the accuracy of geographically targeted anti-poverty programs. First the paper estimates per capita expenditure as a function of selected household and geographic characteristics using the 1998 Vietnam Living Standards Survey. Next these results are combined with data on the same household characteristics from the 1999 Census to estimate the incidence of poverty in each province. The results indicate that rural poverty is concentrated in ten provinces in the Northern Uplands two provinces of the central Highlands and two provinces in the Central Coast. Finally Receiver Operating Characteristics curves are used to evaluate the effectiveness of geographic targeting. The results show that the existing poor communes system excludes large numbers of poor people but there is potential to sharpen poverty targeting using a small number of easy-to-measure household characteristics.,10.1.1.1.2087,?,?
An Autonomous Spacecraft Agent Prototype,Barney Pell  Douglas E. Bernard  Steve A. Chien  Erann Gat Nicola Muscettola  P. Pandurang Nayak Michael D. Wagner  Brian C. Williams,1997,This paper describes the New Millennium Remote  Agent #NMRA# architecture for autonomous spacecraft  control systems. This architecture integrates traditional  real-time monitoring and control with constraintbased  planning and scheduling robust multi-threaded  execution and model-based diagnosis and recon#guration.,10.1.1.1.2088,?,ACM Press
Fully Automatic Cross-Associations,Deepayan Chakrabarti Spiros Spiros Papadimitriou Dharmendra S. Modha Christos Faloutsos,2004,Large sparse binary matrices arise in numerous data mining applications such as the analysis of market baskets web graphs social networks co-citations as well as information retrieval collaborative filtering sparse matrix reordering etc. Virtually all popular methods for the analysis of such matrices---e.g. k-means clustering METIS graph partitioning SVD/PCA and frequent itemset mining---require the user to specify various parameters such as the number of clusters number of principal components number of partitions and support. Choosing suitable values for such parameters is a challenging problem.,10.1.1.1.2089,?,ACM Press
Word Association Thesaurus,As Resource For Anna Sinopalnikova,2004,The goal of the present paper is to report on the on-going research for  applying psycholinguistic resources to building a WordNet-like lexicon of the Russian  language. We are to survey different kinds of the linguistic data that can be extracted  from a Word Association Thesaurus a resource representing the results of a largescaled  free association test. In addition we will give a comparison of Word Association  Thesaurus and other language resources applied to wordnet constructing (e.g. text  corpora explanatory dictionaries) from the viewpoint of the quality and quantity of  information they supply the researcher with.,10.1.1.1.2091,?,?
Twin Primes Conjecture 95,Two-Sided Error Ufd Victor Shoup,2005,solving linear congruences  integer 19  polynomial 358  Sophie Germain prime 94  splitting field 364  square root (modular) 275  algorithm for computing  284  square-free  integer 12  polynomial 431  square-free decomposition  algorithm 457 467  standard basis 298  statistical distance 125  Stein C. 273  Stein J. 74  Strassen V. 55 258 289  strict polynomial time 142  subalgebra 347  subfield 212  subgroup 177  generated by 194  submodule 293  generated (or spanned) by  294  subring 211  subspace 300  surjective 2  theta function of Chebyshev 77  total degree 221 222  trace 440  transcendental element 363  transpose 310  trial division 236  trivial ring 206  Pomerance C. 55 96 258 259  344 345 482  de la Vallee Poussin C.-J. 95 96  power map 186  pre-image 2  pre-period 72  prefix free 143  primality test  deterministic 471  probabilistic 236  prime  ideal 226  in an integral domain 371  number 5  prime number theorem,10.1.1.1.2092,?,Cambridge University Press
An Architecture for Mobile Distributed Application Delivery with Soft Real-time Constraints,Joel Jones Susan Vrbsky Jingyuan Zhang  Sibrabrata Ray,?,The power of ubiquitous computing lies not just in constant access but also in tailoring of information based upon location. In this paper we describe an architecture that supports tailoring of information and applications for their environment. This environment includes the mobile client device its location the available bandwidth and any soft real-time constraints.,10.1.1.1.2093,?,?
Motivation to e-Learn within organizational settings: What,Is It And Maria Alex Ra Rentroia-bonito Joaquim Arm O Pires Jorge,?,e-Learning is expected to support organizations in being more adaptable  and competitive and individuals in becoming or staying more employable.,10.1.1.1.2094,?,?
Forthcoming in Proceedings of Medinfo. San Francisco 7-11 September 2004,Actions In Health Lowell Vizenor,1403,In order to ensure that the information and knowledge needed for the management of healthcare is appropriately shared human behavior within health care organizations (HCOs) needs to be carefully analyzed. Hence guidelines protocols and messaging standards must be combined with models of resources and processes of patient care that are based on a sound ontology of organizations. This requires a general theory of the ontology of social institutions. Among the many groups attempting to develop efficient ways of sharing information across healthcare systems and organizations is Health Level 7 (HL7). Here I address the question whether HL7 reflects a sound analysis of behavior within HCOs on the basis of a sound ontology of organizations. I then apply ontological principles designed to show how the Reference Information Model (RIM) might be modified in such a way as to support efficient communication of medical information within and between healthcare organizations.,10.1.1.1.2095,Ontology Speech Acts HL7 RIM Electronic Health Record,?
Practical Partition-Based Theorem Proving for Large Knowledge Bases,Bill Maccartney Sheila Mcilraith,2003,Query answering over commonsense knowledge  bases typically employs a first-order logic theorem  prover. While first-order inference is intractable  in general provers can often be hand-tuned to answer  queries with reasonable performance in practice.,10.1.1.1.2096,?,?
Evaluating Adaptive Signal Control Using Corsim,Charlie Stallard  Larry E. Owen D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,1998,This paper discusses the evaluation of adaptive traffic signal control using TSIS/CORSIM. The paper reviews three adaptive control strategies that have been developed through contracts awarded by the FHWAs TurnerFairbank IST (Intelligent Systems and Technology) Division. The paper discusses the framework and evaluation procedures for testing and assessing these advanced control algorithms before they are deployed in the field. The paper also discusses sophisticated hardware in the loop experiments that permit the benefits of other ITS concepts and technologies to be assessed and quantified.,10.1.1.1.2097,?,?
Trying Again to Fail-First,J. Christopher Beck Patrick Prosser Richard J. Wallace,2005,In ECAI 1998 Smith  Grant performed a study [1] of the fail-first  principle of Haralick  Elliott [2]. The fail-first principle states that To succeed  try first where you are most likely to fail. For constraint satisfaction problems  (CSPs) Haralick  Elliott realized this principle by minimizing branch depth.,10.1.1.1.2098,?,Springer
Analyzing Library Collections With Starfield Visualizations,J. Alfredo Sánchez  Michael B. Twidale David M. Nichols  Nabani N. Silva J. Alfredo Sánchez A Michael B. Twidale B David M. Nichols C Nabani N. Silva A,2004,This paper presents a qualitative and formative study of the uses of a starfield-based visualization interface for analysis of library collections. The evaluation process has produced feedback that suggests ways to significantly improve starfield interfaces and the interaction process to improve their learnability and usability. The study also gave us clear indication of additional potential uses of starfield visualizations that can be exploited by further functionality and interface development. We report on resulting implications for the design and use of starfield visualizations that will impact their graphical interface features their use for managing data quality and their potential for various forms of visual data mining. Although the current implementation and analysis focuses on the collection of a physical library the most important contributions of our work will be in digital libraries in which volume complexity and dynamism of collections are increasing dramatically and tools are needed for visualization and analysis.,10.1.1.1.2099,Collections starfields large information spaces libraries,?
Automated Composition of Semantic Web Services into Executable Processes,P. Traverso  M. Pistore,2004,Different planning techniques have been proposed so far which address the problem of automated composition of web services. However in realistic cases the planning problem is far from trivial: the planner needs to deal with the nondeterministic behaviour of web services the partial observability of their internal status and with complex goals e.g. expressing temporal conditions and preference requirements. We propose...,10.1.1.1.2100,?,Springer-Verlag
Target Localization Based on Energy Considerations in Distributed Sensor Networks,Yi Zou  Krishnendu Chakrabarty,2003,Wireless distributed sensor networks (DSNs) are important for a number of strategic applications such as coordinated target detection surveillance and localization. Energy is a critical resource in wireless sensor networks and system lifetime needs to be prolonged through the use of energyconscious sensing strategies during system operation. We propose an energy-aware target detection and localization strategy for cluster-based wireless sensor networks. The proposed method is based on an a posteriori algorithm with a two-step communication protocol between the cluster head and the sensors within the cluster. Based on a limited amount of data received from the sensor nodes the cluster head executes a localization procedure to determine the subset of sensors that must be queried for detailed target information. This approach reduces both energy consumption and communication bandwidth requirements and prolongs the lifetime of the wireless sensor network. Simulation results show that a large amount of energy is saved during target localization using this strategy.,10.1.1.1.2101,?,?
Genome Informatics 14: 408--409 (2003) Detection of Tissue Specific Genes by Putative,Regulatory Motifs In Katsuhiko Murakami Toshio Kojima Yoshiyuki Sakaki,?,Introduction  Gene expression of multi-cellular organisms is regulated by transcription factors (TFs) that interact with regulatory cis-elements on DNA sequences. To find the functional regulatory elements computer searching can predict TF binding sites (TFBS) using position weight matrices (PWMs) that represent positional base frequencies of collected experimentally determined TFBS. However it is still di#cult to tell authentic sites from false positives. Reports have shown that particular TFBS are concentrated in promoters though a general tendency is uncertain. Computational approaches to reveal structure of promoter as combination of TFBS are required. Here we have examined the correlation between predicted TFBS and promoters and identified two PWM groups 1) PWMs whose TFBS are clustered in promoters mainly by the existence of CpG islands (CGI) 2) PWMs whose TFBS are clustered in promoter independent of CGI. As an application of the groups we show that tissue specific genes ,10.1.1.1.2102,promoter tissue-specific gene expression position weight matrix regulatory motif CpG,?
Achieving Design Closure through Delay Relaxation Parameter,Ankur Srivastava  Seda Ogrenci Memik  Bo-Kyung Choi Memik Bo-kyung  Majid Sarrafzadeh,2003,Current design automation methodologies are becoming incapable of achieving design closure especially in the presence of deep submicron effects. This paper addresses the issue of design closure from a high level point of view. A new metric called delay relaxation parameter (DRP) for RTL (Register Transfer Level) designs is proposed. DRP essentially captures the degree of delay relaxation that the design can tolerate without violating the clock constraint. This metric when optimized results in quicker design flow. Algorithms to optimize DRP are formulated and their optimality are investigated. Experimental results are conducted using a state of the art design flow with Synopsys Design Compiler followed by Cadence Place and Route. Our approach of optimizing DRP resulted in lesser design iterations and faster design closure as compared to designs generated through Synopsys Behavioral Compiler and a representative academic design flow.,10.1.1.1.2103,?,?
Profiles for the Situated Web,L. Suryanarayana  Johan Hjelm Odolwkd#wul Vef Frp,2002,The World Wide Web is evolving into a medium that will soon make it possible for conceiving and implementing situation-aware services. A situation-aware or situated web application is one that renders the user with an experience (content interaction and presentation) that is so tailored to his/ her current situation. This requires the facts and opinions regarding the context to be communicated to the server by means of a profile which is then applied against the description of the application objects at the server in order to generate the required experience. This paper discusses a profiles view of the situated web architecture and analyzes the key technologies and capabilities that enable them. We conclude that trusted frameworks wherein rich vocabularies describing users and their context applications and documents along with rules for processing them are critical elements of such architectures.,10.1.1.1.2104,General Terms Design Standardization Languages. Keywords Situated-aware applications web architecture profiles vocabulary XML CC/PP,?
PatManQL: A language to manipulate patterns and data in hierarchical catalogs,Panagiotis Bouros  Theodore Dalamagas  Timos Sellis Manolis Terrovitis,2004,Hierarchical structures and catalogs is a way to organize and enrich semantically the available information in the Web. From simple tree-like structures with syntactic constraints and type information like DTDs and XML schemas to hierarchies on a category/subcategory basis like thematic hierarchies and RDF(s) models such structures group data under certain properties. Paths in these structures are the knowledge artifacts to represent such groups. Considering paths in hierarchies as patterns which provide a conceptual clustering of data in groups sharing common properties we present   a language to manipulate patterns and data in hierarchical catalogs. 1 ,10.1.1.1.2105,?,?
Analysis on an On-Line Iterative Correction Control Law for Visual Tracking,David Liu  Li-Chen Fu David Liu Li-chen Su-hau Hsu Teng-kai Kuo,2002,We present and analyze an iterative control algorithm that enables us to find a control input that generates the desired output asymptotically with parameter uncertainties. The proposed algorithm keeps the clearness and compactness of the control input update form of iterative learning control while being applicable to nonrepeatable tracking problems specifically visual tracking. Uncertainties such as misalignment of the optical axis of the camera with the motion platform miscalibration and other unknown parametric inaccuracies can be eliminated. Sufficient conditions for the convergence of the trajectories to the desired one are given. The performance and effectiveness are demonstrated through simulation.,10.1.1.1.2106,?,?
Fueling the Ethnographic Imagination by Design,David M. Frohlich  Girish Prabhu,2004,?,10.1.1.1.2107,?,Kestone Research Pvt. Ltd
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Francisco Pulgar-vidal,?,This paper argues that to achieve success a simulation project must not only describe the future state of a business process but also indicate the best way to reach that state. The paper also suggests how simulation may be used to guide such change program. Prototyping to select the best change approach is critical for success given that organizations can move toward various future states along many different paths. By not analyzing implementation options the traditional simulation project leaves management without a roadmap for the proposed change. The roadmap must be plotted by a dynamic management tool a simulator that can analyze future contextual factors and determine how the chosen path must adapt to respond to new environments.,10.1.1.1.2108,improvement efforts i.e Total Quality Management,?
Supporting Frequent Updates in R-Trees: A Bottom-Up Approach,Mong Li Lee Wynne Hsu  Christian S. Jensen Bin Cui Keng Lik Teo,2003,Advances in hardware-related technologies  promise to enable new data management applications  that monitor continuous processes. In these  applications enormous amounts of state samples  are obtained via sensors and are streamed to a  database. Further updates are very frequent and  may exhibit locality. While the R-tree is the  index of choice for multi-dimensional data with  low dimensionality and is thus relevant to these  applications R-tree updates are also relatively inefficient.,10.1.1.1.2109,?,?
Exploration with Active Loop-Closing for FastSLAM,Cyrill Stachniss  Dirk Hähnel  Wolfram Burgard,2004,Acquiring models of the environment belongs to the fundamental tasks of mobile robots. In the last few years several researchers have focused on the problem of simultaneous localization and mapping (SLAM). Classic SLAM approaches are passive in the sense that they only process the perceived sensor data and do not influence the motion of the mobile robot. In this paper we present a novel and integrated approach that combines autonomous exploration with simultaneous localization and mapping. Our method uses a grid-based version of the FastSLAM algorithm and at each point in time considers actions to actively close loops during exploration. By re-entering already visited areas the robot reduces its localization error and this way learns more accurate maps. Experimental results presented in this paper illustrate the advantage of our method over pervious approaches lacking the ability to actively close loops.,10.1.1.1.2110,?,?
Evolving Dynamics in an Artificial Regulatory Network Model,P. Dwight Kuo  Andre Leier Wolfgang Banzhaf,2004,In this paper artificial regulatory networks (ARN) are evolved  to match the dynamics of test functions. The ARNs are based on a  genome representation generated by a duplication / divergence process.,10.1.1.1.2111,?,Springer
Composing High-Performance Memory Allocators,Emery D. Berger Benjamin G. Zorn Kathryn S. McKinley,2001,Current general-purpose memory allocators do not provide sufficient speed or flexibility for modern high-performance applications. Highly-tuned general purpose allocators have per-operation costs around one hundred cycles while the cost of an operation in a custom memory allocator can be just a handful of cycles. To achieve high performance programmers often write custom memory allocators from scratch -- a difficult and error-prone process. In this,10.1.1.1.2112,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,Screening experiments are performed to eliminate unimportant factors so that the remaining important factors can be more thoroughly studied in later experiments. Sequential bifurcation (SB) is a screening method that is well suited for simulation experiments the challenge is to prove the correctness of the results. This paper proposes Controlled Sequential Bifurcation (CSB) a procedure that incorporates a two-stage hypothesis-testing approach into SB to control error and power. A detailed algorithm is given performance is proved and an empirical evaluation is presented.,10.1.1.1.2113,?,?
Space The Final Frontearcon: The Identification Of Concurrently Presented Earcons In . . . ,David K. McGookin Stephen A. Brewster,2004,Two experiments which investigate the impact of spatialised presentation on the identification of concurrently presented earcons are described. The first experiment compared the identification of concurrently presented earcons based on the guidelines for individual earcon design and presentation of Brewster Wright and Edwards [1] which were presented in spatially distinct locations to the identification of non-spatially presented earcons which incorporated guidelines for concurrent presentation from McGookin and Brewster [2]. It was found that a significant increase in earcon identification occurred as well as an increase in earcon register identification when earcons were spatially presented. The second experiment compared the identification of concurrently presented earcons based on the guidelines of Brewster Wright and Edwards [1] which were presented in spatially distinct locations to the identification of spatially presented earcons which incorporated guidelines for the presentation of concurrent earcons from McGookin and Brewster [2]. The incorporation of the concurrent earcon guidelines was found to significantly increase identification of the timbre attribute but did not significantly effect the overall identification of earcons.,10.1.1.1.2114,?,?
Tamper-Resistant Biometric IDs,Darko Kirovski   Nebojsa Jojic Gavin Jancke,?,We present FaceCerts a si5((( i nexp e and cryptographi/Ri securei denti y certiR]5/0z system. A FaceCert i a pri tout of persons portrai photo anarbi(//R textual message and a 2-D color barcode whi h encodes an SAsi$7$zFR of the message hash and the compressed representatie of the face encompassed by the photo. The si5z7$)R i created usi0 the pri ate key of the partyi ssui( the ID. ID veri$/R]5) i performed by a si((F o#-li7 scanni/ devi that contaiF thepubli key of theiR$7F$ The system does not requi4 smart cardsi t can be expanded to encompass otherbierR$7/ features and morei nteresti]$7  the ID does not need to bepri ted by a trusted or hi5)z0( pri teri can be pri ted anywhere anyti$4 and potentinR$ by anyone. The ID veri$) uses a si5F5 scan process whi h does not requiz the use ofdi$4z ys. Wedetai systems components and present a preli/R]$0 performance evaluatiz using an in-field experiment.,10.1.1.1.2116,?,?
SORMA: Interoperating Distributed . . . ,Jörg A. Walter,1997,This paper introduces the Service Object Request Management Architecture  (SORMA) its design issues and its concepts. It is a software framework for rapid development of object-oriented software modules and their integration into stand-alone and distributed applications. SORMA provides an intelligent object-bus for inter-operating and sharing distributed computing and robotics hardware. We,10.1.1.1.2117,?,?
Configuration Design Problem Solving,B. J. Wielinga A. Th. Schreiber,1997,this paper.  The work reported here was partly carried out in the course of the KACTUS project. This project is partially funded by the ESPRIT Programme of the Commission of the European Communities as project number 8145. The partners in the KACTUS project are ISL (UK) LABEIN (Spain) Lloyds Register (United Kingdom) STATOIL (Norway) Cap Programmator (Sweden) University of Amsterdam (The Netherlands) University of Karlsruhe (Germany) IBERDROLA (Spain) DELOS (Italy) FINCANTIERI (Italy) and SINTEF (Norway). This paper reflects the opinions of the authors and not necessarily those of the consortium,10.1.1.1.2118,?,?
Three Practical Ways to,Improve Your Network,?,This paper presents three simple techniques for improving network service using relatively unknown features of many existing networks. The resulting system provides greater reliability enhanced securityand ease of management. First it addresses the application of IP anycast to provide reliable recursive DNS service. Next it explains the use of unicast reverse path forwarding and its usefulness in preventing local nodes from originating packets with spoofed source addresses. Finallyitexplains how unicast reverse path forwarding can be used to quickly and easily apply source address filters on your network. As an added benefit some of these features provide mechanisms to conform a network to Best Common Practices (BCP) of network operators. Anycast DNS Service  Anycast [1] is an IP addressing technique where unicast IP addresses are assigned to multiple hosts and routes configured accordingly.Routers receiving packets destined for anycast addresses select one of potentially several valid paths to hosts configured with the address. This technique can be used wherever unicast IP routing exists as anycast IP addresses are simply unicast addresses designated by network operators. Here we use anycast addressing to improve the reliability of DNS service load balance DNS requests across a number of servers minimize service downtime due to maintenance and automatically direct requests to the topologically nearest server.,10.1.1.1.2119,?,?
YACHTS -- YET ANOTHER COOPERATIVE HIGH LEVEL ARCHITECTURE TRAINING SOFTWARE,Agostino G. Bruzzone et al.,2001,The paper proposes a new tool for supporting educational and professional skill development in HLA environment the application proposed by the authors is devoted to provide a realistic case and an easy to understand/modify example where to extend technical knowledge of HLA.,10.1.1.1.2120,?,?
Individuality of Handwritten Characters,Bin Zhang  Sargur N. Srihari  Sangjik Lee,2003,important role in forensic document examination. However so far there lacks a comprehensive and quantitative study on individuality of handwritten characters. Based on a large number of handwritten characters extracted from handwriting samples of 1000 individuals in US the individuality of handwritten characters has been quantitatively measured through identification and verification models. Our study shows that in general alphabetic characters bear more individuality than numerals and use of a certain number of characters will significantly outperform the global features of handwriting samples in handwriting identification and verification. Moreover the quantitative measurement of discriminative powers of characters offers a general guidance for selecting most-informative characters in examining forensic documents.,10.1.1.1.2121,?,?
Ribosomes: Protein synthesis in slow motion,Peter Moore Using Peter B. Moore,?,ese early ribosome models were not rigorous three-dimensional reconstructions but at about the same time the quantitative analysis of ribosome images began and these studies have recently produced extremely important results.  The easiest ribosome images to obtain are those of fields of randomly oriented particles. For the image analyst however it is easy to reconstruct the three-dimensional form of objects from projection images when their relative orientations are known in advance but much harder when orientations must be deduced after the fact as is the case here. It took years to develop the technology required and as it evolved increasingly accurate ribosome reconstructions appeared but the improvements were so gradual that they attracted little notice.  In 1995 there was a major breakthrough in the study of ribosomal structure. Two independently derived 20--25  resolution reconstructions of the 70S ribosome from Escherichia coli were published one by Joachim Frank ,10.1.1.1.2122,Dispatch R179,?
QoS management for MPEG-4 flows in wireless environment,D. Bruneo  M. Villari  A. Zaia A. Puliafito,2003,QoS represents one of the most crucial issues as it involves many different aspects and directly impacts the user satisfaction. In this paper we will tackle the very complex and challenging issue to develop a comprehensive architecture to allow mobile wireless user to acces MPEG4 flows while moving and at a given level of QoS. We will assume that network resources are managed according to the Grid paradigm and that mobile agents are the underlying technology to implement coordination and communication mechanisms.,10.1.1.1.2123,QoS management Wireless systems Grid computing Mobile agents MPEG-4,?
Adaptive Functional Programming,Umut A. Acar   Guy E. Blelloch Robert Harper,2001,An adaptive computation maintains the relationship between its input and output as the input changes. Although various techniques for adaptive computing have been proposed they remain limited in their scope of applicability. We propose a general mechanism for adaptive computing that enables one to make any purely-functional program adaptive. We show,10.1.1.1.2124,?,ACM Press
Full paper at IADIS International Conference WWW/Internet 2002. Lisbon Portugal 13-15 November.,Digital Cities The Luis Borges Gouveia Joaquim Borges Gouveia,2002,The paper presents the initial model proposed for the Gaia Digital project . This three-year project is currently starting off within the Portugal Digital Initiative within the Information Society operation program framework. It provides a digital city counterpart for Vila Nova de Gaia with around 288000 inhabitants considering 2001 figures.,10.1.1.1.2125,Information Society Gaia Digital,?
Design of a High-Throughput Assay for Alternative Splicing Using Polymerase Colonies,J. D. Buhler R. M. Souvenir W. Zhang R. D. Mitra,1999,Introduction  Alternative splicing of gene transcripts  12  is believed to be a major mechanism by which eukaryotes can amplify the number of distinct proteins produced from a limited number of genes. Estimates of the fraction of alternatively spliced genes in the human genome range from 20% to nearly 60%    . In several cases di#erent splice variants of a gene have been shown to play distinct or tissue-specific functional roles  567  . These facts have driven the development of assays to discover and quantify alternative splicing.  Quantitative detection of alternative splicing aims to measure for one or more genes the amounts of each splice variant of that gene present in a pool of RNA. In this work we focus on splicing events that result in insertion or deletion of one or more complete exons from a transcript. A gene is treated as an ordered list of exons G =  {E  1 . . . E n  }  with each splice variant containing a subset of these exons. We seek to determine which subsets ,10.1.1.1.2126,?,?
Stochastic Scheduling,José Niño-Mora,2001,?,10.1.1.1.2128,?,?
Estimation of Average Switching Activity in Combinational Logic Circuits Using Symbolic Simulation,José Monteiro Srinivas Devadas  Abhijit Ghosh Kurt Keutzer Jacob White,1997,We address the problem of estimating the average switching activity of combinational circuits under random input sequences. Switching activity is strongly affected by gate delays and for this reason we use a variable delay model in estimating switching activity. Unlike most probabilistic methods that estimate switching activity our method takes into account correlation caused at internal gates in the circuit due to reconvergence of input signals.,10.1.1.1.2129,?,?
Subspace Analysis and Optimization for AAM Based Face Alignment,Ming Zhao Chun Chen et al.,2004,Active Appearance Models (AAM) is very powerful for extracting objects e.g. faces from images. It is composed of two parts: the AAM subspace model and the AAM search. While these two parts are closely correlated existing efforts treated them separately and had not considered how to optimize them overall. In this paper an approach is proposed to optimize the subspace model while considering the search procedure. We first perform a subspace error analysis and then to minimize the AAM error we propose an approach which optimizes the subspace model according to the search procedure. For the subspace error analysis we decomposed the subspace error into two parts which are introduced by the subspace model and the search procedure respectively. This decomposition shows that the optimal results of AAM can be achieved only by optimizing both of them jointly rather than separately. Furthermore based on this error decomposition we develop a method to find the optimal subspace model according to the search procedure by considering both the two decomposed errors. Experimental results demonstrate that our method can find the optimal AAM subspace model rapidly and improve the performance of AAM significantly.,10.1.1.1.2130,?,?
A Logic of Partially Satisfied Constraints,Nic Wilson,2003,Soft constraints are recognised as being important for many  constraints applications. These include (a) over-constrained problems  where we cannot satisfy all the constraints (b) situations where a constraint  can be partially satisfied so that there are degrees of satisfaction  and (c) where the identity of a constraint is uncertain so that it can be  uncertain whether a constraint is satisfied or not by a tuple.,10.1.1.1.2131,?,?
Microelectronic Engineering 59 (2001) 435--442,Www Elsevier Com Yukinori Ono Kenji Yamazaki Masao Nagase Seiji Horiguchi Kenji Shiraishi Yasuo Takahashi,?,This paper describes from the viewpoint of device fabrication single-electron and quantum devices using silicon-oninsulators (SOIs). We point out that control of the oxidation of Si is quite important and could be the key to their fabrication. We also introduce our technique for making single-electron transistors (SETs) which uses special phenomena that occur during the oxidation of SOIs and show that the technique enables us to realize primary single-electron circuits as a result of its high controllability and high reproducibility.  2001 Elsevier Science B.V. All rights reserved.,10.1.1.1.2132,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan Monte Carlo Extension Of Quasi-monte Carlo,?,This paper surveys recent research on using Monte Carlo techniques to improve quasi-Monte Carlo techniques. Randomized quasi-Monte Carlo methods provide a basis for error estimation. They have in the special case of scrambled nets also been observed to improve accuracy. Finally through Latin supercube sampling it is possible to use Monte Carlo methods to extend quasi-Monte Carlo methods to higher dimensional problems.,10.1.1.1.2133,?,?
The Statistics of Dynamic Networks,Richard G. Clegg,2004,This thesis describes describes a small number of problems arising from the applied study of networks in various contexts. The work can be split into two main areas: telecommunications networks (particularly the Internet) and road networks.,10.1.1.1.2134,?,?
Using Tree-Grammars for Training Set Expansion in Page Classification,Stefano Baldi Simone,?,In this paper we describe a method for the expansion of training sets made by XY trees representing page layout. This approach is appropriate when dealing with page classification based on MXY tree page representations. The basic idea is the use of tree grammars to model the variations in the tree which are caused by segmentation algorithms. A set of general grammatical rules are defined and used to expand the training set. Pages are classified with a k    nn approach where the distance between pages is computed by means of tree-edit distance.,10.1.1.1.2135,?,?
Towards a General Theory for the Evolution of Application Domains,H. A. Proper Th. P. van der Weide,1993,In this article we focus on evolving information systems. First a delimitation of the  concept of evolution is discussed. The main result is a first attempt to a general  theory for such evolution. In this theory the underlying data model is a parameter  making the theory applicable for a wide range of modelling techniques.,10.1.1.1.2137,?,?
SOCRATES: Barrier Free Communities of Aphasics on the Internet,Marc Spaniol Luise Springer  Ralf Klamma  Matthias Jarke,?,The barrier free internet is one of the greatest challenges for computer science in the future. While in the last years the growth of the internet was exponential still many potential user communities can not use internet technology for their communication needs because of inappropriate tools and narrowly designed communication processes. These problems become obvious when transferring applications to communities of people with special needs. Many people su#ering from aphasia are not able to interact with current chat tools while need for money for therapists could be eased by such virtual self-help groups in a geographically distributed setting. This is because massive word finding problems can sum up typing a simple sentence up to several minutes. We have designed implemented and preliminary evaluated a new chat tool for such groups. By using the tool aphasics can constantly monitor their communication behavior and in case of di#culties switch to a synchronous talk mode where up to four people can monitor typing letter by letter. Proposal for phrases can be generated by the community to help their member. Therapists and linguistic researchers can also monitor online and o#ine conversations from automatically generated transcripts.,10.1.1.1.2138,?,?
Confidence Estimation for Machine Translation,John Blatz Erin Fitzgerald George Foster  Simona Gandrabur  Cyril Goutte  Alex Kulesza Alberto Sanchis Nicola Ueffing,2004,?,10.1.1.1.2139,1.2.1 Sentence-Level Confidence Estimation......... 11,Yale University Press
A Meta Model for Update in Evolving Information Systems,J. L. H. Oei H. A. Proper E. D. Falkenberg,1992,An evolving information system supports the information needs of an evolving organisation. These  systems are able to adapt themselves instantaneously to the changes of the supported organisation such  that there is no need to interrupt the activities of the organisation. Furthermore evolving information  systems support changes of all time- and application-dependent aspects such as the database and the  schema of the application. The main focus,10.1.1.1.2140,PUBLISHED AS,?
Space-Gene: Microbial Gene Prediction System Based on Linux Clustering,Jong-won Chang Chungoo Park Dong Soo Jung  Mi-hwa Kim Jae-woo Kim Seung-sik Yoo Hong Gil Nam,?,this paper to enhance the accuracy of gene prediction we propose a scheme that merges the ab-initio method with the homology-based one. While the latter identifies each gene by taking advantage of the known information for previously identified genes the former makes use of predefined gene features. Also the proposed scheme adopts parallel processing to guarantee optimum system performance in the face of the crucial drawback of the homology-based method i.e. the bottleneck that inevitably occurs due to the large amount of sequence information that has to be processed,10.1.1.1.2141,space-gene prokaryotes Gene prediction hidden Markov model parallel processing,?
A PCA Based Method of Gene Expression Visual Analysis,Kunihiro Nishimura Koji Abe  Shumpei Ishikawa Shuichi Tsutsumi Koichi Hirota Hiroyuki Aburatani Michitaka Hirose,2003,Introduction  Gene expression data has been rapidly accumulated and the methods of these data analysis are required. Statistical methods are used in these data analysis. However the biological interpretation of the data and the result of the statistical analysis are di#cult. Thus we are developing a method of analysis to interpret the data easily. We propose a PCA based analysis method and developed tools based on our proposal.  2 Method and Results  Figure 1: Analysis process we proposed Hatching boxes: developed tools.  A process of human gene expression data analysis is followings: 1) pre-filtering 2) statistical analysis 3) interpretation of the data. First we reduce and eliminate a noise of the data as pre-filtering that is we select data such as genes or samples according to the liability. Second we analyze the data statistically. Generally many researchers use hierarchical clustering analysis [1] and principal component analysis (PCA) [3] as statistical method. They chec,10.1.1.1.2142,visualization PCA gene expression analysis annotation chromosomal viewer,?
Analysis Of The Complexity Of Exact Power Estimation Problems,,?,Although many algorithms for power estimation have been proposed to date no comprehensive  results have been presented on the actual complexity of power estimation problems.,10.1.1.1.2143,?,?
Consensus of Information under Dynamically Changing Interaction Topologies,Wei Ren  Randal W. Beard,2004,This paper considers the problem of information consensus among multiple agents in the presence of limited and unreliable information exchange with dynamically changing interaction topologies. Both discrete and continuous update schemes are proposed for consensus of information. That the union of a collection of interaction graphs across some time intervals has a spanning tree frequently enough as the system evolves is shown to be a necessary and sufficient condition for information consensus under dynamically changing interaction topologies. Simulation results show the effectiveness of our results.,10.1.1.1.2144,?,?
Experiments Contingencies and Curriculum: Providing Opportunities for Learning through Improvisation in Science Teaching,Gregory J. Kelly Candice Brown Teresa Crawford,2000,In thisarticle we eicle how throughdiscourse proceseb a thirdgrade tede-- and he stude--5 come to situationallydetu scieat inthe-- classroom.The tessroo use of particulardiscursive strateive promote studee talk thus providing opportunitie  forstude6-- toleb1 aboutscieF6 throughthe eughF6164 of ase of anomalous remalo in alife sciePb eePbFf7(1 Drawing from social studie ofscie6b6 we use a discourse analytical approach toeF6b(( the classroommessroo logic ofe4P--P6Ff7P( tion the eFbbP(7Ff andscie-664 de-664Ff andthe6 accounts ofthe ee5P7 The5 analyse allowe us toide(56-- how particularterticu stratelar afforde studee opportunitie  toleb-- scie1-- conce---- and aboutscieF671 proce71(1  # 2000 John Wile  Sons Inc. Sci Ed 84:624 -- 657 2000. ,10.1.1.1.2145,?,?
VisDic -- Wordnet Browsing and Editing Tool,Aleš Horák  Pavel Smrž ,2004,This paper deals with wordnet development tools. It presents a designed  and developed system for lexical database editing which is currently employed in  many national wordnet building projects. We discuss basic features of the tool as well  as more elaborate functions that facilitate linguistic work in multilingual environment.,10.1.1.1.2146,?,?
Analytic Evaluation of Shared-Memory Architectures,Daniel J. Sorin Jonathan L. Lemon Derek L. Eager Mary K. Vernon,2003,This paper develops and validates an efficient analytical model for evaluating the performance of shared memory  architectures with ILP processors. First we instrument the SimOS simulator to measure the parameters for such a model and we find a  surprisingly high degree of processor memory request heterogeneity in the workloads. Examining the model parameters provides  insight into application behaviors and how they interact with the system. Second we create a model that captures such heterogeneous  processor behavior which is important for analyzing memory system design tradeoffs. Highly bursty memory request traffic and lock  contention are also modeled in a significantly more robust way than in previous work. With these features the model is applicable to a  wide range of architectures and applications. Although the features increase the model complexity it is a useful design tool because  the size of the model input parameter set remains manageable and the model is still several orders of magnitude quicker to solve than  detailed simulation. Validation results show that the model is highly accurate producing heterogeneous per processor throughputs that  are generally within 5 percent and for the workloads validated always within 13 percent of the values measured by detailed simulation  with SimOS. Several examples illustrate applications of the model to studying architectural design issues and the interactions between  the architecture and the application workloads.,10.1.1.1.2147,?,?
One More Step in the Direction of Modularized Integration Concerns,Hridesh Rajan,2004,Component integration creates value by automating the costly and error-prone task of imposing desired behavioral relationships on components manually. Requirements for component integration however complicate software design and evolution in several ways: first they lead to coupling among components second the code that implements various integration concerns in a system is often scattered over and tangled with the code implementing the component behaviors. Straightforward software design techniques map integration requirements to scattered and tangled code compromising modularity in ways that dramatically increase development and maintenance costs. ,10.1.1.1.2148,?,ACM Press
Proc. Int’l. Conf. on Dublin Core and Metadata Applications 2001,Curtis Dyreson Michael Michael H. Böhlen Christian S. Jensen,2001,This paper presents the METAXPath data model and query language. METAXPath extends XPath with support for XML metadata. XPath is a specification language for locations in an XML document. It serves as the basis for XML query languages like XSLT and the XML Query Algebra.,10.1.1.1.2149,Metadata Query language XML XPath,?
Efficient Clustering With Fuzzy Ants,Schockaert De Cock S. Schockaert M. De Cock C. Cornelis E. E. Kerre,2004,this paper we show how the combination of the ant-based  approach with fuzzy rules leads to an algorithm which is conceptually simpler  more e#cient and more robust than previous approaches,10.1.1.1.2150,?,?
Correction of Misclassifications Using a Proximity-Based Estimation Method,Antti Niemistö Ilya Shmulevich Vladimir V. Lukin Alexander N. Dolia Olli Yli-harja,2004,rovement in classification accuracy that is obtained by the proposed method is assessed statistically using Kappa analysis.  Keywords and phrases: misclassification correction image recognition training-based optimization genetic algorithms musical key finding remote sensing.  1. INTRODUCTION  Automatic classification of data is a standard problem in signal and image processing. In this context the overall objective of classification is to categorize all data samples into dierent classes as accurately as possible. The selection of classes depends naturally on the particular application. Powerful supervised classification methods based on neural networks genetic algorithms Bayesian methods and Markov random fields have been developed (see e.g. [1 2 3]). However even the most advanced methods of automatic classification are typically unable to provide a classification without misclassifications. The main reason for this is the inherent presence of noise in data as well as ,10.1.1.1.2151,misclassification correction image recognition training,?
Regional Air Quality Modeling System (RAQMS) predictions,Of The Tropospheric,?,ults in  very small average accumulation (#1 Tg) of O 3 in the east Asian region and very little net  export averaged over the period (0.03 Tg d #1 ). The low ozone export from east Asia  predicted by RAQMS during TRACE-P is a consequence of relatively high dry deposition  rates which are 37% of the gross ozone formation (1.469 Tg d #1 ) within the TRACE-P  regional domain. INDEX TERMS: 0345 Atmospheric Composition and Structure: Pollution---urban and  regional (0305) 0365 Atmospheric Composition and Structure: Troposphere---composition and chemistry  0368 Atmospheric Composition and Structure: Troposphere---constituent transport and chemistry 3362  Meteorology and Atmospheric Dynamics: Stratosphere/troposphere interactions 3367 Meteorology and  Atmospheric Dynamics: Theoretical modeling KEYWORDS: tropospheric ozone Asian emissions  stratosphere-troposphere exchange ozone budget regional photochemical modeling global photochemical  modeling  Citation: Pierce R. B. et al. ,10.1.1.1.2152,0368 Atmospheric Composition and Structure,?
The Social Context of Home Computing,David Frohlich Robert Kraut,2003,This paper is also based on interviews with 11 families in the Boston area in 1997 conducted by the first author. They were designed specifically to examine the location and use of the home PC by difference members of the family. All families owned a multimedia PC and had children living at home but represented a spread of income levels (between $20-100+k per year) housing types (private house condominium apartment) and locations (urban suburban rural). Eight of the 11 families had an Internet connection. Transcripts of both sets of interviews were coded to indicate discussion of topics relevant to the dynamics of computer and Internet use. The resulting topic collections were surprisingly large for both studies indicating that families had a lot to say about constituent issues such as the location of the computer and the way it is shared and managed within the family. In the following sections of the chapter we step through the major findings in this collection as they relate to the groups of questions raised in the previous section. Where necessary we cite relevant quantitative findings to back-up the qualitative analysis. We preserve the same ordering of issues and questions as before addressing the timing location and shared use of the home computer in turn,10.1.1.1.2154, Internal Accession Date Only Approved for External Publication,Springer
Social Minded Commitment Management,Robert Ross  Rem Collier  G.M.P. OHare G. M. P. O’hare,2003,Over the past 30 years Artificial Intelligence has fragmented from one broad subject into a cluster of narrow but deep individual disciplines. During this time we have also seen the development of increasingly complex software systems for application domains such as robot control mobile computing and expert system interfaces. Many of these designs use elements from the branches of AI but pay little attention to the integration of these elements in an intelligent way. This paper presents an approach to this intelligent integration problem based on a community of Intentional Agents. Each of the agents within the community uses a Social Minded Commitment Manager (SMCM) to allow it to reason and cooperate in order to achieve goals when individual execution has failed. An implementation of the SMCM that has been developed for AgentFactory is presented and its use then motivated through the description of a robust redundancy tolerant robot control architecture named MARC.,10.1.1.1.2155,?,?
Introduction to Modeling and Simulation,S. Chick  II P. J. Sánchez D. Ferrin D. J. Morrice John S. Carson,2003,In concept a models state is a (long) vector that is a list of values that are sufficient to define the state of the system at any point in time. In practice a models state is defined implicitly by the internal status of all the entities used in the simulation software package.,10.1.1.1.2156,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin Patrick James Delaney,?,Prior to this study the Combined Forces Command (CFC) in Korea used a planning factor of 1.3 or 30% more assets than calculated as the minimum required. This rigid number represents an expectation on the part of the planners with no assumption as to the level of risk accepted.,10.1.1.1.2157,?,?
Application of Multi-domain and Multi-language Cosimulation,To An Optical,2002,This paper presents the applicability of a cosimulation methodology based on an object-oriented simulation environment to multi-domain and multi-language systems design. This methodology start with a system model given as a netlist of heterogeneous components and enables the systematic generation of simulation models for multi-domain and multi-language heterogeneous systems. For experiments we used a complex multi-domains application: an optical MEM switch.,10.1.1.1.2158,?,?
A Format-Driven Handwritten Word Recognition System,Xia Liu And Xia Liu Zhixin Shi,?,A format-driven word recognition system is proposed for recognition of handwritten words. Unlike most traditional handwritten word recognizers being given a set of target words as lexicon we assume that our system is given a set of format descriptions other than lexicon words. Applications of the proposed system include recognition of relatively more important keywords such as postal codes titles or trademarks. The format descriptions are in terms of the lengths of the keywords the types of the characters in the keywords and positional informations. Due to the important role of the keywords in the applications the recognition expectations in terms of recognition rate and accuracy are usually higher then lexicon-driven word recognizers.,10.1.1.1.2159,?,?
Prototyping Web Services based Network Monitoring,Thomas Drevers Remco Van De Meent Aiko Pras,2004,Web services is one of the emerging approaches in network management. This paper describes the design and implementation of four Web services based network monitoring prototypes. Each prototype follows a specific approach to retrieve management data ranging from retrieving a single management data object to retrieving an entire table of such objects at once. We have focused on the interfaces table (ifTable) as described in the IF-MIB.,10.1.1.1.2160,performance network,?
Washington D.C. 20006 U.S.A.,To Full Peer Xinshen Diao Xinshen Diao Yukitsugu Yanoma Yukitsugu Yanoma,2003,Identifying growth poles in the SSA region strengthening linkages and  generating mutual benefits across African countries is an important part of the  strategy to promote agriculture-led growth at the Africa-wide scale. Using  agricultural trade data this study focuses on identifying major countries that play  important roles in regional agricultural trade and commodities in which African  countries have a comparative advantage and where there is potential for more trade  within the region.  There are 10 largest traders in the regions either as large agricultural exporters  or importers and they seemingly have potential to become growth poles in Africawide growth led by promoting agricultural trade. However at the present intra-SSA  trade only plays a marginal role and that official trade data often significantly  underestimate the actual trade flows between countries. In order to avoid historical  bias we focus on the potential trade opportunities by investigating whether a group  of commodities in which some countries have a comparative advantage matched with  the group of commodities imported by other African countries. We find that  foodstuffs are among the most dynamic products in regional agricultural trade as  value of the correlation between the staple good exports and imports is high and  doubles over the two observation periods up from 0.34 in the first period (19901995) .  Poor infrastructure and institutional barriers are among the major reasons  constraining African countries to exploit their comparative advantage and strengthen  iv their economic linkages. The model simulations show that opening the EU market is  strongly in the common interest of African countries. Reducing African countries  own trade barriers both in agriculture and non-agricul...,10.1.1.1.2161,?,?
EPTD DISCUSSION PAPER NO. 76 MARKET IMPERFECTIONS AND LAND PRODUCTIVITY IN THE ETHIOPIAN HIGHLANDS,Stein Holden Bekele Shiferaw John Pender,?,This study analyzes how market imperfections affect land productivity in a degraded low-potential cereal- livestock economy in the Ethiopian highlands. A wide array of variables is used to control for land quality in the analysis. Results of three different selection models were compared with least squares models using the HC3 heteroskedasticity-consistent covariance matrix estimator. Market imperfections in labor and land markets were found to affect land productivity. Land productivity was positively correlated with household male and female labor force per unit of land. Female-headed households achieved much lower land productivity than male-headed households. Old age of household heads was also correlated with lower land productivity. Imperfections in the rental market for oxen appeared to cause overstocking of oxen by some households. Conservation technologies had no significant positive short-run effect on land productivity. The main results were consistent across the different econometric models. . KEYWORDS: Market imperfections land productivity Ethiopian highlands ii  ACKNOWLEDGMENTS  We are thankful for valuable comments from Peter Hazell and two anonymous reviewers on an earlier draft of this paper. Funds for this research have been received from the Research Council of Norway and the Norwegian Ministry of Foreign Affairs. Logistical support has been received from the International Food Policy Research Institute and the International Livestock Research Institute. iii  TABLE OF CONTENTS 1. ,10.1.1.1.2162,Market imperfections land productivity Ethiopian highlands i ACKNOWLEDGMENTS,?
GreedyDual-Join -- Locality-Aware Buffer Management for Approximate Join Processing over Data Streams,Feifei Li Ching Chang Azer Bestavros George Kollios,2004,We investigate adgate e buffer management techniques for approximate evaluation of sliding window joins over multipledti streams. In many applicationsdpl stream processing systems havelimited memory or have todN: with very high speed dd streams. In both cases computing the exact results of joins between these streams may not be feasible mainly because the buffers used to compute the joins contain much smaller number of tuples than the tuples contained in the slidA2 wind ws. Therefore a stream buffer management policy isneedA in that case. We show that the buffer replacement policy is an importantd2---1:D]1: t of the quality of the prodoD2 results. To that end we propose Greed2D]1NC1---D (GDJ) anad:BFF e and locality-aware buffering technique for managing these bu#ers. GDJ exploits the temporal correlations (at both long and short time scales) which wefound to be prevalent in many real dal streams. We note that our algorithm is read2C applicable to multipledip streamsand multiple joins and requires almost no adNA:C---D] system resources. We report results of an experimentalstud using both syntheticand real-world d ata sets. Our results demonstrate the superiority and flexibility of our approach when contrasted to other recently proposed techniques.,10.1.1.1.2163,?,?
In Open Systems,Date Quinn Snell Date Bryan S. Morse Brigham Young University G. Rex Bryce Fuk Wing Thomas Fuk Wing Fuk Wing Thomas Chan Thomas Chan Thomas Chan,?,PRESERVING TRUST ACROSS MULTIPLE SESSIONS  IN OPEN SYSTEMS  Fuk Wing Thomas Chan  Department of Computer Science  Master of Science  Trust negotiation a new authentication paradigm enables strangers on the Internet to establish trust through the gradual disclosure of digital credentials and access control policies. Previous research in trust negotiation does not address issues in preserving trust across multiple sessions. This thesis discusses issues in preserving trust between parties who were previously considered strangers. It also describes the design and implementation of trust preservation in TrustBuilder a prototype trust negotiation system. Preserving trust information can reduce the frequency and cost of renegotiation. A scenario is presented that demonstrates that a server supporting trust preservation can recoup the cost of the trust preservation facility when approximately 25% of its requests are from repeat customers. The throughput and response time improve up to approximately 33% as the percentage of repeat customers grows to 100%.,10.1.1.1.2164,?,?
Grammars with Regulated Rewriting,Jürgen Dassow,1986,Context-free grammars are not able to cover all linguistic phenomena. Thus we define,10.1.1.1.2165,?,?
Linguistic Feature Extraction using Independent Component Analysis,Timo Honkela  Aapo Hyvarinen,2004,Our aim is to find syntactic and semantic relationships of words based on the analysis of corpora. We propose the application of independent component analysis which seems to have clear advantages over two classic methods: latent semantic analysis and self-organizing maps. Latent semantic analysis is a simple method for automatic generation of concepts that are useful e.g. in encoding documents for information retrieval purposes. However these concepts cannot easily be interpreted by humans. Self-organizing maps can be used to generate an explicit diagram which characterizes the relationships between words. The resulting map reflects syntactic categories in the overall organization and semantic categories in the local level. The self-organizing map does not however provide any explicit distinct categories for the words. Independent component analysis applied on word context data gives distinct features which reflect syntactic and semantic categories. Thus independent component analysis gives features or categories that are both explicit and can easily be interpreted by humans. This result can be obtained without any human supervision or tagged corpora that would have some predetermined morphological syntactic or semantic information.,10.1.1.1.2166,?,?
An Error Catastrophe in Cancer?,Ricard V. Sole Ricardv Sol!e A  Thomas S. Deisboeck,2004,A comparison  betweenth  evolution of cancer cell populations andRNA viruses reveals a number of remarkable similarities. Both displayhsp  levels of plasticity and adaptability as a consequence ofhdG degrees of genetic variation. It hd been suggested thgg  as it  occurswith  RNA  virusesthus  is a  thIqO9d3  in th levels of genetic instability affordable by cancer cells in order to be able to overcome selection barriers (Trends Genet. 15 (1999) M57). Here we  explorethl  concept by means of a  simplemathd1OIx1d  model. It isshxx thx an errorthordqMM exists inthI  modelwhel investigatesboth  competition between cancer cell populations and its impact on overall  tumorgrowth  dynamics.,10.1.1.1.2167,Cancer RNA viruses Quasispecies Genomic instability Genetic instability Tumor progression Phase transitions Error threshold,?
Septic Shock Diagnosis by Neural Networks and Rule Based Systems,R. Brause F. Hamker J. Paetz,2001,In intensive care units physicians are aware of a high lethality rate of septic shock patients. In this contribution we present typical problems and results of a retrospective data driven analysis based on two neural network methods applied on the data of two clinical studies.,10.1.1.1.2168,?,Springer Verlag
Whole-Body Modelling of People From Multi-View,Images To Populate,?,In this paper a new technique is introduced for automatically building recognisable  moving 3D models of individual people. A set of multi-view colour images of a person  are captured from the front side and back using one or more cameras. Model-based reconstruction  of shape from silhouettes is used to transform a standard 3D generic humanoid  model to approximate the persons shape and anatomical structure. Realistic appearance  is achieved by colour texture mapping from the multi-view images. Results demonstrate  the reconstruction of a realistic 3D facsimile of the person suitable for animation in a virtual  world. The system is low-cost and is reliable for large variations in shape size and  clothing. This is the first approach to achieve realistic model capture for clothed people and  automatic reconstruction of animated models. A commercial system based on this approach  has recently been used to capture thousands of models of the general public.,10.1.1.1.2169,1,?
Relevance LVQ versus SVM,Barbara Hammer   Marc Strickert Thomas Villmann,2004,The support vector machine (SVM) constitutes one of the most successful  current learning algorithms with excellent classification accuracy in large  real-life problems and strong theoretical background. However a SVM solution  is given by a not intuitive classification in terms of extreme values of the training  set and the size of a SVM classifier scales with the number of training data. Generalized,10.1.1.1.2171,?,Springer
TüSBL: A Similarity-Based Chunk Parser for Robust Syntactic Processing,Sandra Kübler Erhard W. Hinrichs,2001,Chunk parsing has focused on the recognition of partial constituent structures at the level of individual chunks. Little attention has been paid to the question of how such partial analyses can be combined into larger structures for complete utterances. The TüSBL,10.1.1.1.2173,chunk parsing,?
Scalable Live Video Streaming to Cooperative Clients Using Time Shifting and Video Patching,Meng Guo  Mostafa H. Ammar,2004,We consider the problem of how to enable the streaming of live video content from a single server to a large number of clients. One recently proposed approach relies on the cooperation of the video clients in forming an application layer multicast tree over which the video is propagated. Video continuity is maintained as client departures disrupt the multicast tree using multiple description coded (MDC) streams multicast over several application layer trees. While this maintains continuity it can cause video quality fluctuation as clients depart and trees are reconstructed around them. In this paper we develop a scheme using the transmission of a single-description coded video over an application layer multicast tree formed by cooperative clients. Video continuity is maintained in spite of tree disruption caused by departing clients using a combination of two techniques: 1) providing time-shifted streams at the server and allowing clients that suffer service disconnection to join a video channel of the time-shifted stream and 2) using video patching to allow a client to catch up with the progress of a video program. Simulation experiments demonstrate that our design can achieve uninterrupted service while not compromising the video quality at moderate cost.,10.1.1.1.2174,?,?
Towards Multidimensional User Manuals for Geospatial Datasets: Legal Issues . . . ,Yvan Bédard Rodolphe Devillers Marc Gervais Robert Jeansoulin,?,?,10.1.1.1.2175,?,?
Traffic Grooming Routing and Wavelength Assignment in Optical WDM Mesh Networks,J.Q. Hu  Brett Leida,2004,In this paper we consider the traffic grooming routing and wavelength assignment (GRWA) problem for optical mesh networks. In most previous studies on optical mesh networks traffic demands are usually assumed to be wavelength demands in which case no traffic grooming is needed. In practice optical networks are typically required to carry a large number of lower rate (sub-wavelength) traffic demands. Hence the issue of traffic grooming becomes very important since it can significantly impact the overall network cost. In our study we consider traffic grooming in combination with traffic routing and wavelength assignment. Our objective is to minimize the total number of transponders required in the network. We first formulate the GRWA problem as an integer linear programming (ILP) problem. Unfortunately for large networks it is computationally infeasible to solve the ILP problem. Therefore we propose a decomposition method that divides the GRWA problem into two smaller problems: the traffic grooming and routing problem and the wavelength assignment problem which can then be solved much more efficiently. In general the decomposition method only produces an approximate solution for the GRWA problem. However we also provide some sufficient condition under which the decomposition method gives an optimal solution. Finally some numerical results are provided to demonstrate the efficiency of our method.,10.1.1.1.2176,System design Mathematical programming,?
Four Paradigms Of Information Systems Development,Rudy Hirschheim  H. Klein,1989,?,10.1.1.1.2177,?,?
A Method for Converting Thesauri to RDF/OWL,Mark Van Assem  Maarten R. Menken Guus Schreiber  Jan Wielemaker Bob Wielinga,2004,This paper describes a method for converting existing thesauri  and related resources from their native format to RDF(S) and  OWL. The method identifies four steps in the conversion process. In  each step decisions have to be taken with respect to the syntax or semantics  of the resulting representation. Each step is supported through  a number of guidelines. The method is illustrated through conversions of  two large thesauri namely MeSH and WordNet.,10.1.1.1.2178,?,Springer-Verlag
Seamless Texture Mapping of Subdivision Surfaces by Model Pelting and Texture Blending,Dan Piponi  George Borshukov,?,Subdivision surfaces solve numerous problems related to the geometry of character and animation models. However unlike on parametrised surfaces there is no natural choice of texture coordinates on subdivision surfaces. Existing algorithms for generating texture coordinates on non-parametrised surfaces often find solutions that are locally acceptable but globally are unsuitable for use by artists wishing to paint textures. In addition for topological reasons there is not necessarily any choice of assignment of texture coordinates to control points that can satisfactorily be interpolated over the entire surface. We introduce a technique pelting for finding both optimal and intuitive texture mapping over almost all of an entire subdivision surface and then show how to combine multiple texture mappings together to produce a seamless result.,10.1.1.1.2179,Curves  Surfaces Texture Mapping Physically Based Animation,?
Evaluation of a Silent Killer the PMN Anti-Personnel Blast Mine,R. J. Swinton D. M. Bergeron,?,U)   4. AUTHOR(S)   5. CORPORATE AUTHOR     Systems Sciences Laboratory   PO Box 1500   Edinburgh South Australia 5111 Australia   6a. DSTO NUMBER   6b. AR NUMBER     6c. TYPE OF REPORT   Technical Report   7. DOCUMENT DATE     8. FILE NUMBER   E9505-28-28   9. TASK NUMBER   ARM 01/044   10. TASK SPONSOR   DGLD   11. NO. OF PAGES     12. NO. OF REFERENCES     ...,10.1.1.1.2180,Executive Summary,?
First International Conference on Multisource-Multisensor Information Fusion July 6 - 9,Las Vegas Nevada A. Bendjebbour W. Pieczynski,?,The Dempster-Shafer combination rule can be of great utility in multisensor image segmentation. In addition the approach based on theory of evidence can be seen as generalizations of the classical Bayesian approach which is often used in the Hidden Markov Field Model context. Finally some recent works allow one to use the DempsterShafer combination rule in the Markovian context and different methods so obtained can greatly improve the effectiveness of Markovian methods working alone. The aim of this paper is to make these methods unsupervised by proposing some parameter estimation algorithms. In order to do so we use some recent methods of generalized mixture estimation which allows one to estimate mixtures in which the exact nature of components is not known.,10.1.1.1.2181,?,?
Evidence Assessment Criteria and the Difficulty of Automated IT Skills Assessment,R. D. Dowsing S. Long,?,In general automated assessment is based on collecting evidence of a candidates performance in answering one or more questions relating the evidence to the correct answer or answers to determine any errors and determining the assessment by relating any errors to the given assessment criteria. In IT full-skills tests the candidate undertakes a typical exercise using a particular IT tool and the evidence collected is analysed to assess what individual skills the candidate has exhibited during the test. One of the major difficulties of automated IT skills assessment arises from the difficulty in knowing how to associate errors made by the candidate with particular skills. The difficulties can be reduced by suitable design of the test by reducing the complexity of the assessment criteria and by the judicious use of human examiners. This paper illustrates the connection between evidence assessment criteria and the difficulty of assessment with examples from word processing and the use of spreadsheets. ,10.1.1.1.2182,?,?
The Squiggle: A Digital Musical Instrument,Brian Sheehan,2004,This paper discusses some of the issues pertaining to the design of digital musical instruments that are to effectively fill the role of traditional instruments (i.e. those based on physical sound production mechanisms). The design and  implementation of a musical instrument that addresses some of these issues using scanned synthesis coupled to a smart physical system is described.,10.1.1.1.2183,synthesis pd tactile interfaces sensors Shapetape mapping,?
Bayesian model comparison using Gauss,Approximation On Multicomponent From Ch Plasma H. D. Kang V. Dose,?,We performed Bayesian model comparison on mass spectra from CH 4 rf process plasmas  to detect radicals produced in the plasma. The key ingredient for its implementation is the highdimensional  evidence integral. We apply Gauss approximation to evaluate the evidence. The results  were compared with those calculated by the thermodynamic integration method using Markov  Chain Monte Carlo technique. In spite of very large difference in the computation time between  two methods a very good agreement was obtained. Alternatively a Monte Carlo integration method  based on the approximated Gaussian posterior density is presented. Its applicability to the problem  of mass spectrometry is discussed.,10.1.1.1.2184,?,?
Programmable Port Forwarding for Mobile Peers in Private Networks,Peter Tabery  Rüdiger Schollmeier  Christian Bachmeir,2003,Peer-to-Peer file sharing networks have gained tremendous popularity in recent years. However traversing Network Address and Port Translators (NAPT) may still fail in certain topologies. In this paper we present Programmable Port Forwarding a lightweight approach for allowing private hosts to fully participate in a Peer-to-Peer network. By extending the NAPT that a private host uses to connect to hosts outside its private realm we enlarge the applicability of Peer-to-Peer systems in todays networks. Additionally we show that our proposed solution is able to deal with terminal mobility within the domain of the NAPT server as well.,10.1.1.1.2185,Communication Systems Peer-to-Peer Networks Network,?
Dynamic Virtual Fences for Controlling Cows,Butler Corke Peterson Z. Butler P. Corke R. Peterson D. Rus,2004,A virtual fence is created by applying an aversive stimulus to an animal when it approaches a predefined boundary. It is implemented by a small animal-borne computer system with a GPS receiver. This approach allows the implementation of virtual paddocks inside a normal physically fenced paddock. Since the fence lines are virtual they can be moved by programming to meet the needs of animal or land management. This approach enables us to consider animals as agents with natural mobility that are controllable and to apply a vast body of theory in motion planning. In this paper we describe a herd-animal simulator and physical experiments conducted on a small herd of 10 animals using a Smart Collar. The Smart Collar consists of a GPS PDA wireless networking and a sound amplifier. In particular we describe a motion planning algorithm that can move a virtual paddock which is suitable for mustering cows. We present simulation results and data from experiments with 8 cows equipped with Smart Collars.,10.1.1.1.2186,?,?
Computing the digest of an RDF graph,Craig Sayers   Alan H. Karp,2004,?,10.1.1.1.2187,?,?
Development and Evaluation of NL interfaces in a Small Shop,Barbara Di Eugenio  Susan Haller  Michael Glass,2003,The standard development of a dialogue system today  involves the following steps: corpus collection and analysis  system development guided by corpus analysis  and finally rigorous evaluation. Often evaluation may  involve more than one version of the system for example  when it is desirable to show the effect of system  parameters that differ from one version to another.,10.1.1.1.2188,?,?
Integration of Shape Constraints in Data Association Filters,Giambattista Gennari   Alessandro Chiuso Fabio Cuzzolin Ruggero Frezza,2004,Many algorithms have been proposed in literature to deal with the tracking and data association problem. A common assumption made in the proposed algorithms is that the targets are independent. There are however many interesting applications in which targets exhibit some sort of coordination they satisfy shape constraints. In the current work a general and well formalized method which allows to embed such constraints into data association filters is proposed. The resulting algorithm performs robustly in challenging scenarios.,10.1.1.1.2189,?,?
Tile Automaton in the Well-Mixed Medium,Tomoyuki Yamamoto  Kunihiko Kaneko,2003,By introducing a mean-field version of the tile automaton model introduced in earlier works growth of molecules through chemical reaction networks is studied with explicit consideration for molecule shape as a tile. Tiles are picked up randomly to collide and with a certain rule they react to form new tiles. A non-trivial growth pattern called joint growth is found with which tiles grow by combining tiles successively. This joint growth leads to a power-law distribution of tile sizes by forming a positive feedback process for reproduction of tiles through cooperative relationship among large tiles. This effective growth is achieved by spontaneous differentiation of time scales: quick process for an autocatalytic network and a slower process with joint growth. We also discuss the relevance of the present results to the origin of life as a loose set of reproducting chemicals.  ,10.1.1.1.2190,?,?
Median-Based Robust Algorithms for Tracing Neurons from Noisy Confocal Microscope Images,Khalid A. Al-kofahi  Ali Can Sharie Lasek  Donald H. Szarowski Natalie Dowell-mesfin William Shain James N. Turner Badrinath Roysam,2003,This paper presents a method to exploit rank statistics to improve fully automatic tracing of neurons from noisy digital confocal microscope images. Previously proposed exploratory tracing (vectorization) algorithms work by recursively following the neuronal topology guided by responses of multiple directional correlation kernels. These algorithms were found to fail when the data was of lower quality (noisier less contrast weak signal or more discontinuous structures). This type of data is commonly encountered in the study of neuronal growth on microfabricated surfaces. We show that by partitioning the correlation kernels in the tracing algorithm into multiple subkernels and using the median of their responses as the guiding criterion improves the tracing precision from 41% to 89% for low-quality data with a 5% improvement in recall. Improved handling was observed for artifacts such as discontinuities and/or hollowness of structures. The new algorithms require slightly higher amounts of computation but are still acceptably fast typically consuming less than 2 seconds on a personal computer (Pentium III 500 MHz 128 MB). They produce labeling for all somas present in the field and a graph-theoretic representation of all dendritic/axonal structures that can be edited. Topological and size measurements such as area length and tortuosity are derived readily. The efficiency accuracy and fully-automated nature of the proposed method makes it attractive for large-scale applications such as high-throughput assays in the pharmaceutical industry and study of neuron growth on nano/micro-fabricated structures. A careful quantitative validation of the proposed algorithms is provided against manually derived tracing using a performance measure that combines the precis...,10.1.1.1.2191,?,?
COllective INtelligence with Sequences of Actions (Extended Abstract),P.J. t Hoen  S.M. Bohte,2004,?,10.1.1.1.2192,?,Springer
Human Full-Length Pre-mRNA Sequence Dataset for Computational Gene Prediction and Alternative Splicing Analysis,Masahiko Mizuno  Osamu Gotoh Makiko Suwa,2003,Introduction  Computational gene prediction has recently become essential to identify all the genes from enormous genome sequences and to define their functions. However gene prediction methods still show low specificity (45% at the exon level) [7]. Although computationally predicted data by automatic annotation system are growing rapidly experimentally verified data provide the cornerstone for improvements of gene prediction. Because there is no guarantee that the predicted events occur in vivo. It has become important to discriminate experimentally verified data from computationally predicted data [5].  Aligning expressed sequence tags (ESTs)/mRNAs to the genomic sequences has been a practical approach to detect gene regions and to identify alternative splicing on a genomic scale. In previous studies EST-genome alignments were made using 90-93% sequence identity as threshold [2 3 4]. However their low thresholds allow ESTs to incorrectly align with paralogous genes or pseudogene,10.1.1.1.2193,human full-length pre-mRNA sequence gene prediction alternative splicing splice site exon-intron structure GenBank annotation experimental evidence EST-genome alignment,?
Pointerless Implementation of Hierarchical Simplicial Meshes and Efficient Neighbor Finding in Arbitrary Dimensions,F. Betul Atalay David M. Mount,2004,We describe a pointerless representation of hierarchical regular simplicial meshes based  on a bisection approach proposed by Maubach. We introduce a new labeling scheme called an  LPT code that uniquely encodes each simplex of the hierarchy. We present rules to efficiently  compute the neighbors of a given simplex through the use of these codes. In addition we  show how to traverse the associated tree and how to answer point location and interpolation  queries.Our system works in arbitrary dimensions.,10.1.1.1.2194,?,?
How to Be a Relativist about Truth,John MacFarlane,2004,this paper by context-sensitivity). The first and most obvious is indexicality. A sentence is indexical (as I use the term here) if it expresses different propositions at different contexts of use. But not all context-sensitivity can be traced to indexicality (including hidden indexicality not attributable to an expressed component of the sentence). The sentence The number of AIDS babies born in the United States in 2003 is greater than ten thousand is indexical-free yet it is context-sensitive because its truth varies with the world of utterance,10.1.1.1.2195,?,?
Nonparametric methods for heavy tailed vector data: A survey with applications from finance and hydrology,Mark M. Meerschaert  Hans-Peter Scheffler,?,This paper surveys nonparametric methods for modeling such data sets. These models are based on a generalized central limit theorem. The limit laws in the generalized central limit theorem are operator stable a class that contains the multivariate Gaussian as well as marginally stable random vectors with di#erent tail behavior in each coordinate. Modeling this kind of data requires choosing the right coordinates estimating the tail index for those coordinates and characterizing dependence between the coordinates. We illustrate the practical application of these methods with several example data sets from finance and hydrology,10.1.1.1.2196,?,?
Named Graphs Provenance and Trust,Jeremy J. Carroll Christian Bizer  Patrick Hayes Patrick Stickler,2004,The Semantic Web consists of many RDF graphs nameable by URIs. This paper,10.1.1.1.2197,?,?
View Connectors for the integration of Domain Specific Access Control,Tine Verhanneman Frank Piessens  Bart De Win Wouter Joosen,2004,is a challenging problem for many application domains. It should be possible to set and manage one organization-wide access control policy that must then be enforced reliably in a multitude of applications running within the organization. This is severely complicated by the fact that an access control policy can be fine-grained and dependent on application state and hence its enforcement can crosscut an application in an intricate way.,10.1.1.1.2199,?,?
Generative Temporal Planning with Complex Processes,Brian C. Williams Arthur C. Smith Jonathan Kennell Jonathan Kennell,2003,Autonomous vehicles are increasingly being used in mission-critical applications and robust methods are needed for controlling these inherently unreliable and complex systems. This thesis advocates the use of model-based programming which allows mission designers to program autonomous missions at the level of a coach or wing commander. To support such a system this thesis presents the Spock generative planner. To generate plans Spock must be able to piece together vehicle commands and team tactics that have a complex behavior represented by concurrent processes. This is in contrast to traditional planners whose operators represent simple atomic or durative actions. Spock represents operators using the RMPL language which describes behaviors using parallel and sequential compositions of state and activity episodes. RMPL is useful for controlling mobile autonomous missions because it allows mission designers to quickly encode expressive activity models using object-oriented design methods and an intuitive set of activity combinators. Spock also is significant in that it uniformly represents operators and plan-space processes in terms of Temporal Plan Networks which support temporal flexibility for robust plan execution. Finally Spock is implemented as a forward progression optimal planner that walks monotonically forward through plan processes closing any open conditions and resolving any conflicts. This thesis describes the Spock algorithm in detail along with example problems and test results.,10.1.1.1.2200,?,?
The Supervisor-Worker Pattern,Sebastian Fischmeister And Sebastian Fischmeister Wolfgang Lugmayr,1999,Mobile agents and mobile computing have grown in importance recently. The SupervisorWorker  pattern is an architectural pattern that helps architects solving the problem of protecting the mobile agent from leakage and tampering. The fundamental MasterSlave Pattern is widespread and heavily used in traditional applications. The SupervisorWorker  pattern inherits many of the Master-Slave patterns benefits. It also solves several of the security issues of mobile agents.,10.1.1.1.2201,?,?
First-Year Implementation Effects of a Straff Development Program on Cooperative Learning,Karen Krol  Simon Veenman Marinus Voeten,2001,In this study the first year implementation effects of a staff development program on cooperative learning for Dutch elementary school teachers were studied. A pretest-posttest control group design was used to investigate program effects on teachers instructional behaviors. Based on observations of teacher behavior during a cooperative lesson a statistically significant treatment effect was found for the following instructional cooperative behaviors: structuring positive interdependence individual accountability social skills and evaluation of the group processing. Training effects were also found for the use of cooperative activities in the direct instruction model and for activating pupils prior knowledge of social skills. 3  on Cooperative Learning Promotion of cooperative learning has been high on the educational reforms and restructuring agendas for the last few decades. Cooperative learning (CL) involves pupils working together to accomplish shared learning goals. Facilitating active learning involving teaching for understanding the use of teaching methods to develop critical thinking and problem solving and the development of learning communities at school are central principles for the educational reforms in the OECD countries (Stern  Huber 1997 Adviesraad Onderwijs 1994). The emphasis on active learning is supported by current cognitive conceptions of both learning and instruction (Shuell 1996). CL structures and approaches are seen as valuable instructional strategies for strengthening pupils capacity for active learning at school and for the promotion of pupils cognitive and social development. According to Johnson Johnson and Stanne (2000) and Slavin (1995) there are many reasons for CL to enter the mainstream of educational practice. Fi...,10.1.1.1.2202,?,?
Aliasing in XCS and the Consecutive State Problem: 1 - Effects,Alwyn Barry,1999,Whilst XCS (Wilson 1998) has been shown to  be more robust and reliable than previous LCS  implementations (Kovacs 1996 1997) Lanzi  (1997) identified a potential problem in the  application of XCS to certain simple multi-step  non Markovian environments. The Aliasing  Problem occurs when the environment provides  the same message for two states in  environmental positions that generate different  constant payoffs. This prevents classifiers  forming a correct payoff prediction for that  message. This paper introduces a sub-class of the  aliasing problem termed the Consecutive State  Problem and uses the subclass to identify the  effects of consecutive state aliasing on the  learning of the State  Action  Payoff mapping  within XCS. It is shown that aliasing states can  prevent the formation of classifiers covering  preceding states due to the trade-off of accuracy  for match set occupancy made by the classifiers  covering the aliasing states. This can be  prevented by identifying a condition encoding  which makes such match set piracy improbable. However,10.1.1.1.2203,?,?
Tonal and temporal manifestations of successively higher emphasis in two communicative contexts,Eva Strangert,2003,Introduction  The research reported on is undertaken within the Swedish GROG project Boundaries and groupings -- the structuring of speech in different communicative situations (Carlson et al. 2002)    . An extended version of the present paper will appear in Strangert (2003).  Focal accent is the highest level of prominence in the Swedish intonation model (Bruce 1977). It is signalled primarily by a rise in f 0  although recent studies point to strong effects also of other parameters in particular duration (Heldner 2001). A focused word further may be more or less emphasized within the phonologic category of focus a continuous variation of emphasis can be assumed (Bruce 1998). The means used to increase emphasis are tonal as well as temporal. Carlson et al. (1975) observed temporal and tonal adjustments to successively higher levels of emphasis and Ericson  Lehiste (1995) reported on longer word durations in emphasized words. To emphasize and for contrastive purposes ,10.1.1.1.2204,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,This paper provides an introduction to the technique of simulation-based production planning and scheduling a fast growing and popular area in the simulation industry. SIMUL8 and Visual8 Corporations have collaborated to develop a new software application called SIMUL8Planner that assists in the development of this type of system. The following document outlines some of the requirements advantages and features within this exciting new product.,10.1.1.1.2205,?,?
Experience from a New Course on Digital Logic and,Computer Fundamentals At Lasse Natvig Tormod Njølstad,2001,We have developed a compact new course on digital logic design and computer fundamentals integrated with laboratory assignments using state-of-the-art design tools and a custom designed lab system board. The labs give the students hands-on experience with FPGA design using Xilinx Foundation and 8051 assembler programming. Through five assignments the students design verify and demonstrate a simple audio processing system. Feedback from students tells that the lab makes the course fun and helps the understanding of the theory. In this paper we outline the objectives and contents of the course give a brief description of the labs and summarise the experience from running this course for about 2000 students during the last four years.,10.1.1.1.2206,Digital design computer fundamentals education laboratory FPGA 8051,?
A Requirements-based Framework for the Analysis of Socio-Technical System Behaviour,Jon G. Hall et al.,2003,Requirements Engineerings theoretical and practical developments typically look forward to the future (i.e. a system to be built). Under certain conditions however they can also be used for the analysis of problems related to actual systems in operation. Building on the Jackson/Zave reference model [2] for requirements and specifications this paper presents a framework useful for the prevention analysis and communication of designer and operator errors and importantly their subtle interactions so typical in complex socio-technical systems. ,10.1.1.1.2207,?,?
ROMA: Reliable Overlay Multicast with Loosely Coupled TCP Connections,Gu-in Kwon John W. Byers,2004,We consider the problem of architecting a reliable content delivery system across an overlay network using TCP connections as the transport primitive. We first argue that natural designs based on store-and-forward principles that tightly couple TCP connections at intermediate end-systems impose fundamental performance limitations such as dragging down all transfer rates in the system to the rate of the slowest receiver. In contrast the ROMA architecture we propose incorporates the use of loosely coupled TCP connections together with fast forward error correction techniques to deliver a scalable solution that better accommodates a set of heterogeneous receivers. The methods we develop establish chains of TCP connections whose expected performance we analyze through equation-based methods. We validate our analytical findings and evaluate the performance of our ROMA architecture using a prototype implementation via extensive Internet experimentation across the PlanetLab distributed testbed.,10.1.1.1.2208,?,?
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros B. A. Peters J. S. Smith D. J. Medeiros M. W. Rohrer,?,Telemarketers direct marketing agencies collection agencies and others whose primary means of customer contact is via the telephone invest considerable sums of money to make the calling operation efficient and productive. Investments are required in human resources infrastructure and technology. Having invested the dollars businesses want to ensure that value is maximized. Call scheduling algorithms provide an efficient method to maximize customer contact. However management at a large national credit-card bank was not convinced that the software used to schedule calls was providing an adequate level of service. Simulation studies showed that management was justified in this assumption. The study also revealed that process improvement opportunities exist which if implemented would likely produce the desired performance improvements.,10.1.1.1.2209,?,?
Integrating Topographic Information and Landmarks for Mobile Navigation,Mark Hampe And Mark Hampe Birgit Elias,2004,To help a mobile user navigating and finding his or her way in a foreign environment there are nowadays more possibilities than only using a paper map namely using small mobile devices. But nevertheless there is need for research and development before using these new technical possibilities in an ideal manner and replacing the traditional paper map. small mobile devices in terms of location based services  The optimum would be to pass the user the most actual data within a few seconds representing the data in an understandable uncomplicated and clear way meeting the users needs by personalising the visualisation and filtering the unimportant information. To satisfy all these claims different steps of research are necessary.,10.1.1.1.2210,?,?
Protocol Selection and Interface Generation for HW-SW Codesign,Jean-Marc Daveau   Gilberto Fernandes Marchioro Tarek Ben-Ismail  Ahmed Amine Jerraya,1997,The aim of this paper is to present a communication synthesis approach stated as an allocation problem. In the proposed approach communication synthesis allows to transform a system composed of processes that communicate via high level primitives through abstract channels into a set of processes executed byinterconnected processors that communicate via signals and share communication control. The proposed communication synthesis approach deals with both protocol selection and interface generation and is based on binding/allocation of communication units. This approach allows a wide design space exploration through automatic selection of communication protocols. We presenta  new algorithm that performs binding/allocation of communication units. This algorithm makes use of a cost function to evaluate different allocation alternatives. We illustrate through an example the usefulness of the algorithm for allocating automatically different protocols within the same application system.,10.1.1.1.2211,?,?
Design of Integrated Circuits for the Power Domain,J. A. Neves Rodrigues A. Th. Schwarzbacher  P.A. Comiskey J. B. Foley,1998,Until the late 80s the only constraints when designing integrated circuits (ICs) were the area and speed. The field of low power design was confined to applications such as digital wrist watches or cardiac pacemakers. In the beginning of the early 90s this changed rapidly with the growing demand for portable electronic equipment such as cellular phones and notebook computers. However decreasing feature sizes and the demand for real-time processing systems have resulted in a level of miniaturisation where the heat dissipation is now the main problem. Here the trade-off between special packaging capable of cooling the chip and expensive fan solutions has to be balanced against the consumers demand for low cost applications. Furthermore the recent demand for environmentally friendly consumer goods have pushed companies to design non-portable systems using low power techniques. This has resulted in increased market share for companies producing such green machines.,10.1.1.1.2213,?,?
Comparing Consequence Relations,Peter Flach Dept,1998,The technical problem addressed in this paper is given two rule systems for consequence relations X and Y how to construct Y-approximations of a given X-relation. While an upper Y- approximation can be easily constructed if all Y- rules are Horn the construction of lower Y- approximations is less straightforward. We address the problem by defining the notion of coclosure under co-Horn rules that can be used to remedy violation of certain rules by removing arguments. In particular we show how the coclosure under Monotonicity can be used to construct the monotonic restriction of a preferential relation. Unlike the more usual closure under the rules of M  this co-closure operator supports the intuition that preferential reasoning is more liberal than monotonic reasoning. The approach is embedded in a general framework for comparing rule systems for consequence relations. A salient feature of this framework is that it is also possible to compare rule systems that are not related by metalevel entailment.,10.1.1.1.2214,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,The new portfolio optimization engine OptFolio^TM simultaneously addresses financial return goals catastrophic loss avoidance and performance probability. The innovations embedded in OptFolio enable users to confidently design effective plans for achieving financial goals employing accurate analysis based on real data. Traditional analysis and prediction methods are based on mean variance analysis -- an approach known to be faulty. OptFolio takes a much more sophisticated and strategic direction. State-ofthe -art technology integrates optimization and simulation techniques and a new surface methodology based on linear programming into a global system that guides a series of evaluations to reveal truly optimal investment scenarios. OptFolio is currently being used to optimize project portfolio performance in oil and gas applications and in capital allocation and budgeting for investments in technology.,10.1.1.1.2215,?,?
Computation in a Distributed Information Market,Joan Feigenbaum David M. Pennock Lance Fortnow Rahul Sami,2003,According to economic theory supported by empirical and laboratory evidence the equilibrium price of a financial  security reflects all of the information regarding the securitys value. We investigate the dynamics of the  computational process on the path toward equilibrium where information distributed among traders is revealed stepby  -step over time and incorporated into the market price. We develop a simplified model of an information market  along with trading strategies in order to formalize the computational properties of the process. We show that securities  whose payoffs cannot be expressed as a weighted threshold function of distributed input bits are not guaranteed  to converge to the proper equilibrium predicted by economic theory. On the other hand securities whose payoffs  are threshold functions are guaranteed to converge for all prior probability distributions. Moreover these threshold  securities converge in at most n rounds where n is the number of bits of distributed information. We also prove a  lower bound showing a type of threshold security that requires at least n/2 rounds to converge in the worst case.,10.1.1.1.2216,?,?
Using the Web as a Measure of Familiarity and Obscurity,David Shamma Sara Sara Owsley Shannon Bradshaw Sanjay Sood Jay Budzik Kristian Hammond,?,In this article we explore the structure of the web as an indicator of popular culture. In a series of art and technology installations the software agency needs to keep `grounded to what people can readily understand. We administered a survey to understand how people perceived word and phrase obscurity related with frequency information gathered from a popular Web search engine. We found the frequency data gathered from the engine closely matched judgments gathered from people. The results of this study point to a promising new area of research venturing out from a view of the Web as a tool for corpus linguistics to its use in applications of art and science that provide compelling explorations of popular culture.,10.1.1.1.2217,Media Arts Culture World Wide Web Software Agents,?
Simultaneous Total Variation Image Inpainting and Blind Deconvolution,Tony F. Chan  Andy M. Yip  Frederick E. Park,2004,We propose a total variation based model for simultaneous image inpainting and blind deconvolution.,10.1.1.1.2218,?,?
Optimizing Visible Objects Embedding Towards Realtime Interactive Internet TV, Bin Yu et al.,?,Embedding new visible objects such as video or images into MPEG video has many applications in newscasting pay-per-view Interactive TV and other distributed video applications. Because the embedded foreground content interferes with the original motion compensation process of the background stream we need to decode macroblocks in I and P frames via motion compensation and re-encode all macroblocks with broken reference links via motion reestimation. Although previous work has explored DCTcompressed domain algorithms and provided a heuristic approach for motion re-estimation the computation intensive motion compensation step is not much optimized and so still prevents efficient realtime embedding. In this work we optimize previous work to enable realtime embedding processing that can be applied to Interactive Internet TV applications. We study the motion compensation process and show that on average up to 90% of the macroblocks decoded are not used at all. To explore this phenomenon we propose to buffer a GOP (Group-Of-Picture) of frames and apply a backtracking process that identifies the minimum set of macroblocks which need to go through the decoding operation. At the price of a delay of one-GOP time this approach greatly speeds up the whole embedding process and enables on-line software embedding operation even capable for processing HDTV stream. Further optimizations are discussed and a real-world application scenario is presented. Experimental results have confirmed that this approach is much more efficient than previous solutions and results in equally good video quality.,10.1.1.1.2219,Digital TV (HDTV 2]) Broadcast Internet Video,?
Experiences of Teaching Systems Architetcing,Gerrit Muller,2004,The experiences of four years teaching systems architecting are described. The duration of the course systems architecting is 5 days. The target audience consists of (potential) architects and stakeholders that cooperate intensely with the architect such as project leaders product managers and group leaders. The course has been given 23 times in the period November 1999 to January 2004. The maximum number of participants is 16.,10.1.1.1.2220,?,?
Constraint Driven Web Service Composition in METEOR-S,Rohit Aggarwal  Kunal Verma John Miller  William Milnor,2004,Creating Web processes using Web service technology gives us the opportunity for selecting new services which best suit our need at the moment. Doing this automatically would require us to quantify our criteria for selection. In addition there are challenging issues of correctness and optimality. We present a Constraint Driven Web Service Composition tool in METEOR-S which allows the process designers to bind Web Services to an abstract process based on business and process constraints and generate an executable process. Our approach is to reduce much of the service composition problem to a constraint satisfaction problem. It uses a multi-phase approach for constraint analysis. This work was done as part of the METEOR-S framework which aims to support the complete lifecycle of semantic Web processes.,10.1.1.1.2221,?,?
First-Order Glue,Miltiadis Kokkonidis,2006,Glue has evolved significantly during the past decade. Although the recent move to type-theoretic notation was a step in the right direction basing the current Glue system on system F (second-order #-calculus) was an unfortunate choice. An extension to two sorts and ad hoc restrictions had to be improvised to avoid inappropriate composition of meanings. As a result the current system is unnecessarily complicated. A first-order Glue system is proposed. This new system is not only simpler and more elegant as it captures the exact requirements for Gluestyle compositionality without ad-hoc improvisations but it also turns out to be more powerful than the current two-sorted (pseudo-) second-order system. Firstorder Glue supports all existing Glue analyses as well as new more elegant and/or more demanding analyses.,10.1.1.1.2222,Glue first-order linear logic compositional semantics syntax-semantics,?
Stellar Collapse*,Waldron University Of R. A. Waldron,2001,this paper. The possibility of collapsing to within the Schwarzschild radius depends on m being greater than about 1.4 and this is in keeping with the result obtained above in section III. So far there is no conflict between the two theories,10.1.1.1.2224,?,?
A Practical Mobile-Code Format with Linear Verification Effort,Ning Wang Michael Franz,2003,We present an abstract machine that encodes both type safety and control  safety in an efficient manner and that is suitable as a mobile-code format. At  the code consumer a single linear-complexity algorithm performs not only  verification but simultaneously also transforms the stack-based wire format  into a register-based internal format. The latter is beneficial for interpretation  and native code generation. Our dual-representation approach overcomes  some of the disadvantages of existing mobile-code representations such as  the JVM and CLR wire formats.,10.1.1.1.2225,Contents,?
Performance Comparison of Combined Blind/Non-Blind Source Separation Algorithms,Marcel Joho Heinz Mathis,1999,Source separation is becoming increasingly important in acoustical applications for spatial filtering. In the absence of any known source signals (blind case) a blind update equation similar to the natural gradient method [1] is presented a derivative of which can be used in the case of known references (non-blind case). If some but not all source signals are known blind-only algorithms are suboptimal since some available information is not exploited. To overcome this problem non-blind separation techniques can be incorporated. For the instantaneous mixing case (no time delays no convolution) two different ways of combining blind and non-blind source separation methods are shown namely an echo cancellertype and an equalizer-like approach. Simulations allow a comparison of the convergence time of both structures versus the convergence time of the blind-only case and clearly demonstrate the benefit of using combined blind/non-blind separation techniques.,10.1.1.1.2226,?,?
Minors in Lifts of Graphs,Yotam Drier Nathan Linial,2004,We study here lifts and random lifts of graphs as defined in [1]. We consider the Hadwiger number # and the Hajos number # of #-  lifts of K    and analyze their extremal as well as their typical values (that is for random lifts). When # = 2 we show that       n  and random lifts achieve the lower bound (as n  # #).,10.1.1.1.2227,?,?
  Fading Channels: Information-Theoretic And Communications Aspects,Ezio Biglieri John Proakis Shlomo Shamai (Shitz),1998,In this paper we review the most peculiar and interesting information-theoretic and communications features of fading channels. We first describe the statistical models of fading channels which are frequently used in the analysis and design of communication systems. Next we focus on the information theory of fading channels by emphasizing capacity as the most important performance measure. Both single-user and multiuser transmission are examined. Further we describe how the structure of fading channels impacts code design and finally overview equalization of fading multipath channels.,10.1.1.1.2228,?,?
What Goals Do Students Have When Choosing the Actions They Perform?,Ido Roll Ryan Ryan Shaun Baker Vincent Aleven Kenneth Koedinger,?,Introduction  Several models were built recently in the metacognitive level of the students interaction with Cognitive Tutors an intelligent tutoring system based on ACT-R theory. After finding suboptimal help-seeking behavior we built a metacognitive model of desired help-seeking behavior (Aleven et al. in press). In a different Cognitive Tutor Baker et al. (2004) built a model that identifies misuse of the tutor.  Here we take another step and describe a model of students goals and strategies which rely in the basis of their metacognitive actions. By comparing the models predictions to students log-files we find the correlation between having the goals and learning gains.  Goals and actions  According to the model each student has tendencies towards four different local-goals. Each goal is related to a certain strategy which leads to specific action/s with the tutor (table 1). The unique personal pattern of tendencies categorizes the individual learning process with the tut,10.1.1.1.2229,?,?
A General and Flexible Access-Control System for the Web,Lujo Bauer   Michael A. Schneider Edward W. Felten,2002,We describe the design implementation and performance of a new system for access control on the web. To achieve greater flexibility in forming access-control policies -- in particular to allow better interoperability across administrative boundaries -- we base our system on the ideas of proof-carrying authorization (PCA). We extend PCA with the notion of goals and sessions and add a module system to the proof language. Our access-control system makes it possible to locate and use pieces of the security policy that have been distributed across arbitrary hosts. We provide a mechanism which allows pieces of the security policy to be hidden from unauthorized clients. Our system is implemented as modules that extend a standard web server and web browser to use proof-carrying authorization to control access to web pages. The web browser generates proofs mechanically by iteratively fetching proof components until a proof can be constructed. We provide for iterative authorization by which a server can require a browser to prove a series of challenges. Our implementation includes a series of optimizations such as speculative proving and modularizing and caching proofs and demonstrates that the goals of generality flexibility and interoperability are compatible with reasonable performance.,10.1.1.1.2230,?,?
An Efficient Methodology and Semi-Automated Flow for Design and Validation of Complex Digital Signal Processing ASICS Macro-Cells,L. Tambour N. Zergainoh P. Urard H. Michel A. A. Jerraya,2003,We present a methodology and design flow for signal processing application specific integrated circuit macro-cells. The key features of the methodology are the mastering the complexity of design the increasing of reuse factor and the early error detection. It takes advantages of a derivative designs a signal processing modularity generic modeling and combines both levels of abstraction in order to produce an efficient architecture. The flow includes a fast verification platform that drives both algorithm and architecture validation in an efficient way. We illustrate the effectiveness of the proposed methodology by a significant industrial application. Experimental design results indicate strong advantages of the proposed schemes. ,10.1.1.1.2232,?,?
Representing Utility for  Automated Negotiation,Alan H. Karp,2003,We present a means to represent utility the measure of goodness of a  possible deal. This representation includes a number of features necessary  to represent complex requirements such as time dependence explicit combinations  of terms and cross dependences. The formulation is closely tied to  the form used to represent contracts which makes it useful for automated  negotiation software.,10.1.1.1.2233,?,?
Developing a DataBlade for a New Index,Rasa Bliujute   Simonas Saltenis  Giedrius Slivinskas  Christian S. Jensen ,1999,In order to better support current and new applications the major DBMS vendors are stepping beyond uninterpreted binary large objects termed BLOBs and are beginning to offer extensibility features that allow external developers to extend the DBMS with e.g. their own data types and accompanying access methods. Existing solutions include DB2 extenders Informix DataBlades and Oracle cartridges. Extensible systems offer new and exciting opportunities for researchers and third-party developers alike. This paper reports on an implementation of an Informix DataBlade for the GR-tree a new R-tree based index. This effort represents a stress test of the perhaps currently most extensible DBMS in that the new DataBlade aims to achieve better performance not just to add functionality. The paper provides guidelines for how to create an access method DataBlade describes the sometimes surprising challenges that must be negotiated during DataBlade development and evaluates the extensibility of the Informix Dynamic Server.,10.1.1.1.2234,?,?
 Woodlot Devolution in Northern Ethiopia: Opportunities for Empowerment Smallholder Income Diversification and Sustainable Land Management,Pamela Jagger John Pender Berhanu Gebremedhin,2003,This paper explores the patterns and determinants of empowerment income generation and environmental sustainability under varying degrees of woodlot management in Tigray Ethiopia. Our analysis is based upon a survey of 120 collectively managed woodlots devolved to varying degrees and 66 households that have recently received small plots of community land for tree planting. We find that more devolved woodlot,10.1.1.1.2235,?,?
A Quantum of Light Shed on Classical Potentials and Fields,Cynthia Kolb Whitney,1997,this paper remarked that Einsteins thinking was more along the lines of Section 7. For the benefit of the present author and the audience that first saw some of the plots presented here J.P. Vigier recounted his own knowledge of the history of privately expressed doubts about the Linard-Wiechert results. The history traces through Louis deBroglie and indeed back to Einstein. But nobody articulated the doubts in print. The fact that Einstein used the Linard-Wiechert results conferred on them unwarranted authority. With the end results assumed not subject to question modern authors have generally just retro-fitted modern mathematical methods onto them without seizing the opportunity to delve into questions that the modern methods might have exposed. For example the modern concept of invariant scalar inner product underlies the formulation (3). But the fact that gkR   is equivalent to the inner product        means only that it is an invariant it does not  mean that it is the invariant that corresponds to the correct time argument i.e. the correct proper time of the correct entity in the problem. The slipperiness of the construct V R      has been demonstrated. For example Whitney (1989) shows that the operations of retardation and Lorentz transformation can lead to ambiguity by failing to commute. Another of the modern approaches uses generalized functions: the Dirac delta and the Heaviside step. [See for example Jackson (1975) Sections 12.11 and 14.1.] The problem with the generalized functions is that they lack the mathematical property of uniform convergence and as a result they can produce apparently pathological behaviors. Worst among these is failure in operator commutation: as the generalized functions are used in field theory the operations of diffe...,10.1.1.1.2236,?,?
Multiple Pattern Avoidance with Respect to Fixed Points and Excedances,Sergi Elizalde,2004,We study the distribution of the statistics `number of fixed points and `number  of excedances in permutations avoiding subsets of patterns of length 3. We solve  all the cases of simultaneous avoidance of more than one pattern giving generating  functions enumerating these two statistics. Some cases are generalized to patterns  of arbitrary length. For avoidance of one single pattern we give partial results. We  also describe the distribution of these statistics in involutions avoiding any subset  of patterns of length 3.,10.1.1.1.2237,?,?
Vector Fields and Nilpotent Lie Algebras,Matthew Grayson Robert Grossman,1988,?,10.1.1.1.2240,?,?
On A Use Of Golay Sequences For Asynchronous Ds Cdma Applications,Jennifer R. Seberry Beata J. Wysocki Tadeusz A. Wysocki,?,Golay complementary sequences often referred to as Golay pairs are characterised by the property that the sum of their aperiodic autocorrelation functions equals to zero except for the zero shift. Because of this property Golay complementary sequences can be utilised to construct Hadamard matrices defining sets of orthogonal spreading sequences for DS CDMA systems of the lengths not necessary being a power of 2. In the paper we present an evaluation from the viewpoint of asynchronous DS CDMA applications of some sets of spreading sequences derived from Golay complementary sequences. We then modify those sets of sequences to enhance their correlation properties for asynchronous operation and simulate a multiuser DS CDMA system utilising the modified sequences.,10.1.1.1.2241,Key words Spread Spectrum Spreading Sequences Correlation Functions Golay Complementary Sequences,?
Least Squares Splines with Free Knots: Global Optimization Approach,Gleb Beliakov,?,Splines with free knots have been extensively studied in regard to calculating the optimal knot positions. The dependence of the accuracy of approximation on the knot distribution is highly nonlinear and optimisation techniques face a difficult problem of multiple local minima. The domain of the problem is a simplex which adds to the complexity. We have applied a recently developed cutting angle method of deterministic global optimisation which allows one to solve a wide class of optimisation problems on a simplex. The results of the cutting angle method are subsequently improved by local discrete gradient method. The resulting algorithm is sufficiently fast and guarantees that the global minimum has been reached. The results of numerical experiments are presented.,10.1.1.1.2242,Key words,?
Nash Equilibrium in Graphical Games and Stochastic Graphical Games,Le Chang Department,?,In this paper graphical games a compact graphical  representation for multi-player game theory is introduced.,10.1.1.1.2243,?,?
Functional Difference Predictors (FDPs): Measuring Meaningful Image Differences,James A. Ferwerda Fabio Pellacini,?,In this paper we introduce Functional Difference Predictors (FDPs) a new class of perceptually-based image difference metrics that predict how image errors affect the ability to perform visual tasks using the images. To define the properties of FDPs we conduct a psychophysical experiment that focuses on two visual tasks: spatial layout and material estimation. In the experiment we introduce errors in the positions and contrasts of objects reflected in glossy surfaces and ask subjects to make layout and material judgments. The results indicate that layout estimation depends only on positional errors in the reflections and material estimation depends only on contrast errors. These results suggest that in many task contexts large visible image errors may be tolerated without loss in task performance and that FDPs may be better predictors of the relationship between errors and performance than current Visible Difference Predictors (VDPs).,10.1.1.1.2244,?,?
Optimal Admission Control Using Handover Prediction in Mobile Cellular Networks ,Vicent Pla José Manuel Giménez-Guzmán Jorge Martínez Vicente Casares-Giner,2004,In this paper we study the impact of incorporating handover prediction information into the call admission  control process in mobile cellular networks. The comparison is done between the performance of  optimal policies obtained with and without the predictive information. The prediction agent classifies mobile  users in the neighborhood of a cell into two classes those that will probably be handed over into the  cell and those that probably will not. We consider the classification error by modeling the false-positive and  non-detection probabilities. Two different approaches to compute the optimal admission policy were studied:   dynamic programming and reinforcement learning. Preliminary results show significant performance  gains when the predictive information is used in the admission process.,10.1.1.1.2246,?,?
Postal Envelope Segmentation by 2-D Histogram Clustering,Through Watershed Transform Eduardo Akira Yonekura Jacques Facon,?,In this paper we present a new postal envelope segmentation method based on 2-D histogram clustering and watershed transform. Segmentation task consists in detecting the modes associated with homogeneous regions in envelope images such as handwritten address block postmarks stamps and background. The homogeneous modes in 2-D histogram are segmented through the morphological watershed transform. Our approach is applied to complex Brazilian postal envelopes. Very little a priori knowledge of the envelope images is required. The advantages of this approach will be described and illustrated with tests carried out on 300 different images where there are no fixed position for the handwritten address block postmarks and stamps.,10.1.1.1.2247,?,?
Symbolic State-space Exploration and Numerical Analysis of State-sharing Composed Models,Salem Derisavi  Peter Kemper William H. Sanders,2004,The complexity of stochastic models of real-world systems is usually managed by abstracting details and structuring models in a hierarchical manner. Systems are often built by replicating and joining subsystems making possible the creation of a model structure that yields lumpable state spaces. This fact has been exploited to facilitate model-based numerical analysis. Likewise recent results on model construction suggest that decision diagrams can be used to compactly represent large Continuous Time Markov Chains (CTMCs). In this paper we present an approach that combines and extends these two approaches. In particular we propose methods that apply to hierarchically structured models with hierarchies based on sharing state variables. The hierarchy is constructed in a way that exposes structural symmetries in the constructed model thus facilitating lumping. In addition the methods allow one to derive a symbolic representation of the associated CTMC directly from the given model without the need to compute and store the overall state space or CTMC explicitly. The resulting representation of a generator matrix allows the analysis of large CTMCs in lumped form. The efficiency of the approach is demonstrated with the help of two example models.,10.1.1.1.2248,key words Multi-valued Decision Diagrams Matrix Diagrams Numerical Analysis Symbolic State-space Exploration,?
DNA Computing Capabilities for Game Theory,David Harlan Wood,?,Problems in game theory can be used for benchmark DNA computations. Large numbers of game strategies and chance events can be assembled into finite state machines. These many machines perform in parallel distinct plays of a game. Strategies can be exposed to selection and breeding. The computational capabilities of DNA are matched with aspects of game theory but the most interesting problems are yet to be treated.,10.1.1.1.2249,?,?
A Study Of Self-Adjusting Quality Of Service Control Schemes,Sheng-Tzong Cheng  Chi-Ming Chen,1998,Thispaperreportssimulationmethodsandresultsfor analyzingaself-adjustingQualityofService(QoS)control schemeformultimedia/telecommunicationsystemsbased onresourcereservation.Westudythecaseinwhichhigh priorityclientsQoSrequirementisnotchangedthroughout theserviceperiodwhilelowpriorityclientsQoSmaybe adjustedbythesystembetweenthemaximumandminimum QoSlevelsspecifiedinordertoadapttotheloadofthe system.Thegoalofthesystemdesignistooptimizethe systemrewardasaresultofservicingclientswithdifferent QoSandreward/penaltyrequirements.AQoSmanagerin thesesystemscandoatablelookupoperationusingthe simulationresultreportedheretooptimizethesystemtotal rewarddynamicallyinresponsetochangingworkloads duringtheruntime.Thesimulationresultisparticularly applicabletomultimediaandtelecommunicationsystems inwhichdynamicQoSnegotiation/renegotiationisusedas amechanismtooptimizetheoverallsystemperformance. 1 ,10.1.1.1.2250,?,?
Statistical Monitoring + Predictable Recovery = Self-*,Armando Fox And Armando Fox Emre K?c?man,?,It is by now motherhood-and-apple-pie that complex distributed Internet services form the basis not only of ecommerce but increasingly of mission-critical networkbased applications. What is new is that the workload and internal architecture of three-tier enterprise applications presents the opportunity for a new approach to keeping them running in the face of both natural failures and adversarial attacks. The core of the approach is anomaly detection and localization based on statistical machine learning techniques. Unlike previous approaches we propose anomaly detection and pattern mining not only for operational statistics such as mean response time but also for structural behaviors of the system---what parts of the system in what combinations are being exercised in response to different kinds of external stimuli. In addition rather than building baseline models a priori we extract them by observing the behavior of the system over a short period of time during normal operation. We explain the necessary underlying assumptions and why they can be realized by systems research report on some early successes using the approach describe benefits of the approach that make it competitive as a path toward selfmanaging systems and outline some research challenges. Our hope is that this approach will enable new science in the design of self-managing systems by allowing the rapid and widespread application of statistical learning theory techniques (SLT) to problems of system dependability. 1 Recovery as Rapid Adaptation  A five nines availability service (99.999% uptime) can be down only five minutes a year. Putting a human in the critical path to recovery would expend that entire budget on a single incident hence the increasing interest in self-managing or so-cal...,10.1.1.1.2252,?,?
A new efficient variable learning rate for Perrys spectral conjugate gradient training method.,A. E. Kostopoulos  D.G. Sotiropoulos and T.N. Grapsa D. G. Sotiropoulos T. N. Grapsa,2004,Since the presentation of the backpropagation algorithm several adaptive learning algorithms for training a multilayer perceptron (MLP) have been proposed. In a recent article we have introduced an efficient training algorithm based on a nonmonotone spectral conjugate gradient. In particular a scaled version of the conjugate gradient method suggested by Perry which employ the spectral steplength of Barzilai and Borwein was presented. The learning rate was automatically adapted at each epoch according to Shannos technique which exploits the information of conjugate directions as well as the previous learning rate. In addition a new acceptability criterion for the learning rate was utilized based on nonmonotone Wolfe conditions. A crucial issue of these training algorithms is the learning rate adaptation. Various variable learning rate adaptations have been introduced in the literature to improve the convergence speed and avoid convergence to local minima. In this contribution we incorporate in the previous training algorithm a new e#ective variable learning rate adaptation which increases its efficiency. Experimental results in a set of standard benchmarks of MLP networks show that the proposed training algorithm improves the convergence speed and success percentage over a set of well known training algorithms.,10.1.1.1.2253,supervised training backpropagation spectral steplength conjugate gradient methods Perry’s method nonmonotone Wolfe conditions,?
Storage Device Performance Prediction with CART Models,Mengzhi Wang Kinman Au Anastassia Ailamaki  Anthony Brockwell Christos Faloutsos  Gregory R. Ganger,2004,Storage device performance prediction is a key element of self-managed storage systems and application planning tasks such as data assignment. This work explores the application of a machine learning tool CART models to storage device modeling. Our approach predicts a devices performance as a function of input workloads requiring no knowledge of the device internals. We propose two uses of CART models: one that predicts per-request response times (and then derives aggregate values) and one that predicts aggregate values directly from workload characteristics. After being trained on our experimental platforms both provide accurate black-box models across a range of test traces from real environments. Experiments show that these models predict the average and 90th percentile response time with an relative error as low as 16% when the training workloads are similar to the testing workloads and interpolate well across different workloads.,10.1.1.1.2254,Performance prediction storage device modeling,?
Negotiated Formations,David J. Naffin Gaurav S. Sukhatme,2004,We present a decentralized behavior-based approach to assembling and  maintaining robot formations. Our approach dynamically grows formations from single  robots into line segments and ultimately larger and more complex formations. Formation growth,10.1.1.1.2255,?,?
Migration of Mobile Agents in Java: Problems Classification and Solutions,Torsten Illmann University Torsten Illmann Michael Weber,2000,In this paper we examine migration techniques of mobile agents in Java. We identify the problems in Java technology classify different migration styles and present possible solutions and related work. The proposed classification distinguishes between code migration execution migration and data migration. The classification defines a partial order to compare different migration approaches. For realizing strong migration in Java two solutions are proposed. On the one hand a pre-processor adds all the necessary information for migration to the source code before compilation time. On the other hand A JNI-based plugin for any virtual machine provides mechanisms to captures the agents execution state. The restoration of the execution state is done by the plugin in combination with a byte code modifier which slightly changes the byte code of the agent.,10.1.1.1.2256,?,Springer
Distributed Control Flow with Classical Modal Logic,Tom Murphy VII  Karl Crary  Robert Harper,2005,In previous work we presented a foundational calculus for spatially distributed computing based on intuitionistic modal logic. Through the modalities # and # we were able to capture two key invariants: the mobility of portable code and the locality of fixed resources. This work,10.1.1.1.2257,?,Springer
Maximizing Information Throughput for Multimedia Browsing on Small Displays,Xing Xie Wei-ying Ma Hong-jiang Zhang,?,As a great many of new devices with diverse capabilities are making a population boom their limited display sizes become the major obstacle that has undermined the usefulness of these devices for information access. In this paper we introduce our recent research on adapting multimedia content including images videos and web pages for browsing on small-formfactor devices. A theoretical framework as well as a set of novel methods for presenting and rendering multimedia under limited screen sizes is proposed to improve the user experience. The content modeling and processing are provided as subscriptionbased web services on the Internet. Experiments show that our approach is extensible and able to achieve satisfactory results with high efficiency.,10.1.1.1.2258,SPOT watch Smartphone Pocket PC Tablet PC etc are,?
Overcoming Gamut and Dynamic Range Limitations in Digital Images,Gregory Ward Larson,2001,The human eye can accommodate luminance in a single view over a range of about 10000:1 and is capable of distinguishing about 10000 colors at a given brightness. By comparison typical CRT displays have a luminance range less than 100:1 and cover about half of the visible color gamut. Despite this difference most digital image formats are geared to the capabilities of conventional displays rather than the characteristics of human vision. In this paper we propose two compact encodings suitable for the transfer manipulation and storage of full range color images. The first format is a replacement for conventional RGB images and encodes color pixels as log luminance values and CIE (uv) chromaticity coordinates. We have implemented and distributed this encoding as part of the standard TIFF I/O library on the net. The second format is proposed as an adjunct to conventional RGB data and encodes out-of-gamut (and out-of-range) pixels in a supplemental image suitable as a layer extension to the Flashpix standard. This data can then be recombined with the original RGB layer to obtain a high dynamic range image covering the full gamut of perceivable colors. Finally we demonstrate the power and utility of full gamut imagery with example images and applications.,10.1.1.1.2260,?,?
prInvestor: Pattern Recognition based Financial Time Series Investment System,Dymitr Ruta,?,Predictability of financial time series (FTS) is a well-known dilemma. A typical approach to this problem is to apply a regression model built on the historical data and then further extend it into the future. If however the goal is to support or even make investment decisions regression-based FTS predictions are inappropriate as on top of being uncertain and unnecessarily complex they require further analysis to make an investment decision. Rather than precise FTS prediction a busy investor may prefer a simple decision on the current day transaction: buy wait sell that would maximise his return on investment. Based on such assumptions a classification model is proposed that learns the transaction patterns from optimally labelled historical data and accordingly gives the profit-driven decision for the current day transaction. Exploiting a stochastic nature of an investment cycle the model is locally reduced to a 2-class classification problem and is built on many features extracted from the share price and transaction volume time series. Simulation of the model over 20 years of NYSE:CSC share price history showed substantial improvement of the profit compared to a passive long-term investment.,10.1.1.1.2261,KEY WORDS Financial Time Series Regression Classification Decision Support,?
Stabilized Vegas,Hyojeong Choe  Steven H. Low,2002,We show that the current TCP Vegas algorithm can become unstable in the presence of network delay and propose a modification that stabilizes it. The stabilized Vegas remains completely source-based and can be implemented without any network support. We suggest an incremental deployment strategy for stabilized Vegas when the network contains a mix of links some with active queue management and some without.,10.1.1.1.2262,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Jeffrey S. Smith Yali Li,?,This paper describes a simulation-based analysis of a printed circuit board (PCB) testing process. The PCBs are used in a defense application and the testing process is fairly complex. Boards are mounted on a test unit in batches and go through three thermal test cycles. As boards fail testing during the thermal cycling operators can either replace the failed boards at fixed points during the cycling or can allow the test unit to complete the testing cycle before removing failed boards. The primary objective of the simulation study is to select an operating strategy for a given set of operating parameters. A secondary objective is to identify the operating factors to which the strategy selection is sensitive. Initial testing indicated that failed boards should be replaced as soon as possible under the current operating configuration of the sponsors facility. Secondary testing is also described.,10.1.1.1.2263,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,This paper presents a simulation optimization of a real scheduling problem in industry simulated annealing is introduced for this purpose. Investigation is performed into the practicality of using simulated annealing to produce high quality schedules. Results on the solution quality and computational effort show the inherent properties of the simulated annealing. It is shown that when using this method high quality schedules can be produced within reasonable time constraints.,10.1.1.1.2264,?,?
Supervision And Control Of Heterarchical Discrete Event Systems: The Laas Approach,Marcos R. Da Silveira Michel Combacau,2002,This paper presents the current state of researches about supervision and control of discrete event systems. The,10.1.1.1.2265,Supervision monitoring distributed models discrete event systems architectures,?
Analysis of Buffer Design for . . . ,Annette Lagman Walid A. Najjar,1996,The performance of a massively parallel computing system is often limited by the speed of its interconnection network. One strategy that has been proposed for improving network efficiency is the use of adaptive routing in which network state information can be used in determining message paths. The design of an adaptive routing system involves several parameters and in order to build high speed scalable computing systems it is important to understand the costs and performance benefits of these parameters. In this paper we investigate the effect of buffer design on communication latency. Four message storage models and their related route selection algorithms are analyzed. A comparison of their performance is presented and the features of buffer design which are found to significantly impact network efficiency are discussed.,10.1.1.1.2266,?,?
Tobias Scheer Toulouse Phonology Conference,Universit De Nice,?,traints. In other words constraints select representations  but not the reverse.    d. the arbitral award of representations is not sovereign anymore. A representation is  not ill- or well-formed as it was before it is as everything else in OT more or less   ill- or well-formed: there is nothing that cannot be violated.   In OT computation does not operate ON representations as before but WITH   representations. Hence OT has abolished the red line between structure and process:   there is no structure left computation (= process) decides alone.    e. point out the consequences of the demotion of representations:    1. they had a function i.e. fighting back overgeneration. Giving up on them sets  phonology back to where it stood in post-SPE times.   - 2 -    2. another job of representations was to offer explanations for the facts we   observe. Their absence has triggered a run on extra-phonological explanations  for phonological events: grounded constraints.    - is a phon,10.1.1.1.2267,?,?
Practical Suffix Tree Construction,Sandeep Tata Richard A. Hankins Jignesh M. Patel,2004,Large string datasets are common in a number  of emerging text and biological database applications.,10.1.1.1.2268,?,?
Active And Unsupervised Learning for Automatic Speech Recognition,Giuseppe Riccardi  Dilek Hakkani-Tür,2003,State-of-the-art speech recognition systems are trained using human transcriptions of speech utterances. In this paper we describe a method to combine active and unsupervised learning for automatic speech recognition (ASR). The goal is to minimize the human supervision for training acoustic and language models and to maximize the performance given the transcribed and untranscribed data. Active learning aims at reducing the number of training examples to be labeled by automatically processing the unlabeled examples and then selecting the most informative ones with respect to a given cost function. For unsupervised learning we utilize the remaining untranscribed data by using their ASR output and word confidence scores. Our experiments show that the amount of labeled data needed for a given word accuracy can be reduced by 75% by combining active and unsupervised learning.,10.1.1.1.2269,?,?
High Classification Accuracy Does Not Imply Effective Genetic Search,Tim Kovacs  Manfred Kerber,?,Learning classifier systems their parameterisation and their rule discovery systems have often been evaluated by measuring classification accuracy on small Boolean functions. We demonstrate that by restricting the rule set to the initial random population high classification accuracy can still be achieved and that relatively small functions require few rules. We argue this demonstrates that high classification accuracy on small functions is not evidence of effective rule discovery. However we argue that small functions can nonetheless be used to evaluate rule discovery when a certain more powerful type of metric is used.,10.1.1.1.2270,?,?
Automatically and Accurately Conflating Satellite Imagery and Maps (Extended Abstract),Ching-Chien Chen Craig A. Knoblock Cyrus Shahabi Snehal Thakkar,2000,Ching-Chien Chen Craig A. Knoblock Cyrus Shahabi and Snehal Thakkar  University of Southern California  Department of Computer Science and Information Sciences Institute  4676 Admiralty Way  Marina del Rey CA 90292 USA  {chingchc knoblock shahabi snehalth}@usc.edu  1 ,10.1.1.1.2271,?,?
Discovery of Serial Episodes from Streams of Events,Taneli Mielikäinen,?,this paper we focus on finding serial episodes from data streams. To the best of our knowledge the problem of mining serial episodes from data streams has been studied in depth only for length-1 episodes [2],10.1.1.1.2272,?,?
Quantumlike Chaos in the Frequency Distributions of Bases A C G T in Human Chromosome1 DNA,Bases A T In Human Chromosome Dna A. M. Selvam,2004,Introduction  DNA topology is of fundamental importance for a wide range of biological processes [1]. Since the topological state of genomic DNA is of importance for its replication recombination and transcription there is an immediate interest to obtain information about the supercoiled state from sequence periodicities [23]. Identification of dominant periodicities in DNA sequence will help understand the important role of coherent structures in genome sequence organization [45]. Li [6] has discussed meaningful applications of spectral analyses in DNA sequence studies. Recent studies indicate that the DNA sequence of letters A C G and T exhibit the inverse power law form 1/f    frequency spectrum where f is the frequency and a the exponent. It is possible therefore that the sequences have longrange order [7-14]. Inverse power-law form for power spectra of fractal space-time fluctuations is generic to dynamical systems in nature and is identified as self-organized criticality ,10.1.1.1.2273,biology fractals,?
GENERATING FUNCTIONS FOR IRREDUCIBLE CHARACTERS OF Sn INDEXED WITH MULTIPLE HOOKS,La Somme Est Alain Goupil,?,We present new expressions for generating functions of irreducible characters of the symmetric group S n . These generating functions are of the form       where the sum is over partitions # of restricted shapes such as hooks and double hooks. We use the #-ring theory for symmetric functions to demonstrate our statements. 1. ,10.1.1.1.2274,?,?
Multi-dimensional Sparse Matrix Storage,Jiri Dvorsky  Michal Kratky,?,Large sparse matrices play important role in many modern information retrieval methods. These methods such as clustering latent semantic indexing performs huge number of computations with such matrices thus their implementation should be very carefully designed. In this paper we discuss three implementations of sparse matrices. The first one is classical based on lists. The second is previously published approach based on quadrant trees. The multi-dimensional approach is extended and usage of general multi-dimensional structure for sparse matrix storage is introduced in this paper.,10.1.1.1.2275,?,?
Table of Contents,,?,This white paper provides a technical overview of the Red Hat Cluster Suite layered product. The paper describes several of the software technologies used to provide high availability and provides outline hardware configurations. The paper is suitable for people who have a general understanding of clustering technologies such as those found in Microsoft Windows 2000 Advanced Server and Sun Cluster products.,10.1.1.1.2277,Introduction........................................................................................,?
C. Roy Keys Inc.,Quantumlike Chaos In A. M. Selvam,?,this paper shows (Section 2) that Fibonacci series underlies fractal fluctuations on all space-time scales,10.1.1.1.2278,Penrose,?
Co-training and Self-training for Word Sense Disambiguation,Rada Mihalcea Department Rada Mihalcea,2004,This paper investigates the application of cotraining  and self-training to word sense disambiguation.,10.1.1.1.2279,?,?
On the Accuracy of Transmembrane Segment Prediction of Helical Integral Membrane Proteins,Shin Tanimoto  Gautam Basu Takeshi Kawabata  N. Go Nobuhiro Go,2003,Introduction  Integral membrane proteins play a vital role in a number of essential biological functions. Although abundant about 30% of genes are known to code for membrane proteins the number of solved structures in the pdb is less than 1%. Thus structure prediction of membrane proteins is an essential tool for understanding their functions. A fundamental characteristic of the predicted structure is the topology -- identification of trans-membrane segments and the overall orientation with respect to the membrane (intra- or extra-cellular). Several prediction methods have been developed for this purpose both knowledge-based and residue hydrophobicity-based. Although the performances of almost all of these methods are rather high short loops and long helices are predicted less accurately [1]. One of the problems of estimating accuracy of di#erent prediction methods is the absence of experimentally reliable trans-membrane annotations to compare with. Thus one is forced to compare ,10.1.1.1.2280,transmembrane helix prediction hydrophobicity topology,?
Knowledge State Reconsideration: Hindsight Belief Revision,Frances Johnson And Frances L. Johnson Stuart C. Shapiro,?,this paper we assume a global decision function is used in the belief change operations and it will favor retaining the most preferred beliefs as determined by a preference ordering (#) that is irreflexive anti-symmetric and transitive (referred to here as an IAT-preference ordering),10.1.1.1.2281,?,?
Stellar and Planetary Aberration,Thomas E. Phipps  Jr.,1994,This paper has been rewritten half a dozen times and each time it has looked completely different. The reader will have to bear with the present report as a fallible one of tentative progress to date,10.1.1.1.2282,?,?
Improved Nearest Neighbor Based Approach to Accurate Document Skew Estimation,Yue Lu  Chew Lim Tan,2003,The nearest-neighbor based document skew detection methods do not require the presence of a predominant text area and are not subject to skew angle limitation. However the accuracy of these methods is not perfect in general. In this paper we present an improved nearest-neighbor based approach to perform accurate document skew estimation. Size restriction is introduced to the detection of nearest-neighbor pairs. Then the chains with a largest possible number of nearest-neighbor pairs are selected and their slopes are computed to give the skew angle of document image. Experimental results on various types of documents containing different linguistic scripts and diverse layouts show that the proposed approach has achieved an improved accuracy for estimating document image skew angle and has an advantage of being language independent.,10.1.1.1.2283,?,?
High-Performance QoS Routing,Progress Report On Klara Nahrstedt,2001,erform routing table lookups in parallel manner control agents (CA) to handle routing table computation and QoS control tasks and high-speed switch fabric. Separating IP header analysis and the routing table lookups the line cards become light weighted. Furthermore this separation allowed us to achieve better load-balancing and therefore higher performance.  The major contribution in this work is the IP Packet Distribution Approach performed by LCs and RAs. This approach satisfies two requirements: RAs are working in a load-balanced manner and packets from the same flow are not reordered. The algorithm distributes packets when arriving at LCs using the Enhanced Hash-based Distribution Algorithm (EHDA). When a packet arrives EHDA generates a hash value for each IP packet based on its destination address and then EHDA uses indirect hashing (hash values are used as indices to a hash table) to obtain the ID number of each RA. The content of the hash table is dynamically changed a,10.1.1.1.2284,?,?
Using Parameterised Contracts to Predict Properties of Component Based Software Architectures,Ralf H. Reussner Heintz W. Schmidt,2002,This position paper presents an approach for predicting functional and extra-functional properties of layered software component architectures. Our approach is based on parameterised contracts a generalisation of design-bycontract. The main contributions of the paper are twofold. Firstly it attempts to clarify the meaning of contractual use of components a term sometimes used loosely -- or even inconsistently -- in current literature. Secondly we demonstrate how to deploy parameterised contracts to predict properties of component architectures with non-cyclic dependencies.,10.1.1.1.2285,?,?
Emergent Skills in Higher Education:,From Know-How To Luis Borges Gouveia,?,New models and strategies have been on trial for the advantage of emerging information and communication technologies over the last decades. Among these a particular group of technologies impacts the way time and space constraints are now consider. Additionally the information and knowledge society requires new skills to both the professional and the learner. In particular considering a higher education context the need to deal with change innovation and evolving models of competition and collaboration brings new challenges. Although higher education keeps a traditional background of sharing ideas experimentation and reflection about impact and future applications of available knowledge it lacks the ability to embed within its own practices both its work and ideas as also efforts from its community. Presential teaching organisational structures administrative processes curricula organisation and knowledge sharing strategies are now put on pressure by an increasing number of high education newcomers who fail to adhere to the current status and learn the skills that the so called information and knowledge society may require. A huge challenge is on place based on a transition from processes to information based activities from an individual approach to a collaborative one from a knowledgeoriented learning to a skill-oriented learning. It seems that the network both for individuals organisations and also for organising the learning in higher education is a central concept: connecting people and sharing knowledge not efforts The use of virtuality considered here as the desmaterialisation of learning settings and experiences provides the opportunity to cope with time and space constraints and to innovate both on practices as on what individuals need to know-h...,10.1.1.1.2286,?,?
Augmented Trading: From news articles to stock price predictions using syntactic analysis,Arthur Hugo Van Bunningen Anton Nijholt Mannes Poel Martijn Van Otterlo,2004,This thesis tries to answer the question how to predict the reaction of the stock market to news articles using the latest suitable developments in Natural Language Processing. This is done using text classification where a new article is matched to a category of articles which have a certain influence on the stock price. The thesis first discusses why analysis of news articles is a feasible approach to predicting the stock market and why analysis of past prices should not be build upon. From related work in this domain two main design choices are extracted what to take as features for news articles and how to couple them with the changes in stock price. This thesis then suggests which di#erent features are possible to extract from articles resulting in a template for features which can deal with negation favorability abstracts from companies and uses domain knowledge and synonyms for generalization. To couple the features to changes in stock price a survey is given of several text classification techniques from which it is concluded that Support Vector Machines are very suitable for the domain of stock prices and extensive features. The system has been tested with a unique data set of news articles for which results are reported that are significantly better than random. The results improve even more when only headlines of news articles are taken into account. Because the system is only tested with closing prices it cannot concluded that it will work in practice but this can be easily tested if stock prices during the days are available. The main suggestions for feature work are to test the system with this data and to improve the filling of the template so it can also be used in other areas of favorability analysis or maybe even to extract interesting information o...,10.1.1.1.2287,?,?
Programming Languages and Systems for Prototyping Concurrent Applications,Wilhelm Hasselbring,2000,... This paper presents a survey of programming languages and systems for  prototyping concurrent applications to review the state of the art in this area. The  surveyed approaches are classified with respect to the prototyping process,10.1.1.1.2288,?,?
CACTI 3.0: An Integrated Cache Timing Power and Area Model,Premkishore Shivakumar  Norman P. Jouppi Premkishore Shivakumar,2001,CACTI 3.0 is an integrated cache access time cycle time area aspect ratio and power model. By integrating all these models together users can have confidence that tradeoffs between time power and area are all based on the same assumptions and hence are mutually consistent. CACTI is intended for use by computer architects so they can better understand the performance tradeoffs inherent in different cache sizes and organizations.,10.1.1.1.2289,?,?
Techniques de Coordination Multi-Agents . . .,Nguyen-Duc,2003,INTRODUCTION   e syst e ATC actue est centr sur espace. Lespace  arien est divis en p usieurs secteurs dont a tai e  dpend du nombre davions dans a rgion et a gomtrie  des routes ariennes. I y a habitue ement deux contr eurs  ariens dans chaque secteur qui manipu ent e trafic: un  contr eur p anificateur et un contr eur excutif. Le  p anificateur travai e un niveau stratgique et essaye de  rduire au minimum e nombre de conf its ou eur comp exit.  Le contr eur excutif travai e un niveau tactique et sassure    MaVj crit reu le 20 septembre 2002.  Minh NGUYEN-DUC.  La bora  toire  dInforma  tique de  Pa  ris 6 (LIP6) Universit  dePa  ris 6  Pa  ris Fra- e minh.nguyen-duc@lip6.fr. Institut de  la  Fra cophonie pour  lInforma  tique (IFI) Ha@J  Vietna  ndminh@ifi.edu.vn.  Vu DUONG EUROCONTROL  Experimenta  l Center BrtignyFraV   vu.duong@eurocontrol.int.  Jea-BHHV  re BRIOT.La oraV ire dInform a ique dePa@ 6 (LIP6)  Universit de  Pa  ris 6  Pa  ris  Fra  nce  jea  n-p,10.1.1.1.2290,?,?
Intersecting Quadrics: An Efficient and Exact Implementation,Sylvain Lazard  Luis Mariano Peñaranda  Sylvain Petitjean,2004,We present the first complete exact and efficient C++ implementation of a method for parameterizing  the intersection of two implicit quadrics with integer coefficients of arbitrary size. It is based on the near-optimal  algorithm recently introduced by Dupont et al. [4]. Unlike,10.1.1.1.2292,?,ACM Press
Game-theoretic agent programming in Golog,Alberto Finzi Thomas Lukasiewicz,2004,  We present the agent programming language GTGolog which integrates explicit agent programming in Golog with game-theoretic multi-agent planning in Markov games. It is a generalization of DTGolog to a multi-agent setting where we have two competing single agents or two competing teams of agents. The language allows for specifying a control program for a single agent or a team of agents in a high-level logical language. The control program is then completed by an interpreter in an optimal way against another single agent or another team of agents by viewing it as a generalization of a Markov game and computing a Nash strategy. We illustrate the usefulness of this approach along a robotic soccer example. We also report on a first prototype implementation of a simple GTGolog interpreter.,10.1.1.1.2293,?,IOS Press
Tel.:972-2-5345730972-2-881368 Fax:972-2-882045 E-Mail: Msazohar@mscc.nujc.ac.il.,Teaching And Teacher Anat Zohar,?,The purpose of the present study was to investigate teachers declarative metacognitive knowledge of higher order thinking skills. This was a qualitative study conducted within the educational setting of in-service science teachers courses. The main finding is that teachers intuitive (i.e. pre-instructional) knowledge of metacognition of thinking skills is unsatisfactory for the purpose of teaching higher order thinking in science classrooms. A general practical implication of this study is that courses which prepare teachers for instruction of higher order thinking should address extensively the issue of metacognition of thinking skills. # 1999 Elsevier Science Ltd. All rights reserved.,10.1.1.1.2295,Metacognition Higher order skills Teacher thinking Science teachers Teacher education,?
Virtuoso: A System for Virtual Machine Marketplaces,Alex Shoykhet Alex Shoykhet  Jack Lange Jack Lange  Peter Dinda Peter Dinda,2004,This  report describes the interface and implementation of the Virtuoso  system. It is also a user manual for those who wish to try Virtuoso,10.1.1.1.2296,virtual machines distributed computing economic models of computing,?
Application of LUT Cascades to Numerical Function Generators,Sasao Butler Riedel T. Sasao J. T. Butler M. D. Riedel,2004,The availability of large inexpensive memory has made it possible to realize numerical functions such as the reciprocal square root and trigonometric functions using a lookup table. This is much faster than by software. However a naive look-up method requires unreasonably large memory. In this paper we show the use of a look-up table (LUT) cascade to realize a piecewise linear approximation to the given function. Our approach yields memory of reasonable size and significant accuracy.,10.1.1.1.2297,?,?
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros B. A. Peters J. S. Smith D. J. Medeiros M. W. Rohrer,?,Parameters of statistical distributions that are input to simulations are typically not known with certainty. For existing systems or variations on existing systems they are often estimated from field data. Even if the mean of simulation output were estimable exactly as a function of input parameters there may still be uncertainty about the output mean because inputs are not known precisely. This paper considers the problem of deciding how to allocate resources for additional data collection so that input uncertainty is reduced in a way that effectively reduces uncertainty about the output mean. The optimal solution to the problem in full generality appears to be quite challenging. Here we simplify the problem with asymptotic approximations in order provide closed-form sampling plans for additional data collection activities. The ideas are illustrated with a simulation of a critical care facility.,10.1.1.1.2298,?,?
PAWNs: Satisfying the Need for Ubiquitous Secure Connectivity and Location Services,P. Bahl Paramvir Bahl Allen Miu Wilf Russell Geoffrey M. Voelker Yi-min Wang,2002,The dawning of the 21st century has seen unprecedented growth in the number of wireless users applications and network access technologies. This trend is enabling the vision of pervasive ubiquitous computing where users have network access anytime anywhere and applications are location-sensitive and contextaware. To realize this vision we need to extend network connectivity beyond private networks such as corporate and university networks into public spaces like airports malls hotels parks arenas etc. -- those places where individuals spend a considerable amount of their time outside of private networks.,10.1.1.1.2299,?,?
A positive systems model of TCP-like congestion control: Asymptotic results,Robert Shorten  Fabian Wirth Douglas Leith,2004,In this paper we study communication networks that employ drop-tail  queueing and Additive-Increase Multiplicative-Decrease (AIMD) congestion  control algorithms. We show that the theory of nonnegative matrices  may be employed to model such networks. In particular we show that  important network properties such as: (i) fairness (ii) rate of convergence  and (iii) throughput can be characterised by certain non-negative matrices  that arise in the study of AIMD networks. We demonstrate that these  results can be used to develop tools for analysing the behaviour of AIMD  communication networks. The accuracy of the models is demonstrated by  means of several NS-studies.,10.1.1.1.2300,?,Hamilton Institute
Toward Automatic Context-Based Attribute Assignment for Semantic File Systems,Craig A. N. Soules  Gregory R. Ganger,2004,Semantic file systems enable users to search for files based on attributes rather than just pre-assigned names. This paper develops and evaluates several new approaches to automatically generating file attributes based on context complementing existing approaches based on content analysis. Context captures broader system state that can be used to provide new attributes for files and to propagate attributes among related files context is also how humans often remember previous items [2] and so should fit the primary role of semantic file systems well. Based on our study of ten systems over four months the addition of context-based mechanisms on average reduces the number of files with zero attributes by 73%. This increases the total number of classifiable files by over 25% in most cases as is shown in Figure 1. Also on average 71% of the content-analyzable files also gain additional valuable attributes.,10.1.1.1.2301,semantic filesystems context attributes classfication,?
Recognition of Whitehead-minimal Elements in Free Groups of Large Ranks,Alexei D. Miasnikov,2004,In this paper we introduce a pattern classification system to  recognize words of minimal length in their automorphic orbits in free  groups. This system is based on Support Vector Machines and does not  use any particular results from group theory. The main advantage of the  system is its stable performance in recognizing minimal elements in free  groups with large ranks.,10.1.1.1.2302,?,?
Difficulties in Simulationg Queues with Pareto Service,E. Yücesan C. H. Chen J. L. Snowdon J. M. Charnes Donald Gross John F. Shortle,2002,M/G/1 queues where G is a heavy-tailed distribution have applications in Internet modeling and modeling for insurance claim risk. The Pareto distribution is a special heavytailed distribution called a power-tailed distribution and has been found to serve as adequate models for many of these situations. However to get the waiting time distribution one must resort to numerical methods e.g. simulation. Many difficulties arise in simulating queues with Pareto service and we investigate why this may be so. Even if we are willing to consider truncated Pareto service there still can be problems in simulating if the truncation point (maximum service time possible) is too large.,10.1.1.1.2303,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Sameer T. Shikalgar David Fronckowiak,?,The importance of semiconductor wafer fabrication has been increasing steadily over the past decade. Wafer fabrication is the most technologically complex and capital intensive phase in semiconductor manufacturing. It involves the processing of wafers of silicon in order to build up layers and patterns of metal and wafer material. Many operations have to be performed in a clean room environment to prevent particulate contamination of wafers. Also since the machines on which the wafers are processed are expensive service contention is an important concern. All these factors underline the importance of seeking policies to design and operate them efficiently. We describe a simulation model of a planned 300mm wafer fabrication line that we are using to make strategic decisions related to the factory.,10.1.1.1.2304,?,?
Verifying Workflow Processes against Organization Security Policies,Carlos Ribeiro Carlos Paulo Guedes,1999,this paper is to show how a security specification written in a generic and flexible security language (SPL) can be checked for inconsistencies with a workflow specification written in an off-the-shelf workflow process definition language namely WPDL (Workflow Process Definition language) [8],10.1.1.1.2305,?,IEEE Computer Society
Optimal QoS Tradeoff and Power Control in CDMA Systems,Holger Boche  Slawomir Stanczak,2004,Dynamic power control and scheduling strategies provide efficient mechanisms for improving performance of wireless communications networks. A common objective is to maximize throughput performance of a network or to minimize the total transmission power while satisfying quality-of-service (QoS) requirements of the users. The achievement of these objectives requires the development of medium access control (MAC) strategies that optimally utilize scarce resources in wireless networks. When developing such strategies a good understanding of the structure of the feasibility region is essential. The feasibility region is defined as a set of all QoS requirements that can be supported by a network with all users active concurrently. Thus the structure of this set shows when (if at all) scheduling strategies can improve network performance. In particular if the feasibility region is a convex set then concurrent transmission strategies are optimal and the optimal power allocation can be obtained efficiently via a convex optimization. Other important problems are how the total transmission power depends on QoS requirements and what the optimal QoS tradeoff is. In this paper we address all these problems and solve them completely in some important cases. The purpose of this paper is to explore the interrelationship between QoS requirements and physical quantities such as transmission power. Although the results are obtained in the context of a power-controlled CDMA system they also apply to some other communications systems. A key assumption is that there is a monotonous relationship between a QoS parameter of interest (such as data rate) and the signal-to-interference ratio at the output of a linear receiver.,10.1.1.1.2306,?,?
Compiling and Optimizing Image Processing Algorithms for FPGAs,Bruce Draper Walid Walid Najjar Wim Böhm Jeff Hammes Bob Rinker Charlie Ross Monica Chawathe José Bins,2000,This paper presents a high-level language for expressing image processing algorithms and an optimizing compiler that targets FPGAs. The language is called SA-C and this paper focuses on the language features that 1) support image processing and 2) enable efficient compilation to FPGAs. It then describes the compilation process in which SA-C algorithms are translated into non-recursive data flow graphs which in turn are translated into VHDL. Finally it presents performance numbers for some wellknown image processing routines written in SAC and automatically compiled to an Annapolis Microsystems WildForce board with Xilinx 4036XL FPGAs.,10.1.1.1.2307,?,?
Non-convexity Issues for Internet Rate Control with Multi-class Services: Stability and Optimality,Jang-Won Lee   Ravi R. Mazumdar Ness B. Shroff ,2004,In this paper we investigate the problem of distributively allocating transmission rates to users on the Internet. We allow users to have concave as well as sigmoidal utility functions that are natural in the context of various applications. In the literature for simplicity most works have dealt only with the concave case. However we show that when applying rate control algorithms developed for concave utility functions in a more realistic setting (with both concave and sigmoidal types of utility functions) they could lead to instability and high network congestion. We show that a pricing based mechanism that solves the dual formulation can be developed based on the theory of subdifferentials with the property that the prices self-regulate the users to access the resource based on the net utility. We discuss convergence issues and show that an algorithm can be developed that is efficient in the sense of achieving the global optimum when there are many users.,10.1.1.1.2308,?,?
DCT-Domain Watermarking Techniques for Still Images: Detector Performance Analysis and a New Structure,Juan R. Hernández Fernando Pérez-González  Martin Amado,2000,In this paper a spread-spectrum-like discrete cosine transform domain (DCT domain) watermarking technique for copyright protection of still digital images is analyzed. The DCT is applied in blocks of 8 8 pixels as in the JPEG algorithm. The watermark can encode information to track illegal misuses. For flexibility purposes the original image is not necessary during the ownership verification process so it must be modeled by noise. Two tests are involved in the ownership verification stage: watermark decoding in which the message carried by the watermark is extracted and watermark detection which decides whether a given image contains a watermark generated with a certain key. We apply generalized Gaussian distributions to statistically model the DCT coefficients of the original image and show how the resulting detector structures lead to considerable improvements in performance with respect to the correlation receiver which has been widely considered in the literature and makes use of the Gaussian noise assumption. As a result of our work analytical expressions for performance measures such as the probability of error in watermark decoding and probabilities of false alarm and detection in watermark detection are derived and contrasted with experimental results.,10.1.1.1.2309,?,?
Relaying and Cooperation - A System Perspective,Patrick Herhold  Ernesto Zimmermann Gerhard Fettweis,2004,The paper considers various relaying strategies for wireless networks. We comparatively discuss and analyse direct transmission conventional multihop relaying and the novel concepts of cooperative relaying from the viewpoint of system level performance. While conventional relaying exploits pathloss savings cooperative relaying additionally takes two inherent advantages of relay-based systems into account: the ability to exploit the broadcast nature of the wireless medium and the diversity offered by the relay channel. Following a description of these concepts we analyse the performance of such systems in an exemplary manner for power-controlled cellular and ad hoc CDMA systems. The resulting power savings and capacity improvements suggest that cooperative relaying may constitute an interesting candidate for future cellular and ad hoc network architectures.,10.1.1.1.2310,?,?
A Novel Face-tracking Mouth Controller and its Application To Interacting with . . . ,Gamhewage C. De Silva et al.,2002,We describe a simple computationally light real-time system for tracking the lower face and extracting information about the shape of the open mouth from a video sequence. The system allows unencumbered control of audio synthesis modules by action of the mouth. We report work in progress to use the mouth controller to interact with a physical model of sound production by the avian syrinx.,10.1.1.1.2312,Face Tracking Bioacoustics,?
A Modular Approach to Optimizing Highly-Dynamic Distributed Systems (Extended Abstract),Benoît Garbinato  Fernando Pedone  Rodrigo Schmidt Benoît Garbinato Fern O Pedone Rodrigo Schmidt,?,Beno t Garbinato    Fernando Pedone + Rodrigo Schmidt +    Universit e de Lausanne CH-1015 Lausanne Switzerland  Phone: +41 21 692 3409 Fax: +41 21 692 3405  E-mail: benoit.garbinato@unil.ch  + Ecole Polytechnique F ed erale de Lausanne (EPFL) CH-1015 Lausanne Switzerland  Phone: +41 21 693 4797 Fax: +41 21 693 6600  E-mail:  {fernando.pedone  rodrigo.schmidt}@epfl.ch  1. Dynamic Distributed Systems  With the emergence of a mobile and large-scale Internet highly-dynamic distributed systems are becoming increasingly important. Examples of this growing importance can be found in recent researches in largescale peer-to-peer protocols [1 3] as well as in ad hoc network technologies [4].,10.1.1.1.2313,?,?
Query Languages and Data Models for Database,Sequences And Data Yan-nei Law Haixun Wang Carlo Zaniolo,2004,We study the fundamental limitations of relational  algebra (RA) and SQL in supporting  sequence and stream queries and present effective  query language and data model enrichments  to deal with them. We begin by observing  the well-known limitations of SQL in  application domains which are important for  data streams such as sequence queries and  data mining. Then we present a formal proof  that for continuous queries on data streams  SQL su#ers from additional expressive power  problems. We begin by focusing on the notion  of nonblocking (NB) queries that are the only  continuous queries that can be supported on  data streams. We characterize the notion of  nonblocking queries by showing that they are  equivalent to monotonic queries. Therefore  the notion of    for RA can be  formalized as its ability to express all monotonic  queries expressible in RA using only the  monotonic operators of RA. We show that RA  is not  NB-complete  and SQL is not more  powerful than RA for monotonic queries.,10.1.1.1.2314,?,?
Sensor Positioning in Wireless Ad-hoc Sensor Networks Using Multidimensional Scaling,Xiang Ji  Hongyuan Zha,2004,Sensor Positioning is a fundamental and crucial issue for sensor network operation and management. In the paper we first study some situations where most existing sensor positioning methods tend to fail to perform well an example being when the topology of a sensor network is anisotropic. Then we explore the idea of using dimensionality reduction techniques to estimate sensors coordinates in two (or three) dimensional space and we propose a distributed sensor positioning method based on multidimensional scaling technique to deal with these challenging conditions. Multidimensional scaling and coordinate alignment techniques are applied to recover positions of adjacent sensors. The estimated positions of the anchors are compared with their true physical positions and corrected The positions of other sensors are corrected accordingly. With iterative adjustment our method can overcome adverse network and terrain conditions and generate accurate sensor position. We also propose an on demand sensor positioning method based on the above method.,10.1.1.1.2315,?,?
Reliability Models and Evaluation of Internal BGP Networks,Li Xiao Klara Nahrstedt,2004,The performance of global Internet communication is significantly influenced by the reliability and the stability of Internet routing systems especially the Border Gateway Protocol (BGP) the de facto standard for inter-domain routing. In this paper we investigate the reliability of BGP sessions and the Internal BGP (IBGP) networks in the environment of unreliable physical and routing layers.,10.1.1.1.2316,?,?
Probabilistic Tracking With Exemplars in a Metric Space ,Kentaro Toyama Andrew Blake,2002,A new exemplar-based probabilistic paradigm for visual tracking is presented. Probabilistic mechanisms are attractive because they handle fusion of information especially temporal fusion in a principled manner. Exemplars are selected representatives of raw training data used here to represent probabilistic mixture distributions of object configurations. Their use avoids tedious hand-construction of object models and problems with changes of topology. Using exemplars,10.1.1.1.2317,probabilistic tracking exemplar-based tracking,?
Hands-Free Documentation,Karen Ward The Karen Ward,?,In this paper we introduce an analysis of the requirements and design choices for hands-free documentation. Hands-busy tasks such as cooking or car repair may require substantial interruption of the task: moving the pan off the burner and wiping hands or crawling out from underneath the car. We review the need for hands-free documentation and explore the role of task in the use of documentation. Our central analysis examines the roles and characteristics of input and output modalities of hands-free documentation. In particular we review the use of speech as an input modality and then visual means and speech as possible output modalities. Finally we discuss the implications of our analysis for the design of hands-free documentation and suggest future work. The design implications include issues of navigating through the documentation determining the users task and taskstep establishing mutual understanding of the state of the task and determining when to start conveying information to the user.,10.1.1.1.2318,methods General Terms Documentation Human Factors Keywords Hands-free,?
Energy-Efficient Hardware Architecture for Variable N-point 1D DCT,Andrew Kinane Valentin Muresan  Noel OConnor Noel Murphy  Sean Marlow,2004,This paper proposes an energy-efficient hardware acceleration architecture for the variable N-point 1D Discrete Cosine Transform (DCT) that can be leveraged if implementing MPEG-4s Shape Adaptive DCT (SA-DCT) tool. The SA-DCT algorithm was originally formulated in response to the MPEG-4 requirement for object based texture coding and is one of the most computationally demanding blocks in an MPEG-4 video codec. Therefore energy-efficient implementations are important - especially on battery powered wireless platforms. This N-point 1D DCT architecture employs a re-configurable distributed arithmetic data path and clock gating to reduce power consumption.,10.1.1.1.2319,?,?
Circular Shortest Path in Images,Changming Sun Stefano Pallottino,2003,Shortest path algorithms have been used in a number of applications such as crack detection road or linear feature extraction in images. There are applications where the starting and ending positions of the shortest path need to be constrained. In this paper we present several new algorithms for the extraction of a circular shortest path in an image such that the starting and ending positions coincide. The new algorithms we developed include multiple search algorithm image patching algorithm multiple backtracking algorithm the combination of image patching and multiple back-tracking algorithm and approximate algorithm. The typical running time of our circular shortest path extraction algorithm on a 256256 image is about 0.3 seconds on a rather slow 85MHz Sun SPARC computer. A variety of real images for crack detection in borehole data object boundary extraction and panoramic stereo matching have been tested and good results have been obtained.,10.1.1.1.2321,Circular shortest path Dynamic programming Multiple search algorithm Image patching algorithm Multiple backtracking algorithm Combination algorithm Approximate,?
Motion Segmentation with Missing Data using PowerFactorization and GPCA,Rene Vidal Richard Hartley,2004,We consider the problem of segmenting multiple rigid motions from point correspondences in multiple affine views. We cast this problem as a subspace clustering problem in which the motion of each object lives in a subspace of dimension two three or four. Unlike previous work we do not restrict the motion subspaces to be four-dimensional or linearly independent. Instead our approach deals gracefully with all the spectrum of possible affine motions: from twodimensional and partially dependent to four-dimensional and fully independent. In addition our method handles the case of missing data meaning that point tracks do not have to be visible in all images. Our approach involves projecting the point trajectories of all the points into a 5dimensional space using the PowerFactorization method to fill in missing data. Then multiple linear subspaces representing independent motions are fitted to the points in   using GPCA. We test our algorithm on various real sequences with degenerate and nondegenerate motions missing data perspective effects transparent motions etc. Our algorithm achieves a misclassification error of less than 5% for sequences with up to 30% of missing data points.,10.1.1.1.2322,?,?
Using Strict Implication in Background Theories for Abductive Tasks,M. G. Jansen A. Th. Schreiber  B.J. Wielinga,?,Abduction is usually defined in terms of classical  logical consequence. In this paper we substitute  this inferential parameter by the notion of strict  implication. By doing so we hope to put more of  the intended meaning of the abductive explanative  relation into the background theory.,10.1.1.1.2323,?,?
ATPG and DFT Algorithms for Delay Fault Testing,Xiao Liu,2004,With ever shrinking geometries growing metal density and increasing clock rate on chips delay testing is becoming a necessity in industry to maintain test quality for speed-related failures. The purpose of delay testing is to verify that the circuit operates correctly at the rated speed. However functional tests for delay defects are usually unacceptable for large scale designs due to the prohibitive cost of functional test patterns and the difficulty in achieving very high fault coverage. Scanbased delay testing which could ensure a high delay fault coverage at reasonable development cost provides a good alternative to the at-speed functional test.,10.1.1.1.2324,?,?
An Experience of Dependability Assessment of a Typical,Industrial Safety Critical Michele Minichino Ester Ciancamerla Silvano Chiaradonna Andrea Bondavalli,2000,In this paper we describe an experience of dependability assessment of a typical industrial Programmable Logic Controller (PLC). The PLC is based on a two out of three voting policy and it is intended to be used for safety functions. Safety assessment of computer based systems performing safety functions is regulated by standards and guidelines. In all of them there is a common agreement that no single method can be considered sufficient to achieve and assess safety. The paper addresses the PLC assessment by probabilistic methods to determine its dependability attributes related to Safety Integrity Levels as defined by IEC61508 standard. The assessment has been carried out by independent teams starting from the same basic assumptions and data. Diverse combinatorial and state space probabilistic modelling techniques implemented by public tools have been used. Even if the isolation of teams was not formally granted the experience has shown different topics worthwhile to be described. First of all the usage of different modelling techniques has led to diverse models. Moreover models focus on different system details also due the diverse teams skill. Also slight differences in understanding PLC assumptions have been occurred. In spite of all the numerical results of the diverse models are comparable. The experience has also allowed a comparison of the different modelling techniques as implemented by the considered public tools.,10.1.1.1.2325,?,?
Automated Analysis of Some Security Mechanisms of SCEP,Fabio Martinelli  Marinella Petrocchi  Anna Vaccarelli,?,The paper analyzes SCEP the Simple Certificate Enrollment Procedure  a two-way communication protocol to manage the secure emission of digital  certificates to network devices. The protocol provides a consistent method of  requesting and receiving certificates from different Certification Authorities by  offering an open and scalable solution for deploying certificates which can be  beneficial to all network devices and IPSEC software solutions. We formally analyze  SCEP through a software tool for the automatic analysis of cryptographic  protocols able to discover at a conceptual level attacks against security procedures.,10.1.1.1.2326,?,?
Scheduling Algorithms For Web Crawling,n.n.,2004,?,10.1.1.1.2327,?,?
FCND DP No. 136 FCND DISCUSSION PAPER NO. 136 DIETARY DIVERSITY AS A FOOD SECURITY INDICATOR,John Hoddinott Yisehac Yohannes,?,Household food security is an important measure of well-being. Although it may not encapsulate all dimensions of poverty the inability of households to obtain access to enough food for an active healthy life is surely an important component of their poverty. Accordingly devising an appropriate measure of food security outcomes is useful in order to identify the food insecure assess the severity of their food shortfall characterize the nature of their insecurity (for example seasonal versus chronic) predict who is most at risk of future hunger monitor changes in circumstances and assess the impact of interventions. However obtaining detailed data on food security status---such as 24-hour recall data on caloric intakes---can be time consuming and expensive and require a high level of technical skill both in data collection and analysis. This paper examines whether an alternative indicator dietary diversity defined as the number of unique foods consumed over a given period of time provides information on household food security. It draws on data from 10 countries (India the Philippines Mozambique Mexico Bangladesh Egypt Mali Malawi Ghana and Kenya) that encompass both poor and middle-income countries rural and urban sectors data collected in different seasons and data on calories acquisition obtained using two different methods. The paper uses linear regression techniques to investigate the magnitude of the association between dietary diversity and food security. An appendix compiles the results of using methods such as correlation coefficients contingency tables and receiver operator curves. iii We find that a 1 percent increase in dietary diversity is associated with a 1 percent increase in per capita consumption a 0.7 percent increase in tota...,10.1.1.1.2328,?,?
Hedged Responses and Expressions of Affect in Human/Human and Human/Computer Tutorial Interactions,Khelan Bhatt Martha Evens  Shlomo Argamon,2004,We study how students hedge and express affect when interacting with both humans and computer systems during keyboard-mediated natural language tutoring sessions in medicine. We found significant differences in such student behavior linked to whether the tutor was human or a computer. Students hedge and apologize often to human tutors but very rarely to computer tutors. The type of expressions also differed---overt hostility was not encountered in human tutoring sessions but was a major component in computer-tutored sessions. Little gender-linking of hedging behavior was found contrary to expectations based on prior studies. A weak gender-linked effect was found for affect in human tutored sessions.,10.1.1.1.2329,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson,?,Parallel discrete event simulation (PDES) decreases a simulations runtime by splitting the simulations work between multiple processors. Many users avoid PDES because it is difficult to specify a large and complicated model using existing PDES tools. In this paper we describe how the ParaSol PDES system uses migrating user level threads to support the process interaction world view. The process interaction world view is popular in sequential simulation languages and is a major departure form the logical process view supported by most PDES systems.,10.1.1.1.2330,?,?
High Order Finite Difference Methods in Space and Time,Wendy Kress,2003,Kress W. 2003. High Order Finite Difference Methods in Space and Time. Acta Universitatis Upsaliensis. Comprehensive Summaries of Uppsala Dissertations from the Faculty of Science and Technology 880. 28 pp. Uppsala. ISBN 91-554-5721-5 In this thesis high order accurate discretization schemes for partial differential equations are investigated.,10.1.1.1.2331,?,Springer
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,A critical issue in advanced technology product development is assessing economic feasibility based on the potential for commercial success. This is particularly difficult for an environmental product that has intangible benefits such as reduced air emissions. Corporate confidentiality compounds this problem since many of the target customers of the new product do not allow product developers to access important process cost and environmental operating information.,10.1.1.1.2332,?,?
Indexing the Past Present and Anticipated Future Positions of Moving Objects,Mindaugas Pelanis  Simonas Saltenis  Christian S. Jensen,2004,With the proliferation of wireless communications and geo-positioning e-services are envisioned  that exploit the positions of a set of continuously moving users to provide context-aware functionality  to each individual user. Because advances in disk capacities continue to outperform Moores Law it  becomes increasingly feasible to store on-line all the position information obtained from the moving  e-service users. With the much slower advances in I/O speeds and many concurrent users indexing  techniques are of essence in this scenario. Past,10.1.1.1.2333,?,?
Correct and Efficient Timestamping of Temporal Data,  Kristian Torp Richard Snodgrass Christian S. Jensen,1997,Previous approaches to timestamping temporal data have implicitly assumed that transactions have  no duration. In this paper we identify several situations where a sequence of operations over time within  a single transaction can violate ACID properties. It has been,10.1.1.1.2334,?,?
True Concurrency vs. Nondeterministic Sequential Interleavings in 1-D Cellular Automata,Predrag Tosic Gul Agha,?,Cellular automata (CA) are considered an abstract model of fine-grain parallelism in that the elementary operations executed at each node are rather simple and hence comparable to the most elementary operations in the computer hardware. In a classical cellular automaton all the nodes execute their operations in a truly concurrent manner: the state of node x i at time step t + 1 is some simple function of the states of node x i and a set of its pre-specified neighbors at time t. We consider herewith the sequential version of CA or SCA and compare it with the classical parallel (meaning  truly concurrent) CA. In particular we show that there are 1-D CA with very simple node state update rules that cannot be simulated by any comparable  SCA irrespective of the node update ordering. We argue that while the CA and SCA we consider are very simple the di#erence in dynamic behaviors (or equivalently the computation properties) are rather fundamental. Hence perhaps the granularity of basic CA operations insofar as the ability to interpret their concurrent computation via an appropriate nondeterministic sequential interleaving semantics is not fine enough - namely we prove that no such sequential interleaving semantics can capture even rather simplistic concurrent CA computations. We also share some thoughts on how to extend our early results and in particular motivate introduction and study of asynchronous cellular automata.,10.1.1.1.2335,formal methods for RTS,?
Algebraic Reasoning for Object-Oriented Programming,Paulo Borba  Augusto Sampaio  Ana Cavalcanti  Marcio Cornelio,2004,We present algebraic laws for a language similar to a subset of sequential Java that includes inheritance recursive classes dynamic binding access control type tests and casts assignment but no sharing. These laws are proved sound with respect to a weakest precondition semantics. We also show that they are complete in the sense that they are sufficient to reduce an arbitrary program to a normal form substantially close to an imperative program the remaining object-oriented constructs could be further eliminated if our language had recursive records. This suggests that our laws are expressive enough to formally derive behaviour preserving program transformations we illustrate that through the derivation of provably-correct refactorings.,10.1.1.1.2336,?,?
An Analysis of a Circadian Model Using The Small-Gain Approach to Monotone Systems,David Angeli  Eduardo D. Sontag,2003,In this note we show how certain properties of Goldbeters 1995 model for circadian oscillations can be proved mathematically using techniques from the recently developed theory of monotone systems with inputs and outputs. The theory establishes global asymptotic stability and in particular no oscillations if the rate of transcription is somewhat smaller than that assumed by Goldbeter. This stability persists even under arbitrary delays in the feedback loop.,10.1.1.1.2337,?,IEEE Publications
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Sean Connors Julie Gauldin,?,Assessing the life-cycle impacts of operations and maintenance decisions made for new or aging systems requires an accurate ability to measure and respond to uncertainty. Maintenance and parts requirements forecasts for fielded military systems are traditionally performed through historical repair and supply demand models. These models work well once several years of steady state weapon system operation has been accomplished but tend to depend on a stable and somewhat regular operations and support structure. Predictions based on data that capture the cyclic trends that tend to occur as the fleet endures standard operations scheduled maintenance and average component failure rates work best when components are relatively new. Aging systems comprised of component populations of varying ages can be adversely affected by change or the failure to change the traditional maintenance and support concepts. The right action for a new system may result in adverse impacts when considering older systems.,10.1.1.1.2338,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,A course titled Process Design and Improvement -- Computer Based Tools was developed and offered by the authors in Fall 2000 and 2001 for part-time graduate students in Manufacturing Systems Engineering and Technology Management programs at the University of St. Thomas Minnesota www.stthomas.edu/technology/2001Fall/MMSE 850-13-F01.htm. The objective of the course is to introduce students to the current software and methods used to organize data and model manufacturing and industrial systems through virtual representation of business operations choosing problems from their workplaces. The course was created to make the complex processes and tools of computer modeling more accessible to non-specialists for a better understanding of how their operations work. It is not unusual that people only know a small part of their overall system. This gives them a way to see the big picture. A case study illustrates the application of these tools.,10.1.1.1.2339,?,?
Telecommunication of Stabilizing Signals in Power Systems,Guillaume J. Raux  Ali Feliachi Matthew C. Valenti,2003,The dampening of low-frequency inter-area oscillations using Power System Stabilizers (PSS) may require remote stabilizing signals. In this case delays are associated with the signal transmission. In this paper several telecommunication schemes are investigated and critical communication delays are determined for a two-area four-generator (2A4G) power system widely used in the literature. OPNET Modeler a discrete event simulator is used to characterize those delays and also the number of packets dropped between each node. This information about the network delays is then used to study the performance of the 2A4G system in the presence of non-ideal communications. I. ,10.1.1.1.2340,?,?
A Note on Core Regions of Membership Functions,Jürgen Paetz,?,In neuro-fuzzy approaches different membership functions are used for modeling the systems rule set. Two wellknown membership function types are triangle functions and trapezoid functions. In our contribution we demonstrate that trapezoid functions with larger core regions are the more appropriate functions for calculating the membership degrees within neuro-fuzzy systems. If regions of the data of different classes are highly overlapping or if the data is noisy the values of the membership degrees could be misleading with respect to rule confidence if the core region is modeled too small. In fact we show that data regions with a high membership degree need not to be the regions with a high rule confidence. This effect that we call membership unrobustness is discussed. We give preliminary benchmark examples and show how this effect influenced our recent work of analysing septic shock patient data. KEYWORDS: neuro-fuzzy system membership function core region rule confidence robustness medical data ,10.1.1.1.2341,neuro-fuzzy system membership function core region rule confidence robustness medical data,?
per DoD Directive 5230.24,Distribution Authorized To Task Pa,1996,iv  CDRL: AC01 31 December 1996 Data Reference: STARS-PA29-AC01/001/01  Version 2.0  (Signatures on File)  Principal Author(s):  Approvals:  Mark Simos Organon Motives Inc.,10.1.1.1.2342,TASK PA29,?
1989,Of Food Policy,?,this paper. The list would start with my three predecessors as director general but then becomes too vast to include even a part of it here,10.1.1.1.2343,?,?
TLIB: a real-time computer vision library for HCI,Sbastien Grange Terrence Terrence Fong Charles Baur,2003,A computer vision software library is a key component of vision-based  applications. While there are several existing libraries most are large and comple or  limited to a particular hardware/platform combination. These factors tend to impede  the development of research applications especially for non-computer vision experts.,10.1.1.1.2346,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Thomas J. Schriber (moderator Jerry Banks Andrew F. Seila,?,In order to get more people to use simulation improved  teaching of simulation is important. In this context textbooks  and more generally teachware play a critical role.   The panel looks at some of the older and successful textbooks  as well as textbooks and teachware that are quite   new and in some cases are still under development.   1 ,10.1.1.1.2347,?,?
Proceedings of the International Workshop on Middleware Performance (MP 2004) part of the 23rd International Performance Computing and Communications Conference (IPCCC) April 2004,Performance Analysis Of Xuehai Zhang Jennifer M. Schopf,2004,Monitoring and information services form a key component of a distributed system or Grid. A quantitative study of such services can aid in understanding the performance limitations advise in the deployment of the monitoring system and help evaluate future development work. To this end we examined the performance of the Globus Toolkit Monitoring and Discovery Service (MDS2) by instrumenting its main services using NetLogger. Our study shows a strong advantage to caching or prefetching the data as well as the need to have primary components at well-connected sites.,10.1.1.1.2348,Grid Information Services Performance Analysis,?
Skew Detection for Complex Document Images Using Fuzzy Runlength,Zhixin Shi Venu Govindaraju,2003,A skew angle estimation approach based on the application of a fuzzy directional runlength is proposed for complex address images. The proposed technique was tested on a variety of USPS parcel images including both machine print and handwritten addresses. The testing results showed a successful rate more than 90% of the test set.,10.1.1.1.2349,?,?
Limiting Path Exploration in BGP,Jaideep Chandrashekar   Zhenhai Duan Zhi-Li Zhang Jeff Krasky,2005,Slow convergence in the Internet can be directly attributed to the path exploration phenomenon  inherent in all path vector protocols. The root cause for path exploration is the  dependency among paths propagated through the network. Addressing this problem in BGP is  particularly difficult as the AS paths exchanged between BGP routers are highly summarized. In  this paper we describe why path exploration cannot be countered effectively within the existing  BGP framework and propose a simple novel mechanism---forward edge sequence numbers---  to annotate the AS paths with additional path dependency information. Then we develop an  enhanced path vector algorithm EPIC which can be shown to limit path exploration and lead to  faster convergence. In contrast to other solutions ours is shown to be correct on a very general  model of Internet topology and BGP operation. Using theoretical analysis and simulations we  demonstrate that EPIC can achieve a dramatic improvement in routing convergence compared  to BGP and other existing solutions.,10.1.1.1.2350,?,?
Pollution in P2P File Sharing Systems,Jian Liang Rakesh Kumar et al.,2005,One way to combat P2P file sharing of copyrighted content is to deposit into the file sharing systems large volumes of polluted files. Without taking sides in the file sharing debate in this paper we undertake a measurement study of the nature and magnitude of pollution in KaZaA currently the most popular P2P file sharing system. We develop a crawling platform which crawls the majority of the KaZaA 20000+ supernodes in less than 60 minutes. From the raw data gathered by the crawler for popular audio content we obtain statistics on the number of unique versions and copies available in a 24-hour period. We develop an automated procedure to detect whether a given version is polluted or not and we show that the probabilities of false positives and negatives of the detection procedure are very small. We use the data from the crawler and our pollution detection algorithm to determine the fraction of versions and fraction of copies that are polluted for several recent and old songs. We observe that pollution is pervasive for recent popular songs. We also identify and describe a number of anti-pollution mechanisms.,10.1.1.1.2351,?,?
Eptd Discussion Paper No. 61,Environment And Production Ruth Meinzen-dick K. V. Raju Ashok Gulati,?,Policies of devolving management of resources from the state to user groups are premised upon the assumption that users will organize and take on the necessary  management tasks. While experience has shown that in many places users do so and are very capable expansion of co-management programs beyond initial pilot sites often  shows that this does not happen everywhere. Yet much is at stake in this with more  widespread adoption of irrigation management transfers and other forms of communitybased resource management. It is therefore important to move beyond isolated case  studies to comparative analysis of the conditions for collective action.,10.1.1.1.2352,?,?
Iterative K-Means Algorithm Based on Fisher Discriminant,Mantao Xu Box Mantao Xu,?,K-Means clustering is a well-known tool in unsupervised learning. The performance of K-Means clustering measured by the F-ratio validity index highly depends on selection of its initial partition. This problematic dependency always leads to a local optimal solution for k-center clustering. To overcome this difficulty we present an intuitive approach that iteratively incorporates Fisher discriminant analysis into the conventional K-Means clustering algorithm. In other words at each time a suboptimal initial partition for K-Means clustering is estimated by using dynamic programming in the discriminant subspace of input data. Experimental results show that the proposed algorithm outperforms the two comparative clustering algorithms the PCA-based suboptimal K-Means clustering algorithm and the kd-tree based K-Means clustering algorithm.,10.1.1.1.2353,?,?
Document Image Retrieval Based on 2D Density Distributions of Terms with Pseudo Relevance Feedback,Koichi Kise  Yin Wuotang  Keinosuke Matsumoto,?,Document image retrieval is a task to retrieve document images relevant to a users query. Most of existing methods based on word-level indexing rely on the representation called bag of words which originated in the field of information retrieval. This paper presents a new representation of documents that utilizes additional information about the location of words in pages so as to improve the retrieval performance. We consider that pages are relevant to a query if they contains its terms densely. This notion is embodied as density distributions of terms calculated in the proposed method. Its performance is improved with the help of pseudo relevance feedback i.e. a method of expanding a query by analyzing pages. Experimental results on English document images show that the proposed method is superior to conventional methods of electronic document retrieval at recall levels 0.0--0.6.,10.1.1.1.2354,?,?
Intl. Conf. RIVF04,February Hanoi Vietnam,2004,Quality of service (QoS) architectures have been required in recent years to support a wide range of distributed applications particularly in wide-area systems. In the context of QoS information management associated with QoS activities QoS information modeling and mapping enable QoS architectures to be developed independently of the underlying environment and/or application. This paper provides a review of existing QoS architectures on these aspects and presents our current framework.,10.1.1.1.2355,Mot clés – Qualité de Service (QdS modèle d’informations,?
Stability of Data Networks: Stationary and Bursty Models,Heng-Qing Ye Jihong Ou Xue-Ming Yuan,2005,This paper studies stability of network models that capture macroscopic features of data  communication networks including the Internet. The network model consists of a set of links  and a set of possible routes which are fixed subsets of links. A connection is dynamically  established along one of the routes to transmit data as requested and terminated after  the transmission is over. The transmission bandwidth of a link is dynamically allocated  according to specific bandwidth allocation policy to ongoing connections that traverse the  link. A network model is said to be stable under a given bandwidth allocation policy if  roughly the number of ongoing connections in the network will not blow up over time.,10.1.1.1.2356,data network Internet rate control bandwidth allocation burstiness stability fluid network model,?
PLX FP: An Efficient Floating-Point Instruction Set for 3D Graphics,Xiao Yang And Xiao Yang Ruby B. Lee,2004,Introduction   The importance of multimedia processing on generalpurpose computing platforms has prompted processor  designers to add multimedia instructions to  microprocessor instruction set architectures (ISAs). These  include MAX-2 for the PA-RISC architecture [1] MMX  SSE and SSE-2 for the Intel IA-32 architecture [2] and a  superset of these to the Itanium IA-64 architecture [3].  Although these multimedia instructions may be very  effective they still incur the overhead of their base  microprocessor ISA. PLX [4] is a new ISA designed from  scratch for fast and efficient multimedia processing. Prior  work has demonstrated its effectiveness for integer media  applications [4].  This paper describes the new floating-point ISA for  PLX version 1.3 designed to enable support for very fast  3D graphics. With the proliferation of 3D games it is  highly desirable to support fast 3D graphics with the same  media processor used for integer media types like images  video and audio. ,10.1.1.1.2357,?,?
Iterative Detection of Differentially Modulated APSK Signals in an OFDM Transmission System,Peter Haase  Hermann Rohling,?,In this paper an iterative detection technique for DPSK and its extension to higher level DAPSK modulation schemes is presented. We consider the well-known OFDM transmission technique that requires in combination with noncoherent detection no channel state information. By simulation it is shown that the proposed algorithm leads to a significant performance gain in terms of bit error rate.,10.1.1.1.2359,?,?
Towards Design And Validation Of Mixed-Technology SOCs,Mir Charlot Nicolescu S. Mir B. Charlot G. Nicolescu P. Coste F. Parrain N. Zergainoh B. Courtois A. Jerraya M. Rencz,2000,This paper illustrates an approach to design and validation of heterogeneous systems. The emphasis is placed on devices which incorporate MEMS parts in either a single mixed-technology (CMOS + micromachining) SOC device or alternatively as a hybrid system with the MEMS part in a separate chip. The design flow is general and it is illustrated for the case of applications embedding CMOS sensors. In particular applications based on fingerprint recognition are considered since a rich variety of sensors and data processing algorithms can be considered. A high level multilanguage /multi-engine approach is used for system specification and co-simulation. This also allows for an initial high-level architecture exploration according to performance and cost requirements imposed by the target application. Thermal simulation of the overall device including packaging is also considered since this can have a significant impact in sensor performance. From the selected system specification the actual architecture is finally generated via a multi-language co-design approach which can result in both hardware and software parts. The hardware parts are composed of available IP cores. For the case of a single chip implementation the most important issue of embedded-core-based testing is briefly considered and current techniques are adapted for testing the embedded cores in the SOC devices discussed.,10.1.1.1.2360,Index terms Design Verification SOCs MEMS HDLs Cosimulation Architecture exploration,?
Towards a Common API for Structured Peer-to-Peer Overlays,Frank Dabek Ben Zhao Peter Druschel John Kubiatowicz Ion Stoica,2003,In this paper we describe an ongoing effort to define common APIs  for structured peer-to-peer overlays and the key abstractions that can be built  on them. In doing so we hope to facilitate independent innovation in overlay  protocols services and applications to allow direct experimental comparisons  and to encourage application development by third parties. We provide a snapshot  of our efforts and discuss open problems in an effort to solicit feedback from the  research community.,10.1.1.1.2361,?,?
Dual-transponder Precision Navigation System for Synthetic Aperture Sonar,E N Pilbrow  M P Hayes P T Gough,2002,The technical details of a dual-transponder long-baseline positioning system to measure  the sway of a free towed Synthetic Aperture Sonar (SAS) are presented. The sway  is measured with respect to freely deployed battery powered transponders which sit  stationary on the seabed connected via cables to floating buoys housing high-accuracy  GPS timing receivers. A T/R switch allows a single hydrophone on each transponder  to alternately receive and transmit linear FM chirp signals. The time of flight of the  signals is determined by matched-filtering using a DSP and transmitted to the towboat  for storage in real time using RF modems. The sway information is completely independent  for each sonar ping and allows the deblurring of the SAS images by post  processing. A Matlab simulation predicts a worst case sway accuracy of    cm.,10.1.1.1.2362,Baseline Positioning Synthetic Transponder Navigation,?
Investigating The Utility of MMX/SSE Instruction Sets Now And In The Future,Jernej Barbic Brian Potetz Matt Rosencrantz,?,In this report we examine several multimedia applications with and without MMX/SSE enhancements and examine the impact on execution time and cache performance of these enhancements. We implement several versions of the programs to isolate their memory and processing requirements.One criticism of SIMD technology is that it may be doomed to obsolesence as processors gain speed with respect to memory. We discover that the multimedia applications we looked at are not memory bound. Enhancing applications with MMX does make them more memory bound but not so much as to nullify the gain given by the enhancement. We show that prefetching instructions can be used to hide memory latency and that MMX style enhancement will still be useful as long as the latency is predictable the memory bandwidth scales sufficiently and the total runtime of the program is large compared to the latency of memory.,10.1.1.1.2363,?,?
Data integration under the schema tuple query assumption,Michael J. Minock,2003,Typically data integration systems have significant gaps of coverage over the global (or mediated) schema they purport to cover. Given this reality users are interested in knowing exactly which part of their query is supported by the available data sources. This report introduces a set of assumptions which enable users to obtain intensional descriptions of the certain uncertain and missing answers to their queries given the available data sources. The general assumption is that query and source descriptions are written as tuple relational queries which return only whole schema tuples as answers. More specifically queries and source descriptions must be within an identified sub-class of these `schema tuple queries which is closed over syntactic query difference. Because this identified query class is decidable for satisfiability query containment and equivalence are also decidable. Sidestepping the schema tuple query assumption the identified query class is more expressive than conjunctive queries with negated subgoals. The ability to directly express members of the query class in standard SQL makes this work immediately applicable in a wide variety of contexts.,10.1.1.1.2364,?,?
Mssd Discussion Paper No. 34,Market And Structural Eleni Z. Gabre-madhin Bruce F. Johnson Contact Diana Flores,?,iv 1. ,10.1.1.1.2365,The authors are respectively Postdoctoral Fellow Markets and Structural Studies Division of IFPRI and Professor Emeritus Food Research Institute,?
Rhetoric and Teacher Education,Rafael Heller,1999,Recent scholarship on teacher education has drawn a sharp contrast between top}downa and teacher-directeda approaches to instructional reform. However this article suggests that all forms of teacher education share a common ground: they are all inescapably rhetorical in nature aimed at the persuasion of teachers. While reformers may attempt to deny such intentions they cannot help but employ rhetoric in practice. By way of illustration the author provides a case study of a reform project that seeks to supporta teachers rather than trying to exert power over them. Analysis reveals this to be an impossible ideal one whose appearance can be maintained only by refusing to admit to contradictory motives. # 1999 Elsevier Science Ltd. All rights reserved.,10.1.1.1.2366,of this journal Robert Floden (1985) challenged his,?
PeerPressure for Automatic Troubleshooting,Helen Wang John Platt Yu Chen Ruyun Zhang  Yu-Min Wang Yi-min Wang,2004,this paper we address the problem of misconfiguration troubleshooting. There are two essential goals in designing such a troubleshooting system:  1. Troubleshooting effectiveness: the system should effectively identify a small set of sick configuration candidates with a short response time  2. Automation: the system should minimize the number of manual steps and the number of users involved,10.1.1.1.2367,Statistics Bayesian Estimates PeerPressure,?
 A Critical Test of the Failure-to-Engage Theory of Task-Switching ,Scott Brown Curtis Lehmann,?,When people switch between two tasks their performance on each is worse than when they perform that task in isolation. This switch cost has been extensively studied and many theories have been proposed to explain it. One influential theory is the failure to engage (FTE) theory which posits that observed responses are a mixture of prepared and unprepared response strategies. The probability that participants use prepared processes can be manipulated experimentally by changing preparation time for example. The FTE theory is a binary mixture model and therefore makes a strong prediction about the existence of fixed points in response time distributions. We found evidence contradicting this prediction using data from 54 participants in a standard task-switching paradigm. ,10.1.1.1.2368,?,?
Perfect Recovery and Sensitivity Analysis of Time Encoded Bandlimited Signals,Aurel A. Lazar László T. Tóth,2004,A time encoding machine is a real-time asynchronous mechanism for encoding amplitude information into a time sequence. We investigate the operating characteristics of a machine consisting of a feedback loop containing an adder a linear filter and a noninverting Schmitt trigger. We show that the amplitude information of a bandlimited signal can be perfectly recovered if the difference between any two consecutive values of the time sequence is bounded by the inverse of the Nyquist rate. We also show how to build a nonlinear inverse time decoding machine (TDM) that perfectly recovers the amplitude information from the time sequence. We demonstrate the close relationship between the recovery algorithms for time encoding and irregular sampling. We also show the close relationship between time encoding and a number of nonlinear modulation schemes including FM and asynchronous sigma–delta modulation. We analyze the sensitivity of the time encoding recovery algorithm and demonstrate how to construct a TDM that perfectly recovers the amplitude information from the time sequence and is trigger parameter insensitive. We derive bounds on the error in signal recovery introduced by the quantization of the time sequence. We compare these with the recovery error introduced by the quantization of the amplitude of the bandlimited signal when irregular sampling is employed. Under Nyquist-type rate conditions quantization of a bandlimited signal in the time and amplitude domains are shown to be largely equivalent methods of information representation.,10.1.1.1.2369,?,?
The Neutrino: What is it?,Yu. A. Baurov,2002,this article has arisen: The Neutrino what is it?  It should be noted that the predictions of the theory of Refs. [1314] associated with the notion of neutrino differ markedly from 2002 C. Roy Keys Inc,10.1.1.1.2370,neutrino byuons ß-decay and cosmology) © 2002 C. Roy Keys Inc,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson Michael Andersson,1998,This paper reports on a project in the area of simulation based decision support (SBDS) at the operational level of the manufacturing system. The purpose of the project was to explore and describe the possibilities to use a standard discrete event simulation package for capacity planning purpose in a situation where labor was a primary and scarce production resource. This has been done through a case study at a Radio Base Station (RBS) assembly line at Ericsson Radio System Gvle. Results from the study are a conceptual structure for a SBDS system and a prototype simulation system tailored for the RBS-2000 assembly line. The system has been tested in a simulated environment and results indicate a delivery precision improvement of eleven percent. Conclusions from the study are that this kind of tool for operational decision support offers a flexible decision support environment and that the need for high quality information and information collecting systems are crucial for the success of such tools.,10.1.1.1.2371,?,?
Authentication and Integrity in Outsourced Databases,Einar Mykletun  Maithili Narasimha  Gene Tsudik,2004,In the Outsourced Database (ODB) model organizations outsource their data management needs to an external service provider. The service provider hosts clients databases and offers seamless mechanisms to create store update and access (query) their databases. This model introduces several research issues related to data security. One of the core security requirements is providing efficient mechanisms to ensure data integrity and authenticity while incurring minimal computation and bandwidth overhead. In this work we investigate the problem of ensuring data integrity and suggest secure and practical schemes that help facilitate authentication of query replies. We explore the applicability of popular digital signature schemes (RSA and DSA) as well as a recently proposed scheme due to Boneh et al. [1] and present their performance measurements.,10.1.1.1.2372,Application Service Providers. By outsourcing organizations,?
Quality of Service (QoS) Policy Framework,Kaustubh Phanse Bradley,?,For successful deployment of robust quality of service (QoS) framework the need for a QoS policy system looks inevitable. In this report we explore the various elements which together form a QoS policy framework and also try to gain insight into the implementation issues of such a framework and provide directives for future research.,10.1.1.1.2374,?,?
Chapter VIII,The Role Of Wilhelm Hasselbring,2001,This paper discusses the role of domain-specific standards for managing semantic heterogeneity among dissimilar information sources. The process of integrating such heterogeneous information systems is also discussed in this context whereby standards play a central role for `initiating top-down processes by means of defining common data models for the involved information sources,10.1.1.1.2375,?,?
Error Detection and Recovery in Spoken Dialogue Systems,Edward Filisko Stephanie Seneff,2004,This paper describes our research on both the  detection and subsequent resolution of recognition  errors in spoken dialogue systems. The  paper consists of two major components. The  first half concerns the design of the error detection  mechanism for resolving city names in our  MERCURY flight reservation system and an investigation  of the behavioral patterns of users  in subsequent subdialogues involving keypad  entry for disambiguation. An important observation  is that upon a request for keypad entry  users are frequently unresponsive to the extent  of waiting for a time-out or hanging up the  phone. The second half concerns a pilot experiment  investigating the feasibility of replacing  the solicitation of a keypad entry with that  of a speak-and-spell entry. A novelty of our  work is the introduction of a speech synthesizer  to simulate the user which facilitates development  and evaluation of our proposed strategy. We have,10.1.1.1.2376,?,?
Voluntary and involuntary speech variations- a few examples from the VeriVox database,Inger Karlsson,2001,Some speech variations due to involuntary and voluntary speech productions have been investigated. In this very preliminary report duration variations for two speakers are discussed.,10.1.1.1.2377,?,?
A New SVM Approach to Speaker Identification and Verification Using Probabilistic Distance Kernels,Pedro J. Moreno Purdy P. Ho,2004,?,10.1.1.1.2378,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Jumi Kim Sigurdur Ólafsson,?,The nested partitions method is a flexible and effective framework of optimizing large-scale problems with combinatorial structure. In this paper we consider the nested partitions method for simulation optimization and propose a new variant that uses inheritance to speed convergence. The new nested partitions method with inheritance algorithm performs well for when applied to test problems but it also calls for new analysis of convergence.,10.1.1.1.2379,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Via Supply Chain Simulation Under Order-to-delivery Environment,?,In support of the order-to-delivery (OTD) business initiative a simulation framework has been developed at GM RD. The OTD simulation program is aimed at simulating the behavior of the OTD supply chain using detailed inputs associated with demand supply and production processes. Customer demand variation is a key source of uncertainty in GMs supply chain. Early capture of customer demand fluctuation enables GM to effectively reduce aggregate mismatch between production and sales and appropriate time series models have been suggested to capture demand patterns based on actual data. The vehicle model and option mix with a given demand variation influences the performance of the OTD supply chain and provides a means to establish certain principles determining the extent of product offering and the scope of production leveling. Analyzing the impact of the model and option mix on primary supply chain performance measures such as customer wait time condition mismatch and parts usage capacitates reduction of the mismatch between demand and production and stabilizes supply chain operations.,10.1.1.1.2380,?,?
Safe Kernel Programming in the OKE,Herbert Bos Bart Samwel,2002,This paper describes the implementation of the OKE which allows users other than root to load native and fully optimised code in the Linux kernel. Safety is guaranteed by trust management language customisation and a trusted compiler. By coupling trust management with the compiler the OKE is able to vary the level of restrictions on the code running in the kernel depending on the programmers privileges. Static sandboxing is used as much as possible to check adherence to the security policies at compile time.,10.1.1.1.2381,?,?
Handling IP Traffic Surges via Optical Layer,Reconfiguration Panita Pongpaibool Robert Doverspike Matthew Roughan Joel Gottlieb,2002,Through a dynamically reconfigurable optical layer we propose a simple approach to  handle traffic surges in IP networks. Its effectiveness is established by analysis of data traffic in a  large ISP.,10.1.1.1.2382,?,?
LMPS: Localized Multi-Path Selection for QoS Routing in VoIP Networks,Khaled M. F. Elsayed Hassan Fadel Amin M. Nassar,?,Localized QoS routing techniques were proposed to achieve acceptable  performance without exchanging global state information over the network.,10.1.1.1.2384,?,?
Physiological Data Modeling Contest,Joao Gama  Pedro Rodrigues,2004,Introduction The physiological data is characterized by large amounts of data sequential data issues of sensor fusion and a rich domain complete with noise hidden variables and significant e#ects of context. There is a continuous flow of data and the problem is to built a predictive model from the data stream. Several authors refer desirable properties for mining data streams: incremental algorithms able to process examples in constant time and memory performing a single scan over the training data maintaining classifiers at any time and dealing with concept drift. Our recent work focus on induction of decision trees from data streams. The possibility to evaluate the system in a real problem is the main motivation to participate in the Workshop.,10.1.1.1.2385,?,?
The Term Structure of Defaultable Bond Prices,Philipp J. Schönbucher,1996,In this paper we present a new methodology for modelling the  development of the prices of defaultable zero coupon bonds that is  inspired by the Heath-Jarrow-Morton (HJM) [19] approach to risk-free  interest rate modelling. Instead of precisely specifying the mechanism  that triggers the default we concentrate on modelling the development  of the term structure of the defaultable bonds and give conditions  under which these dynamics are arbitrage-free. These conditions are  a drift restriction that is closely related to the HJM drift restriction  for risk-free bonds and the restriction that the defaultable short rate  must always be not below the risk-free short rate.,10.1.1.1.2386,arbitrage term structure of interest rates default risk Contents,?
Solving Generalized Semi-Markov Decision Processes,Using Continuous Phase-Type,2004,We introduce the generalized semi-Markov decision process  (GSMDP) as an extension of continuous-time MDPs  and semi-Markov decision processes (SMDPs) for modeling  stochastic decision processes with asynchronous events and  actions. Using phase-type distributions and uniformization  we show how an arbitrary GSMDP can be approximated by  a discrete-time MDP which can then be solved using existing  MDP techniques. The techniques we present can also be  seen as an alternative approach for solving SMDPs and we  demonstrate that the introduction of phases allows us to generate  higher quality policies than those obtained by standard  SMDP solution techniques.,10.1.1.1.2387,?,?
Coupling MDA and Parlay to Increase Reuse in Telecommunication Application Development,Babak A. Farshchian  Sune Jakobsson Erik Berg,2002,MDA (Model-Driven Architecture) has been coined by OMG (Object Management Group) as the next step in application integration. Being based on standards already embraced by a large segment of the software engineering industry MDA promises fully automatic model transformation. MDA enables application developers to use formalisms such as UML to specify their applications in a totally platform-independent way. Later transformations to platform-dependent software are automated. Parlay a middleware specification developed for the telecommunication domain is on the other hand promising network independent development and deployment of telecommunication services and applications. In this position paper we report on our experience from a Eurescom project where we try to couple MDA and Parlay in order to increase reuse in the telecommunication domain. Telecommunication service development is hampered by long development cycles and low level of reuse. We describe how MDA approach can be applied to telecommunication domain through the use of Parlay. We believe this approach has substantial potential for reducing development costs for many telecommunication operators. In addition developed models and applications can be deployed on a wide variety of platforms without much change.,10.1.1.1.2388,?,?
Parametric Freehand Sketches,Ferran Naya   Manuel Contero Nuria Aleixos Joaquim Jorge,2004,In this paper we present the 2D parametric freehand sketch component  of an experimental prototype called GEGROSS (GEsture  Geometric  ReconstructiOn based Sketch System). The module implements a gesture alphabet  and a calligraphic interface to manage geometric constraints found in  2D sections that are later used to perform modeling operations. We use different  elements to implement this module. The geometric kernel stores model  data. The constraint manager 2D DCM handles restrictions. Finally we use the  CALI library to define gestural interfaces. In this paper we present a strategy  for integrating these tools and a calligraphic interface we developed to provide  dimensional controls over freehand sketches. Our system allows users to build  simple sketches composed by line segments and arcs which are automatically  tidied and beautified. Proportional and dimensional information over sketched  parts is provided by handwriting their corresponding sizes.,10.1.1.1.2389,?,?
Language Corpora: Present Indian Need,Niladri Sekhar Dash,2004,Corpora have proved their value both in linguistics and language technology. Information obtained from corpora has challenged the intuitive language study since intuitive observations are found inadequate while compared with findings from corpora. However the value of corpora is not yet acknowledged in India although in recent times some sporadic attempts are made for designing corpora in Indian languages. We argue here for initiating large-scale projects to develop corpora of various types in Indian languages not only to contribute in research of language technology but also to provide reliable language resources for the benefit of people of the country. We plea for the generation of specific types of corpus required for designing tools and systems for language technology linguistics research and education.,10.1.1.1.2390,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,This paper presents a brief introduction to the use of duality theory and simulation in financial engineering. It focuses on American option pricing and portfolio optimization problems when the underlying state space is high-dimensional. In general it is not possible to solve these problems exactly due to the so-called curse of dimensionality and as a result approximate solution techniques are required. Approximate dynamic programming (ADP) and dual based methods have recently been proposed for constructing and evaluating good approximate solutions to these problems. In this paper we describe these ADP and dual-based methods and the role simulation plays in each of them. Some directions for future research are also outlined.,10.1.1.1.2391,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,This paper introduces a new technique for estimating cycle time quantiles from discrete event simulation models run at a single traffic intensity. The Cornish-Fisher expansion is used as a vehicle for this approximation and it is shown that for an M/M/1 system and a full factory simulation model the technique provides accurate results with low variability for the most commonly estimated quantiles without requiring unreasonable sample sizes. Additionally the technique provides the advantages of being easy to implement and providing multiple cycle time quantiles from a single set of simulation runs.,10.1.1.1.2392,?,?
PatternHunter II: Highly Sensitive and Fast Homology Search,Ming Li Bin Ma Derek Kisman  John Tromp,2003,Extending the single optimized spaced seed of PatternHunter [20] to multiple ones PatternHunter  II simultaneously remedies the lack of sensitivity of Blastn and the lack of speed of SmithWaterman  for homology search. At Blastn speed PatternHunter II approaches Smith-Waterman  sensitivity bringing homology search technology back to a full circle.,10.1.1.1.2393,homology search sensitivity speed,?
Information Extraction for Semi-Structured Documents,Dan Smith And Dan Smith Mauricio Lopez,1997,this paper constitutes a suitable basis for building an effective solution to extracting information from semi-structured documents for two principal reasons. First it provides an extensible architecture basis for: extracting structured information from semistructured documents providing fast and accurate selective access to this information performing selective dissemination of relevant documents depending on filtering criteria. Second it is simple in terms of: the complexity of the algorithms used for structure recognition and document filtering the number and size of data structures required to perform the three functions mentioned above the amount and complexity of the metadata required to handle a given collection of documents. The work described here is part of the Dyade    Mdiation project which aims to provide integrated software components for accessing heterogeneous data sources in Internet/Intranet environments,10.1.1.1.2394,?,?
Articles Students Attitudes Toward Technology in Selected Technology Education Programs,Richard A. Boser James D. Palmer  Michael K. Daugherty,1998,this paper. The results of the PATT-USA study indicated that: (a) students are interested in technology (b) boys are more interested in technology than girls (c) students in the U. S. think that technology is a field for both girls and boys (d) girls are more convinced that technology is a field for both genders (e) there is a positive influence of a parents technological profession on the students attitude (f) U. S. students concept of technology became more accurate with increasing age (g) U. S. students are strongly aware of the importance of technology (h) the U. S. has a rather low score on items measuring the concepts of technology compared to other industrialized countries (i) students who had taken industrial arts/technology education classes had more positive attitudes on all sub-scales and (j) the existence of technical toys in the home had a significantly positive impact on all attitude scales. Although research on student attitudes in technology education has been used to assess student attitudes prior to curriculum development a standardized attitude measure such as the PATT-USA has not been used to assess changes in attitude as the result of a treatment such as participation in a technology education program. It is logical that students who have a positive experience in a technology education program will develop a positive attitude toward technology and the pursuit of technological careers and would therefore be more interested in studying about technology. As a result students should become more technologically literate. This premise is grounded in research from the affective domain that indicates that students who exhibit a positive attitude -7toward a subject are more likely to actively engage in learning during and after instruction (Po...,10.1.1.1.2395,?,?
Transient Fault Detection via Simultaneous Multithreading,Steven K. Reinhardt Shubhendu S. Mukherjee,2000,Smaller feature sizes reduced voltage levels higher transistor counts and reduced noise margins make future generations of microprocessors increasingly prone to transient hardware faults. Most commercial fault-tolerant computers use fully replicated hardware components to detect microprocessor faults. The components are lockstepped (cycle-by-cycle synchronized) to ensure that in each cycle they perform the same operation on the same inputs producing the same outputs in the absence of faults. Unfortunately for a given hardware budget full replication reduces performance by statically partitioning resources among redundant operations. We demonstrate,10.1.1.1.2396,?,ACM Press
Tailoring Evaluative Arguments to Users Preferences,Giuseppe Carenini And Johanna Moore,1999,Computer systems that serve as personal assistants advisors or sales assistants  frequently need to argue evaluations of domain entities. Argumentation theory shows that  to argue an evaluation convincingly requires to base the evaluation on the hearers values  and preferences. In this paper we propose a framework for tailoring an evaluative argument  about an entity when users preferences are modeled by an additive multiattribute value  function. Since we adopt and extend previous work on explaining decision-theoretic advice  as well as previous work in computational linguistics on generating natural language  arguments our framework is both formally and linguistically sound.,10.1.1.1.2397,?,?
Implementing A Scalable XML Publish/Subscribe System Using Relational Database Systems,Feng Tian et al.,2004,An XML publish/subscribe system needs to match many XPath queries (subscriptions) over published XML documents. The performance and scalability of the matching algorithm is essential for the system when the number of XPath subscriptions is large. Earlier solutions to this problem usually built large finite state automata for all the XPath subscriptions in memory. The scalability of this approach is limited by the amount of available physical memory. In this paper we propose an implementation that uses a relational database as the matching engine. The heavy lifting part of evaluating a large number of subscriptions is done inside a relational database using indices and joins. We described several different implementation strategies and presented a performance evaluation. The system shows very good performance and scalability in our experiments handling millions of subscriptions with moderate amount of physical memory.,10.1.1.1.2398,?,?
PlaNet -- A Software Package for Algorithms and   Heuristics for Disjoint Paths in Planar Networks,Ulrik Brandes Wolfram Schlickenrieder  Gabriele Neyer  Dorothea Wagner  Karsten Weihe ,1999,We present a package for algorithms on planar networks. This package comes with a graphical user interface which may be used for demonstrating and animating algorithms. Our focus so far has been on disjoint path problems. However the package is intended to serve as a general framework wherein algorithms for various problems on planar networks may be integrated and visualized. For this aim the structure of the package is designed so that integration of new algorithms and even new algorithmic problems amounts to applying a short recipe. The package has been used to develop new variations of well-known disjoint path algorithms which heuristically optimize additional NP-hard objectives such as the total length of all paths. We will prove that the problem of finding edge-disjoint paths of minimum total length in a planar graph is NP -hard even if all terminals lie on the outer face the Eulerian condition is fulfilled and the maximum degree is four. Finally as a demonstration how PlaNet can be used as a tool for developing new heuristics for NP-hard problems we will report on results of experimental studies on e#cient heuristics for this problem. ,10.1.1.1.2400,Algorithms engineering Planar graphs Disjoint paths Length minimization,?
Automatic Application-Specific Instruction-Set Extensions Under Microarchitectural Constraints,Kubilay Atasu et al.,2003,Many commercial processors now offer the possibility of extending their instruction set for a specific application---that is to introduce customised functional units. There is a need to develop algorithms that decide automatically from highlevel application code which operations are to be carried out in the customised extensions. A few algorithms exist but are severely limited in the type of operation clusters they can choose and hence reduce significantly the effectiveness of specialisation. In this paper we introduce a more general algorithm which selects maximal-speedup convex subgraphs of the application dataflow graph under fundamental microarchitectural constraints and which improves significantly on the state of the art.,10.1.1.1.2401,ASIPs Instruction-set extensions,?
Middleware to support sensor network applications,Wendi B. Heinzelman Amy L. Murphy Hervaldo S. Carvalho Mark A. Perillo,2004,Current trends in computing include increases in both distribution and wireless connectivity leading to highly dynamic complex environments on top of which applications must be built. The task of designing and ensuring the correctness of applications in these environments is similarly becoming more complex. The unified goal of much of the research in distributed wireless systems is to provide higher-level abstractions of complex low-level concepts to application programmers easing the design and implementation of applications. A new and growing class of applications for wireless sensor networks require similar complexity encapsulation. However sensor networks have some unique characteristics including dynamic availability of data sources and application quality of service requirements that are not common to other types of applications. These unique features combined with the inherent distribution of sensors and limited energy and bandwidth resources dictate the need for network functionality and the individual sensors to be controlled to best serve the application requirements. In this article we describe different types of sensor network applications and discuss existing techniques for managing these types of networks. We also overview a variety of related middleware and argue that no existing approach provides all the management tools required by sensor network applications. To meet this need we have developed a new middleware called MiLAN. MiLAN allows applications to specify a policy for managing the network and sensors but the actual implementation of this policy is effected within MiLAN. We describe MiLAN and show its effectiveness through the design of a sensor-based personal health monitor.,10.1.1.1.2402,?,?
Colored Prufer codes for k-edge colored trees,Manwon Cho Dongsu Dongsu Kim Seunghyun Seo Heesung Shin,2004,A combinatorial bijection between k-edge colored trees and colored Prufer codes for labelled trees is established. This bijection gives a simple combinatorial proof for the number k(n     nk-n   of k-edge colored trees with n vertices. 1 ,10.1.1.1.2403,?,?
Mechanical Analogy for the Wave-Particle: Helix on a Vortex Filament,Valery P. Dmitriyev,2001,tes into  the collection of the elementary asymptotic helices. An  asymptotic helix obeys the linear Schroedinger equation with  no dependence on mass. The mass of the particle appears  explicitly when we describe the motion of the whole ensemble  of the elementary splinters.  Keywords: quantum physics ideal fluid line vortex soliton.  1. Introduction  elow the earlier suggested [1] mechanical analogy for quantum particle is further deve loped. A helical wave on a vortex filament in the ideal fluid is considered. It is shown to obey the linear Schroedinger equation. Other properties of a vortex filament also reproduce the specific features of a quantum object.  This work is a constituent of the whole project aimed at  constructing a regular mechanical analogy of physical fields and particles. The approach is based on the concept of a substratum for physics. The substratum is a universal medium serving to model the waves and action-at-a-distance in vacuum. This medium is viewed meso,10.1.1.1.2404,quantum physics ideal fluid line vortex soliton,?
SSCH: Slotted Seeded Channel Hopping for Capacity Improvement in IEEE 802.11 Ad-Hoc Wireless Networks,Paramvir Bahl  Ranveer Chandra,2004,Capacity improvement is one of the principal challenges in wireless networking. We present a link-layer protocol called Slotted Seeded Channel Hopping or SSCH that increases the capacity of an IEEE 802.11 network by utilizing frequency diversity. SSCH can be implemented in software over an IEEE 802.11-compliant wireless card. Each node using SSCH switches across channels in such a manner that nodes desiring to communicate overlap while disjoint communications mostly do not overlap and hence do not interfere with each other. To achieve this SSCH uses a novel scheme for distributed rendezvous and synchronization. Simulation results show that SSCH significantly increases network capacity in several multi-hop and single-hop wireless networking scenarios.,10.1.1.1.2405,pseudo-randomness scheduling,?
Lyapunov-Based Stability Analysis for REM,Congestion Control Orhan,?,This paper investigates convergence properties of basic REM flow control algorithm via Lyapunov functions. The decentralized algorithm REM consists of a link algorithm that updates a congestion measure also called price based on the excess capacity and backlog at that link and a source algorithm that adapts the source rate to congestion in its path. At the equilibrium of the algorithm links are fully utilized and all buffers are cleared. Convergence of the algorithm is established for single and two-link cases using a Lyapunov argument. Extension to the general multi-link model is discussed as well.,10.1.1.1.2406,?,?
A Proposal To Support Collaborative Learning: Using A Structure To Share Context ,Luis Borges Gouveia,?,?,10.1.1.1.2407,be shared is represented using a simple structure composed by concepts,?
A New Routing Architecture for DiffServ Domains,Shiping Chen  Yibei Ling Key Words,2003,This paper proposes a new DiffServ routing architecture (PAP) that integrates the admission control signaling and the QoS routing. It differs from traditional routing in its ability to route most Expedite Forwarding (EF) traffic along the shortest paths while making use of alternative paths to absorb transient overload. Once an EF data flow is admitted its performance is assured. The overhead for storing alterative path information is minimal since only one routing entry at a branching point is needed for each alternative path. The route map of Cisco IOS provides a mechanism for implementing PAP.,10.1.1.1.2408,?,Springer-Verlag
Natural Resource Management in the Hillsides of Honduras - Bioeconomic Modeling at the Microwatershed Level,Bruno Barbier  Gilles Bergeron Barbier Bruno Figures Vii,?,this report may be reproduced without the express  permission of but with acknowledgment to the International Food Policy Research Institute,10.1.1.1.2410,?,?
Redshift in Absolute Space: Periodicity of Quasars And Other . . . ,Héctor A. Múnera,1998,?,10.1.1.1.2411,?,?
Model-based Simulation of Web Applications for Usability Assessment,Robert Chatley  Jeff Kramer Jeff Magee Sebastian Uchitel,2003,In this paper we discuss an approach for simulating the behaviour of interactive software systems before starting on any of the actual implementation based on a model of the system at the architectural level. By providing a mock-up of the final user interface for controlling the simulation it is possible to carry out usability assessments of the system much earlier in the design process than is usually the case. This means that design changes informed by this usability assessment can be made at this early stage. This is much less expensive than having to wait until an implementation of the system is completed before discovering flaws and having to make major changes to already implemented components. The approach is supported by a suite of cooperating tools for specification formal modelling and animation of the system.,10.1.1.1.2412,?,?
Sparse Representations are Most Likely to be the Sparsest Possible,Michael Elad,2004,and a full rank matrix D    with N  L we define the signals  overcomplete representations as all #    satisfying S = D#. Among all the possible solutions  we have special interest in the sparsest one -- the one minimizing    0 . Previous work has  established that a representation is unique if it is sparse enough requiring    0  Spark(D)/2.,10.1.1.1.2413,Sparse representation Overcomplete transforms Spark Signature of matrices Uniqueness,?
Big Ball of Mud,Brian Foote And Brian Foote Joseph Yoder,1997,?,10.1.1.1.2414,?,?
Tobias Scheer 11,Manchester Phonology Meeting,?,empty Nucleus may exist only if it is governed (there is more to it but thats enough for now). c. instead of being translated into the familiar arborescence syllabic generalisations are described by two lateral relations: 1. Government (destructive) 2. Licensing (supporting) example: a consonant occurs in a Coda iff it is follwed by a governed empty Nucleus (R = any sonorant T = any obstruent) internal Coda (boldfaced) final Coda (boldfaced) Gov O N O N O N | | | | | | C V R T V Gov O N O N | | | | - 2 -   d. The Coda Mirror (Sgral  Scheer 2001)  there is a reason why consonants are weak in Codas (and strong in the Coda Mirror = {#C}__): goverend Nuclei are laterally disabled i.e. can neither govern nor license. Therefore Coda-consonants are neither supported (by Licensing) nor damaged (by Government). internal Coda (boldfaced) final Coda (boldfaced) Gov Gov O N O N O N | | | | | | C V R T V Lic Gov Gov O N O N | | | | C V R # Lic e. ok thats it you will be relieved of empty,10.1.1.1.2415,b. the Empty Category Principle,?
Performance Impact of Addressing Modes on Encryption Algorithms,A. Murat Fiskiran et al.,2001,Encryption algorithms commonly use table lookups to perform substitution which is a confusion primitive. The use of table lookups in this way is especially common in the more recent encryption algorithms such as the AES finalists like MARS and Twofish and the AES winner Rijndael. Workload characterization studies indicate that these algorithms spend a significant fraction of their execution cycles on performing these table lookups more specifically on effective address calculations. This study . . . ,10.1.1.1.2416,?,?
Commercial Simulation Over The Web,Larry Whitman  Brian Huff  Senthil Palaniswamy D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,1998,Modeling and simulation provide objective analysis tools for many fields including manufacturing. This paper presents the requirements and describes the usefulness of a web-based interface to discrete-event simulation. A description of related efforts is first presented and an approach is then described. The approach develops a webbased interface to use commercial discrete-event commercial tools.,10.1.1.1.2417,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson,?,Incorporation into construction engineering and management curricula of tasks that improve the abilities of students to manage the complex dynamics pressures and demands of construction sites is becoming critical to meet the demands of the construction industry. These goals are however difficult to incorporate using traditional educational tools. This paper reviews the role in construction engineering and management education of computing and information technology in general and of simulation in particular. The paper provides an overview of a Simulation Based Interactive Construction Management Learning System currently being developed at Western Michigan University (WMU) as part of a three-year project funded by the National Science Foundation and Western Michigan University.,10.1.1.1.2418,?,?
Using Multi-level Graphs for Timetable Information in Railway Systems,Frank Schulz Dorothea Wagner Christos Zaroliagis,2002,In many fields of application shortest path finding problems in  very large graphs arise. Scenarios where large numbers ofonW##O queries for shortest paths have to be processedin real-time appear for examplein tra#cinc5###HF5 systems.In such systems the techn5Ww# con sidered to speed up the shortest pathcomputation are usually basedon precomputed incomputed5 On approach proposedoften in thiscon text is a spacereduction where precomputed shortest paths are replaced by sin## edges with weight equal to thelenOq of the corresponres shortest  path.In this paper we give a first systematic experimen tal study of such a spacereduction approach. Wein troduce theconOkW of multi-level graph decomposition Foron specificapplication scenica from the field of timetable information in public tranc ort we perform a detailed anai ysisan experimen tal evaluation of shortest path computation based on multi-level graph decomposition.,10.1.1.1.2419,?,Springer
A Generic Persistence Model for (C)LP Systems,J. Correas  J. M. Gomez M. Carro D. Cabeza M. Hermenegildo,2003,ng persistence once and for all in a reusable (system) library providing the class of persistent predicates. The main e#ect of declaring a predicate persistent (a process for which we propose a suitable syntax compatible with the Ciao systems assertion language) is that any changes made to such predicates persist from one execution to the next one and are transactional and optionally externally visible. The model allows associating an external persistent storage medium (a file a database table etc.) to each such predicate which will reside in that medium. Notably persistent predicates appear to a program as ordinary (dynamic) predicates: calls to them do not need to be coded or marked specially and the builtins to update them are (suitably modified versions of) the same used with the internal database (e.g. asserta/1 assertz/1 retract/1 etc.). Thus only minor modifications to the program code (often independent of its internal logic) are needed to achieve persistence,10.1.1.1.2420,?,?
Genome Informatics 14: 510--511 (2003) Structure-Thermodynamic Relationship in Protein-DNA Binding: Heat Capacity Changes,Hatsuho Uedaira Hidetoshi Hidetoshi Kono Prabakaran Ponraj Koji Kitajima Akinori Sarai,?,this paper we will discuss the relationship between experimental #C p and #ASA upon binding calculated based on the structural information and the prediction of #C p based on #ASA,10.1.1.1.2421,protein-nucleic acid interactions database heat capacity change solvent accessible surface,?
Prediction of Protein-Protein Interactions from Phylogenetic Trees Using . . . ,Tetsuya Sato Yoshihiro Yamanishi Katsuhisa Horimoto Hiroyuki Toh Minoru Kanehisa,2003,?,10.1.1.1.2422,protein-protein interactions phylogenetic tree co-evolution partial correlation coefficient,?
Using P-trees,Qin Ding Qiang Ding William Perrizo,?,Association Rule Mining originally proposed for market basket data has potential applications in many areas. Remote Sensed Imagery (RSI) data is one of the promising application areas. Extracting interesting patterns and rules from datasets composed of images and associated ground data can be of importance in precision agriculture community planning resource discovery and other areas. However in most cases the image data sizes are too large to be mined in a reasonable amount of time using existing algorithms. In this paper we propose an approach to derive association rules on RSI data using Peano Count Tree (P-tree) structure. P-tree structure proposed in our previous work [21] provides a lossless and compressed representation of image data. Based on P-trees an efficient association rule mining algorithm P-ARM with fast support calculation and significant pruning techniques are introduced to improve the efficiency of the rule mining process. P-ARM algorithm is implemented and compared with FP-growth and Apriori algorithms. Experimental results showed that our algorithm is superior for association rule mining on RSI spatial data.,10.1.1.1.2423,Data Mining Association Rule Mining Remote Sensed Imagery (RSI) 1 Patents are pending on the P-tree technology,?
Individualised Revision Material for Use on a Handheld Computer,Susan Bull Eileen Reid,2004,?,10.1.1.1.2424,learner model revision material,?
On The Rayleigh Nature Of Gabor Filter Outputs,Sitaram Bhagavathy Jelena B. S. Manjunath,2003,Texture has been recognized as an important visual primitive  in image analysis. A widely used texture descriptor which is part of the MPEG-7 standard is that computed using multiscale Gabor filters. The high dimensionality and computational complexity of this descriptor adversely a#ect the e#ciency of content-based retrieval systems. We propose a modified texture descriptor that has comparable performance but with nearly half the dimensionality and less computational expense. This gain is based on a claim that the distribution of (absolute values of) filter outputs have a strong tendency to be Rayleigh. Experimental results show that the dimensionality can be reduced by almost 50% with a tradeo# of less than 3% on the error rate. Furthermore it is easy to compute the new feature using the old one without having to repeat the computationally expensive filtering step. We also propose a new normalization method that improves similarity retrieval and indexing e#ciency.,10.1.1.1.2425,?,?
Wavelet-Based Texture Retrieval Using Generalized Gaussian Density and Kullback-Leibler Distance,Minh N. Do Martin Vetterli,2002,We present a statistical view of the texture retrieval problem by combining the two related tasks namely feature extraction (FE) and similarity measurement (SM) into a joint modeling and classification scheme. We show that using a consistent estimator of texture model parameters for the FE step followed by computing the Kullback--Leibler distance (KLD) between estimated models for the SM step is asymptotically optimal in term of retrieval error probability. The statistical scheme leads to a new wavelet-based texture retrieval method that is based on the accurate modeling of the marginal distribution of wavelet coefficients using generalized Gaussian density (GGD) and on the existence a closed form for the KLD between GGDs. The proposed method provides greater accuracy and flexibility in capturing texture information while its simplified form has a close resemblance with the existing methods which uses energy distribution in the frequency domain to identify textures. Experimental results on a database of 640 texture images indicate that the new method significantly improves retrieval rates e.g. from 65% to 77% compared with traditional approaches while it retains comparable levels of computational complexity.,10.1.1.1.2426,?,?
Ordering Broken Unit Tests for Focused Debugging,Markus Gälli Michele Lanza Oscar Nierstrasz  Roel Wuyts,2004,Current unit test frameworks present broken unit tests in an arbitrary order but developers want to focus on the most specific ones first. We have therefore inferred a partial order of unit tests corresponding to a coverage hierarchy of their sets of covered method signatures: When several unit tests in this coverage hierarchy break we can guide the developer to the test calling the smallest number of methods. Our experiments with four case studies indicate that this partial order is semantically meaningful since faults that cause a unit test to break generally cause less specific unit tests to break as well.,10.1.1.1.2427,Unit testing debugging,?
A Biometric Identity Based Signature Scheme,Andrew Burnett  Adam Duffy  Tom Dowling Nui Maynooth,2004,We describe an identity based signature scheme that uses biometric information to construct the  public key. Such a scheme would be beneficial in a legal dispute over whether a contract had been signed  or not by a user. A biometric reading provided by the alleged signer would be enough to verify the  signature. We make use of Fuzzy extractors [7] to generate a key string from a biometric measurement.,10.1.1.1.2428,?,?
Stuck between aesthetics and commercialization?,Betina Nakel Andersen Marie Terp Mester Lone Kristensen,2004,In this paper we will do a heuristic evaluation on a homepage that belongs to an illustrator who wants to show his work. Before we present the result of the evaluation we will shortly explain the context. The result of the heuristic evaluation falls in two parts. First we look at some of the usability problems we discovered overall at the website and secondly we look at one particular problem with the website where the illustrator tries to sell his book. After each part we present some recommendations to the problems. Finally we try to answer some of the questions that arose when we carried out the evaluation. Questions like -- is it possible to do a traditional heuristic evaluation on a website which aim is rather aesthetic than commercial? Is a website aesthetic if it has a commercial touch? And finally what are the problems with heuristic evaluation in this content?  KEYWORDS: Heuristic evaluation website aesthetic commercial user involvement  ,10.1.1.1.2429,Heuristic evaluation website aesthetic commercial user,?
Distributed Spatio-Temporal Modeling and Simulation,E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Thomas Schulze,2002,is to evolve interoperability standards to develop flexible and scalable controlling and simulation services. In order to overcome the limitations of proprietary solutions efforts have been made to support interoperability among simulation models and geo information systems (GIS). Existing standards in the domain of spatial information and spatial services define geoinformation (GI) in a more or less static way. Though time can be handled as an additional attribute its representation is not explicitly specified. In contrast as the standard for distributed heterogeneous simulation the High Level Architecture (HLA) provides a framework for distributed time-variant simulation processes but HLA is lacking in supporting spatial information. A web-based Distributed spAtio-temporaL In- teroperability architecture DALI integrating these initiatives will be presented here. The long term goal of this DALI Architecture is making standardized off-theshelf GI and simulation services usable for highly specialized simulation and controlling applications.,10.1.1.1.2431,?,?
A Web Service-based Experiment Management System for the Grids,Radu Prodan  Thomas Fahringer,2002,We have developed ZENTURIO which is an experiment management system for performance and parameter studies as well as software testing for cluster and Grid architectures. In this paper we describe our experience with developing ZENTURIO as a collection of Web services. A directivebased language called ZEN is used to annotate arbitrary  les and specify arbitrary application parameters. An Experiment Generator Web service parses annotated application les and generates appropriate codes for experiments. An Experiment Executor Web service compiles executes and monitors experiments on a single or a set of local machines on the Grid. Factory and Registry services are employed to create and register Web services respectively. An event infrastructure has been customised to support high-level events under ZENTURIO in order to avoid expensive polling and to detect important system and application status information. A graphical user portal allows the user to generate control and monitor experiments. We compare our design with the Open Grid Service Architecture (OGSA) and highlight similarities and dierences. We report results of using ZENTURIO to conduct performance analysis of a material science code that executes on the Grid under the Globus Grid infrastructure.,10.1.1.1.2432,?,IEEE Computer Society
Photometric Stereo for Archeological Inscriptions (sketches 0338),Per Einarsson Tim Tim Hawkins Paul Debevec,?,One of the input image for an inscription on a column of the Parthenon.  The light-capturing frame (Fig. 1) consists of fiducials and MacBeth color checker chart samples from which the cameras position and the incident radiant intensity can be estimated as well as two glossy black spheres used to indicate the position of the light source. To reconstruct each object we re-adjusted the size of the frame and placed it around the geometry. We took approximately ten images each lit with a remotely mounted camera flash at a different position pointed towards the center of the frame. For each set of images we also took an additional image without the flash which was subtracted from the other images to remove any ambient # e-mail:einarsson timh debevec@ict.usc.edu  lighting. The full process including setup took approximately 20 minutes for each inscription.  To compute a surface normal map we first determine the light vector  l by shooting rays from the cameras center toward the o,10.1.1.1.2433,?,?
Three design Patterns for Secure Distributed Systems,Alan Karp Alan H. Karp Kevin Smathers Kevin Smathers,2003,The computers we use are not secure and they are even less so when connected to the Internet. A lot of blame has been put on lazy sysadmins for not applying patches promptly but the fault is not entirely theirs. We believe that distributed systems should be designed to make attacks harder and to limit the damage done when attacks succeed. We propose three components of the system architecture that address these goals and make distributed systems easier to monitor and manage while simplifying the task of writing secure applications. Following these guidelines wont make the system secure but doing so will make it easier to build systems that are.,10.1.1.1.2434,?,?
Information Visualization Supporting Modelling and Evaluation of Tasks for Climate Models,S. Chick  Uwe Böhm P. J. Sánchez D. Ferrin D. J. Morrice Thomas Nocke Heidrun Schumann,2003,Information visualization exploits the phenomenal abilities of human perception to identify structures by presenting abstract data visually allowing an intuitive exploration of data to get insight to draw conclusions and to interact directly with the data. The specification analysis and evaluation of complex models and simulated model data can benefit from information visualization techniques by obtaining visual support for different tasks. This paper presents an approach that combines modelling and visualization functionality to support the modelling process. Based on this general approach we have developed and implemented a framework that allows to combine a variety of models with statistical and analytical operators as well as with visualization methods. We present several examples in the context of climate modelling.,10.1.1.1.2436,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,Typically large-scale optimistic parallel simulations will spend 90% or more of the total execution time forward processing events and very little time executing rollbacks. In fact it was recently shown that a large-scale TCP model consisting of over 1 million nodes will execute without generating any rollbacks (i.e. perfect optimistic execution is achieved). The major cost involved in forward execution is the preparation for a rollback in the form of state-saving. Using a technique called reverse computation state-saving overheads can be greatly reduced. Here the rollback operation is realized by executing previously processed events in reverse. However events are retained until GVT sweeps past. In this paper we define a new algorithm for realizing a continuum of reverse computation-based parallel simulation systems which enables us to relax the computing of GVT and potentially further reduces the amount of memory required to execute an optimistic simulation.,10.1.1.1.2437,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Eleazer Martin,?,Large corporations can achieve significant cost savings by developing and employing a sophisticated and continuously updated billing and credit policy. Days of sale outstanding (DSO) is a major cost driver for corporations with large revenues as this leads to an increased risk of default increased dunning and collection costs a non-optimal billing procedure with attendant costs and perhaps most importantly an increase in the order-to-cash cycle time and the significant increase in hidden costs this implies. Segmentation of the customer base according to behavior and risk combined with the design of bespoke billing and credit policies suited to the behavior and risk associated with each segment can lead to a significant decrease in the costs mentioned above. This paper illustrates the work done at Norways largest telecommunication operator Telenor to address these issues using the continuous simulation methodology as well as other econometric tools.,10.1.1.1.2438,?,?
Probability matching . . . ,W. Todd Maddox Corey J. Bohil,2004,?,10.1.1.1.2439,?,?
Extraction of Speaker Features from Different Stages of DSR Front-ends for Distributed Speaker Verification,Man-Wai Mak Chin-hung Sit Hong Kong Sun-yuan Kung,2004,The ETSI has recently published a front-end processing standard for distributed speech  recognition systems. The key idea of the standard is to extract the spectral features of  speech signals at the front-end terminals so that acoustic distortion caused by communication  channels can be avoided. This paper investigates the e#ect of extracting spectral features  from di#erent stages of the front-end processing on the performance of distributed speaker  verification systems. A technique that combines handset selectors with stochastic feature  transformation is also employed in a back-end speaker verification system to reduce the  acoustic mismatch between di#erent handsets. Because the feature vectors obtained from  the back-end server are vector quantized the paper proposes two approaches to adding  Gaussian noise to the quantized feature vectors for training the Gaussian mixture speaker  models. In one approach the variances of the Gaussian noise are made dependent on the  codeword distance. In another approach the variances are a function of the distance between  some unquantized training vectors and their closest code vector. The HTIMIT corpus was  # Correspondence should be sent to M.W. Mak Dept. of Electronic and Information Engineering The Hong Kong Polytechnic University Hong Kong. Email: enmwmak@polyu.edu.hk. Tel: (852)27666257. Fax: (852)23628439.,10.1.1.1.2440,Distributed speaker verification DSR DSR front-end processing feature,?
A Hardware Signaling Paradigm For Fine-Grained Resource,Reservation Dan Gluskin Dan Gluskin Israel Cidon,2003,Current implementation of real time service quality within converged IP networks is mainly accomplished by over-provisioning of bandwidth with limited definition of traffic classes on a network wide basis possibly enhanced by quasi-static provisioning of network elements using traffic engineering. Per-flow ondemand resource reservation is mostly unavailable in large packet networks. Examples are establishments of switched VC using PNNI signaling in ATM and establishment of LSPs using RSVP signaling in MPLS supported networks. Management complexities and limited scalability slow down this trend. While perflow reservation is a conceptually straightforward QoS solution it is usually looked at as an impractical nonscalable and even a higher cost solution. Today highend routers and switches can handle traffic volumes of many hundreds gigabit and even terabits per seconds which can be translated to millions of simultaneous voice and video connections. However currentsignaling technologies will enable to handle only several hundreds connections that can be translated to only few thousands simultaneous short lived connections. Clearly today call establishment mechanisms cannot scale to support per-flow reservation that is conceptually a simple QoS solution. In order to solve this limitation there is an on-going effort to reduce the required reservation rate by developing complex hierarchical aggregation schemes and multiplexing concepts. This limits the use of connection establishment signaling to aggregate traffic engineering which is hard to define understand and manage and may fail to provide a required QoS solution.,10.1.1.1.2441,?,?
Sequence Complexity for Biological Sequence Analysis,L. Allison  L. Stern   Tim Edgoose T. I. Dix ,2000,A new statistical model for DNA considers a sequence to be a mixture of regions with little structure and regions that are approximate repeats of other subsequences i.e. instances of repeats do not need to match each other exactly. Both forward- and reverse-complementary repeats are allowed. The model has a small number of parameters which are fitted to the data. In general there are many explanations for a given sequence and how to compute the total probability of the data given the model is shown. Computer algorithms are described for these tasks. The model can be used to compute the information content of a sequence either in total or base by base. This amounts to looking at sequences from a data-compression point of view and it is argued that this is a good way to tackle intelligent sequence analysis in general.,10.1.1.1.2442,?,?
Information Theory of Complex Networks: on evolution and architectural constraints,Ricard V. Sole Sergi Valverde,2004,Complex networks are characterized by highly heterogeneous distributions of links often pervading the presence of key properties such as robustness under node removal. Several correlation measures have been defined in order to characterize the structure of these nets. Here we show that mutual information noise and joint entropies can be properly defined on a static graph. These measures are computed for a number of real networks and analytically estimated for some simple standard models. It is shown that real networks are clustered in a well-defined domain of the entropy/noise space. By using simulated annealing optimization it is shown that optimally heterogeneous nets actually cluster around the same narrow domain suggesting that strong constraints actually operate on the possible universe of complex networks. The evolutionary implications are discussed.,10.1.1.1.2443,Information theory complex networks evolution selection emergence simulated annealing,Springer-Verlag
A Multiscale Finite Element Method For Numerical Homogenization,Grégoire Allaire Robert Brizzi,2004,This paper is concerned with a multiscale finite element method for numerically solving  second order scalar elliptic boundary value problems with highly oscillating coefficients. In  the spirit of previous other works our method is based on the coupling of a coarse global  mesh and of a fine local mesh the latter one being used for computing independently an  adapted finite element basis for the coarse mesh. The main new idea is the introduction  of a composition rule or change of variables for the construction of this finite element  basis. In particular this allows for a simple treatment of high order finite element methods. We provide,10.1.1.1.2444,?,?
The Java CoG Kit User Manual,Gregor Von Laszewski Beulah Alunkal Kaizar Amin Jarek Gawor Mihael Hategan Sandeep Nijsure,2003,?,10.1.1.1.2445,?,?
More Enforceable Security Policies,Lujo Bauer Jarred Ligatti David Walker,2002,We analyze the space of security policies that can be enforced by monitoring  programs at runtime. Our program monitors are automata that  examine the sequence of program actions and transform the sequence  when it deviates from the specified policy. The simplest such automaton  truncates the action sequence by terminating a program. Such automata  are commonly known as security automata and they enforce Schneiders  EM class of security policies. We define automata with more powerful  transformational abilities including the ability to insert a sequence of actions  into the event stream and to suppress actions in the event stream  without terminating the program. We give a set-theoretic characterization  of the policies these new automata are able to enforce and show that  they are a superset of the EM policies.,10.1.1.1.2446,?,?
Inferring Reduced Ordered Decision Graphs of Minimal Description Length,Arlindo L. Oliveira    Alberto Sangiovanni-Vincentelli,1994,This work describes an approach for the inference of reduced ordered decision graphs from training sets. Reduced ordered decision graphs (RODGs) are graphs where the variables can only be tested in accordance with a pre-specified order and no redundant nodes exist. RODGs have several interesting properties that has made them the representation of choice for the manipulation of Boolean functions in the logic synthesis community. We derive a RODG representation of the function implemented by a decision tree. This decision tree can be obtained from a training set using any one of the different algorithms proposed to date. This RODG is then used as the starting point for an algorithm that derives another RODG of minimal description length. The reduction in complexity is obtained by performing incremental changes in the RODG. By using ordered decision diagrams the task of identifying common subgraphs is made much simpler than the identification of common sub-trees in a decision tree. Ordered decision graphs require that a variable ordering be specified in advance. The algorithm that derives such an ordering is based on a reordering algorithm commonly used that finds a locally optimal ordering by swapping the order of two adjacent variables. These algorithms are tested in a set of examples that are known to be hard to solve using decision trees. The results show that when an effective reduction of the description length is obtained significant gains in generalization accuracycan be achieved. In all casesthe generalization accuracy of the final RODG was better than the generalization accuracy of the decision tree that was used as the starting point.  ,10.1.1.1.2448,?,Morgan Kaufmann
Power-aware Base Station Positioning for Sensor Networks,Andrej Bogdanov Elitza Maneva Samantha Riesenfeld,2004,We consider the problem of positioning data collecting base stations in a sensor network. We show that in general the choice of positions has a marked influence on the data rate or equivalently the power efficiency of the network. In our model which is partly motivated by an experimental environmental monitoring system the optimum data rate for a fixed layout of base stations can be found by a maximum flow algorithm. Finding the optimum layout of base stations however turns out to be an NP-complete problem even in the special case of homogeneous networks. Our analysis of the optimum layout for the special case of the regular grid shows that all layouts that meet certain constraints are equally good. We also consider two classes of random graphs chosen to model networks that might be realistically encountered and empirically evaluate the performance of several base station positioning algorithms on instances of these classes. In comparison to manually choosing positions along the periphery of the network or randomly choosing them within the network the algorithms tested find positions which significantly improve the data rate and power efficiency of the network.,10.1.1.1.2449,?,?
A Practical Approach to Partial Functions in CVC Lite,Sergey Berezin Clark Barrett Igor Shikanian Marsha Chechik Arie Gurfinkel  David L. Dill,2004,Most verification approaches assume a mathematical formalism in which functions are total even though partial functions occur naturally in many applications. Furthermore although there have been various proposals for logics of partial functions there is no consensus on which is the right logic to use for verification applications. In this paper we propose using a three-valued Kleene logic where partial functions return the undefined value when applied outside of their domains. The particular semantics are chosen according to the principle of least surprise to the user if there is disagreement among the various approaches on what the value of the formula should be its evaluation is undefined. We show that the problem of checking validity in the three-valued logic can be reduced to checking validity in a standard two-valued logic and describe how this approach has been successfully implemented in our tool CVC Lite.,10.1.1.1.2450,?,?
How to Formalize It? Formalization Principles for Information System Development Methods,A. H. M. Ter Hofstede  H.A. Proper,1998,Although the need for formalisation of modelling techniques is generally recognised not much literature  is devoted to the actual process involved. This is comparable to the situation in mathematics where  focus is on proofs but not on the process of proving. This paper tries to accomodate for this lacuna and  provides essential principles for the process of formalisation in the context of modelling techniques as  well as a number of small but realistic formalisation case studies.,10.1.1.1.2451,Formalization Methodologies Information Systems,?
iCAP: An Informal Tool for Interactive Prototyping of Context-Aware Applications,Timothy Y. Sohn  Anind K. Dey,2003,iCAP is a system that assists users in prototyping contextaware applications. iCAP supports sketching for creating input and output devices and using these devices to design interaction rules which can be prototyped in a simulated or real context-aware environment. We were motivated to build our system by the lack of tools currently available for developing rich sensor-based applications. We iterated on the design of our system using paper prototypes and obtained feedback from fellow researchers to develop a robust system for prototyping context-aware applications.,10.1.1.1.2452,?,?
History of the 2.7 K Temperature Prior to Penzias and Wilson,A. K. T. Assis São Paulo  M. C. D. Neves,2001,this paper we show that other models of a Universe in dynamical equilibrium without expansion had predicted this temperature prior to Gamow. Moreover we show that Gamows own predictions were worse than these previous ones. Before beginning let us list briefly some important historical information which help to understand the findings. Stefan found experimentally in 1879 that the total bolometric flux of radiation F emitted by a black body at a temperature T is given by F T = s    where s is now called Stefan-Boltzmanns constant (5 67 10  8    Wm K  - - 2 4  ). The theoretical derivation of this expression was obtained by Boltzmann in 1884. In 1924 Hubble established that the nebulae are stellar systems outside the Milky Way. In 1929 he obtained the famous redshiftdistance law,10.1.1.1.2453,?,?
ThumbTec: A New Handheld Input Device,Philippe Stanislas Zaborowski,?,This paper describes ThumbTEC a novel general purpose input device for the thumb or finger that is useful in a wide variety of applications from music to text entry. The device is made up of three switches in a row and one miniature joystick on top of the middle switch. The combination of joystick direction and switch(es) controls what note or alphanumeric character is selected by the finger. Several applications are  detailed.,10.1.1.1.2454,Computing Handheld Devices Musical Instrument,?
Approximate Classification via Earthmover Metrics,Aaron Archer  Jittat Fakcharoenphol  Chris Harrelson Robert Krauthgamer Kunal Talwar  Éva Tardos,2004,Given a metric space (X d) a natural distance measure on probability distributions over X is the earthmover metric. We use randomized rounding of earthmover metrics to devise new approximation algorithms for two well-known classification problems namely metric labeling and 0-extension.,10.1.1.1.2455,?,?
Property Coverage for Quality Assessment of Fault Tolerant or Fail Safe Systems,F.M. Gonçalves  M.B. Santos  J.P. Teixeira J. P. Teixeira Ist/inesc-id Rua Alves Redol,?,In the design environment system properties such as fault tolerance and safe operation need to be demonstrated in new product development of safety-critical systems. The onus of the proof is by no means trivial and the associated computational costs can be overwhelming. In this paper a novel quality metrics is introduced Property Coverage (PC) which allows with affordable computational effort to have a measure of the degree of confidence within which the Property under evaluation holds. The proposed method uses fault sampling and enables PC evaluation with limited fault list sizes. The methodology and associated metrics are ascertained through a case study an ASIC for a safety-critical gas burner control system recently certified to be compliant to EN 298 safety standard.,10.1.1.1.2456,?,?
New Measure of Classifier Dependency in Multiple Classifier Systems,Dymitr Ruta Bogdan Gabrys,2002,Recent findings in the domain of combining classifiers provide a surprising  revision of the usefulness of diversity for modelling combined performance.,10.1.1.1.2458,?,Springer Verlag
Although Keyword-Based Queries Are,Now Familiar Part,?,jects that use these technologies for archiving and retrieval. The main goal of the MAESTRO project is to discover implement and evaluate various combinations of these technologies  to achieve analysis performance that surpasses  the sum of the parts. For example  British Prime Minister Tony Blair can be  identified in the news by his voice his  appearance captions and other cues. A  combination of these cues should provide  more reliable identification of the Prime  Minister than using any of the cues on  their own.  MAESTRO is a highly multidisciplinary  effort involving contributions from  three laboratories across two divisions at  SRI. Each of these SRI technologies is  described in more detail here. The integrating  architecture makes it easy to combine  these in different ways and to  incorporate new analysis technologies  developed by our team or by others.  Multimedia Analysis Technologies on the MAESTRO Score  On the MAESTRO Score (see Figure 1) on each line similar,10.1.1.1.2459,?,?
A Portable Virtual Machine Target for Proof-Carrying Code,Michael Franz  Deepak Chandra Andreas Gal Vivek Haldar  Fermin Reig Ning Wang,2003,Virtual Machines (VMs) and Proof-Carrying Code (PCC) are two techniques that have been used independently to provide safety for (mobile) code. Existing virtual machines such as the Java VM have several drawbacks: First the e#ort required for safety verification is considerable. Second and more subtly the need to provide such verification by the code consumer inhibits the amount of optimization that can be performed by the code producer. This in turn makes justin -time compilation surprisingly expensive. Proof-Carrying Code on the other hand has its own set of limitations among which are the sizes of the proofs and the fact that the certified code is no longer machine-independent. In this paper we describe work in progress on combining these approaches. Our hybrid safe-code solution uses a virtual machine that has been designed specifically to support proofcarrying code while simultaneously providing e#cient justin -time compilation and target-machine independence. In particular our approach reduces the complexity of the required proofs resulting in fewer proof obligations that need to be discharged at the target machine.,10.1.1.1.2460,?,?
Matching Output Queueing with a Multiple Input/Output-Queued Switch,Hyoung-Il Lee et al.,2004,In this paper we show that the multiple input/outputqueued (MIOQ) switch proposed in our previous paper [22] can emulate an output-queued switch only with two parallel switches. The MIOQ switch requires no speedup and provides an exact emulation of an output-queued switch with a broad class of service scheduling algorithms including FIFO weighted fair queueing (WFQ) and strict priority queueing regardless of incoming traffic pattern and switch size. First we show that an   N MIOQ switch with a (2 2)-dimensional crossbar fabric can exactly emulate an N    N output-queued switch. For this purpose we propose the stable strategic alliance (SSA) algorithm that can produce a stable many-to-many assignment and then apply it to the scheduling of an MIOQ switch. Next we prove that a (2 2)-dimensional crossbar fabric can be implemented by two NN crossbar switches in parallel for an NN MIOQ switch. For a proper operation of two crossbar switches in parallel each input-output pair matched by the SSA algorithm must be mapped to one of two crossbar switches. For this mapping we propose a simple algorithm that requires at most 2N steps for all matched input-output pairs. In addition to relieve the implementation burden of N input buffers being accessed simultaneously we propose a buffering scheme called redundant buffering which requires two memory devices instead of N physically-separate memories.,10.1.1.1.2461,?,?
Stopping Criterion For A Simulation-Based Optimization Method,Sigurdur Olafsson  Leyuan Shi D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,1998,We consider a new simulation-based optimization method called the Nested Partitions (NP) method. This method generates a Markov chain and solving the optimization problem is equivalent to maximizing the stationary distribution of this Markov chain over certain states. The method may therefore be considered a Monte Carlo sampler that samples from the stationary distribution. We show that the Markov chain converges geometrically fast to the true stationary distribution and use these results to derive a stopping criterion for the method.,10.1.1.1.2462,?,?
Lucas-Kanade 20 Years On: A Unifying Framework: Part 3,Simon Baker Ralph Gross Iain Matthews,2002,Since the Lucas-Kanade algorithm was proposed in 1981 image alignment has become one of the most widely used techniques in computer vision. Applications range from optical flow tracking and layered motion to mosaic construction medical image registration and face coding. Numerous algorithms have been proposed and a variety of extensions have been made to the original formulation. We present an overview of image alignment describing most of the algorithms in a consistent framework. We concentrate on the inverse compositional algorithm an efficient algorithm that we recently proposed. We examine which of the extensions to the Lucas-Kanade algorithm can be used with the inverse compositional algorithm without any significant loss of efficiency and which cannot. In this paper Part 3 in a series of papers we cover the extension of image alignment to allow linear appearance variation. We first consider linear appearance variation when the error function is the Euclidean L2 norm. We describe three different algorithms the simultaneous project out and normalization inverse compositional algorithms and empirically compare them. Afterwards we consider the combination of linear appearance variation with the robust error functions described in Part 2 of this series. We first derive robust versions of the simultaneous and normalization algorithms. Since both of these algorithms are very inefficient as in Part 2 we derive efficient approximations based on spatial coherence. We end with an empirical evaluation of the robust algorithms.,10.1.1.1.2463,?,?
The Convergence of Control Communication and Computation,Scott Graham P. R. Kumar,2003,The convergence of communication and computation over  the past two decades has given us the Internet. We believe that the next  phase of the information technology revolution will be the convergence  of control communication and computation. This will provide the ability  for large numbers of sensors actuators and computational units all  interconnected wirelessly or over wires to interact with the physical environment.,10.1.1.1.2465,?,Springer-Verlag
Glass-Box and Black-Box Views on Object-Oriented Specifications,Michel Bidoit  Rolf Hennicker  Alexander Knapp  Hubert Baumeister,2004,We present a logical foundation for object-oriented specifications which supports a rigorous formal development of object-oriented systems. In this setting we study two different views on a system the implementors view (glass-box view) and the users view (black-box view) which both are founded on a model-theoretic semantics. We also discuss the hierarchical construction of specifications and realisations. Our approach is abstract in the sense that it can be instantiated by various concrete specification formalisms like OCL or JML.,10.1.1.1.2466,?,?
The Boundary between Decidability and Undecidability for Transitive-Closure Logics,N. Immerman A. Rabinovich T. Reps M. Sagiv G. Yorsh,2004,To reason effectively about programs it is important to have some version of a transitive-closure operator so that we can describe such notions as the set of nodes reachable from a programs variables. On the other hand with a few notable exceptions adding transitive closure to even very tame logics makes them undecidable. In this paper we explore...,10.1.1.1.2467,?,?
Journal of Rehabilitation Research  Development The Smart Wheelchair Component System,Volume Number Pages Richard Simpson Atp Edmund Lopresti Phd Steve Hayashi Phd Illah Nourbakhsh David Miller Phd,?,While the needs of many individuals with disabilities can be satisfied with power wheelchairs some members of the disabled community find it difficult or impossible to operate a standard power wheelchair. To accommodate this population several researchers have used technologies originally developed for mobile robots to create smart wheelchairs that reduce the physical perceptual and cognitive skills necessary to operate a power wheelchair. We are developing a Smart Wheelchair Component System (SWCS) that can be added to a variety of commercial power wheelchairs with minimal modification. This paper describes the design of a prototype of the SWCS which has been evaluated on wheelchairs from four different manufacturers.,10.1.1.1.2468,?,?
Tree Music: Composing with GAIA,Judith Shatin  David Topper,2004,In this report we discuss Tree Music an interactive computer music installation created using GAIA (Graphical Audio Interface Application) a new open-source interface for controlling the RTcmix synthesis and effects processing engine. Tree Music commissioned by the University of Virginia Art Museum used a wireless camera with a wide-angle lens to capture motion and occlusion data from exhibit visitors. We show how GAIA was used to structure and navigate the compositional space and how this program supports both graphical and text-based programming in the same application. GAIA provides a GUI which combines two open-source applications: RTcmix and Perl.,10.1.1.1.2469,Real time audio GUI controllers video tracking,?
Mobile Middleware Solutions for the Adaptive Management of Multimedia QoS to Wireless Portable Devices,Paolo Bellavista Antonio Corradi,2003,New challenging service scenarios are integrating  wireless portable devices with limited and heterogeneous  capabilities. They are expected to access both  traditional and novel (context-dependent) Internet services.,10.1.1.1.2471,?,?
Toward Better Weighting of Anchors,David Hawking et al.,2004,Okapi BM25 scoring of anchor text surrogate documents has been shown to facilitate e#ective ranking in navigational search tasks over web data. We hypothesize that even better ranking can be achieved in certain important cases particularly when anchor scores must be fused with content scores by avoiding length normalisation and by reducing the attentuation of scores associated with high tf . Preliminary results are presented.,10.1.1.1.2472,General Terms Performance Experimentation Theory. Keywords Anchor text Enterprise search Web search,?
Data Mining and Tree-based Optimization,Bodek And Grossman H. Bodek R. L. Grossman H. V. Poor,1996,Consider a large collection of objects each of which has a large number of attributes of several di#erent sorts. We assume that there are data attributes representing data attributes which are to be statistically estimated from these and attributes which can be controlled or set. A motivating example is to assign a credit score to a credit card prospect indicating the likelihood that the prospect will make credit card payments and then to set a credit limit for each prospect in such a way as to maximize the over-all expected revenue from the entire collection of prospects. In the terminology above the credit score is called a statistical attribute and the credit limit a control attribute. The methodology we describe in the paper uses data mining to provide more accurate estimates of the statistical attributes and to provide more optimal settings of the control attributes. We briefly describe how to parallelize these computations. We also briefly comment on some of data management issues which arise for these types of problems in practice. We propose using object # For additional information please contact Robert L. Grossman Magnify Inc. 815 Garfield Oak Park IL 60304 708 383 7002 708 383 7084 fax rlg@magnify.com. This work was supported in part by the Massive Digital Data Systems (MDDS) Program which is supported by the Community Management Sta# in the Department of Defense.,10.1.1.1.2474,tree-based optimization parallel classification and regression trees stochastic,?
Robot Architectures for Believable Game Agents,Ian Horswill And,1999,Computer game character design and robotics share many  of the same goals and computational constraints. Both  attempt to create intelligent artifacts that respond  realistically to their environments in real time using  limited computation resources. Unfortunately none of the  current AI architectures is entirely satisfactory for either  field. We discuss some of the issues in believability and  computational complexity that are common to both fields  and the types of architectures that have been used in the  robotics world to cope with these problems. Then we  present a new class of architectures called role passing  architectures which combine the ability to perform high  level inference with real-time performance.,10.1.1.1.2475,?,?
A Sense of Place: Toward a Location-aware Information Plane for Data Centers,Justin Moore Jeff Chase Keith Farkas Partha Ranganathan,2004,The continuing drive to improve operating efficiency of information technology is motivating the development of knowledge planes or frameworks for coordinated monitoring and control of large data computing infrastructures. In this paper we propose the notion of a location- and environment-aware extended knowledge plane. Asanillustration  of such an extended knowledge plane we architect the Splice framework that extends the knowledge plane to include data from environmental sensors and the notions of physical location and spatial and topological relationships with respect to facilities-level support systems. Our proposed architecture is designed to support easy extensibility scalability and support the notion of higher-level object views and events in the data center. Using the above architecture we demonstrate the richness  of queries facilitated by Splice and discuss their potential  for automating several categories of data center maintenance and control. We also discuss our experience with deploying Splice on real-world data centers and discuss the value from Splice in the context on one specific optimization that would have otherwise not been possible without the extended knowledge plane. Finally we also provide evidence of the scalability of this deployment with number of readings both in terms of database storage and  query performance.,10.1.1.1.2476,?,?
Blind Channel Identifiability/Equalizability of Single Input Multiple Output Nonlinear Channels from Second Order Statistics,Roberto Lopez-Valcarce  Soura Dasgupta,2000,We explore the utility of second-order statistics for blind identification/equalization of nonlinear channels. Under standard assumptions it is shown that the channel cannot be identified to within a scaling factor from the output second order statistics but that the ambiguity is at a level that permits equalization. Weshow that these results cover cases that the prior literature does not address.,10.1.1.1.2477,?,?
Reasoning with Large Numbers of Individuals Moves on: Extending The Instance Store,Lei Li,?,?,10.1.1.1.2478,?,?
Bayesian Learning for Weakly Supervised Object Classification,Peter Carbonetto Gyuri Peter Carbonetto Gyuri Dorkó Cordelia Schmid,2004,We explore the extent to which we can exploit interest point detectors for representing and recognising  classes of objects. Detectors propose sparse sets of candidate regions based on local salience and  stability criteria. However local selection does not take into account discrimination reliability across  instances in the same object class so we realise selection by learning from weakly supervised data in  the form of images paired with their captions. Through experiments on a wide variety of object classes  and detectors we show that modeling object recognition as a constrained data association problem and  learning the Bayesian way by integrating over multiple hypotheses leads to sparse classifiers that outperform  contemporary methods. Moreover our learned representations based on local features leave little  room for improvement on standard image databases so we propose new data sets to corroborate models  for general object recognition.,10.1.1.1.2479,?,?
Bandwidth-Efficient Wireless Multimedia Communications,Lajos Hanzo,1998,?,10.1.1.1.2480,AWGN Additive white Gaussian noise,?
Philosophical Scrutiny for Run-Time Support of Application Ontology Development,Mariana Casella dos Santos Christoffel Dhaen Matthew Fielding Werner Ceusters Maaltecenter Blok A Derbystraat,2004,The development and maintenance of domain-specific application ontologies  require knowledge input from domain experts who are usually without any  formal ontology or AI background. When dealing with large-scale ontologies for  example of the kind with which we are currently familiar in the biomedical spheres  quality assurance becomes important in minimizing modelling mistakes and the application  errors which they bring in their wake. In this paper we describe how the  upper-level framework BFO (for: Basic Formal Ontology) developed by the Institute  for Formal Ontology and Medical Information Science is being used to provide  automatic error detection and run-time modelling support to the development of  LinKBase a large-scale medical domain ontology developed by Language and  Computing NV to serve a range of natural language processing applications.,10.1.1.1.2481,?,?
UBIWISE A Simulator for Ubiquitous Computing Systems Design,John J. Barton Vikram Vijayaraghavan,2003,We describe UbiWise a simulator for ubiquitous computing. The  simulator concentrates on computation and communications devices situated  within their physical environments. It presents two views each in a separate  window on the desktop of the users PC. One of the views provides a three  dimensional world built on the Quake III Arena graphics engine and serves to  simulate a first-person view of the physical environment of a user. The other  view built using Java shows a close-up view of devices and objects the user  may manipulate. These views act as one unified whole by maintaining a clientserver  model with a central server. Multiple users can attach to the same server  to create interactive ubiquitous computing scenarios. We describe how UbiWise  looks to researchers and examples of its use as tool for ubiquitous computing  research.,10.1.1.1.2482,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,Simulation modeling and analysis requires an investment in human resources and software. And the rewards from using simulation are significant. Many companies fine tune their operations and reduce waste using simulation. But in the end every time modeling and analysis are performed a decision has to be made whether the simulation is worth doing (Waite 1999). In this paper we will enumerate how AutoMod has been used to improve return on investment (ROI) from simulation.,10.1.1.1.2483,?,?
Fast Sparse Matrix Multiplication,Raphael Yuster Uri Zwick,2004,Let A and B two n    n matrices over a ring R (e.g. the reals or the integers) each containing at most m  non-zero elements. We present a new algorithm that multiplies A and B using O(m        ) algebraic  operations (i.e. multiplications additions and subtractions) over R. The naive matrix multiplication  algorithm on the other hand may need to perform #(mn) operations to accomplish the same task. For       the new algorithm performs an almost optimal number of only n    operations. For m      the new algorithm is also faster than the best known matrix multiplication algorithm for dense matrices  which uses O(n    ) algebraic operations. The new algorithm is obtained using a surprisingly straightforward  combination of a simple combinatorial idea and existing fast rectangular matrix multiplication  algorithms. We also obtain improved algorithms for the multiplication of more than two sparse matrices.,10.1.1.1.2485,?,?
Detecting Deception by Analysis of Competing Hypotheses,Christopher Elsaesser  Frank Stech,2003,This paper describes the central component of a system to assist intelligence analysts detect deception. We describe how deceptions exploit cognitive limits and biases and review prior work on processes that can help people recognize organized deceptions. Our process is based on Heuers Analysis of Competing Hypotheses which we automate by generating state-based plans and converting them to Bayesian belief networks. Our decision aid uses a concept from Bayesian classification to identify distinguishing evidence that a deceiver must hide and a counter-deceiver must uncover. We illustrate the process with one of the most   Century.,10.1.1.1.2486,?,?
Public Spending in Developing Countries: Trends . . .,S. Fan  N. Rao Shenggen Fan Neetha Rao,2003,The objective of this paper is to review trends in government expenditures in the  developing world to analyze the causes of change and to develop an analytical framework  for determining the differential impacts of various government expenditures on economic  growth.    Contrary to common belief it is found that structural adjustment programs increased  the size of government spending but not all sectors received equal treatment. As a share of  total government spending expenditures on agriculture education and infrastructure in  Africa on agricultural and health in Asia and on education and infrastructure in Latin  America all declined as a result of the structural adjustment programs.    The impact of various types of government spending on economic growth is mixed. In  Africa government spending on agriculture and health was particularly strong in promoting  economic growth. Asias investments in agriculture education and defense had positive  growth-promoting effects. However all types of government spending except health were  statistically insignificant in Latin America. Structural adjustment programs promoted growth  in Asia and Latin America but not in Africa.    Growth in agricultural production is most crucial for poverty alleviation in rural areas.  Agricultural spending irrigation education and roads all contributed strongly to this growth.  Disaggregating total agricultural expenditures into research and non-research spending reveals  that research had a much larger impact on productivity than non-research spending.         ii  Table of Contents     1. ,10.1.1.1.2487,?,?
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros B. A. Peters J. S. Smith D. J. Medeiros M. W. Rohrer,?,Silk    and SML are software libraries of Java C++ C# and VB.Net classes that support object-oriented discrete-event simulation. SML^TM is a new open-source or free software library of simulation classes that enable multi-language development of complex yet manageable simulations through the construction of usable and reusable simulation objects. These objects are usable because they express the behavior of individual entity-threads from the system object perspective using familiar process-oriented modeling within an object-oriented design supported by a general purpose programming language. These objects are reusable because they can be easily archived edited and assembled using professional development environments that support multilanguage cross-platform execution and a common component architecture. This introduction supports the tutorial session that describes the fundamentals of designing and creating an SML or Silk model.,10.1.1.1.2488,different people (SML 2001 Healy and Kilgore 1997,?
Bonds or Loans? On the Choice of International Debt Instrument by Emerging Market Borrowers,Galina Hale,2001,This paper analyzes the access of emerging market borrowers to international debt markets  and specifically their decision of whether to borrow from banks or on the bond market (a  decision that does not appear to have been analyzed in the literature before). This choice is  modeled using a framework that focuses on the implications of asymmetric information. In  this model monitoring by banks can attenuate moral hazard. But monitoring has costs which  cause the bank loan market to dry up faster than the bond market as risk and interest rates rise  (reflecting the presence of adverse selection). These are the factors that drive the borrowers  decision between bank loans or bonds and that determine whether high risk borrowers can access  international markets at all. The model predicts that borrowers from countries where economic  and political risks are highest will not have market access. More substantively it predicts that  borrowers from countries where economic and political risks are somewhat lower will issue junk  bonds while those from countries where risks are still lower will borrow from banks and that  borrowers from the lowest risk countries will issue high-quality (investment grade) bonds. A  censored regression model with random e#ects estimated using simulated maximum likelihood  supports these predictions and reveals the variables that a#ect the choice of debt instrument at  each end of the risk spectrum.,10.1.1.1.2489,Key words emerging markets international debt censored regression,?
Reference Ontologies — Application Ontologies:  Either/Or or Both/And?,Christopher Menzel,2003,The distinction between reference ontologies and application ontologies crept rather unobtrusively into the recent literature on knowledge engineering. A lot of the discourse surrounding this distinction – notably the one framing the workshop generating this collection of papers – suggests the two types of ontologies are in some sort of opposition to one another. Thus Borge et al. [3] characterize reference ontologies (more recently foundational ontologies) as rich axiomatic theories whose focus is to clarify the intended meanings of terms used in speci?c domains. Application ontologies by contrast provide a minimal terminological structure to ?t the needs of a speci?c community. Re?ecting their minimal nature Masolo et al. [7] refer to such ontologies as “lightweight” ontologies. An application ontology can be lightweight in a second respect as well namely that it may not necessarily take the form of fully-?edged axiomatic theory. Rather it might only be a taxonomy of the relevant domain a division of the domain into a salient collection of classes perhaps ordered by the subclass relation. Importantly though for an application ontology to “?t the needs of a speci?c community” needn’t require representational accuracy. In the “worst” case (from a reference ontology perspective) to ?t the needs of a community is just to represent uncritically what people in that community think about the ontology’s domain. The preceding paragraph is perhaps a good ?rst cut but it strikes me that the distinction between reference ontologies and application ontologies has not been clearly made. To clarify the distinction and its signi?cance is my goal in this short paper. I conclude that in fact the distinction is not really an opposition rather reference ontologies and application ontologies re?ect different aspects of a single methodology for ontology development. ,10.1.1.1.2490,?,?
Fractional Laplace Model for Hydraulic Conductivity,Mark M. Meerschaert  Tomasz J. Kozubowski  Fred J. Molz Silong Lu,2004,Introduction  The stochastic theory of non-stationary processes with stationary increments began to be applied to detailed hydraulic conductivity (K) measurements during the early 1990s [Molz and Bowman 1993 Painter 1996]. Numerous additional applications followed [Molz et al. 2003]. Initial studies assumed that ln(K) increments or fluctuations (the stationary process) would follow Gaussian probability density functions (PDFs). However careful analysis of a variety of measurements soon showed that the increment PDFs were strongly non-Gaussian with a distinct resemblance to the Levy-stable PDF [Painter and Paterson 1994]. This PDF was attractive because like the Gaussian PDF it served as the natural mathematical basis for a stochastic fractal. Still further analysis of measurements and simulations led researchers to realize that the tails of the empirical PDFs do not have a power-law decay [Painter 1996 Lu and Molz 2001]. This led to the proposal of stochastic models that c,10.1.1.1.2492,?,?
Assessing the Reliability of open Source Information,David F. Noble,2004,Open source information on the Internet can contribute significantly to such assessments as competitive intelligence business trends or evolving social attitudes. However because the accuracy of this open source information varies widely the correctness of the information needs to be assessed before it can be used reliably. Current methods for estimating correctness rely on the subjective opinions of knowledgeable people in the field and can vary among evaluators. Today new data collection and information management tools enable objective reviewer-independent assessment of open source information correctness. These tools support four objective methods for estimating reliability: (1) objective assessment of the historical accuracy of a particular source by subject matter and viewpoint (2) selfassessment of reliability from the source itself (3) consistency of report with prior incidents and with established facts and (4) consistency of information with other independent reports. This paper describes how these techniques are employed in Evidence Based Researchs war rooms to help clients understand the diversity and credibility of viewpoints on clientselected topics.,10.1.1.1.2493,open source reliability objective fusion 1 The assessment problem,International Society of Information Fusion
Ronald M. Lee,And Jos Van Ronald M. Lee Jos Van Hillegersberg,2001,This paper introduces the concept of an electronic trade scenario as an aid to the management of (global) supply chains and other forms of international businessto -business electronic commerce. The problem addressed is the following. Competition demands that trade transactions be handled efficiently and securely. However the same competitive environment also demands flexibility and the ability to re-design the supply chain as conditions change. Current advances in electronic document technologies notably XML schemas ebXML offer new possibilities for generic resusable component software at the level of document specifications. Here we address the additional challenge of supporting the rapid re-engineering of the process specifications for the supply chain. For this we focus on the component technologies for electronic trade scenarios: generic reusable models of the entire trade transaction. They are stored in a on-line repository where each member of the supply chain can download the transaction component for their role in the transaction. We describe a CASE tool called InterProcs which provides a graphical modeling internface for supply chain process specifications at several levels of abstraction including Unified Modeling Language (UML) and Documentary Petri Nets (DPN). Once specified InterProcs auotmatically produces an operating prototyping of the supply chain transaction model. In this paper we address the additional step to production implementation of the prototype supply chain model using distributed component technology. Because we are concerned with open standards we focus specially on the Java 2 Enterprise Edition (J2EE) platform.,10.1.1.1.2494,?,?
Extending Practical Pre-Aggregation in On-Line Analytical Processing,Torben Bach Pedersen et al.,1999,On-Line Analytical Processing (OLAP) based on  a dimensional view of data is being used increasingly  for the purpose of analyzing very large  amounts of data. To improve query performance  modern OLAP systems use a technique known  as practical pre-aggregationwhereselect combinations  of aggregate queries are materialized  and re-used to compute other aggregates full preaggregation  where all combinations of aggregates  are materialized is infeasible. However this reuse  of aggregates is contingent on the dimension  hierarchies and the relationships between facts  and dimensions satisfying stringent constraints  which severely limits the scope of practical pre-aggregation. This paper,10.1.1.1.2496,?,?
Temporal Entity-Relationship Models - A Survey,Heidi Gregersen  Christian S. Jensen Senior Member,1999,The Entity-Relationship (ER) model using varying notations and with some semantic variations is enjoying a  remarkable and increasing popularity in both the research community#the computer science curriculum#and in industry. In step  with the increasing diffusion of relational platforms ER modeling is growing in popularity. It has been widely recognized that  temporal aspects of database schemas are prevalent and difficult to model using the ER model. As a result how to enable the ER  model to properly capture time-varying information has for a decade and a half been an active area in the database-research  community. This has led to the proposal of close to a dozen temporally enhanced ER models. This paper surveys all temporally  enhanced ER models known to the authors. It is the first paper to provide a comprehensive overview of temporal ER modeling and  it thus meets a need for consolidating and providing easy access to the research in temporal ER modeling. In the presentation of  each model the paper examines how the time-varying information is captured in the model and presents the new concepts and  modeling constructs of the model. A total of 19 different design properties for temporally enhanced ER models are defined and each  model is characterized according the these properties.,10.1.1.1.2497,?,?
Controlling Spam by Secure Internet Content Selection,Amir Herzberg,2004,Unsolicited and undesirable e-mail (spam) is a growing problem for Internet users and service providers. We present the Secure Internet Content Selection (SICS) protocol an efficient cryptographic mechanism for spam-control based on allocation of responsibility (liability). With SICS e-mail is sent with a content label and a cryptographic protocol ensures labels are authentic and penalizes falsely labeled e-mail (spam). The protocol supports trusted senders (penalized by loss of trust) and unknown senders (penalized financially). The recipient can determine the compensation amount for falsely labeled e-mail (spam)). SICS is practical with negligible overhead gradual adoption path and use of existing relationships it is also flexible and appropriate for most scenarios including deployment by end users and/or ISPs and support for privacy and legitimate properly labeled commercial e-mail. SICS improves on other crypto-based proposals for spam controls and complements non-cryptographic spam controls.,10.1.1.1.2498,?,?
Soft Computing Methodologies for Structural Optimization,Manolis Papadrakakis Nikos D. Lagaros,2003,The paper examines the efficiency of soft computing techniques in structural optimization in particular algorithms based on evolution strategies combined with neural networks for solving large-scale continuous or discrete structural optimization problems. The proposed combined algorithms are implemented both in deterministic and reliability based structural optimization problems in an effort to increase the computational efficiency as well as the robustness of the optimization procedure. The use of neural networks was motivated by the time-consuming repeated finite element analyses required during the optimization process. A trained neural network is used to perform either the deterministic constraints check or in the case of reliability based optimization both the deterministic and the probabilistic constraints checks. The suitability of the neural network predictions is investigated in a number of structural optimization problems in order to demonstrate the computational advantages of the proposed methodologies.,10.1.1.1.2499,Evolution strategies Neural networks Structural optimization Reliability analysis Monte Carlo simulation Parallel computations,?
Power-Aware Multimedia Streaming in Heterogeneous Multi-User Environments,Radu Cornea  Shivajit Mohapatra Nikil Dutt  Alex Nicolau Nalini Venkatasubramanian,?,Streaming multimedia content to heterogeneous handheld devices is a significant research challenge due to  the diverse computation capabilities and battery lifetimes of these devices. A unified framework that integrates  low level architectural optimizations (CPU memory) OS power-saving mechanisms (Dynamic Voltage Scaling)  and adaptive middleware techniques (admission control transcoding network tra#c regulation) can provide  significant improvements in both the system performance and user experience. In this paper we present such an  integrated framework and investigate the trade-o#s involved in serving distributed clients simultaneously while  maintaining acceptable QoS levels for each client. We show that the power savings attained at both CPU/memory  and network levels can be aggregated for increased overall performance. Based on this we demonstrate how an  integrated framework that supports tight coupling of inter-level parameters can enhance user experience on  handheld devices.,10.1.1.1.2500,?,?
As we may live -- Real-world implications of Ubiquitous Computing,Marc Langheinrich Vlad Coroama Jürgen Bohn Michael Rohs,2002,The young field of ubiquitous computing is steadily making progress  and gaining attention in both academia and industry. While new gadgets and  smart home appliances cannot appear fast enough for many technologists such  rapid introductions of new technologies often come with unexpected side-effects. Due to the,10.1.1.1.2501,?,?
Internets Critical Path Horizon,S. Valverde  R.V. Sole,?,Internet is known to display a highly heterogeneous structure and complex fluctuations in its  tra#c dynamics. Congestion seems to be an inevitable result of users behavior coupled to the network  dynamics and it e#ects should be minimized by choosing appropriate routing strategies. But what are the  requirements of routing depth in order to optimize the tra#c flow? In this paper we analyse the behavior of  Internet tra#c with a topologically realistic spatial structure as described in a previous study [S.-H. Yook  et al. Proc. Natl Acad. Sci. USA 99 13382 (2002)]. The model involves self-regulation of packet generation  and di#erent levels of routing depth. It is shown that it reproduces the relevant key statistical features  of Internets tra#c. Moreover we also report the existence of a critical path horizon defining a transition  from low-e#cient tra#c to highly e#cient flow. This transition is actually a direct consequence of the  webs small world architecture exploited by the routing algorithm. Once routing tables reach the network  diameter the tra#c experiences a sudden transition from a low-e#cient to a highly-e#cient behavior. It  is conjectured that routing policies might have spontaneously reached such a compromise in a distributed  manner. Internet would thus be operating close to such critical path horizon.,10.1.1.1.2502,?,?
Terminological Mapping For,High Throughput Comparative Y. A. Lussier J. Li,2004,this paper were written in Perl and SQL. The Database used was IBM  BD2 for workgroup version 7. Additionally the Norm component of the UMLS Lexical Tools was obtained from the National Library of Medicine in 2003. Applications were run on a Dual-processor SUN UltraSparc III V880 under the SunOS 5.8 operating system,10.1.1.1.2503,?,?
Genome Informatics 14: 390--391 (2003) Transcriptome Profiling and Deciphering the Regulatory Role of Global Transcription Factor fadR,Ung Hun Kim Byung Hun Kim Si Jae Park Sang Yup Lee,?,Introduction  fadR is a transcription factor which has a Helix-turn-Helix motif [5] one of most common prokaryotic transcription factor. It regulates metabolic pathway such as the fatty acid biosynthesis and degradation pathways glyoxylate pathway and possible role in regulation of amino acid biosynthesis directly or indirectly [1 2 3 4]. By use of cDNA microarray one can search for regulation of transcription factors and its impact on metabolism using microarray data analysis and sequence information.  By comparing wild-type W3110 strain fadR null mutant strain subjecting them in various conditions (i.e. di#erent carbon sources such as oleic acid) it is possible to identify the functional role of fadR [1 3]. Also candidate genes that could possibly be regulated by fadR can be predicted using sequence information which assist microarray data analysis.  Expression profile of wild-type W3110 strain and fadR null mutant strain (WFR) was compared in LB media (peptone 10g/L yeas,10.1.1.1.2505,transcriptome fatty acid transcription factor,?
Discovering Web Services Using Behavioural,Constraints And Ontology Natenapa Sriharee Twittie Senivongse,2003,The ability to locate useful on-line Web Services is becoming critical  for todays service-oriented business applications. A number of efforts have  been put to enhance the service discovery process by using conceptualised  knowledge called ontology of particular service domains to describe service  characteristics. This paper presents an ontology-based approach to enhance  descriptions of Web Services that are expressed in WSDL with ontology-based  behavioural information i.e. input conditional/unconditional output  precondition and conditional/unconditional effect of the services. Having a  service ontology associated with each Web Service description queries for  services based on behavioural constraints can benefit from inferring semantics  of the service from the service ontology. The service discovery process  becomes closer to discovery by service semantics or behaviour in contrast with  discovery by matching of service attributes values -- the mechanism that is  supported currently by Web Services.,10.1.1.1.2506,?,?
Indexing and Retrieval of On-line Handwritten Documents,Anil Jain And,?,Recent advances in on-line data capturing technologies and its widespread deployment in devices like PDAs and notebook PCs is creating large amounts of handwritten data that need to be archived and retrieved efficiently. Word-spotting which is based on a direct comparison of a handwritten keyword to words in the document is commonly used for indexing and retrieval. We propose a string matching-based method for word-spotting in on-line documents. The retrieval algorithm achieves a precision of 92.3% at a recall rate of 90% on a database of 6 672 words written by 10 different writers. Indexing experiments show an accuracy of 87.5% using a database of 3 872 on-line words.,10.1.1.1.2507,Online Document Word Spotting Indexing Document Retrieval,?
Tuples On The Air: a Middleware for Context-Aware Computing in Dynamic Networks,Marco Mamei Franco Zambonelli Letizia Leonardi,2003,We present TOTA (Tuples On The Air) a novel  middleware for supporting adaptive context-aware  application in dynamic network scenarios. The key idea  in TOTA is to rely on spatially distributed tuples for  both representing contextual information and  supporting uncoupled and adaptive interactions  between application components. The middleware  propagates tuples across a network on the basis of  application-specific patterns and adaptively re-shapes  the resulting distributed structures accordingly to  changes in the network scenario. Application  components can locally sense these structures and  exploit them to acquire contextual information and  carry on complex coordination activities in an adaptive  way. Several examples show the effectiveness of the  TOTA approach.,10.1.1.1.2508,?,Press
Seven Dimensions of Portability for Language Documentation and Description ,Steven Bird Gary Simons ,2003,The process of documenting and describing the worlds languages is undergoing radical transformation with the rapid uptake of new digital technologies for capture storage annotation and dissemination. While these technologies greatly enhance our ability to create digital data their uncritical adoption has compromised our ability to preserve this data. The new digital language resources of all kinds -- lexicons interlinear texts grammars language maps field notes recordings -- are difficult to reuse and less portable than the conventional printed resources they replace. This article is concerned with the portability of digital language resources specifically with their ability to transcend computer environments scholarly communities domains of application and the passage of time. We begin by reviewing current uses of software tools and digital technologies for language documentation and description. This sheds light on how digital language resources are created and managed and leads to an analysis of portability problems in the seven areas of content format discovery access citation preservation and rights. After characterizing each problem we articulate a set of values which underlie our intuitions about good and bad practices and which serve as requirements for new practices supporting the creation of portable language resources. Next we lay out an extensive set of recommendations to serve as a starting point for the community-based effort that we envision. We conclude with a discussion of OLAC  the Open Language Archives Community which provides a process that may be used to identify community-agreed best practices over the long term.,10.1.1.1.2509,?,?
Processing Multi-modal Primitives from Image Sequences,Norbert Krüger Michael Felsberg Florentin Wörgötter,2004,In this paper we describe a new kind of image representation in terms of local multi--modal Primitives. Our  local Primitives can be characterized by three properties: (1) They represent different aspects of the image in  terms of multiple visual modalities. (2) They are adaptable according to context. (3) They provide a condensed  representation of local image structure.,10.1.1.1.2510,?,?
Mixed Emotions: Teachers Perceptions Of Their Interactions With Students,Andy Hargreaves,2000,This paper describes the conceptual framework methodology and some results from a project on the Emotions of Teaching and Educational Change. It introduces the concepts of emotional intelligence emotional labor emotional understanding and emotional geographies. Drawing on interviews with 53 teachers in 15 schools the paper then describes key di!erences in the emotional geographies of elementary and secondary teaching. Elementary teaching is characterized by physical and professional closeness which creates greater emotional intensity but in ambivalent conditions of classroom power where intensity is sometimes negative. Secondary teaching is characterized by greater professional and physical distance leading teachers to treat emotions as intrusions in the classroom. This distance the paper argues threatens the basic forms of emotional understanding on which high-quality teaching and learning depend. # 2000 Elsevier Science Ltd. All rights reserved.,10.1.1.1.2511,Emotions of teaching Elementary teachers Secondary teachers,?
Effects of Growth Hormone Transgenesis on Metabolic,Rate Exercise Performance D. J. Mckenzie A. Morales J. Acosta R. Morales E. W. T Aylor J. F. Steffensen,?,te oxygen uptake.  INTRODUCTION  There has been much recent interest in the potential for enhancement of fish growth in aquaculture through genetic manipulation (Du et al. 1992 Devlin et al. 1994 Martinez et al. 1996 1999). A strain of growth hormone transgenic (GHT) tilapia Oreochromis sp. hybrids has been created that expresses homologous tilapia growth hormone (GH) at low levels in its tissues and exhibits increased growth relative to wild-type (W) conspecifics (de la Fuente et al. 1995 Martinez et al. 1996 1999).  +Author to whom correspondence should be addressed at present address: CREMA LHoumeau Place du Se minaire B.P. 5 17137 LHoumeau France. Tel.:    5 46 50 06 29 fax:    5 46 50 06 00 email: david.mckenzie@ifremer.fr  Journal of Fish Biology (2003) 63 398--409  doi:10.1046/j.1095-8649.2003.00162.xavailableonlineathttp://www.blackwell-synergy.com 398  # 2003 The Fisheries Society of the British Isles  Tilapia are important in warm-water aquaculture throug,10.1.1.1.2512,?,?
Does Radioactivity Correlate with the Annual Orbit of Earth around Sun?,Gerhard Wolfgang Bruhn,2002,be the true solution but this is ---as will be shown---a flawed reasoning.  Keywords: Radioactivity Neutrinos Solar activity  Determinism Quantum mechanics Causality  1 Analysing the data  Since Figure 2 in [1] is not sufficient for a mathematical analysis of the data I asked E.D. Falkenberg for the data in form of a numerical list. Falkenberg was so kind as to send me his data of 73 measurements [t M(t)] (attached in the Appendix) adding the comment that he wondered what an analysis of the data by a  mathematician could bring out in addition.  Now here is the result:  First of all I plotted the graph of the measurements [t M(t)] (see Fig.  1). A careful examination of the graph of M(t) seems to show a slight  corner at t 1 = 223.4. In order to consider the graph in more detail we make use of a kind of microscope.  We know from experience that radioactive decay is (at least roughly) governed by exponential decrease. Hence we remove the exponential function by taking the lo,10.1.1.1.2514,Radioactivity Neutrinos Solar activity Determinism Quantum mechanics Causality 1 Analysing the data,?
Individual Information,Adaptation Based On Internet Metadata Erik Oskar Wallin,?,Todays increasing information supply raises the need for more effective and automated information processing where individual information adaptation (personalization) is one possible solution. Earlier computer systems for personalization lacked the ability to easily define and measure the effectiveness of personalization efforts. Numerous projects failed to live up to the their expectations and the demand for evaluation increased. This thesis presents some underlying concepts and methods for implementing personalization in order to increase stated business objectives. A personalization system was developed that utilizes descriptions of information characteristics (metadata) to perform content based filtering in a non-intrusive way. Most of the described measurement methods for personalization in the literature are focused on improving the utility for the customer. The evaluation function of the personalization system described in this thesis takes the business operator?s standpoint and pragmatically focuses on one or a few measurable business objectives. In order to verify operation of the personalization system a function called bifurcation was created. The bifurcation function divides the customers stochastically into two or more controlled groups with different personalization configurations. By giving one of the controlled groups a personalization configuration that deactivates the personalization a reference group is created. The reference group is used to measure quantitatively objectives by comparison with the groups with active personalization. Two different companies had their websites personalized and evaluated: one of Sweden?s largest recruitment services and the second largest Swedish daily newspaper. The purpose with the implementations was to define measure and increase the business objectives. The results of the two case studies show that under propitious conditions personalization can be made to increase stated business objectives. Keywords: metadata semantic web personalization information adaptation one-to-one marketing evaluation optimization personification customization individualization internet content filtering automation.,10.1.1.1.2515,metadata semantic web personalizati,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Bert Van Beek Niek G. Jansen Koos E. Rooda Ramon R. H. Schiffelers,?,A hybrid automaton is one of the most popular formal models for hybrid system specification. The Chi language is a hybrid formalism for modeling simulation and verification. It consists of a number of operators that operate on all process terms including differential algebraic equations. This paper relates the two formalisms by means of a formal translation from a hybrid automaton model to a Chi model and a comparison of the semantics of the two models in terms of their respective transition systems. The comparison is illustrated by means of three examples: a thermostat a railroad gate controller and dry friction.,10.1.1.1.2516,?,?
JVTOS -- A Multimedia Telecooperation Service Bridging Heterogeneous Platforms,Konrad Froitzheim  Michael Weber,?,... This paper describes the design and implementation of JVTOS on different platforms. ,10.1.1.1.2518,?,?
FCND DP No. 121,Fcnd Discussion Paper Michelle Adato Lawrence Haddad,?,Since the transition to democracy South African public works programs are to involve community participation and be targeted to the poor and women. This paper examines the targeting performance of seven programs in Western Cape Province and analyzes the role of government community-based organizations trade unions and the private sector in explaining targeting outcomes. These programs were not well-targeted geographically in terms of poverty unemployment or infrastructure. Within localities jobs went to the poor and unemployed though not always the poorest. They did well in reaching women despite local gender bias. Targeting guidelines of the state are mediated by diverse priorities that emerge in programs with multiple objectives local perceptions of need and entitlement and competing voices within civil society.   iii  CONTENTS  Acknowledgments............................................................................................................... v 1. ,10.1.1.1.2519,1. Introduction.....................................................................................,?
Rigid Melting and Flowing Fluid,Mark Thomas Carlson,2004,?,10.1.1.1.2520,DEDICATION......................................... iii,?
Passwords Youll Never Forget But Cant Recall,Daphna Weinshall School Daphna Weinshall,2004,We identify a wide range of human memory phenomena as potential certificates of identity. These imprinting  behaviors are characterized by vast capacity for complex  experiences which can be recognized without apparent  effort and yet cannot be transferred to others. They are  suitable for use in near zero-knowledge protocols which  minimize the amount of secret information exposed to  prying eyes while identifying an individual. We sketch  several examples of such phenomena[1-3] and apply them  in secure certification protocols. This provides a novel  approach to human-computer interfaces and raises new  questions in several classic areas of psychology.,10.1.1.1.2521,interfaces,ACM Press
One for All and All in One,Learner Modelling Server Isabel Machado Re Martins Ana Paiva,1999,For the past few years several research teams have been developing intelligent  learning environments (ILE) based on multi-agent architectures. For such type of architectures  to be possible the agents must have specific roles in the architecture and must  be able to communicate in between them. To handle such needs we have established a  generic multi-agent architecture - the Pedagogical Agents Communication Framework  (PACF). In PACF a set of agents were defined their roles established and their communication  infrastructure built. Such communication infrastructure is based on a subset of  the KQML language. There are two main general agents in PACF: the Server that acts  both as a facilitator in the KQML sense and as an application-independent name server  and a Learner Modelling Server (LMS). The LMS can be used by several applications  (composed by several agents) and each one can adapt the modelling strategy to its needs  through the parameterisation of three configuration files: one that provides the application  domain structure and the others the learner modelling strategies. Through this  parameterisation the applications define how the LMS will model their learners. The  LMS keeps one single database for all the learners being modelled by all the agents allowing  different applications to access to the same learner model simultaneously. These  different applications can share parts of the learner models provided that they use the  same domain ontology in the modelling process. This architecture has been used in a  Web based distance learning scenario with two different ILEs.,10.1.1.1.2522,?,Springer-Verlag
Reactive Petri Nets for Workflow Modeling,Rik Eshuis Juliane Dehnert,2003,Petri nets are widely used for modeling and analyzing workflows.,10.1.1.1.2524,?,Springer
A Tale of Two Helicopters,Srikanth Saripalli Jonathan Jonathan M. Roberts Peter I. Corke Gregg Buskey Gaurav S. Sukhatme,2003,This paper discusses similarities and differences in autonomous helicopters developed at USC and CSIRO. The most significant differences are in the accuracy and sample rate of the sensor systems used for control. The USC vehicle like a number of others makes use of a sensor suite that costs an order of magnitude more than the vehicle. The CSIRO system by contrast utilizes low-cost inertial magnetic vision and GPS to achieve the same ends.,10.1.1.1.2525,?,?
On the Stability of Equation-Error Estimates of All-Pole Systems,Roberto Lopez-Valcarce  Soura Dasgupta,1998,It is well known that the standard equation-error (EE) method for the identification of linear systems yields biased estimates if the data are noise corrupted. Due to this bias the resulting estimate can be unstable in some cases depending on the spectral characteristics of the input and the noise the signal-tonoise ratio (SNR) and the unknown system. In this work the set of all-pole linear systems whose equation-error estimate is stable for all wide sense stationary inputs and white measurement noise is investigated. Some results concerning the structure of this set are given.,10.1.1.1.2526,?,?
A Comparison Of Efficacy And Assumptions Of Bootstrapping Algorithms For Training Information Extraction Systems,Rayid Ghani Rosie Jones ,2002,Information Extraction systems offer a way of automating the discovery of information from text documents. Research and commercial  systems use considerable training data to learn dictionaries and patterns to use for extraction. Learning to extract useful information from  text data using only minutes of user time means that we need to leverage unlabeled data to accompany the small amount of labeled data.,10.1.1.1.2527,?,?
Commission Of The European Communities,Brussels Com Final,?,This report will then be transmitted to the European Parliament the Council and the European Economic and Social Committee. It will be accompanied if necessary by proposals for amendments to the Directive in order to bring it into line with the developments observed in the Internal Market. Paragraph 2 lays down that the Member States must provide the Commission with all the aid and assistance it may need when drawing up that report,10.1.1.1.2528,?,?
Model-Based 3D Face Capture with Shape-from-Silhouettes,Baback Moghaddam Jinho Jinho Lee Hanspeter Pfister Raghu Machiraju,2003,We present a method for 3D face acquisition using a set or sequence of 2D binary silhouettes. Since silhouette images depend only on the shape and pose of an object they are immune to lighting and/or texture variations (unlike feature or texture-based shape-from-correspondence). Our prior 3D face model is a linear combination of eigenheads obtained by applying PCA to a training set of laser-scanned 3D faces. These shape coefficients are the parameters for a near-automatic system for capturing the 3D shape as well as the 2D texture-map of a novel input face. Specifically we use back-projection and a boundary-weighted XOR-based cost function for binary silhouette matching coupled with a probabilistic downhill-simplex optimization for shape estimation and refinement. Experiments with a multi-camera rig as well as monocular video sequences demonstrate the advantages of our 3D modeling framework and ultimately its utility for robust face recognition with built-in invariance to pose and illumination.,10.1.1.1.2529,?,?
New Semantics for Hybrid Probabilistic Programs,Emad Saad,?,Hybrid probabilistic programs framework [5] is a variation  of probabilistic annotated logic programming approach which allows the  user to explicitly encode the available knowledge about the dependency  among the events in the program. In this paper we extend the language  of hybrid probabilistic programs by allowing disjunctive composition  functions to be associated with heads of clauses and change its  semantics to be more suitable for real-life applications. We show on  a probabilistic AI planning example that the new semantics allows us  to obtain more intuitive and accurate probabilities. The new semantics  of hybrid probabilistic programs subsumes Lakshmanan and Sadri [17]  framework of probabilistic logic programming. The fixpoint operator for  the new semantics is guaranteed to be always continuous. This is not the  case in the probabilistic annotated logic programming in general and the  hybrid probabilistic programs framework in particular.,10.1.1.1.2530,?,?
The Continuity Property In Mixed Reality And Multiplatform Systems: A Comparative Study,Murielle Florins Daniela G. Trevisan  Jean Vanderdonckt Jean V,2004,Continuity as usability property has been used in mixed reality systems and in  multiplatform systems. This paper compares the definitions that have been  given to the concept in both fields. Continuity is then given in a consolidated  definition.,10.1.1.1.2531,Augmented reality Continuity Mixed reality Multiplatform systems. 1. CONTINUITY IN THE LITERATURE,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Glenn P. Rioux,?,The title poses the essential question addressed herein: Is it possible to construct simulations that permit use in application domains with widely ranging objectives? The question is raised in a tentative explanation of what is entailed in an answer. Beginning with a taxonomy based on simulation objectives we identify differences among the categories with respect to what is attendant in realizing different objectives and in using associated methodologies and tools. The closing summary highlights the importance of producing an answer or eliminating the question.,10.1.1.1.2532,?,?
Special Purpose Simulation . . .,Appleton E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes John Patra,2002,Historically simulation tools have only been used and understood by the academic community. Special Purpose Simulation (SPS) techniques have introduced computer modeling to the industry resulting in reduced model development time and a user-friendly environment. This paper describes the special purpose simulation template which is based on the tower crane operations performed by PCL Constructors Inc. On-site management of the tower crane resource is based on prioritized work tasks that need to be performed within a set period of time. Traditional SPS modeling techniques use `relationship logic links to represent the logic contained in the modeled system. As the number of work tasks increases for the tower crane resource the model complexity using traditional simulation techniques becomes unmanageable resulting in limited acceptance by industry practitioners. The tower crane template uses `priority rating logic to replace the `relationship logic links. Evaluation of the tower crane operations at the Electrical and Computer Engineering Research Facility (ECERF) being constructed in Edmonton is used to illustrate the advantages of using the `priority rating logic modeling approach for tower crane operations. The simulation model analyzes the ECERF tower crane production cycle yielding outputs for total duration crane utilization and lift activity hook-time analysis.,10.1.1.1.2533,?,?
Modeling Dependencies between Variation Points in Use Case Diagrams,Stan Bühne Günter Halmans Klaus Pohl,2003,Software product family variability facilitates the constructive and pro-active reuse of assets during the development of software applications. The variability is typically represented by variation points the variants and their interdependencies. Those variation points and their variants have to be considered when defining the requirements for the applications of the software product family. To facilitate the communication of the variability to the customer an extension to UML-use case diagrams has been proposed in [9]. In this,10.1.1.1.2534,?,?
When Does a Robot Perceive a Dynamic Object?,K. Madhava Krishna Prem K. Kalra,2002,INTRODUCTION  LiterafiJ eaWW3@-- with ath oahfiW fordea:1 with collision alisionfi ina dyna--L environment. Some of these ase oaefiW require prior knowledge of the # To whom am correspondence should beafi essed e-mafi kkrishnaL----fiOJ1Jfia positionas traionfiL@@L of the objects.  12  Other ahe oaerfi compute the robotspat ina sta--@ environment using globa straL--OWfi  3--5  The computed pap is repla--3fi whendyna: objectsa e introducedtha  crisscross thepla:LL pa: La: a proaLLJ tha involve fuzzy inferencing or neurofuzzy bazy controlha: a: been reported.  67  Recent strafi@:O har extended this tosituaOfi1 tha involve Jourr of Robotic Systems 19(2) 73--90 (2002)  2002 by John Wiley  Sons Inc. coopera1@ collision of multiple robotstha pla aa executea tacu  8  In afi theseaes oasefiW either theexa position or velocity informaW:J of thedynaJJ objectsa e afi--L: to beafiWLLJfi either before the pafi is pla--L or during rea time. However it is difficult to provide such i,10.1.1.1.2535,?,?
Funded in part by NIMH grant ROI MH 57234 and NIAID grant RO1 AI 36986,Corresponding Author Division Jonathan M. Ellen Margaret M. Dolcini Natasha D. Bir Gary W. Harper Susan Watson Thomas Valente,2001,y  experienced. Adolescents location in their social world is associated with sexual behavior among the  close friends of a household sample of urban African American youth.  INTRODUCTION  Thebiologicalemotionalandpsychologicalvulnerabilityofadolescenceaccentuatepotentialnegative outcomes of sexual activity such as sexually transmitted diseases and unwanted pregnancy. Efforts intended to delay onset of sexual behavior would benefit from additional information about determinants of this behavior. One important area of investigation in this area is the role peers play in the onset of sexual behavior (oral anal or vaginal intercourse). Studies show that adolescents perceptions and attitudes about their peers behaviors as well as the peers self-reported behaviors are influential. Adolescents who perceive that their peers have actually engaged in sexual intercourse and those who perceive that their peers are accepting of sexual intercourse are more likely to be sexually experienced,10.1.1.1.2536,?,?
Mtid Discussion Paper No. 66,Markets Trade And Asfaw Negassa Robert Myers Eleni Gabre-madhin,?,In the context of on-going market reform in developing countries there is a need for an  improvement in the existing methods of spatial market efficiency analysis in order to better  inform the debate toward designing and implementing new grain marketing policies institutions  and infrastructure that facilitate the emergence of a well developed and competitive grain  marketing system. The standard parity bounds model (PBM) while it overcomes many  weaknesses of the conventional methods of spatial market efficiency analysis it does not allow  for the test of structural changes in spatial market efficiency as a result of policy changes. In this  paper building on the standard PBM we develop an extended parity bounds model (EPBM). The  EPBM is a stochastic gradual switching model with three trade regimes. The EPBM is estimated  by maximum likelihood procedure and allows for tracing the time path and structural change in  spatial market efficiency conditions due to the policy changes. We applied the EPBM to analyze  the effect of grain marketing policy changes on spatial efficiency of maize and wheat markets in  Ethiopia. The results show that the effect of policy changes on spatial market efficiency is not  significant statistically in many cases there is high probability of spatial inefficiency in maize and  wheat markets before and after the policy changes. The implication of these results is that maize  and wheat markets are characterized by periodic gluts and shortages which can undermine the  welfare of producers grain traders and consumers. It is also observed that the nature of spatial  inefficiency for maize and wheat markets is different implying that the two commodities might  require different policy responses in order to improve spatial market efficie...,10.1.1.1.2537,?,?
Multi Target Tracking of Ground Targets in Clutter with LMIPDA-IMM,Darko Musicki  Sofia Suvorova Subhash Challa,?,Tracking of ground targets presents a number of challenges. Target trajectories meet various motion constraints. Substantial non-homogenous clutter is usually present. In multitarget situations measurement assignment may be computationally challenging as the number of operations increases exponentially with number of tracks and number of measurements. LMIPDA-IMM aims to provide a solution to these issues. Use of the IMM approach allows tracking ground targets with motion constraints and/or maneuvers. LMIPDA calculates the probability of target existence for false track discrimination to enable automatic track initiation and termination. The robust data association properties of LMIPDA are further enhanced by the use of a clutter map. LMIPDA provides multi-target data association with number of operations linear in the number of tracks and the number of measurements. Simulation studies illustrate the effectiveness of this approach in an environment of heavy non-homogenous clutter.,10.1.1.1.2538,Tracking Probabilistic data association (PDA Integrated PDA (IPDA Linear-Multitarget LMIPDA Interacting Multiple Model (IMM,?
An User-centric MIX-net Protocol to Protect Privacy,Alessandro Acquisti,2002,MIX-net systems protect the privacy of participants by clouding together their transactions  through cascades of third parties. Reliability and trust are therefore open issues in  this literature and limit the applicability of these systems. This paper discusses how the  MIX approach can be adapted to put the user at the center of the protocol and in control  of it so that each participant can take active steps to protect his or her privacy. The paper  also highlights various possible uses of the protocol. Being in control comes at a cost  however and the paper discusses the trade-o#s arising from the proposed approach.,10.1.1.1.2539,?,?
FCND DP No. 96 FCND DISCUSSION PAPER NO. 96 ATTRITION IN LONGITUDINAL HOUSEHOLD SURVEY DATA: SOME TESTS FOR THREE,Developing-country Samples Harold Alderman Jere R. Behrman Hans-peter Kohler John A. Maluccio Susan Cotts Watkins,?,Longitudinal household data can have considerable advantages over much more widely used cross-sectional data. The collection of longitudinal data however may be difficult and expensive. One problem that has concerned many analysts is that sample attrition may make the interpretation of estimates problematic. Such attrition may be particularly severe in areas where there is considerable mobility because of migration between rural and urban areas. Many analysts share the intuition that attrition is likely to be selective on characteristics such as schooling and that high attrition is likely to bias estimates made from longitudinal data. This paper considers the extent of and implications of attrition for three longitudinal household surveys from Bolivia Kenya and South Africa that report very high per-year attrition rates between survey rounds. Our estimates indicate that (1) the means for a number of critical outcome and family background variables differ significantly between attritors and nonattritors (2) a number of family background variables are significant predictors of attrition but (3) nevertheless the coefficient estimates for standard family background variables in regressions and probit equations for the majority of the outcome variables considered in all three data sets are not affected significantly by attrition. Therefore attrition apparently is not a general problem for obtaining consistent estimates of the coefficients of interest for most of these outcomes. These results which are very similar to results for developed economies suggest that for these outcome variables---despite suggestions of systematic attrition from iv univariate comparisons between attritors and nonattritors multivariate estimates of behavioral relations of interest may n...,10.1.1.1.2540,?,?
On the Average Case Behavior of the Multidimensional Assignment Problem,Don A. Grundel Pavlo Krokhmal Carlos A. S. Oliveira  Panos M. Pardalos,2004,The multidimensional assignment problem (MAP) is a combinatorial  problem where elements of a variable number of sets must be matched  in order to find a minimum cost solution. The MAP has applications in a  large number of areas and is known to be NP-hard. We survey some of the  recent work being done in the determination of the asymptotic value of optimal  solutions to the MAP when costs are drawn from a known distribution  (e.g. exponential uniform or normal). Novel results concerning the average  number of local minima for random instances of the MAP for random  distributions are discussed. We also present computational experiments with  deterministic local and global search algorithms that illustrate the validity of  our results.,10.1.1.1.2541,multidimensional assignment – asymptotic behavior – combinatorial optimization – deterministic globa,?
Software Engineering Metrics: What Do They Measure and How Do We Know?,Cem Kaner Senior Member  Walter P. Bond,2004,Construct validity is about the question how we know that were measuring the attribute that we think were measuring?  This is discussed in formal theoretical ways in the computing literature (in terms of the representational theory of measurement) but  rarely in simpler ways that foster application by practitioners. Construct validity starts with a thorough analysis of the construct the  attribute we are attempting to measure. In the IEEE Standard 1061 direct measures need not be validated. Direct measurement of  an attribute involves a metric that depends only on the value of the attribute but few or no software engineering attributes or tasks  are so simple that measures of them can be direct. Thus all metrics should be validated. The paper continues with a framework for  evaluating proposed metrics and applies it to two uses of bug counts. Bug counts capture only a small part of the meaning of the  attributes they are being used to measure. Multidimensional analyses of attributes appear promising as a means of capturing the  quality of the attribute in question. Analysis fragments run throughout the paper illustrating the breakdown of an attribute or task of  interest into sub-attributes for grouped study.,10.1.1.1.2542,?,Press
Service-Based Distributed Querying on the Grid ,M. Nedim Alpdemir Arijit Mukherjee   Norman W. Paton Paul Watson Alvaro A. A. Fernandes Anastasios Gounaris Jim Smith,2003,Service-based approaches (such as Web Services and the  Open Grid Services Architecture) have gained considerable attention recently  for supporting distributed application development in e-business  and e-science. The emergence of a service-oriented view of hardware and  software resources raises the question as to how database management  systems and technologies can best be deployed or adapted for use in  such an environment. This paper explores one aspect of service-based  computing and data management viz. how to integrate query processing  technology with a service-based Grid. The paper describes in detail  the design and implementation of a service-based distributed query processor  for the Grid. The query processor is service-based in two orthogonal  senses: firstly it supports querying over data storage and analysis  resources that are made available as services and secondly its internal  architecture factors out as services the functionalities related to the  construction of distributed query plans on the one hand and to their  execution over the Grid on the other. The resulting system both provides  a declarative approach to service orchestration in the Grid and  demonstrates how query processing can benefit from dynamic access to  computational resources on the Grid.,10.1.1.1.2543,?,Springer
Architecture-driven Information System Development -- Toward Framework for Understanding,H.A. (Erik) Proper ,2003,This article discusses a conceptual framework for architecture-driven information system development. Rather than defining a completely new framework the conceptual framework is synthesized out of relevant pre-existing frameworks for system development and architecture. before,10.1.1.1.2544,Information System Development Architecture Information Architecture Stakeholders Requirements,?
Modeling Linguistically Complex Business Domains,S.J.B.A. Hoppenbrouwers H. A. Proper A. I. Bleeker A. I. Bleeker,2004,The paper focuses on business domain modeling as part of requirements engineering  in software development projects. Domain modeling concerns obtaining and modeling  the language (concepts terminologies ontologies) used by stakeholders to talk about a  domain. Achieving conceptual clarity and consensus among stakeholders is an important yet  often neglected part of requirements engineering. Domain modeling can play a key role in  supporting it. This does however require a nuanced approach to language aspects of domain  modeling as well as ambition management concerning its goals and the procedure followed.,10.1.1.1.2545,?,?
A heuristic hill climbing algorithm for Mastermind,Alexandre Temporel  Tim Kovacs,?,The game of Mastermind is a constraint  optimisation problem. There are two aspects  which seem interesting to minimise. The first  is the number of guesses needed to discover  the secret combination and the second is how  many combinations (potential guesses) we  evaluate but do not use as guesses. This paper  presents a new search algorithm for  mastermind which combines hill climbing and  heuristics. It makes a similar number of  guesses to the two known genetic algorithmbased  methods but is more efficient in terms  of the number of combinations evaluated. It  may be applicable to related constraint  optimisation problems.,10.1.1.1.2546,?,?
Towards the Systematic Testing of Aspect-Oriented Programs,Roger T. Alexander  James M. Bieman Anneliese A. Andrews,2004,The code that provides solutions to key software requirements such as security and fault-tolerance tends to be spread throughout (or cross-cut) the program modules that implement the primary functionality of a software system. Aspect-oriented programming is an emerging programming paradigm that supports implementing such cross-cutting requirements into named program units called aspects. To construct a system as an aspect-oriented program (AOP) one develops code for primary functionality in traditional modules and code for cross-cutting functionality in aspect modules. Compiling and running an AOP requires that the aspect code be woven into the code. Although aspect-oriented programming supports the separation of concerns into named program units explicit and implicit dependencies of both aspects and traditional modules will result in systems with new testing challenges which include new sources for program faults. This paper introduces a candidate fault model along with associated testing criteria for AOPs based on interactions that are unique to AOPs. The paper also identifies key issues relevant to the systematic testing of AOPs.,10.1.1.1.2547,?,?
Profile-Based Information Supply from Text Sources,Andreas Dengel   Claudia Wenzel Markus Junker,2000,It is the common goal of todays knowledge management systems to bring the right piece of knowledge to the right person at the right time. As soon as documents are involved in this process of information supply intelligent techniques for information supply from text sources have to be employed. To this end we propose a profile-based approach. Profiles describe the generic information need of individual persons according to their tasks and interests. Attached to these information needs declarative analysis knowledge exhibits the textual properties of information satisfying these profiles. Such patterns are used by intelligent information assistants and allow them a very efficient and goal-directed analysis. Whenever the current context of a user is available it can be used as a dynamic extension of a profile. In this case information assistants can act more specific thus receiving a better result quality. Our approach currently distinguishes three information assistants: one for text categorization one for information extraction and one for process identification. To make profile construction as easy as possible distinct acquisition mechanisms have been developed for each assistant.,10.1.1.1.2548,Information Extraction Text Categorization Document Analysis User Profiles Process Context,?
Evolving Grounded Communication for Robots,Luc Steels,2003,The computational and robotic synthesis of language evolution...,10.1.1.1.2550,?,?
Query Shifting Based On Bayesian,Decision Theory For Giorgio Giacinto Fabio Roli,?,Despite the efforts to reduce the so-called semantic gap between the  user s perception of image similarity and feature-based representation of  images the interaction with the user remains fundamental to improve  performances of content-based image retrieval systems. To this end relevance  feedback mechanisms are adopted to refine image-based queries by asking  users to mark the set of images retrieved in a neighbourhood of the query as  being relevant or not. In this paper Bayesian decision theory is used to  compute a new query whose neighbourhood is more likely to fall in a region of  the feature space containing relevant images. The proposed query shifting  method outperforms two relevance feedback mechanisms described in the  literature. Reported experiments also show that retrieval performances are less  sensitive to the choice of a particular similarity metric when relevance feedback  is used.,10.1.1.1.2552,?,?
Roles in MAS - Managing the Complexity of Tasks and Environments,Ioannis Partsakoulakis George Vouros,2004,Roles have been used both as an intuitive concept in order to analyze multi-agent systems and model inter-agent social activity as well as a formal structure in order to implement coherent and robust teams. The extensive use of roles in implemented systems evidences their importance in multi-agent systems design and implementation. In this paper we emphasize the importance of roles for multi-agent systems to act in complex domains identify some of their properties and we review work done concerning specification and exploitation of roles in agent-oriented system engineering methodologies in formal models about agent social activity and in multi-agent systems that are deployed in dynamic and unpredictable domains.,10.1.1.1.2554,?,Kluwer Academic
Geometrically Stable Sampling for the ICP Algorithm,Natasha Gelfand Szymon Rusinkiewicz,2003,The Iterative Closest Point (ICP) algorithm is a widely used method for aligning three-dimensional point sets. The quality of alignment obtained by this algorithm depends heavily on choosing good pairs of corresponding points in the two datasets. If too many points are chosen from featureless regions of the data the algorithm converges slowly finds the wrong pose or even diverges especially in the presence of noise or miscalibration in the input data. In this paper we describe a method for detecting uncertainty in pose and we propose a point selection strategy for ICP that minimizes this uncertainty by choosing samples that constrain potentially unstable transformations.,10.1.1.1.2555,?,?
Division by Invariant Integers Using Multiplication,Torbjörn Granlund  Peter L. Montgomery,1994,Integer division remains expensive on todays processors as the cost of integer multiplication declines. We present code sequences for division by arbitrary nonzero integer constants and run--time invariants using integer multiplication. The algorithms assume a twos complement architecture. Most also require that the upper half of an integer product be quickly accessible. We treat unsigned division signed division where the quotient rounds towards zero signed division where the quotient rounds towards -# and division where the result is known a priori to be exact. We give some implementation results using the C compiler GCC.,10.1.1.1.2556,?,?
Bounds and Pre-processing for Local Computation ofSemiring Valuations,Nic Wilson,?,this paper we focus on semiring valuations: they are functions from the product set domain of this set of variables which assign each such tuple an element in a semiring. A semiring is a set with two operations one labelled `addition the other `multiplication which are both commutative and associative and are such that the multiplication distributes over the addition,10.1.1.1.2558,?,?
The appearance of Glides in Classical Arabic defective verbs,Abdellah Chekayri Al Akawayn Tobias Scheer Université Nice,?,ls provide 3 consonants for 3 consonantal positions while biliterals such as  assimilated verbs supply only 2 consonants in the perfective.   assimilated verbs lack the Glide in imperfective forms (but 15 verbs out of 251 i.e. 6%)   ex. pf wazan-a ipf ya-zin-u   pf: wazan ipf: ya-zin   apophony   +))    # *     # # # # # # # # # #    w a z n y a z i n    * #    .))))))))))))))))))))))))))))))))))-   apophony    3  (5) genralisation: a. violation of the Template Satisfaction Principle is but a particular case illustrating an illegal situation created by morphology b. the following sequences do not occur in Classical Arabic: any hiatus uwC iyC uyiw wuyi c. we do not know why this is the case but it is consistent to assume that the language reacts when these sequences are produced by morphology. (6) V2 of all imperfective forms is the apophonic output of the corresponding pf V2 Pf. Active Ipf. Active Pf. Passive Ipf. Passive  i C a C i C C a C a C C C i C C C a C a u * #    u u .,10.1.1.1.2559,?,?
Signal Strength Coordination for Cooperative Mapping,Bryan J. Thibodeau  Andrew H. Fagg Brian N. Levine,2004,This work addresses the problem of coordinating a team of mobile robots such that they form a connected ad-hoc wireless network while addressing task objectives. Many tasks such as exploration or foraging can be performed more efficiently when robots are able to communicate with each other. All or parts of these tasks can be performed in parallel thus multiple robots can complete the task more quickly than a single robot. Communication and coordination among the robots can prevent robots from duplicating the effort of other robots allowing the team to address the task more efficiently. In non-trivial environments maintaining communication can be difficult due to the unpredictable nature of wireless signal propagation. We propose a multi-robot coordination method based on perceived wireless signal strength between cooperating robots for exploration in maze-like environments. This new method is tested and compared to an existing method that relies on preserving a clear line of sight between robots to maintain communication.,10.1.1.1.2560,?,?
Designing and Creating a Web Site Based on RDF Content,Eero Hyvönen Markus Holi  Kim Viljanen,2004,This paper presents a method and a tool for designing and automatically creating an HTML web site for publishing Semantic Web content represented in RDF(S). The idea is to specify the needed RDF to HTML transformation on two separate levels. On the HTML level the layout of the pages can be described by an HTML layout designer by using templates and tags. On the RDF level the semantics of the tags are specified by a system programmer in terms of logical rules based on the RDF(S) repository. The idea is to apply logic for defining the semantic linkage structure and the indices of the page repository. The method has been implemented as a tool called SWeHG for generating a static semantically linked site of HTML pages from an RDF repository. As real life case applications web exhibitions generated from museum collection metadata are presented.,10.1.1.1.2561,?,?
Bonds or Loans? - The Effect of Macroeconomic Fundamentals,Galina Hale Galina Hale,2003,The lending boom of the 1990s witnessed considerable variation over time and across countries  in the ratio of international bonds to foreign bank loans used as debt instrument by emerging  market borrowers. Why some issuers float international bonds while others borrow from international  banks has received little if any systematic attention. This paper tests how macroeconomic  fundamentals a#ect the choice of international debt instrument available to emerging market  borrowers. As a stepping stone for empirical analysis a model with asymmetric information is  presented. Empirical results show that macroeconomic fundamentals explain a significant share  of variation in the ratio of bonds to loans for private borrowers but not for the sovereigns.,10.1.1.1.2562,Key words emerging markets foreign debt debt composition country risk,?
Synthesizing Sounds from Rigid-Body Simulations,James F. OBrien James F. O’brien Chen Shen Christine M. Gatchalian,2002,and compelling sounds that correspond to the motions of rigid objects. By numerically precomputing the shape and frequencies of an objects deformation modes audio can be synthesized interactively directly from the force data generated by a standard rigid-body simulation. Using sparse-matrix eigen-decomposition methods the deformation modes can be computed efficiently even for large meshes. This approach allows us to accurately model the sounds generated by arbitrarily shaped objects based only on a geometric description of the objects and a handful of material parameters. We validate our method by comparing results from a simulated set of wind chimes to audio measurements taken from a real set.,10.1.1.1.2563,element method,?
A Convenient Multi-Camera Self-Calibration for Virtual Environments,Tomás Svoboda  Daniel Martinec Tomás  Pajdla,2005,?,10.1.1.1.2564,?,?
Reference Ontologies for Biomedical Ontology Integration and Natural Language Processing,Jonathan Simon James Fielding Mariana Dos Santos  Barry Smith,2004,this paper we describe how this standardization has already led to an improvement in the LinKBase structure that allows for a greater degree of internal coherence than ever before possible. We then show the use of this philosophical standardization for the purpose of mapping external databases to one another using LinKBase as translation hub with a greater degree of success than possible hitherto. We demonstrate how this offers a genuine advance over other application ontologies that have not submitted themselves to the demands of philosophical scrutiny,10.1.1.1.2565,?,?
An Initial Response to the OAS03 Challenge Problem,Michael Wooldridge Ian Dickinson,2003,We present our initial response to the OAS 03 Challenge Problem. The Challenge Problem proposes an agent-assisted travel scenario and asks what the role of ontologies would be to support the agents activity. We discuss a belief-desire-intention (BDI) approach to the problem using our Nuin agent platform and illustrate various ways in which ontology reasoning supports BDI-oriented problem solving and communications by the agents in the system.,10.1.1.1.2566,BDI agents Ontology Semantic web,?
A Generalized Blahut-Arimoto Algorithm,Pascal O. Vontobel,2002,Kavcic proposed in [1] an algorithm that optimizes the parameters of a Markov source at the input to a finite-state machine channel in order to maximize the mutual information rate. Numerical results for several channels indicated that his algorithm gives capacity-achieving input distributions. In this paper we prove that the stationary points of this algorithm indeed correspond one-to-one to the critical points of the information rate curve.,10.1.1.1.2567,?,?
A One-Step Crust and Skeleton Extraction Algorithm,Christopher Gold Jack Snoeyink,2003,We wish to extract the topology from scanned maps. In previous work [GNY96] this was done by extracting a skeleton from the Voronoi diagram but this required vertex labelling and was only useable for polygon maps. We wished to take the crust algorithm of Amenta Bern and Eppstein [ABE98] and modify it to extract the skeleton from unlabelled vertices. We find that by reducing the algorithm to a local test on the original Voronoi diagram we may extract both a crust and a skeleton simultaneously using a variant of the Quad-Edge structure of [GS85]. We show that this crust has the properties of the original and that the resulting skeleton has many practical uses. We illustrate the usefulness of the combined diagram with various applications.,10.1.1.1.2568,?,?
FCNDP No. 174,Fcnd Discussion Paper Natàlia Caldés David Coady John A. Maluccio,?,A common criticism of antipoverty programs is that the high share of  administrative (nontransfer) costs substantially reduces their effectiveness in alleviating  poverty. Yet there is surprisingly little hard empirical evidence on such programs costs.  A recent international review of targeted poverty alleviation programs in less developed  countries found cost informationwhich was rarely comparable between studiesfor  fewer than one-third of the programs examined. Improved information and a better  understanding of the costs of such programs are crucial for effective policymaking. This  study proposes and implements a methodology for a comparative analysis of the level  and structure of costs of three similar poverty alleviation programs in Latin America in  order to assess their cost-efficiency. The findings underscore that any credible  assessment of cost-efficiency requires a detailed analysis of program cost structures that  goes well beyond simply providing aggregate cost information.        iii Contents   Acknowledgments............................................................................................................... v    1. ,10.1.1.1.2569,1. Introduction,?
Anticipating the Three-Dimensional Consequences of Eye Movements,Mark Wexler,2004,integration of information [10]. Furthermore points flashed around the time of a saccade are systematically mislocalized in a way that suggests slow build-up of compensation for retinal shifts [11--17]. The dynamic properties of neurons that remap their receptive fields in the anticipation of saccades may be closely connected with these distortions and contribute to spatial constancy [6]. Such neurons have been found in posterior parietal cortex [18--20] in superior colliculus [21] and in the frontal eye field [22] of monkeys recently neuroimaging has demonstrated similar spatial updating in human parietal cortex [23].  An aspect of the spatial constancy problem that has received little or no attention is the threedimensional  stability of the world during eye movements. Vision serves not only for detecting the directions of points but also---and at least as importantly---for extracting the three-dimensional layout of the environment and in particular the orientations of surface,10.1.1.1.2570,?,?
Practical Applications of Triggers and Constraints: Successes and Lingering Issues,Stefano Ceri et al.,2000,?,10.1.1.1.2571,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson William S. Murphy,?,The current structure of the High Level Architecture (HLA) puts a tremendous burden on network load and CPU utilization for large distributed simulations due to its limited controls for publishing and subscribing object updates and interactions. Several solutions to this problem have been proposed but all require cooperation between federate developers and FOM extensions for both the publishing and subscribing Federates. This paper explores an alternative that has the potential to dramatically reduce communications load by allowing subscribing federates to extend and control the publish/subscribe mechanisms that are local to the publishing federates process without requiring changes to the publishing federate or the Federation Object Model (FOM).,10.1.1.1.2572,?,?
Applications of Graph Probing to Web Document Analysis,Daniel Lopresti  Gordon Wilfong,2001,this paper we describe our first steps towards adapting the graph probing paradigm to allow pre-computation of a compact efficient probe set for databases of graphstructured  documents in general and Web pages coded in HTML in particular. This new model is shown in Figure 1 where the portion of the computation bounded by dashed lines is performed off-line. We consider both comparing two graphs in their entirety as well as determining whether one graph contains a subgraph that closely matches the other. We present an overview of work in progress as well as some preliminary experimental results,10.1.1.1.2573,?,?
Simplicial Mixtures of Markov Chains:,Distributed Modelling Of Mark Girolami Ata Kabán,2003,To provide a compact generative representation of the sequential activity  of a number of individuals within a group there is a tradeoff between  the definition of individual specific and global models. This paper proposes  a linear-time distributed model for finite state symbolic sequences  representing traces of individual user activity by making the assumption  that heterogeneous user behavior may be `explained by a relatively  small number of common structurally simple behavioral patterns which  may interleave randomly in a user-specific proportion. The results of an  empirical study on three different sources of user traces indicates that  this modelling approach provides an efficient representation scheme reflected  by improved prediction performance as well as providing lowcomplexity  and intuitively interpretable representations.,10.1.1.1.2574,?,?
Jane Grimson William Grimson,And Wilhelm Hasselbring Wilhelm Hasselbring,2000,this article is on supporting the clinical process---the fundamental one in health care---most of the comments are applicable to other non-clinical (such as administrative and financial) processes. When considering patient records the starting point is the paper record since it has many advantages. It is familiar portable and can be easily browsed or scanned. However in the climate of modern health care delivery it has a number of major shortcomings,10.1.1.1.2575,?,?
An on-Line Course on Constraint Programming,Christine Solnon,2004,This paper describes an on-line course on constraint programming.,10.1.1.1.2576,?,?
Using Web Standards for Timetabling,P. De Causmaecker P. Demeester G. Vanden Berghe,2002,?,10.1.1.1.2577,timetabling Semantic Web web standards,?
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros B. A. Peters J. S. Smith D. J. Medeiros M. W. Rohrer David Goldsman,1977,This tutorial discusses some statistical procedures for selecting the best of a number of competing systems. The term best may refer to that simulated system having say the largest expected value or the greatest likelihood of yielding a large observation. We describe six procedures for finding the best three of which assume that the underlying observations arise from competing normal distributions and three of which are essentially nonparametric in nature. In each case we comment on how to apply the above procedures for use in simulations.,10.1.1.1.2578,?,?
The Egyptian Food Subsidy System -- Structure Performance and . . . ,Akhter U. Ahmed Howarth E. Bouis Tamar Gutner Hans Löfgren,2001,?,10.1.1.1.2579,?,?
Sub-Voxel Topology Control for Level-Set Surfaces,Stephan Bischoff Leif Kobbelt,2003,Active contour models are an efficient accurate and robust tool for the segmentation of 2D and 3D image data.,10.1.1.1.2580,?,?
APEIRON Vol. 5 Nr.1-2 January-April 1998 Page 73 T h e E p h e m e r i s,Focus And Books,2001,Introduction  The Aharonov-Bohm (1959) effect is a shift in the electron interference pattern produced by an electron beam split to pass on opposite sides of a long thin solenoid when current flows in the solenoid. It is clearly an electrodynamic effect because no effect is produced when no current flows in the solenoid. According to the MaxwellLorentz theory an electron moving outside the solenoid where there is no magnetic field should experience no electrodynamic force. In particular the magnetic vector potential A outside of a long solenoid of radius a carrying a current per unit length h is given by      ph f a  cr   (1)  where e f is a unit vector in the direction of the current and r is the radial distance from the center of the solenoid to the point of observation. From Eq. (1) the curl and divergence of A are seen to vanish thus   = = A A 0 0  . (2) Since A does not change with time and no static charge sources are present the Lorentz force on an electron of charge ,10.1.1.1.2581,?,?
Rule Based Fuzzy Cognitive Maps - Expressing Time in,Qualitative System Dynamics João Paulo Carvalho José A. B. Tomé,?,Time is essential in the study of System Dynamics. When we are trying to represent and analyze the dynamics of complex quantitative systems the problem of expressing the effect of time flow is naturally solved since the mathematical equations that describe the relations between the entities of the system are a function of time. However if we are dealing with real world qualitative systems that are impossible or difficult to model using mathematical equations then the use of natural language becomes the best tool to represent the system and expressing time influence becomes a real issue that has not been addressed before. This paper introduces a coherent procedure to implicitly represent time in Rule Based Fuzzy Cognitive Maps which are a previously introduced methodology and tool to represent and simulate the dynamics of qualitative systems.,10.1.1.1.2582,Fuzzy Rulebased Cognitive Maps System Dynamics,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,Decision making in industry has become more complicated in recent years. Customers are more demanding competition is more fierce and costs for labor and raw materials continue to rise. Managers need state-of-the-art tools to help in planning design and operations of their facilities. Simulation provides a virtual factory where ideas can be tested and performance improved. The AutoMod product suite from Brooks-PRI Automation has been used on thousands of projects to help engineers and managers make the best decisions possible. With the release of AutoMod 11.0 in 2002 AutoMod now supports hierarchical model construction. This new architecture allows users to reuse model objects in other models decreasing the time required to build a model. Composite models are just one of the latest advances that make AutoMod one of the most widely used simulation software packages.,10.1.1.1.2583,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,This paper presents some of my experience in applying a commercial optimum-seeking simulation tool to manufacturing system design and control problems. After a brief introduction to both the general approach and to the specific tool being used namely OptQuest for Arena the main body of the paper reports on the use of the tool in tackling two manufacturing system design and control problems one very simple and one significantly more complex. The paper concludes with some material highlighting how easy the tool is to apply to this kind of problem and also presents some thoughts on how the tool might be enhanced to improve its value.,10.1.1.1.2584,?,?
The Auto-Correlation Function For a Two-Valued Time Series,Richard G. Clegg Maurice Dodson,?,Two simple theorems are proved about the auto-correlation function (ACF) of weakly stationary time series which can only take two values. The first theorem shows how the ACF can be expressed in terms of the conditional probability of occurrence of a single value of the time-series. The second theorem shows how the ACF can be expressed in terms of the variance of the number of occurences of one of the values. Keywords: Autocorrelation binary series 1 ,10.1.1.1.2586,Autocorrelation binary series,?
Natural Intelligence,In Artificial Creatures Christian Balkenius,1995,This memory can be seen as a generalization of the working memory for novel foods introduced in chapter 5. In that simple working memory only the sickness sensor could recall the stored memory. For a more general working memory any sufficiently specific subschema from any modality should recall the entire sensory schema with which it was stored. For example the activation of a place represen- tation will read out the expectations of the stimulus that will be perceived at that location. In the same way the activation of some other sensory property will read out the location at which that property can be found (figure 9.4.1),10.1.1.1.2587,?,?
Feasibility Evaluation of Distributed Energy Generation and Storage for Cost and Reliability Using the ‘Worth-Factor ’ Criterion,Phanikrishna Gomatom Ward Jewell,2002,The unprecedented growth in the electronic and semiconductor industries process controlled industries like automobile textile and paper in addition to the growing domestic load over the past three decades has imposed severe operational economic and maintenance constraints on the power utility companies. Service reliability and power quality are the key contributing factors imposing these constraints. Distributed technologies are a potential solution for the current problem but may not be the optimum solution when specific characteristics like the nature of load desired level of performance geographical location and the available energy resources at the time instance of operation are considered. This paper describes the feasibility of distributed resources in terms of the `worth-factor a criterion that incorporates intangible benefits and translates them in terms of cost.,10.1.1.1.2588,?,?
Genome Informatics 14: 14--22 (2003) A Case Study of Object-Oriented Bio-Chemistry: A,Unified Specification Of Jacqueline Signorini Patrick Greussay,?,We propose a case study where a familiar but very complex and intrinsically woven biocomputing  system - the blood clotting cascade - is specified using methods from software design  known as object-oriented design (OOD). The specifications involve definition and inheritance of  classes and methods and use design techniques from the most widely used OOD-language: the  Unified Modeling Language (UML) as well as its Real-Time-UML extension.,10.1.1.1.2590,object-oriented design UML specifications blood clotting cascade proteolytic enzyme,?
Layout and Language: Challenges for Table Understanding on the Web,Matthew Hurst,2001,In this paper we consider the table understanding task and present a catalogue of particular issues that arise when the tables are those found on the web. In addition we consider what happens when processes commonly associated with web pages are applied to those bearing tables.,10.1.1.1.2591,?,?
8.1. Conclusions CHAPTER 8 CONCLUSIONS AND OUTLOOK,Conclusions And Outlook,?,this paper one being that information gain as it is commonly used in decision tree induction should really be seen as an approximation to an exact expression. This exact expression follows both from the analogy with physical entropy that Shannon [1] noted as well as from a probability argument that is given in Appendix B. The practical success could unfortunately not be demonstrated which may either be due to the requirements of our specific algorithm or may indicate a problem with the concept of using entropy as a criterion. A second idea within the rulebased approach was to generate multiple rules by starting the rule-generation process multiple times with a different starting attribute each time and combining results. This strategy led to a further increase in prediction accuracy,10.1.1.1.2592,?,?
A Proactive Approach to Reconstructing Overlay Multicast Trees, Mengkun Yang et al.,2004,Overlay multicast constructs a multicast delivery tree among end hosts. Unlike traditional IP multicast the nonleaf nodes in the tree are normal end hosts which are potentially more susceptible to failures than routers and may leave the multicast group voluntarily. In these cases all downstream nodes will be affected. Thus an important problem in overlay multicast is how to recover from node departures in order to minimize the disruption of service to those affected nodes. In this paper we propose a proactive approach to restore overlay multicast trees. Rather than letting downstream nodes try to find a new parent after a node departure each non-leaf node precalculates a parent-to-be for each of its children. When this nonleaf node is gone all its children can find their respective new parents immediately. The salient feature of the approach is that each non-leaf node can compute a rescue plan for its children independently and in most cases rescue plans from multiple non-leaf nodes can work together for their children when they fail or leave at the same time. We develop a protocol for nodes to communicate with new parents so that the delivery tree can be quickly restored. Extensive simulations demonstrate that our proactive approach can recover from node departures 5 times faster than reactive methods in some cases and 2 times faster on average.,10.1.1.1.2593,?,?
Towards Explaining Semantic Matching,Deborah L. McGuinness Deborah L. Mcguinness  Pavel Shvaiko Pavel Shvaiko  Fausto Giunchiglia Fausto Giunchiglia Paulo Pinheiro Da Silva Paulo Pinheiro Da Silva,2004,Interoperability among systems using di#erent term vocabularies requires some mapping between terms in the vocabularies. Matching applications generate such mappings. When the matching process utilizes term meaning (instead of simply relying on syntax) we refer to the process as semantic matching. If users are to use the results of matching applications they need information about the mappings. They need access to the sources that were used to determine relations between terms and potentially they need to understand any deductions performed on the information. In this paper we present our approach to explaining semantic matching. Our initial work uses a satisfiability-based approach to determine subsumption and semantic matches and uses the Inference Web and its OWL encoding of the proof markup language to explain the mappings. The Inference Web solution also includes a registration of the OWL reasoning component of JTP as well as other reasoner registrations and thus provides a foundation for explaining semantic matching systems.,10.1.1.1.2594,?,?
Sufficiently Secure Peer-to-Peer Networks,Rupert Gatti Stephen Lewis Andy Ozment Thierry Rayna    Andrei Serjantov,2004,Threat models in computer security often consider a very powerful adversary. A  more useful model may be to consider conflict in which both sides have economic  considerations that limit the resources they are willing to devote to the conflict. This  paper examines censorship resistance in a peer-to-peer network. A simple game  theoretic model is examined and then elaborated to include multiple publishers  non-linear cost functions and non-trivial search heuristics. In each elaboration we  examine the equilibrium behaviour of the censor and the publisher.,10.1.1.1.2595,?,?
Globalization and the Smallholders: A Review of Issues Approaches and Implications,Sudha Narayanan Sudha Narayanan Ashok Gulati Ashok Gulati,2002,A major question that has surfaces in the changing context of world agriculture...,10.1.1.1.2596,1. BACKDROP.........................................................................................,?
Optimal Transmission Scheduling with Base Station Antenna Array in Cellular Networks,Tianmin Ren Richard J. La  Leandros Tassiulas Ros Tassiulas,2004,We study the downlink scheduling problem in a cellular wireless network. The base stations are equipped with antenna arrays and can transmit to more than one mobile user at any time instant provided the users are spatially separable. In previous work an infinite traffic demand model is used to study the physical layer beamforming and power control algorithms that maximize the system throughput. In this paper we consider finite user traffic demands. A scheduling policy makes a decision based on both the queue lengths and the spatial separability of the users. The objective of the scheduling algorithm is to maintain the stability of the system. We derive an optimal scheduling policy that maintains the stability of the system if it is stable under any scheduling policy. However this optimal scheduling policy is exponentially complex in the number of users which renders it impractical. We propose four heuristic scheduling algorithms that have polynomial complexity. The first two algorithms are for the special case of single cell systems while the other two algorithms deal with multiple cell systems. Using a realistic multi-path wireless channel model we evaluate the performance of the proposed algorithms through computer simulations. The results demonstrate the benefits of joint consideration of queue length and dynamic base station assignment.,10.1.1.1.2597,?,?
A First-Principles Approach to Understanding the Internets Router-level Topology,Lun Li David Alderson  Walter Willinger  John Doyle,2004,A detailed understanding of the many facets of the Internets topological structure is critical for evaluating the performance of networking protocols for assessing the effectiveness of proposed techniques to protect the network from nefarious intrusions and attacks or for developing improved designs for resource provisioning. Previous studies of topology have focused on interpreting measurements or on phenomenological descriptions and evaluation of graph-theoretic properties of topology generators. We propose a complementary approach of combining a more subtle use of statistics and graph theory with a first-principles theory of router-level topology that reflects practical constraints and tradeoffs. While there is an inevitable tradeoff between model complexity and fidelity a challenge is to distill from the seemingly endless list of potentially relevant technological and economic issues the features that are most essential to a solid understanding of the intrinsic fundamentals of network topology. We claim that very simple models that incorporate hard technological constraints on router and link bandwidth and connectivity together with abstract models of user demand and network performance can successfully address this challenge and further resolve much of the confusion and controversy that has surrounded topology generation and evaluation.,10.1.1.1.2598,Performance Design Economics Keywords Network topology degree-based generators topology metrics heuristically optimal,?
Probabilistic Modeling for Face Orientation . . . ,Shumeet Baluja,1993,This paper presents probabilistic modeling methods to solve the problem of discriminating  between five facial orientations with very little labeled data. Three  models are explored. The first model maintains no inter-pixel dependencies the  second model is capable of modeling a set of arbitrary pair-wise dependencies  and the last model allows dependencies only between neighboring pixels. We  show that for all three of these models the accuracy of the learned models can  be greatly improved by augmenting a small number of labeled training images  with a large set of unlabeled images using Expectation-Maximization. This is  important because it is often difficult to obtain image labels while many unlabeled  images are readily available. Through a large set of empirical tests we  examine the benefits of unlabeled data for each of the models. By using only  two randomly selected labeled examples per class we can discriminate between  the five facial orientations with an accuracy of 94% with six labeled examples  we achieve an accuracy of 98%.,10.1.1.1.2599,?,?
Networking Issues in Wireless Sensor Networks,Deepak Ganesan Alberto Cerpa Yan Yu Deborah Estrin Wei Ye Jerry Zhao,2003,The emergence of sensor networks as one of the dominant technology trends in the coming  decades [1] has posed numerous unique challenges to researchers. These networks are  likely to be composed of hundreds and potentially thousands of tiny sensor nodes functioning  autonomously and in many cases without access to renewable energy resources.,10.1.1.1.2600,?,?
Mechanical Analogies for the,Lorenz Gauge Particles Valery P. Dmitriyev,2001,Introduction  We are in search of a mechanical medium capable to reproduce or imitate the world of particles and physical fields. Earlier a mechanical model of particles and fields has been proposed which is based on the approximation of an incompressible substratum. Average turbulence in an ideal fluid was considered. In the ground state the turbulence was taken to be homogeneous and isotropic. Perturbations of the background turbulence model the physical fields [1]. Voids in the turbulent fluid give rise to the structures which can be taken as the model of the particles [2]. The condition of the substratum incompressibility manifests itself in the classical electromagnetism as the Coulomb gauge.  Now we give some refinement of the above model. It is suggested that the substratum is represented by a volume distribution of the empty space in the ideal fluid. Microscopically this is conveniently viewed as the vortex sponge -- the plenum of hollow vortex tubes which pierce the ide,10.1.1.1.2601,?,?
Z. Games And Economic Behavior 20 102]116 1997,Article No Ga Robert J. Aumann Sergiu Hart Motty Perry,?,INTRODUCTION  An absent-minded driver starts driving at START in Figure 1. At X he Z. can either EXIT and get to A for a payoff of 0 or CONTINUE to Y.AtY he Z. Z. can either EXIT and get to B payoff 4  or CONTINUE to C payoff 1 . The essential assumption is that he cannot distinguish between intersections X and Y and cannot remember whether he has already gone through one of them.  Z. Piccione and Rubinstein 1997 henceforth P R  who introduced this example claim that a paradox or inconsistency arises when the decision reached at the planning stage}at START}is compared with that at the action stage}when the driver is at an intersection. Though the example is provocative and worth having P  Rs analysis seems flawed. A careful analysis reveals that while the considerations at the planning and action stages do differ there is no paradox or inconsistency.    This is an outgrowth of notes and correspondence originating in May and June of 1994. We thank Ehud Kalai Roger Myerson,10.1.1.1.2602,?,?
Understanding the Effects of Hotspots in Wireless Cellular Networks,J. Jobin Michalis Faloutsos  Satish K. Tripathi Srikanth V. Krishnamurthy,2004,In this work we study and quantify the effects of hotspots in wireless cellular networks. Hotspots are caused when the bandwidth resources available at some location in the network are not enough to sustain the needs of the users which are then blocked or dropped. A deeper understanding of hotspots can help in conducting more realistic simulations and enable improved network design. We identify,10.1.1.1.2603,Simulations system design hotspots cellular,?
Internationa Journal of L eadership in Education,Issn Print Issn Carol A. Mullen Frances K,?,This article offers a unique perspective on one such collaborative network that might serve to assist others in establishing similar inclusive environments. This network the West Alabama Learning Coalition (WALC) is a multi-institutional partnership that seeks to improve schools teacher education and the community. In keeping with the theme of this special issue of International Journal of Leadership in Education we explored this coalition from the practitioners view. We opted to take this approach rather than examine how theory is reflected in practice from a researchers view. This piece creates theory from practice by presenting an analysis of the motivation of members benefits and experience of Carol A. Mullen Assistant Professor is leadership faculty in Leadership Development Department University of South Florida Tampa Florida 33620-5650 USA Frances K. Kochan Professor is leadership faculty in Educational Foundations Technology and Leadership Auburn University Auburn Alabama 36849-5112 USA. They both specialize in collaboration and partnership building with different cultures of professionals which have resulted in numerous academic articles and guest edited issues of journals. Dr Mullen has published four books two on mentoring forms of leadership development. Breaking the Circle of One (Peter Lang 2000 2nd edn) received the Exemplary Research in Teacher Education Award from AERA (Division K) in 1998 (e-mail: cmullen@tempest.coedu.usf. edu). Dr Kochan served as co-editor of the book A Thousand Voices from the Firing Line (1999 UCEA) and as editor of The Southern Regional Council on Educational Administration Yearbook (1999) (e-mail: kochafr@auburn.edu),10.1.1.1.2607,?,?
Introducing Reset Patterns: an Extension to a Rapid Dialogue Prototyping Methodology,Silvia Quarteroni And Silvia Quarteroni Martin Rajman,?,This paper exposes the Rapid Dialogue Prototyping Methodology [1 2  3] a methodology allowing the easy and automatic derivation of an ad hoc  dialogue management system from a specific task description. The goal of  the produced manager is to provide the user with a dialogue based interface to  easily perform the target task. In addition reset patterns an extension of the  prototyping methodology allowing a more flexible interaction with the user  are proposed in order to improve the efficiency of the dialogue. Reset patterns  are justified and theoretically validated by the definition of an average gain  function to optimize. Two approaches to such an optimization are presented  focusing on a different aspect of the gain function. Eventually experimental  results are presented and a conclusion is drawn on the usefulness of the new  feature.,10.1.1.1.2608,Contents,?
Aspects of the timing of fundamental frequency in German chanted call contours,Felix Schaeffler Sonja Biersack,2003,this paper we present data from a preliminary investigation on f0 timing in the chanted call contour. The chanted call is an intonation pattern that exists functionally and formally similar in several languages. Ladd (1996) provides the following description:  In many European languages in certain situations people who are some distance away  from a speaker can be called or hailed using a chanted tune on two sustained notes stepping down from a fairly high level to a somewhat lower level. (p. 136)  We are mainly interested in how syllable borders and the segmental structure take influence on the timing of the f0 contour. The chanted call is an exemplary pattern that we hope will be useful for the investigation of text-tune associations in general and for crosslinguistic comparisons in particular. It is reasonably stable in its form and function across languages easy to elicit and even elicitable with different levels of emphasis. Though we aim at cross-linguistic comparisons and a more general picture of text-tune associations in the long run we will here only present German data,10.1.1.1.2609,?,?
Speccast,Leonid Poutievski   Kenneth L. Calvert James N. Griffioen,2004,In this paper we describe a new network service called Speccast. Speccast offers a generalized addressing and routing abstraction on which a rich variety of semantic services can be built and as such provides a vehicle for studying the relationships among routing addressing and topology. Unlike overlay-based systems we study a more basic problem in which the topology of the network is given and there is not necessarily any pre-existing underlying network service. In the speccast model each packet carries a destination predicate and the networks job is to deliver the packet to all nodes satisfying that predicate. After,10.1.1.1.2610,?,?
A Peer-to-Peer Database Management System,Albena Roshelova Albena Roshelova,2004,Peer-to-Peer Database Management Systems (PDBMS) are still in the beginning of their evolution. They rise  up p2p technology to exploit the power of available distributed database management technologies. The  proposed PDBMS will be completely autonomous and any notions of centralization as central server or  creating a cost-based global schema will be absent. In this paper a number of potential research issues in the  overlap between database and p2p systems is identified and a vision for building a PDBMS is presented. The  PDBMS is envisioned as a system that will be able to manage effectively at runtime semantic interdependences  among databases in a decentralized distributed and collaborative manner. The main focus of the proposed  PhD work is the research of adaptive techniques for development of a database management system  compatible with the p2p paradigm.,10.1.1.1.2611,?,?
FCND DP No. 106 FCND DISCUSSION PAPER NO. 106 STRENGTHENING CAPACITY TO IMPROVE NUTRITION,Stuart Gillespie,?,A major premise of this paper is that the failure---or limited achievements---of many large-scale nutrition programs is very often a function of insufficient sustainable capacities within communities and organizations responsible for implementing them. Following a brief review of the various rationales for an intensified focus on capacity and capacity development the paper examines the linkages between nutrition programming and capacity development processes before proposing a new approach to assessing analyzing and developing capacity. The ensuing sections then focus in more detail on the ingredients and influences of capacity at the levels of the community program management supporting institutions and the government. Finally the implications of a more proactive focus on strengthening nutrition capacity for donor modes of operation and support priorities are discussed. A fundamental premise as enshrined in major international conventions and declarations is that adequate nutrition is a human right. In order to operationalize a truly human-rights-based approach to nutrition action---whether policy or programs a fundamental first step is to assess capacity. The rights approach demands an active involvement of beneficiaries in processes to improve nutrition. Nutrition-vulnerable individuals households and communities are no longer objects of welfare transfers but rather subjects whose capabilities are ultimately the foundations of sustainable progress. There are several key recommendations for donor policy and practice that emerge. First donors need to provide more support for capacity assessment and development operational research and the building of policy-research-training-program networks. A concrete rights-based programming process demands a focu...,10.1.1.1.2612,?,?
The Bin Model,Yaser Abu-mostafa  Xubo Song Alexander Nicholson Malik Magdon-ismail,1995,We propose a novel theoretical framework for understanding learning and generalization which we call  the bin model. Using the bin model a closed form is derived for the generalization error that estimates the  out-of-sample performance in terms of the in-sample performance. We address the problem of over  tting  and show that using a simple exhaustive learning algorithm it does not arise. This is independent of the  target function input distribution and learning model and remains true even with noisy data sets. We  apply our analysis to both classi  cation and regression problems and give an example of how it may be  used eciently in practice.,10.1.1.1.2613,?,?
Performance Analysis of Producer/Consumer Protocols over IEEE802.11 Wireless Links,Daniele Miorandi Stefano Vitturi,2004,Thanks to recent technological advances wireless networks are beginning to represent an interesting opportunity for factory communication systems. Among the o#--the--shelves solutions for radio communications the IEEE802.11 technology is one of the most promising. However industrial applications typically impose severe requirements in terms of both real-- time performances and dependability. In this paper we consider one of the most popular models of fieldbus protocols namely the Producer--Consumer and study the possibility of implementing it on top of IEEE802.11 protocol suite. After a description of how the Producer--Consumer services could be mapped onto IEEE802.11 we introduce an analytical model which enables us to evaluate two important performance indexes: the update time jitter and the mean alarm latency. The analysis is validated by means of numerical simulations.,10.1.1.1.2614,?,?
Quantifiers,Michael Glanzberg,2004,?,10.1.1.1.2615,?,?
Foundation for the Electronic Health Record:,An Ontological Analysis Lowell Vizenor Barry Smith Werner Ceusters,2004,this paper we analyzed the HL7 RIM from the perspective of speech act theory and submitted its various classes to ontological analysis. We discovered that the RIM is marked by a number of problems above all when it comes to taking dependent continuants properly into account. Although the RIM intends to represent registrations of relevant medical acts in a way which acknowledges the distinction between what we have called primary and secondary acts. Yet this very distinction is not adequately maintained in all the parts of the RIM. It is true that this shortfall may be of little practical importance for the purposes of messaging but if the RIM has the goal of being used as a reliable and effective ontology of medical acts in the future then the situation would be quite different. For delivering adequate and cost-effective care it is mandatory that one can trust an ordered test not just to be carried out but also to be registered both as having been ordered (to avoid it being ordered a second time for no other reason than that it was not known to have been ordered before) and as having been carried out. The way this and related types of information are coded in HL7 messages may be sufficient for interpretation by HL7-trained humans but it does not allow algorithms to grasp the underlying differences. We propose that to make this possible in the future correction of the RIM should be undertaken on the basis of a more fine-grained ontological analysis along the lines set forth above,10.1.1.1.2616,Ontology Speech Acts HL7 Electronic Health Record Organizations,?
Simulation with GPSS/H,Robert C. Crain D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,1998,GPSS/H is a well-known traditional simulation tool whose user base continues to grow despite the presence of many new trends in simulation technology. In GPSS/H the process-interaction world view has been combined with many advanced features to make one of the most powerful and flexible tools available capable of handling large and complicated models with ease yet still providing exceptionally high performance.,10.1.1.1.2617,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson On Logistic-manufacturing Networks,?,This paper presents the application of real-time simulation to assign due dates on logistic-manufacturing networks. Information from the manufacturing transportation and supplier elements was integrated into a simulation model of the system to help the assignment of reliable delivery dates. In addition the system was used to generate multiple due date options so customers could pick the delivery speed and cost option that satisfied their specific needs.,10.1.1.1.2618,?,?
Early Childhood Nutrition And Academic Achievement: A Longitudinal Analysis,Paul Glewwe Hanan Hanan Jacoby Elizabeth King,2001,Early childhood nutrition is thought to be an important input into subsequent academic achievement. This paper investigates the nutrition-learning nexus using a unique longitudinal data set which follows a large sample of Philippine children from birth until the end of their primary education. We find that malnourished children perform more poorly in school even after correcting for the effects of unobserved heterogeneity both across and within households. Part of the advantage that wellnourished children enjoy arises from the fact that they enter school earlier and thus have more time to learn. The rest of their advantage appears to stem from greater learning productivity per year of schooling rather than from greater learning effort in the form of homework time school attendance and so forth. Despite these findings our analysis suggests that the relationship between nutrition and learning is not likely to be of overriding importance either for nutrition policy or in accounting for economic growth. CONTENTS  Acknowledgments.....................................................iv 1. ,10.1.1.1.2619,Acknowledgments.....................................................iv,?
Theory of Robustness of Irreversible Differentiation in a Stem Cell System: Chaos Hypothesis,Chikara Furusawa Kunihiko Kaneko,2001,this paper we adopt #2 which implies a quadratic e!ect of enzymes. This specic choice of a quadratic e!ect is not essential in our model of cell di!erentiation. Furthermore we take into account the change in the volume of a cell which varies as a result of the transportation of chemicals between the cell and the environment. For simplicity we assume that the total concentration of chemicals in a cell is constant #  m  x #m#    const. It follows that the volume of a cell is proportional to the sum of the quantities of all chemicals in the cell. The volume change is calculated from the transport as discussed below,10.1.1.1.2620,?,?
Timed Information Flow Logic for Timed Automata,Ruggero Lanotte  Andrea Maggiolo-Schettini Simone Tini,?,We study the problem of information ow in real-time systems described by Timed Automata. We distinguish between secret and observable actions of automata we introduce a logic to express information ow properties as properties of the languages accepted by automata and we give an algorithm to check these properties.,10.1.1.1.2622,?,?
IN–BAND POWER ESTIMATION OF WINDOWED DELTA–SIGMA SHAPED NOISE,Emilia Nunzi Paolo Carbone Dario Petri E. Nunzi P. Carbone D. Petri,?,Performances of ## modulators are evaluated by applying a coherently sampled tone and by estimating powers of the in--band tones and noise. In particular the power of the shaped noise is usually estimated by subtracting the evaluated input tone from the output data and by integrating the power spectral density estimated by means of the periodogram. Although the coherency the finite number of processed samples induces spectral leaking of the wide-- band noise thus affecting the noise power estimate. To cope with such an issue usually data are weighted by the Hanning sequence. In this paper the noise power estimation error induced by the use of such window is investigated and a criterion for choosing the minimum number of samples N which bounds the relative leakage error within a specified maximum value is explicitly given. Moreover it is shown that for any N  such an error is negligible for modulator orders lower than 3. Higher order modulators require the use of a large number of samples to bound the relative error of the noise power estimate when high oversampling ratios are employed.,10.1.1.1.2623,?,?
International,Carpathian Control Conference Tomáš Saloky,2002,Computer vision with appropriate simplifying constraints is providing a powerful sensory tool for robot control and for another important applications. Computer vision supplemented as required by force and torque sensing can greatly enhance the performance of first generation robots presently limited to operations based on fixed predetermined actions. The new capabilities include the identification of workpieces the determination of their position and orientation and the provision of real-time visual feedback for effecting adaptive corrections of the robots trajectories. Typical applications selected from real problems in industry are described and analyzed. Further there are indicated some approaches to possible solutions.,10.1.1.1.2624,?,?
Autonomous Characters in Virtual Environments: The technologies involved in artificial life and their affects of perceived intelligence and playability of computer games,Oliver Edward Wood,2004,Abstract Computer games are viewed by academics as un-grounded hack and patch experiments. Academic artificial intelligence is often viewed as unimplementable and narrow minded by the majority of non-AI programmer. By,10.1.1.1.2625,?,?
Mining Home Video for Photos,Qian Lin Qian Lin Tong Zhang Tong Zhang  Mei Chen Mei Chen Yining Deng Yining Deng  Pere Obrador Pere Obrador,2004,this paper a  complete solution of video to photo is presented. The intent of the user is  first derived by analyzing video motions. Then photos are produced  accordingly from the video. They can be keyframes at video highlights  panorama of the scene or high-resolution frames. Methods and results of  camera motion mining intelligent keyframe extraction video frame  stitching and super-resolution enhancement are described,10.1.1.1.2626,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Lei Wei,?,In this paper we present a variance minimization (VM) procedure for rare event simulation in tandem queueing networks. We prove that the VM method can produce a zero variance. The VM method is suitable to compute optimal importance sampling (IS) parameters for small scale tandem networks. For large scale tandem networks we propose a sub-optimal IS (SOIS) method which projects the optimal biased transition probabilities of the corresponding small scale system into those of a large scale system. In other words we establish an efficient IS method for a large scale system by zooming into a small scale system and then projecting our findings into the large scale system. The numerical results show that our SOIS method can produce accurate results with very short CPU time while many other methods often require much longer.,10.1.1.1.2627,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Harriet Black Nembhard Leyuan Shi,?,Exercising real options often requires an implementation time whereas financial options can be exercised instantly. Neglecting the implementation time needed to exercise a real option causes overvaluing that option. We develop lattice and Monte Carlo simulation techniques to value real option problems where exercising the option requires an implementation time. We present the application of the proposed techniques on a global supply chain network problem with exchange rate uncertainty and value the flexibility to switch between manufacturing options for a firm that has operations in different countries.,10.1.1.1.2629,?,?
MorphoClass -- Recognition and Morphological Classification of Unknown Words for German,Preslav Nakov,2002,A system for recognition and morphological classification of unknown words for German is described and evaluated. It takes raw text as input and outputs a list of the unknown nouns together with a hypothesis about their possible morphological class and stem. MorphoClass exploits global information (ending-guessing rules maximum likelihood   estimations word frequency statistics) morphological properties (compounding inflection affixes) and external knowledge (lexicons German grammar information etc.).,10.1.1.1.2630,?,?
FAB: Building Distributed Enterprise Disk Arrays from Commodity Components,Yasushi Saito Svend Frølund  Alistair Veitch Arif Merchant Susan Spence,2004,This paper describes the design implementation and evaluation of a Federated Array of Bricks (FAB) a distributed disk array that provides the reliability of traditional enterprise arrays with lower cost and better scalability. FAB is built from a collection of bricks small storage appliances containing commodity disks CPU NVRAM and network interface cards. FAB deploys a new majority-votingbased algorithm to replicate or erasure-code logical blocks across bricks and a reconfiguration algorithm to move data in the background when bricks are added or decommissioned. We argue that voting is practical and necessary for reliable high-throughput storage systems such as FAB. We have implemented a FAB prototype on a 22-node Linux cluster. This prototype sustains 85MB/second of throughput for a database workload and 270MB/second for a bulk-read workload. In addition it can outperform traditional masterslave  replication through performance decoupling and can handle brick failures and recoveries smoothly without disturbing client requests.,10.1.1.1.2631,Algorithms Management Performance Reliability Keywords Storage disk array replication erasure coding voting consensus,?
Requirements-Level Semantics and Model Checking of Object-Oriented Statecharts,Rik Eshuis  David N. Jansen Roel Wieringa,2002,this paper we define a requirements-level execution semantics for object-oriented statecharts and show how properties of a system specified by these statecharts can be model checked using tool support for model checkers. Our execution semantics is requirements-level because it uses the perfect technology assumption which abstracts from limitations imposed by an implementation. Statecharts describe object life cycles. Our semantics includes synchronous and asynchronous communication between objects and creation and deletion of objects. Our tool support presents a graphical front-end to model checkers making these tools usable to people who are not specialists in model checking. The model-checking approach presented in this paper is embedded in an informal but precise method for software requirements and design. We discuss some of our experiences with model checking,10.1.1.1.2632,Execution semantics Model checking Statecharts,?
Cleaning and Querying Noisy Sensors,Eiman Elnahrawy  Badri Nath,2003,Sensor networks have become an important source of data with numerous applications in monitoring various real-life phenomena as well as industrial applications and traffic control. Unfortunately sensor data is subject to several sources of errors such as noise from external sources hardware noise inaccuracies and imprecision and various environmental effects. Such errors may seriously impact the answer to any query posed to the sensors. In particular they may yield imprecise or even incorrect and misleading answers which can be very significant if they result in immediate critical decisions or activation of actuators. In this paper we present a framework for cleaning and querying noisy sensors. Specifically we present a Bayesian approach for reducing the uncertainty associated with the data that arise due to random noise in an online fashion. Our approach combines prior knowledge of the true sensor reading the noise characteristics of this sensor and the observed noisy reading in order to obtain a more accurate estimate of the reading. This cleaning step can be performed either at the sensor level or at the base-station. Based on our proposed uncertainty models and using a statistical approach we introduce several algorithms for answering traditional database queries over uncertain sensor readings. Finally we present a preliminary evaluation of our proposed approach using synthetic data and highlight some exciting research directions in this area.,10.1.1.1.2633,General Terms Algorithms Design Experimentation Keywords Wireless Sensor Networks Noisy Sensors Uncertainty Bayesian Theory Query Evaluation Statistics,?
Some Properties of the Gaussian Distribution,Jianxin Wu,2004,this paper. However in order to understand these facts some linear algebra and multivariate analysis are needed which are not always covered su ciently in undergraduate texts. The  attempt of this paper is to pool these facts together and hope that it will be useful for new researchers entering this area,10.1.1.1.2635,?,?
Elementary Particles as Micro-Universes: A Geometric Approach to Strong Gravity,Recami Ammiraju Hernndez E. Recami P. Ammiraju H. E. Hernández L. C. Kretly W. A. Rodrigues,2001,this paper we confine ourselves to examine the possibility of considering elementary particles as micro universes (see e.g. Recami 1983a 1983b 1979 Cf. also Ammiraju Recami  Rodrigues 1983): that is to say the possibility that they be similar---in a sense to be specified---to our cosmos. More precisely we shall refer to the thread followed by P. Caldirola P. Castorina A. Italiano G.D. Maccarrone M. Pavsic V.T. Zanchin and ourselves (for an extended summary of that theory see e.g. Recami 1982 and refs. therein Recami Martnez  Zanchin 1986 and Recami  Zanchin 1992 see also Recami  Zanchin 1986). Let us recall that Riemann as well as Clifford and later on Einstein (see e.g. Einstein 1919) believed that the fundamental particles of matter were the perceptible evidence of a strong local space curvature. A theory which stresses the role of space (or rather space-time) curvature already does exist for our whole cosmos: General Relativity based on Einsteins gravitational field equations which are probably the most important equations of classical physical theories together with Maxwells electromagnetic field equations. While much effort has already been made to generalize Maxwells equations passing for example from the electromagnetic field to Yang-Mills fields (so that almost all modern gauge theories are modeled on Maxwells equations)  on the contrary the Einstein equations have never been applied to domains other than gravitation. Nevertheless like any differential equations they do not  contain any in-built fundamental length so they can be used a priori to describe cosmoses of any size. Our first purpose is to explore whether it is possible to apply successfully the methods of general relativity (GR) to the domain of the so-called nucle...,10.1.1.1.2636,?,?
Efficient Peer-to-Peer Keyword Searching,Patrick Reynolds Amin Vahdat,?,The recent file storage applications built on top of peer-to-peer distributed  hash tables lack search capabilities. We believe that search is an important  part of any document publication system. To that end we have designed and analyzed  a distributed search engine based on a distributed hash table. Our simulation  results predict that our search engine can answer an average query in under one  second using under one kilobyte of bandwidth.,10.1.1.1.2639,search distributed hash table peer-to-peer Bloom filter caching,?
ISA and IBFVS: Image Space Based Visualization of Flow on Surfaces,Robert S. Laramee Jarke J. Van Wijk  Bruno Jobard Helwig Hauser,2004,We present a side-by-side analysis of two recent image space approaches for the visualization of vector fields on surfaces. The two methods Image Space Advection (ISA) and Image Based Flow Visualization for Curved Surfaces (IBFVS) generate dense representations of time-dependent vector fields with high spatio-temporal correlation. While the 3D vector fields are associated with arbitrary surfaces represented by triangular meshes the generation and advection of texture properties is confined to image space. Fast frame rates are achieved by exploiting frame-to-frame coherency and graphics hardware. In our comparison of ISA and IBFVS we point out the strengths and weaknesses of each approach and give recommendations as to when and where they are best applied.,10.1.1.1.2640,?,?
GAMBL Genetic Algorithm Optimization of Memory-Based WSD,Bart Decadt And Bart Decadt Véronique Hoste Walter Daelemans Antal Van Den Bosch,2004,GAMBL is a word expert approach to WSD in which each word expert is trained using memorybased learning. Joint feature selection and algorithm parameter optimization are achieved with a genetic algorithm (GA). We use a cascaded classifier approach in which the GA optimizes local context features and the output of a separate keyword classifier (rather than also optimizing the keyword features together with the local context features). A further innovation on earlier versions of memorybased WSD is the use of grammatical relation and chunk features. This paper presents the architecture of the system briefly and discusses its performance on the English lexical sample and all words tasks in SENSEVAL-3.,10.1.1.1.2641,classifier (rather than also optimizing the,?
Geophysical Research Letters Vol. 28 No. 17 Pages 3235-3238 September 1 2001,Tropospheric Ozone Maximum Qinbin Li Daniel J. Jacob Jennifer A. Logan Isabelle Bey Robert M Hongyu Liu All V. Martin Arlene M. Fiore Brendan D Bryan N. Duncan Valérie Thouret,2001,The GEOS-CHEM global 3-D model of tropospheric chemistry predicts a summertime O3 maximum over the Middle East with mean mixing ratios in the middle and upper troposphere in excess of 80 ppbv. This model feature is consistent with the few observations from commercial aircraft in the region. Its origin in the model reflects a complex interplay of dynamical and chemical factors and of anthropogenic and natural influences. The anticyclonic circulation in the middle and upper troposphere over the Middle East funnels northern midlatitude pollution transported in the westerly subtropical jet as well as lightning outflow from the Indian monsoon and pollution from eastern Asia transported in an easterly tropical jet. Large-scale subsidence over the region takes place with continued net production of O3 and little mid-level outflow. Transport from the stratosphere does not contribute significantly to the O3 maximum. Sensitivity simulations with anthropogenic or lightning emissions shut o# indicate decreases of 20-30% and 10-15% respectively in the tropospheric O3 column over the Middle East. More observations in this region are needed to confirm the presence of the O3 maximum.,10.1.1.1.2643,?,?
An MML Classification of Protein Structure that knows about Angles and Sequence,T. Edgoose L. Allison D. L. Dowe,?,this paper we apply a Hidden Markov Model to model the structure of a collection of known proteins. This Markov classi#cation is able to take advantage of information implicit in the order of a sequence of observations and hence is better suited to modelling protein data than a classi#cation model that assumes independence between observations. We use an Minimum Message Length #MML# information measure to evaluate our protein structure model which enables us to #nd the model best supported by the known evidence,10.1.1.1.2644,?,?
V:C/VC: in Swedish? A perception test with,Bosse Thorén,2003,Introduction  Out of the need to simplify linguistic description for pedagogic purposes a basic prosodic model for Swedish has developed over the last two decades. This model often manifests itself in textbooks in Swedish as a second language in the following way: Potatis r gott.  In each prominent word there is an underlining representing the long sound in the stressed syllable. This marking points out the prominent words in a sentence the stressed syllables in the prominent words and finally the phonologically long sound in the stressed syllable thus also promoting the quantity distinction by increasing or reducing the V/C-ratio.  The model has taken influence by Bruces (1977) model where the quantity distinction -- which requires a prolonged syllable -- is the common denominator of all degrees of word prominence in Swedish. It also owes much to Bannerts (e.g. 1986 1995) many studies that have improved our understanding of what phonetic properties are crucial for speaking i,10.1.1.1.2645,?,?
TCP Vegas-like algorithm for layered multicast,Omar Ait-hellal  Guy Leduc,2004,Layered multicast is probably the most elegant solution to tackle the heterogene ity problem in multicast delivery of real-time multimedia streams. However the multiple join experiments carried out by di#erent receivers in order to detect the available bandwidth make it hard to achieve fairness. In the present paper we present a simple protocol inspired from TCP-Vegas that reduces considerably the unnecessary join experiments while achieving intra-session and inter-session fairness as well as being TCP-Friendly.,10.1.1.1.2647,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson,?,In Gross and Juttijudata (1997) a single node G/G/1 queue was investigated as to the sensitivity of output performance measures such as the mean queue wait to the shape of the interarrival and service distributions selected. Gamma Weibull lognormal and Pearson type 5 distributions with identical first and second moments were investigated. Significant differences in output measures were noted for low to moderate traffic intensities (offered load r) in some cases even as high as 0.8. We continue this type of investigation for two types of queueing networks namely two versions of a two-node call center to see if network mixing might reduce the sensitivity effect.,10.1.1.1.2648,?,?
On the Advantages of Lifetime and RTT Classification Schemes for TCP Flows,Xudong Wu Ioanis Nikolaidis,2002,We exploit the isolation of TCP flows based on their lifetime (classified as short- or long-lived  flows) to eliminate the impact of long-lived flows on the short-lived achieving improved response  time for short-lived flows. An additional classification scheme provides large-grain separation  of flows with drastically di#erent end-to-end round-trip-times (RTTs). The scheme provides  long-term fairness among the long-lived flows. Hence the combined lifetime and RTT classification  appears to be able to provide both fair bandwidth sharing and better response time for  the long-lived and short-lived flows respectively. The presented evaluation results suggest that  the combined classification performs under all tested case comparably or better than RED. The  results indicate that a classification scheme together with some not-perfectly tuned RED or even  with DropTail dropping policy can avoid the complexity of having to properly parameterize  RED while achieving equal or better performance.,10.1.1.1.2649,?,?
A Hardware Optimised CMOS Adaptive Noise Canceller Implementation,A. Th. Schwarzbacher M. Herz  F. David  J. Timoney,2002,Up until now the main foci of development in mobile communication equipment have been to decrease its size and to extend its battery operation times. However further reductions in the size of devices are physically limited by the user interface requirements and therefore alternative aspects of these devices must be targeted for enhancement by designers. A feature of mobile communications equipment is the variety of environments within which they are used so algorithms that can improve the quality of a transmission are highly desirable. In this paper mobile telephony devices are being specifically considered and a CMOS implementation of the filter block of an adaptive noise canceller will be presented. Results will then be given to demonstrate how this circuit can significantly increase speech quality by suppressing interfering noise without requiring any prior assumptions on its properties.,10.1.1.1.2650,?,?
Inferring Sub-culture Hierarchies Based on Object Diffusion on the World Wide Web, Ta-gang Chiou et al.,?,This paper presents our approach to inferring communities on the Web. It delineates the sub-culture hierarchies based on how individuals get involved in the dispersion of online objects. To this end a relatedness function is chosen to satisfy a set of carefully defined mathematical conditions. The conditions are deduced from how people may share common interests through placing common objects on their homepages. Our relatedness function can infer much more detailed degree of relatedness between homepages than other contemporary methods.,10.1.1.1.2651,?,?
Universally Composable Privacy Amplification against Quantum Adversaries,Renato Renner  Robert König,2004,Privacy amplification is the art of shrinking a partially secret string Z to a highly secret key S. We introduce a universally composable security definition for secret keys in a context where an adversary holds quantum information and show that privacy amplification by two-universal hashing is secure with respect to this definition. Additionally we give an asymptotically optimal lower bound on the length of the extractable key S in terms of the adversarys (quantum) knowledge about Z.,10.1.1.1.2652,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,In this tutorial we present an introduction to simulationbased optimization which is perhaps the most important new simulation technology in the last five years. We give a precise statement of the problem being addressed and also experimental results for two commercial optimization packages applied to a manufacturing example with seven decision variables.,10.1.1.1.2653,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,There are thousands of jobs performed on the Queen of the Sky the Boeing 747 final assembly line for each airplane. When the decision was made to implement a moving line for the final assembly of the 747 it was absolutely necessary to evaluate many aspects of these jobs. Discrete event simulation models were constructed to analyze numerous 747 final assembly moving line scenarios throughout several phases. These models not only presented a visual understanding of different concepts but also provided quantitative analysis of suggested scenarios to the moving line team. The results presented highly optimized production flows and processes reducing cost and flow time from the traditionally 24 days to the targeted possible 18 days. This work outlined some of the moving line concepts modeling objectives and simulation analysis. Utilizations of different assembly positions were yielded as the result of discrete simulation modeling of many bundled jobs and stands of the 747 final assembly operation.,10.1.1.1.2654,?,?
A Framework for a Distributed Protocol Set to Provide Better Quality of . . . ,Hossein Mohammadi et al.,2003,Internet is migrating from a simple data network to an environment where a more demanding multimedia content like audio video and IP telephony is being delivered. The Internet Protocol (IP) was originally designed to interconnect heterogeneous networks. It scales well by keeping the core network as simple and dumb as possible and provides a best effort delivery service. However multimedia applications require something better than a simple best effort delivery. Many solutions have been proposed to implement quality of service (QoS) on IP networks. Typically these methods do not take into account the inherent characteristics of multimedia data and leave most of the work to the end hosts. In this paper we propose a framework for a new protocol set to integrate network and application level QoS to reach the best possible quality for multimedia delivery over the Internet. The suggested method has a modular distributed and scalable architecture enabling it to easily grow as the network size and/or QoS requirements change.,10.1.1.1.2655,?,?
Lessons from Deploying NLG Technology for Marine Weather Forecast Text Generation,Somayajulu G. Sripada Ehud Reiter  Ian Davy Kristian Nilssen,2004,SUMTIME-MOUSAM is a Natural Language Generation (NLG) system that produces textual weather forecasts for offshore oilrigs from Numerical Weather Prediction (NWP) data. It has been used for the past year by Weathernews (UK) Ltd for producing 150 draft forecasts per day which are then post-edited by forecasters before being released to end-users. In this paper we describe how the system works how it is used at Weathernews and finally some lessons we learnt from building installing and maintaining SUMTIME-MOUSAM. One important lesson has been that using NLG technology improves maintainability although the biggest maintenance work actually involved changing data formats at the I/O interfaces. We also found our system being used by forecasters in unexpected ways for understanding and editing data. We conclude that the success of a technology owes as much to its functional superiority as to its suitability to the various stakeholders such as developers and users.,10.1.1.1.2656,?,?
Capacity Regions for Wireless Ad Hoc Networks,Stavros Toumpis   Andrea J. Goldsmith,2003,We define and study capacity regions for wireless ad hoc networks with an arbitrary number of nodes and topology. These regions describe the set of achievable rate combinations between all source-destination pairs in the network under various transmission strategies such as variable-rate transmission single-hop or multihop routing power control and successive interference cancellation (SIC). Multihop cellular networks and networks with energy constraints are studied as special cases. With slight modifications the developed formulation can handle node mobility and time-varying flat-fading channels. Numerical results indicate that multihop routing the ability for concurrent transmissions and SIC significantly increase the capacity of ad hoc and multihop cellular networks. On the other hand gains from power control are significant only when variable-rate transmission is not used. Also time-varying flat-fading and node mobility actually improve the capacity. Finally multihop routing greatly improves the performance of energy-constraint networks. ,10.1.1.1.2657,?,?
Corpus Analysis to Extract Information,Fabrice Even,?,This article presents an automatic information extraction method from poor quality specific-domain corpora. This method is based on building a semi-formal ontology in order to model information present in the corpus and its relation. This approach takes place in four steps: corpus normalization by a correcting process ontology building from texts and external knowledge model formalization in grammar and the information extraction itself which is made by a tagging process using grammar rules. After a description of the different stages of our method experimentation on a French bank corpus is presented.,10.1.1.1.2658,quality,?
Query Languages and Data Models for Database,Sequences And Data Yan-nei Law Haixun Wang Carlo Zaniolo,2004,We study the fundamental limitations of relational  algebra (RA) and SQL in supporting  sequence and stream queries and present effective  query language and data model enrichments  to deal with them. We begin by observing  the well-known limitations of SQL in  application domains which are important for  data streams such as sequence queries and  data mining. Then we present a formal proof  that for continuous queries on data streams  SQL su#ers from additional expressive power  problems. We begin by focusing on the notion  of nonblocking (NB) queries that are the only  continuous queries that can be supported on  data streams. We characterize the notion of  nonblocking queries by showing that they are  equivalent to monotonic queries. Therefore  the notion of    for RA can be  formalized as its ability to express all monotonic  queries expressible in RA using only the  monotonic operators of RA. We show that RA  is not  NB-complete  and SQL is not more  powerful than RA for monotonic queries.,10.1.1.1.2659,?,?
Practical Rendering of Multiple Scattering Effects in Participating Media,H. W. Jensen A. Keller (editors Simon Premoze Michael Ashikhmin Ravi Ramamoorthi Shree Nayar,2004,Volumetric light transport effects are significant for many materials like skin smoke clouds snow or water. In  particular one must consider the multiple scattering of light within the volume. While it is possible to simulate  such media using volumetric Monte Carlo or finite element techniques those methods are very computationally  expensive. On the other hand simple analytic models have so far been limited to homogeneous and/or optically  dense media and cannot be easily extended to include strongly directional effects and visibility in spatially varying  volumes. We present a practical method for rendering volumetric effects that include multiple scattering. We  show an expression for the point spread function that captures blurring of radiance due to multiple scattering.,10.1.1.1.2660,?,?
Switching Activity Estimation using Limited Depth Reconvergent Path Analysis,José C. Costa José C. Monteiro Srinivas Devadas,1997,?,10.1.1.1.2661,?,?
EPOCHS: Integrated Commercial Off-The-Shelf Software for Agent-Based Electric Power and Communication Simulation,S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Kenneth M. Hopkinson Kenneth P. Birman,2003,This paper reports on the development of the Electric Power and Communication Synchronizing Simulator (EPOCHS) a distributed simulation environment. Existing electric power simulation tools accurately model power systems of the past which were controlled as large regional power pools without significant communication elements. However as power systems increasingly turn to protection and control systems that make use of computer networks these simulators are less and less capable of predicting the likely behavior of the resulting power grids. Similarly the tools used to evaluate new communication protocols and systems have been developed without attention to the roles they might play in power scenarios. EPOCHS utilizes multiple research and commercial offthe -shelf (COTS) systems to bridge the gap. EPOCHS is also notable for allowing users to transparently encapsulate complex system behavior that bridges multiple domains through the use of a simple agent-based framework.,10.1.1.1.2662,?,?
Self-Referencing Languages Revisited,Gabor Redey And Gábor Rédey Attila Neumann Technische Universität Wien,2004,Paradoxes particularly Tarskis liar paradox represent an  ongoing challenge that have long attracted special interest. There have  been numerous attempts to give either a formal or a more realistic resolution  to this area based on natural logical intuition or common sense.,10.1.1.1.2663,?,?
Foundations for Extended Life Cycle Biological Models,Glen Ropella Li Li Yan C. Anthony Hunt,2003,Introduction: To expand our ability to test current concepts about system and organ function within organisms in normal and disease states we need a new class of discrete event-driven simulation models that achieve a higher level of biological realism across multiple scales while being sufficiently flexible to represent different aspects of the biology. Here we provide the first description of such models one that is focused on the rat liver. We use a middle-out design strategy that begins with primary parenchymal units. The models are sufficiently flexible to represent different aspects of hepatic biology including heterogeneous microenvironments. Model components are designed to be easily joined and disconnected and to be replaceable and reusable. The models function within a multitier in silico apparatus designed to support iterative experimentation on models that will have extended life cycles.,10.1.1.1.2664,?,?
Simple Natural Language Generation and Intelligent Tutoring Systems,Barbara Di Eugenio Michael Glass Michael J. Trolio,2005,In this paper we report on our approach to adding  Natural Language Generation (NLG) capabilities  to ITSs. Our choice has been to apply simple NLG  techniques to improve the feedback provided by  an existing ITS specifically one built within the  DIAG framework (Towne 1997a). We evaluated  the original version of the system and the enhanced  one with a between subjects experiment. On the  whole the enhanced system is better than the original  one other than in helping subjects remember  the actions they took. Current work includes exploiting  more sophisticated NLG techniques but  still without delving into full fledged text planning.,10.1.1.1.2665,?,?
Dsgd Discussion Paper No. 10,Development Strategy And Steven Were Omamo,?,v  I. ,10.1.1.1.2666,?,?
Object-Role Modeling as a Domain Modeling Approach,H. A. Proper A. I. Bleeker  S.J.B.A. Hoppenbrouwers,2004,This paper focuses on the potential role of the Object-Role Modeling (ORM)  approach to information modeling for the task of domain modeling. Domain modeling concerns  obtaining and modeling the language (concepts terminologies ontologies) used by  stakeholders to talk about a domain. Achieving conceptual clarity and consensus among  stakeholders is an important yet often neglected part of system development and requirements  engineering in particular.,10.1.1.1.2667,?,?
HOW PRODUCTIVE IS INFRASTRUCTURE? NEW APPROACH AND EVIDENCE FROM RURAL INDIA,Xiaobo Zhang Xiaobo Zhang Shenggen Fan Shenggen Fan,?,There have been competing arguments about the effect of public infrastructure on productivity in the literature. Level-based regressions generally show a much higher return to public capital than private capital while difference-based regressions tend to find insignificant or even negative effects. To help reconcile this debate this paper proposes that researchers should first test for causality in their data to check for length of lagged relationships and the existence of reverse causality as a critical step before specifying a final model and estimating procedure on the relationship between the stock of capital and productivity growth. A newly developed system GMM method of estimation is proposed for this purpose. Second a new method of estimating the relationship between the capital stock and productivity in level form is proposed that controls for possible endogeneity problems arising from reverse causation. These methods are illustrated using a unique set of pooled time-series cross-section data for India. It is shown that infrastructure development in India is productive with an estimated impact lying between those obtained from level-based and difference-based estimates. ii  TABLE OF CONTENTS 1. ,10.1.1.1.2668,?,?
Contrast Optimisation of Coherent Images,Fortune Hayes And,2003,Contrast optimisation is a method that can be used to correct phase errors in coherent images such as SAS images. However the contrast measure of a given coherent image is a random variable due to the speckle present in coherent images. The variance of this measure puts a limit on the ability of contrast optimisation to focus an image.,10.1.1.1.2669,?,?
A Survey of Web Metrics,Devanshu Dhyani  Wee Keong Ng Sourav S. Bhowmick,2002,... this article we examine this issue by classifying and discussing a wide  ranging set of Web metrics. We present the origins measurement functions  formulations and comparisons of well-known Web metrics for quantifying Web graph  properties Web page significance Web page similarity search and retrieval usage  characterization and information theoretic properties. We also discuss how these metrics  can be applied for improving Web information access and use.,10.1.1.1.2671,Document and Text Processing General General Terms Measurement Additional Key Words and Phrases Information theoretic PageRank quality metrics Web graph Web metrics Web page similarity,?
An Advanced Transaction Meta-Model for Web Services,Environments Peter Hrastnik Peter Hrastnik Werner Winiwarter,2004,Recently the software industry has published several proposals for transactional processing in the Web service world. Even though most proposals support arbitrary transaction models there exists no standardized way to describe such models. This paper describes potential impacts and use cases of utilizing advanced transaction meta-models in the Web service world and introduces a suitable meta-model for defining arbitrary advanced transaction models. In order to make this meta-model more usable in Web service environments it had to be enhanced and an XML representation of the enhanced model had to be developed.,10.1.1.1.2672,?,?
Automatic Delay Selection In Blind Channel Equalization: A Prewhitening + Eigenvector Approach,Roberto Opez-Valcarce And Roberto López-valcarce O Pérez-gonzález,?,We consider the problem of blindly equalizing a single input single output communication channel assuming that the tap input vector to the equalizer has mutually uncorrelated components. This can be achieved if the received signal is preprocessed by an adaptive all-pole filter (which has been suggested as a means for both MSE improvement and DFE initialization) or by a standard lattice predictor. In the former case it has been observed recently that an eigenvector of the (prewhitened) input quadricovariance matrix may provide a good initial estimate for the equalizer. We provide analytical justification for this fact and show that if the MSE of a Wiener equalizer for a given delay is small then this Wiener equalizer is close to an eigenvector of . The corresponding eigenvalue decreases with the MSE and thus picking the smallest eigenvalue automatically provides blind delay optimization. 1. ,10.1.1.1.2673,?,?
Scalable Dissemination: Whats Hot and Whats Not,J. Beaver N. Morsillo K. Pruhs  P. Chrysanthis  V. Liberatore,2004,A major problem in web database applications and on the Internet in general is the scalable delivery of data. One proposed solution for this problem is a hybrid system that uses multicast push to scalably deliver the most popular data and reserves traditional unicast pull for delivery of less popular data. However such a hybrid scheme introduces a variety of data management problems at  the server. In this paper we examine three of these problems: the push popularity problem the document classification problem and the bandwidth division problem. The push popularity problem is to estimate the popularity of the documents in the web site. The document classification problem is to determine which documents should be pushed and which documents must be pulled. The bandwidth  division problem is to determine how much of the server  bandwidth to devote to pushed documents and how much of the  server bandwidth should be reserved for pulled documents. We propose simple and elegant solutions for these problems. We report on experiments with our system that validate our algorithms.,10.1.1.1.2675,?,?
Small-World File-Sharing Communities,Adriana Iamnitchi  Matei Ripeanu Ian Foster ,2003,Web caches content distribution networks peer-to-peer file sharing networks distributed file systems and data grids all have in common that they involve a community of users who generate requests for shared data. In each case overall system performance can be improved significantly if we can first identify and then exploit interesting structure within a communitys access patterns. To this end we propose a novel perspective on file sharing based on the study of the relationships that form among users based on the files in which they are interested. We propose a new structure that captures common user interests in data---the data-sharing graph--- and justify its utility with studies on three data-distribution systems: a high-energy physics collaboration the Web and the Kazaa peer-to-peer network. We find small-world patterns in the data-sharing graphs of all three communities. We analyze these graphs and propose some probable causes for these emergent small-world patterns. The significance of smallworld patterns is twofold: it provides a rigorous support to intuition and perhaps most importantly it suggests ways to design mechanisms that exploit these naturally emerging patterns.,10.1.1.1.2676,?,?
Efficiency of Scale-Free Networks: Error and Attack Tolerance,Paolo Crucitti  Vito Latora  Massimo Marchiori  Andrea Rapisarda,2003,?,10.1.1.1.2677,?,?
A Comparison of Manual and Automatic Constructions of Category Hierarchy for Classifying Large Corpora,Fumiyo Fukumoto Yoshimi Suzuki,2004,We address the problem dealing with a large  collection of data and investigate the use of  automatically constructing category hierarchy  from a given set of categories to improve classification  of large corpora. We use two wellknown  techniques partitioning clustering k-  means and a loss function to create category  hierarchy. k-means is to cluster the given categories  in a hierarchy. To select the proper number  of k we use a loss function which measures  the degree of our disappointment in any  differences between the true distribution over  inputs and the learners prediction. Once the  optimal number of # is selected for each cluster  the procedure is repeated. Our evaluation  using the 1996 Reuters corpus which consists  of 806791 documents shows that automatically  constructing hierarchy improves classification  accuracy.,10.1.1.1.2678,?,?
Decomposing Probability Distributions on Structured Individuals,Peter A. Flach Nicolas Lachiche,?,Naive Bayesian classifiers have been very successful in attribute-value representations.,10.1.1.1.2679,?,?
WordNet Applications,Jorge Morato  Miguel Ángel Marzal Juan Lloréns  José Moreiro,2004,This paper describes WordNet design and development discussing its  origins the objectives it initially intended to reach and the subsequent use to which  it has been put the factor that has determined its structure and success. The emphasis  in this description of the product is on its main applications given the instrumental  nature of WordNet and on the improvements and upgrades of the tool itself along  with its use in natural language processing systems. The purpose of the paper is to  identify the most significant recent trends with respect to this product to provide a full  and useful overview of WordNet for researchers working in the field of information  retrieval. The existing literature is reviewed and present applications are classified to  concur with the areas discussed at the First International WordNet Congress.,10.1.1.1.2682,?,?
Transformations in Information Supply,Van Gils Proper B. Van Gils H. A. Proper P. Van Bommel Th. P. Van Der Weide,2004,In this article we present a model for transformation of resources in information  supply. These transformations allow us to reason more flexibly about information supply and  in particular its heterogeneous nature. They allow us to change the form (e.g. report abstract  summary) and format (e.g. PDF DOC HTML) of data resources found on the Web. In a retrieval  context these transformations may be used to ensure that data resources are presented to the  user in a form and format that is apt at that time.,10.1.1.1.2683,?,?
Teaching Machines about Everyday Life,Push Singh   Barbara Barry Hugo Liu,2004,In order to build a new breed of software that can deeply understand people and our problems so that they can help us to solve them we are developing at the Media Lab a suite of computational tools to give machines the capacity to learn and reason about everyday life---in other words to give machines `common sense. We are building several large-scale commonsense knowledge bases that model broad aspects of the ordinary human world including descriptions of the kinds of goals people have the actions we can take and their effects the kinds of objects that we encounter every day and so forth as well as the relationships between such entities. In this article we describe three systems we have built---ConceptNet LifeNet and StoryNet---that take unconventional approaches to representing acquiring and reasoning with large quantities of commonsense knowledge. Each adopts a different approach: ConceptNet is a large-scale semantic network LifeNet is a probabilistic graphical model and StoryNet is a database of story-scripts. We describe the evolution of these three systems the techniques that underlie their construction and their operation and conclude with a discussion of how we might combine them into an integrated commonsense reasoning system that uses multiple representations and reasoning methods. ,10.1.1.1.2684,?,Press
The Status of the Experimental Evidence for the B,Field Jeffers Department S. Jeffers,2001,Introduction    and others (1997)    have suggested that the description of the classical electromagnetic field may be incomplete and that the usual Maxwellian transverse wave components may be accompanied by a phase free longitudinal component the so-called B    field. The original suggestion was that the conjugate product of the transverse field components yields a phase free longitudinal real magnetic field. The predicted properties of this field have been the subject of many publications (see vols 1-3 Enigmatic Photon    and references therein and this Special Issue). This inference has been criticised by Barron (1993)  4  as violating CPT symmetry and also more recently by Comay (1996)    as actually violating Maxwells equations themselves. Comay (1996)    claims that the inclusion of a B    component to the field of a rotating dipole leads to a violation of one of Maxwells equations. Evans and Jeffers (1996)    have shown that this argument is incorrect since the curl of the,10.1.1.1.2685,?,?
Distributed Packet-Level Simulation for BGP Networks under Genesis,Yu Liu Boleslaw K. Szymanski,2004,The complexity and dynamics of the Internet is driving the demand for scalable and e#cient network simulation. Parallel and distributed network simulation techniques make it possible to utilize the power of multiple processors or clusters of workstations to simulate large-scale networks e#ciently. However synchronization overheads inherent in parallel and distributed simulations limit the e#ciency and scalability of these simulations. We developed a novel distributed network simulation framework and synchronization approach which achieved better e#ciency than conventional approaches. In this framework BGP networks are partitioned into domains of Autonomous Systems (ASes) and simulation time is divided into intervals. Each domain is simulated independently of and concurrently with the others over the same time interval. At the end of each interval packet delays and drop rates for each interdomain flow are exchanged between domain simulators. The simulators iterate over the same time interval until the exchanged information converges to the value within a prescribed precision before progress to the next time interval. This approach allows the parallelization with infrequent synchronization and achieves significant simulation speedups. In this paper we focus on the design of distributed BGP network simulation in Genesis in which many BGP ASes can be assigned to a single Genesis domain. We also report our experimental results that measure Genesis distributed e#ciency in large scale BGP network simulations.,10.1.1.1.2686,?,Press
Businesses Mobilize Production through,Markets Parametric Modeling Harrison C. White,?,this article is to operationalize this across production markets,10.1.1.1.2687,?,?
Characterizing the Mobility and Association Patterns of Wireless Users in a Campus,Maria Papadopouli  Haipeng Shen  Manolis Spanakis,2004,Our goal is to characterize the mobility and access patterns in a IEEE802.11 infrastructure. This can be beneficial in many domains including coverage planning resource reservation supporting location-dependent applications and applications with real-time constraints and produce models for simulations. We conducted an extensive measurement study of wireless users and their association patterns on a major university campus using the IEEE802.11 wireless infrastructure. We propose a new methodology to characterize and analyze the wireless access pattern based on several parameters such as mobility session and visit durations. This methodology can allow us to study how user association and mobility patterns evolve in the temporal and spatial dimension.,10.1.1.1.2689,?,?
On Scheduling Time-Critical On-Demand Broadcast,Jianliang Xu  Xueyan Tang  Wang-Chien Lee,?,On-demand broadcast is an effective data dissemination technique to enhance system scalability and deal with dynamic user access patterns. With the rapid growth of time-critical information services and emerging applications such as mobile location-based services there is an increasing need for the system to support timely data dissemination. This paper studies online scheduling algorithms for time-critical on-demand broadcast. We propose a novel scheduling algorithm called SIN-# that takes into account the urgency and productivity of serving pending requests. An efficient implementation of SIN-# is presented. Moreover we analyze the optimal broadcast schedule in terms of request drop rate when the request arrival rate rises towards infinity. Trace-driven experiments demonstrate that SIN-# significantly outperforms existing algorithms over a wide range of workloads. The results also show that the performance of SIN-# approaches the analytical optimum at high request rates.,10.1.1.1.2690,?,?
Strip-map Phase Gradient Autofocus,Hayes Callow And,2002,This paper describes a generalisation of the Phase Gradient Autofocus (PGA) algorithm that allows strip-map operation. A standard autofocus technique PGA uses prominent points within the target scene to estimate the point spread function of the system. PGA was developed for tomographic mode spotlight synthetic aperture radar (SAR) but has limited applicability for side-scan synthetic aperture operation. We show how it can be generalised to work with stripmap geometries and relate our new method to the previous PGA extension to strip-map systems.,10.1.1.1.2691,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,This paper discusses verification and validation of simulation models. The different approaches to deciding model validity are presented how model verification and validation relate to the model development process are discussed various validation techniques are defined conceptual model validity model verification operational validity and data validity are described ways to document results are given and a recommended procedure is presented.,10.1.1.1.2692,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson,?,Interoperability and reusability are features supported by the new High Level Architecture for Modeling and Simulation (HLA). While the traditional approach of monolithic traffic simulation modeling has proven to be successful distributed traffic simulations gain more attention. The first part of the paper describes our work with distributed traffic simulation based on the High Level Architecture and the lessons learned from enhancing classic simulation and animation tools for HLA and our first HLA prototypes. The second part elaborates on the additional flexibility that architectures for distributed simulation offer focussing on the dynamic integration of information relevant to the overall simulation into the dynamic event space. A promising outlook concludes the paper.,10.1.1.1.2693,?,?
Complexity Thinking: A Middle Way for Analysts,Kurt Richardson   Paul Cilliers Michael Lissack,?,This paper explores the implications of the incompressibility of complex systems for the analysis and modelling of such systems. In particular a provisional epistemology (theory of knowledge) will be developed that attempts to remain faithful to the limitations derived from this aspect of complexity science. We will argue that such an investigation of complex systems highlights the relevance of paradigmatic pluralism or eclecticism analytical creativity and boundary critique and therefore has some affinity to the writings on affirmative postmodernism. Complexity thinking (i.e. thinking based on insights derived in complexity science) like postmodernism provides a clear warning as to the dangers of uncritically adopting any `black and white theoretical position. It encourages the deferral of paradigm selection and a healthy scepticism. In this `middle way there is equal attention paid to qualitative as well as quantitative approaches to analysis.,10.1.1.1.2694,Complexity science critical pluralism postmodernism epistemology,?
Estimation and Analysis of the Deformation of the Cardiac Wall Using Doppler Tissue Imaging,Valerie Moreau  Laurent D. Cohen Denis Pellerin,?,This paper presents different ways to use the Doppler Tissue Imaging (DTI) in order to determine deformation of the cardiac wall. As an extra information added to the ultrasound images the DTI gives the velocity in the direction of the probe. We first show a way to track points along the cardiac wall in a M-Mode image (1D+t). This is based on energy minimization similar to a deformable grid. We then extend the ideas to finding the deformation field in a sequence of 2D images (2D+t). This is based on energy minimization including spatio-temporal regularization.,10.1.1.1.2695,?,?
Requirements by Contracts Allow Automated System Testing,Clementine Nebut Franck Fleurey Yves Le Traon  Jean-Marc Jezequel,2003,Use-cases and scenarios have been identified as good inputs to generate test cases and oracles at requirement level. Yet to have an automated generation information is missing from use cases and sequence diagrams such as the exact inputs of the system and the ordering constraints between the use case. The contribution of this paper is then twofold. First we propose a contract language for functional requirements expressed as parameterized use cases. Then we provide a method a formal model and a prototype tool to automatically derive both functional and robustness test cases from the requirements enhanced with contracts. We study the efficiency of the generated test cases on a case study.,10.1.1.1.2696,?,?
Aiaa 2002-3605,Rapid Prediction Of J. Bradford John E. Bradford,?,While the aftbody engine exhaust flowfield of hypersonic launch vehicles can be analyzed with computer-intensive computational fluid dynamic codes this approach is not suitable for use in conceptual vehicle studies. In order to accomplish any complete vehicle-level optimization in the conceptual design phase performance changes due to the nozzle design must be available quickly. To make this task even more challenging performance changes need to be assessed over a broad range of flight conditions instead of just at a single point.,10.1.1.1.2697,?,?
Denial of Service in Sensor Networks ,Anthony D. Wood John A. Stankovic,2002,?,10.1.1.1.2698,?,Prentice –Hall Inc
Generative Programming of Graphical User Interfaces,Max Schlee Software,2002,Generative Programming (GP) is a new paradigm that allows automatic creation of entire software family using the configuration of elementary and reusable components. GP can be projected on different technologies e.g. C++- templates JavaBeans Aspect-Oriented Programming (AOP) or Frame technology. This paper focuses on Frame Technology which aids the possible implementation and completion of software components. The purpose of this paper is to introduce the GP paradigm in the area of GUI application generation. It also demonstrates how  automatically customized executable applications with GUI  parts can be generated from an abstract specification.,10.1.1.1.2701,?,?
A Cantorian Superfluid Vortex And The . . . ,V. Christianto,2004,This article suggests a preliminary version of a Cantorian  superfluid vortex hypothesis as a plausible model of nonlinear  cosmology. Though some parts of the proposed theory  resemble several elements of what have been proposed by  Consoli (2000 2002) Gibson (1999) Nottale (1996 1997  2001 2002a) and Winterberg (2002b) it seems such a  Cantorian superfluid vortex model instead of superfluid or  vortex theory alone has never been proposed before,10.1.1.1.2703,Cantorian spacetime fluid dynamics,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Paul Stewart,?,Distributed real-time simulation is the focus of intense development with complex systems being represented by individual component simulations interacting as a coherent model. The real-time architecture may be composed of physically separated simulation centres. Commercial offthe -shelf (COTS) and Freeware Real-time software exists to provide data communication channels between the components subject to adequate system bandwidth. However if the individual models are too computationally intensive to run in real time then the performance of the real-time simulation architecture is compromised. In this paper model representations are developed from dynamic simulation by the response surface methodology (RSM) allowing complex systems to be included in a real-time environment. A Permanent Magnet AC (PMAC) motor drive simulation with model reference control for a more electric aircraft application is examined as a candidate for inclusion in a realtime simulation environment.,10.1.1.1.2704,?,?
Dynamic Routing in Translucent WDM Optical Networks,Xi Yang Byrav Ramamurthy,2002,Translucent WDM optical networks use sparse placement of regenerators to overcome the impairments and wavelength contention introduced by fully transparent networks and achieve a performance close to fully opaque networks with much less cost. Our previous study proved the feasibility of translucent networks using sparse regeneration technique. We addressed the placement of regenerators based on static schemes allowing only fixed number of regenerators at fixed locations. This paper furthers the study by proposing a suite of dynamical routing schemes. Dynamic allocation advertisement and discovery of regeneration resources are proposed to support sharing transmitters and receivers between regeneration and access functions. This study follows the current trend in optical networking industry by utilizing extension of IP control protocols. Dynamic routing algorithms aware of current regeneration resources and link states are designed to smartly route the connection requests under quality constraints. A hierarchical network model supported by the MPLS-based control plane is also proposed to provide scalability. Experiments show that network performance is improved without placement of extra regenerators.,10.1.1.1.2705,Routing and Wavelength Assignment Regeneration Optical Network,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Ying-chao Hung,?,Simulation can provide insight to the behavior of a complex queueing system by identifying the response surface of several performance measures such as delays and backlogs. However simulations of large systems are expensive both in terms of CPU time and use of available resources (e.g. processors). Thus it is of paramount importance to carefully select the inputs of simulation in order to adequately capture the underlying response surface of interest and at the same time minimize the required number of simulation runs. In this study we present a methodological framework for designing efficient simulations for complex networks. Our approach works in sequential and combines the methods of CART (Classification And Regression Trees) and the design of experiments. A generalized switch model is used to illustrate the proposed methodology and some useful applications are described.,10.1.1.1.2707,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Kenneth D. Walsh,?,Homebuyer Homebuilder  Framing  Trade  Contractor  Concrete  Trade  Contractor  Plumbing  Trade  Contractor  etc.,10.1.1.1.2708,?,?
Proceedings of the 2003 Winter Simulation Conference S. Chick P. J. Snchez D. Ferrin and D. J. Morrice eds.,Online Simulation Of S. Chick P. J. Sánchez D. Ferrin D. J. Morrice André Hanisch Juri Tolujew Klaus Richter,?,Online simulation of pedestrian flow in public buildings is a  new tool which can be especially useful for improving the  aspects of safety and short-term planning in the phase of organizing and operating large public buildings. These might  be places such as a train station an airport or a shopping  center. This paper provides an insight into the different concepts of pedestrian flow simulation. Special emphasis is  placed on explaining the mesoscopic approach as applied to  the area of traffic simulation. This approach is transferred to  the context of analyzing and predicting the pedestrian flow.  A first prototypical implementation of a simulation supported control center is briefly presented also.   1 ,10.1.1.1.2709,?,?
Multiple Transition Model and Enhanced Boundary Scan Architecture to Test Interconnects for Signal Integrity,Tehranipour Ahmed Nourani,2003,As the technology is shrinking toward 50 nm and the working frequency is going into multi gigahertz range the effect of interconnects on functionality and performance of system-on-chips is becoming dominant. More specifically distortion (integrity loss) of signals traveling on high-speed interconnects can no longer be ignored. In this paper we propose a new fault model called multiple transition and its corresponding test pattern generation mechanism. We also extend the conventional boundaryscan architecture to allow testing signal integrity in SoC interconnects. Our extended JTAG architecture collects and outputs the integrity loss information using the enhanced observation cells. The architecture fully complies with the JTAG standard and can be adopted by any SoC that is IEEE 1149.1 compliant.,10.1.1.1.2710,?,?
The Journal of,Imaging Science And Pamela J. Forness,?,This paper or parts thereof may not be reproduced in any form  without the written permission of IST: The Society for Imaging Science and Technology  the sole copyright owners of The Journal of Imaging Science and Technology,10.1.1.1.2711,?,?
 Adaptive Coded Modulation for Fading Channels,Andrea J. Goldsmith Soon-Ghee Chua,1998,We apply coset codes to adaptive modulation in fading channels. Adaptive modulation is a powerful technique to improve the energy efficiency and increase the data rate over a fading channel. Coset codes are a natural choice to use with adaptive modulation since the channel coding and modulation designs are separable. Therefore trellis and lattice codes designed for additive white Gaussian noise (AWGN) channels can be superimposed on adaptive modulation for fading channels with the same approximate coding gains. We first describe the methodology for combining coset codes with a general class of adaptive modulation techniques. We then apply this methodology to a spectrally efficient adaptive  M-ary  quadrature amplitude modulation (MQAM) to obtain trellis-coded adaptive MQAM. We present analytical and simulation results for this design which show an effective coding gain of 3 dB relative to uncoded adaptive MQAM for a simple four-state trellis code and an effective 3.6-dB coding gain for an eight-state trellis code. More complex trellis codes are shown to achieve higher gains. We also compare the performance of trellis-coded adaptive MQAM to that of coded modulation with built-in time diversity and fixed-rate modulation. The adaptive method exhibits a power savings of up to 20 dB.,10.1.1.1.2712,?,?
Interactive Query Formulation Using Query by Navigation,H.A. Proper,1994,Effective information disclosure in the context of databases with a large conceptual  schema is known to be a non-trivial problem. In particular the formulation  of ad-hoc queries is a major problem in such contexts. Existing approaches  for tackling this problem include graphical query interfaces query by navigation  query by construction and point to point queries. In this report we propose an  adoption of the query by navigation mechanism that is especially geared towards  the InfoAssistant product. Query by navigation is based on ideas from the information  retrieval world in particular on the stratified hypermedia architecture.,10.1.1.1.2713,?,?
Analysis of Educational Media Server Workloads,Jussara M. Almeida   Jeffrey Krueger   Derek L. Eager  Mary K. Vernon ,2001,This paper presents an extensive analysis of the client workloads for educational media servers at two major U.S. universities. The goals of the analysis include providing data for generating synthetic workloads gaining insight into the design of streaming content distribution networks and quantifying how much server bandwidth can be saved in interactive educational environments by using recently developed multicast streaming methods for stored content.,10.1.1.1.2714,?,?
Mining the Posterior Cingulate:,Segregation Between Memory,2003,We present a general method for automatic meta-analyses in neuroscience and apply it  on text data from published functional imaging studies to extract main functions associated  with a brain area --- the posterior cingulate cortex. Abstracts from PubMed are downloaded  words extracted and converted to a bag-of-words matrix representation. The combined data  is analyzed with hierarchical non-negative matrix factorization. We find that the prominent  themes in the PCC corpus are episodic memory retrieval and pain. We further characterize the  distribution in PCC of the Talairach coordinates available in some of the articles. This shows  a tendency to functional segregation between memory and pain components where memory  activations are predominantly in the caudal part and pain in the rostral part of PCC.,10.1.1.1.2715,?,?
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros B. A. Peters J. S. Smith D. J. Medeiros M. W. Rohrer Hideyuki Mizuta,?,The need for new theoretical and experimental approaches to understand dynamic and heterogeneous behavior in complex economic and social systems is increasing recently. An approach using the agent-based simulation and the artificial market on the computer system is considered to be an effective approach. The computational simulation with dynamically interacting heterogeneous agents is expected to re-produce complex phenomena in economics and helps us to experiment various controlling methods to evaluate systematic designs and to extract the fundamental elements which produce the interesting phenomena for future analytical works. In the previous works we investigated the stability of a virtual commodities market and the aggregated behavior of the dynamic online auctions with heterogeneous agents. In this paper we will introduce a simple framework to develop agent-based simulations systematically and consider an application of the agent-based simulation for a dynamical model of the international greenhouse gas emissions trading.,10.1.1.1.2716,?,?
Newtonian Cosmology with Renormalized Zero-Point Radiation,Browne Davenfield Road Manchester M Tl,2001,this paper Newtonian cosmology is extended in a manner which yields the same effects as are obtained for the de Sitter cosmology in Einsteins theory. In particular the emergence of the Hubble redshift in de Sitter cosmology as a Doppler-cum-gravitational effect for de Sitter coordinates and as a tired light effect for Robertson coordinates can be matched in extended Newtonian cosmology,10.1.1.1.2717,?,?
LHAP: A Lightweight Hop-by-Hop Authentication Protocol For Ad-Hoc,Networks Sencun Zhu Sencun Zhu Shouhuai Xu Sanjeev Setia Sushil Jajodia,2003,Most ad hoc networks do not implement any network access  control leaving these networks vulnerable to resource consumption attacks where a malicious node injects packets into the network with the goal of depleting the resources of the nodes relaying the packets. To thwart or prevent such attacks it is necessary to employ authentication mechanisms that ensure that only authorized nodes can inject traffic into the network. In this paper we present LHAP a scalable and light-weight authentication protocol for ad hoc networks. LHAP is based on two techniques: (i) hop-by-hop authentication for verifying the authenticity of all the packets transmitted in the network and (ii) one-way key chain and TESLA for packet authentication and for reducing the overhead for establishing trust among nodes. We analyze the security of LHAP and show LHAP is a lightweight security protocol through detailed performance analysis.,10.1.1.1.2718,?,?
Continuous Trading or Call Auctions: Revealed Preferences of Investors at the Tel Aviv Stock Exchange,Avner Kalay  Li Wei  Avi Wohl Bruno Biais Andrew Ellul Laurent Germain Joel Hasbrouck,?,We use the move of Israeli stocks from call auction trading to continuous trading to show that investors have a preference for stocks that trade continuously. When large stocks move from call auction to continuous trading the small stocks that still trade by call auction experience a significant loss in volume relative to the overall market volume. As small stocks move to continuous trading they experience an increase in volume and positive abnormal returns because of the associated increase in liquidity. Overall though a move to continuous trading increases the volume of large stocks relative to small stocks. Choosing among alternative trading mechanisms is an issue of growing concern to financial economists.,10.1.1.1.2719,?,?
Efficient Acquisition of Web Data through Restricted Query Interfaces,Simon Byers et al.,2001,A wealth of information is available on the Web. But often such data are hidden behind form interfaces which allow only a restrictive set of queries over the underlying databases greatly hindering data exploration. The ability to materialize these databases has endless applications from allowing the data to be effectively mined to providing better response times in Web information integration systems. However reconstructing database images through restricted interfaces can be a daunting task and sometimes infeasible due to network traffic and high latencies from Web servers. In this paper we introduce the problem of generating efficient query covers i.e. given a restricted query interface how to efficiently reconstruct a complete image of the underlying database. We propose a solution to the problem of finding covers for spatial queries over databases accessible through nearestneighbor interfaces. Our algorithm guarantees complete coverage and leads to speedups of over 50 when compared against the naive solution. We use our case-study to illustrate useful guidelines to attack the general coverage problem and we also discuss practical issues related to materializing Web databases such as automation of data retrieval and techniques which make it possible to circumvent unfriendly sites while keeping the anonymity of the person performing the queries.,10.1.1.1.2720,queries,?
Legal Constituencies And,Economic Efficiencies Of A. C. Charania Yuri Takaya Yuri Takaya,?,Recent action in California in the U.S.A. vividly illustrates that lack of appreciation by civil actors of the economics of energy companies. This study seeks to act as future roadmap for legal actors to obtain clarity on economic issues affecting a potential future energy source namely Space Solar Power (SSP). Currently envisioned systems SSP systems would deliver gigawatts of power to terrestrial power grids from space lasting over 20 years and having orbital masses on the order of 40 International Space Stations. The interaction of legal challenges and economic justifications is examined for any group of public and private entities (fully domestic commercial ventures international conglomerates international civil organizations etc) that seek to build and/or operate an SSP system. In April of 2000 the Ministry of Economics and Industry (MITI) of Japan and the National Aeronautics and Space Administration (NASA) of the United States started a joint feasibility study on Space Solar Power. Due to the current climate of limited public funding for such large-scale space projects governments would prefer more industry involvement (technically and more important financially) in SSP. Conceptual case studies are developed of innovative future government and private sector partnerships for SSP. Sensitivities are performed on proposed legal and economic architectures.,10.1.1.1.2721,DSM Design Struc,?
Proceedings of the XII SIBGRAPI (October 1999) 1-10 Multiple Display Viewing Architecture for,Virtual Environments Over Alexandre G. Ferreira Renato F. G. Cerqueira Waldemar Celes Marcelo Gattass,1999,Visualization systems that support multiple-display viewing can greatly enhance user perception.,10.1.1.1.2723,?,SBC
Trained Detection of Buried Mines in SAR Images via the Deflection Optimal Criterion,Russell B. Cosgrove  Peyman Milanfar  Joel Kositsky,2004,In this paper we apply a deflection-optimal linear-quadratic detector to the detection of buried mines in images formed by a forward-looking ground-penetrating synthetic aperture radar. The detector is a linear-quadratic form that maximizes the output signal to noise ratio (deflection) and its parameters are estimated from a set of training data. We show that this detector is useful when the signal to be detected is expected to be stochastic with an unknown distribution and when only a small set of training data is available to estimate its statistics. The detector structure can be understood in terms of the singular value decomposition the statistical variations of the target signature are modelled using a compact set of orthogonal eigenmodes (or principal components) of the training data set. Because only the largest eigenvalues...,10.1.1.1.2724,?,?
Geometric Evolution Problems and Action-Measures,M. Buliga,?,this paper to formulate a general geometric evolution problem based on the notion of action-measure introduced here. For particular choices of the action-measure we obtain formulations of the mean curvature flow or the brittle fracture propagation problems,10.1.1.1.2725,?,?
Combining Rule-Based And Data-Driven Techniques For Grammatical Relation Extraction In Spoken Langugage,Kenji Sagae Alon Lavie  Brian MacWhinney,2003,We investigate an aspect of the relationship between parsing and corpus-based methods in NLP that has  received relatively little attention: coverage augmentation in rule-based parsers. In the specific task of  determining grammatical relations (such as subjects and objects) in transcribed spoken language we show  that a combination of rule-based and corpus-based approaches where a rule-based system is used as the  teacher (or an automatic data annotator) to a corpus-based system outperforms either system in isolation.,10.1.1.1.2726,?,?
FCND DP No. 81 FCND DISCUSSION PAPER NO. 81 THE CONSTRAINTS TO GOOD CHILD CARE PRACTICES IN ACCRA: IMPLICATIONS FOR PROGRAMS,Margaret Armar-klemesu Marie T. Ruel Daniel G. Maxwell Carol E Saul S. Morris,?,Life in urban areas presents special challenges for maternal child care practices. Data from a representative survey of households with children less than 3 years of age in Accra were used to test a number of hypothesized constraints to child care including various maternal (education employment marital status age health ethnic group migration status) and household-level factors (income calorie availability quality of housing and asset ownership availability of services household size and crowding). An age-specific child care index was created using recall data on maternal child feeding practices and use of preventive health services. A hygiene index was created from spot check observations of proxies of hygiene behaviors. Multivariate analyses showed that maternal schooling was the most consistent constraint to both the care and the hygiene index. None of the household-level characteristics were associated with the care index but better housing quality and access to garbage collection services were associated with better hygiene. Female head of household and larger family size were associated with poorer hygiene. The programmatic implications of these findings for nutrition education and behavior change interventions in Accra are discussed. The focus is on using the information to target the right practices to be modified as well as the main constraints to their adoption. iii CONTENTS Acknowledgments.........................................................................................................v 1. ,10.1.1.1.2727,?,?
Economic Small-World Behavior in Weighted Networks,Vito Latora  Massimo Marchiori Physical Journal B,2003,The small-world phenomenon has been already the subject of a huge variety of papers showing  its appeareance in a variety of systems. However some big holes still remain to be filled as the commonly  adopted mathematical formulation is valid only for topological networks. In this paper we propose a generalization  of the theory of small worlds based on two leading concepts e#ciency and cost and valid also  for weighted networks. E#ciency measures how well information propagates over the network and cost  measures how expensive it is to build a network. The combination of these factors leads us to introduce  the concept of economic small worlds that formalizes the idea of networks that are cheap to build and  nevertheless e#cient in propagating information both at global and local scale. In this way we provide an  adequate tool to quantitatively analyze the behaviour of complex networks in the real world. Various complex  systems are studied ranging from the realm of neural networks to social sciences to communication  and transportation networks. In each case economic small worlds are found. Moreover using the economic  small-world framework the construction principles of these networks can be quantitatively analyzed and  compared giving good insights on how e#ciency and economy principles combine up to shape all these  systems.,10.1.1.1.2728,?,?
Properties and Benefits of Calibrated Classifiers,Ira Cohen Ira Cohen Moises Goldszmidt Moises Goldszmidt,2004,A calibrated classifier provides reliable estimates of the true  probability that each test sample is a member of the class of interest.,10.1.1.1.2729,?,Springer
Language Technology and Patients with Limited English,Harold Somers,2004,This paper describes a proposed framework for the use of language technology to provide computer-based help for patients with limited or no English. Aimed at users of the Health Services who are disadvantaged by their (lack of) linguistic skills the system will assist the patient in different ways at different stages of their interactions with health-care providers. In its full conception it will embrace a wide range of NLP technologies. Although the research is based on the UK model of health-care provision there are clear messages for anyone interested in language technology and under-resourced languages whatever the application. Focusing on,10.1.1.1.2730,?,?
Scalable Video Transcaling For The Wireless Internet,Hayder Radha Department Hayder Radha Mihaela Van Der Schaar Shirish Karande,2004,The rapid and unprecedented increase in the heterogeneity of multimedia networks and devices emphasizes the  need for scalable and adaptive video solutions both for coding and transmission purposes. However in general  there is an inherent tradeoff between the level of scalability and the quality of scalable video streams. In other  words the higher the bandwidth variation the lower the overall video quality of the scalable stream that is needed  to support the desired bandwidth range. In this paper we introduce the notion of wireless video TranScaling (TS)  which is a generalization of (non-scalable) transcoding. With transcaling a scalable video stream that covers a  given bandwidth range is mapped into one or more scalable video streams covering different bandwidth ranges.,10.1.1.1.2731,?,?
Input Generation for Path Coverage in Software Testing,José C. Costa José C. Monteiro,?,The most common approach to checking correctness of a hardware or software design is to verify that a description of the design has the proper behavior as elicited by a series of input stimuli. In the case of software the program is simply run with the appropriate inputs and in the case of hardware its description written in a hardware description language (hdl) is simulated with the appropriate input vectors. Complete software,10.1.1.1.2732,?,?
Point-based Surface Rendering with Motion Blur,M. Alexa S. Rusinkiewicz Xin Guan Klaus Mueller,2004,In this paper we show how to extend point-based surface rendering to illustrate object motion. We do this by  first extruding the circular points into ellipsoids which fill the space traced out by the points in motion. Using  ellipsoids instead of cylinders achieves a low-passing effect of the motion trail. We then find the screen-space  projection of each ellipsoid which is an ellipse. These can be rendered conveniently using hardware acceleration.,10.1.1.1.2733,?,?
Trustable Components: Yet Another Mutation-Based Approach,Benoit Baudry   Vu Le Hanh Jean-Marc Jézéquel Yves Le Traon,2000,This paper presents the use of mutation analysis as the main qualification technique for:  - estimating and automatically enhancing a test set (using genetic algorithms)  - qualifying and improving a components contracts (that is the specification facet)  - measuring the impact of contractable robust components on global system robustness and reliability. The,10.1.1.1.2734,?,Kluwer Academic Publishers
Loop-Free Routing Using a Dense Label Set in Wireless Networks,Marc Mosko J. J.  Garcia-Luna-Aceves,?,We present a new class of on-demand routing protocols called Split Label Routing (SLR). The protocols guarantee loop-freedom at every instant by ensuring that node labels are always in topological order and thus induce a directed acyclic graph (DAG). The novel feature of SLR is that it uses a dense ordinal set with a strict partial order to label nodes. For any two labels there is always some label in between them. This allows SLR to insert a node in to an existing DAG without the need to relabel predecessors. SLR inherently provides multiple paths to destinations. We present a practical finitely dense implementation that uses a destination-controlled sequence number. The sequence number functions as a reset to node ordering when no more label splits are possible. The sequence number is changed only by the destination. Simulations show that our proposed protocol outperforms existing state-of-the-art on-demand routing protocols.,10.1.1.1.2735,?,?
Group Testing for Video Compression,Gidon Shavit  Michael F. Ringenburg  Jeff West Richard E. Ladner Eve A. Riskin,2004,Hong and Ladner [6] used context-based group testing to implement bitplane  coding for image compression. We extend this technique to video coding  by replacing the quantization and entropy-coding stages of an H.263 standard  video coder with bit-plane coding. We experiment with ways to improve  baseline coder including di#erent classification schemes and cross-frame adaptive  coding. Our results indicate that our new coder GTV (Group Testing  for Video) significantly outperforms H.263 at medium to high bit-rates (300+  kbps) on most sequences while allowing very precise rate scalability.,10.1.1.1.2736,?,?
Kelb - A Real-Time Programming Environment for the Sony AIBO,Erik Cedheim Ramzi Ferchichi  Anders Jonsson Dan Lind  Henrik Nyman  Olof Sivertsson  Andreas Widenfalk  Jöns Åkerlund  Leonid Mokrushin  Paul Pettersson,?,Kelb is a new real-time programming environment developed at Uppsala University for the Sony AIBO ERS-210. It is aimed to provide efficiency by introducing a notion of light-weight tasks executing according to well-known real-time scheduling algorithms and resource protocols while still allowing applications to be developed in a high-level abstract programming language. In this paper we give an overview of the design of Kelb and describe the status of the environment currently including: a real-time programming language and compiler extending gcc for MIPS with support for time- and event-triggered tasks a runtime library with support for static and dynamic preemptive scheduling algorithms (e.g. fixed priority...,10.1.1.1.2737,?,?
Fast Image Interpolation for Motion Estimation using,Graphics Hardware Francis Francis Kelly Anil Kokaram,2004,Motion estimation and compensation is the key to high quality video coding. Block matching motion estimation is used in most video codecs including MPEG-2 MPEG-4 H.263 and H.26L. Motion estimation is also a key component in the digital restoration of archived video and for post-production and special e#ects in the movie industry. Sub-pixel accurate motion vectors can improve the quality of the vector field and lead to more e#cient video coding. However sub-pixel accuracy requires interpolation of the image data. Image interpolation is a key requirement of many image processing algorithms. Often interpolation can be a bottleneck in these applications especially in motion estimation due to the large number pixels involved. In this paper we propose using commodity computer graphics hardware for fast image interpolation. We use the full search block matching algorithm to illustrate the problems and limitations of using graphics hardware in this way.,10.1.1.1.2738,Image Interpolation Motion Estimation Block Matching Programmable Graphics Hardware,?
PESO: Low Overhead Protection for Ethernet over SONET Transport,Swarup Acharya Bhawna Gupta  Pankaj Risbood Anurag Srivastava,2004,This paper addresses the issue of reliable transport of emerging data services in Ethernet over SONET (EoS) networks that require protection guarantees beyond standard best effort delivery. We argue that the current consensus of using Ethernet spanning tree and a SONET 1+1 protection while providing reliability is an inefficient use of resources. Instead we claim that EoS opens novel opportunities for protection heretofore unavailable in other environments. In particular the deployment of Virtual Concatenation and LCAS protocols enables route splitting creating a fundamentally new routing paradigm for circuit-switched environments. We propose a scheme called PESO appropriate for EoS with innovative routing failure notification and switching components. More importantly it is competitive with SONET protection without its 100% bandwidth overhead. We also suggest a enhancement in LCAS that can further improve PESOs switching time. PESO leverages the underlying protocols making it extremely attractive to implement and use in practice.,10.1.1.1.2739,?,?
A Workbench For Predicting The Performances Of Distributed Object Architectures,Sophie Dumas  Georges Gardarin,1998,The development of a Distributed Information System (DIS) can lead to critical bottlenecks because of the underlying architecture which is becoming more and more complex. Todays applications are both object-oriented and based on a new type of three-tiered client/server architecture. In this context the capabilities of a DIS can be drastically reduced if the performances of the system are not sufficient. Recognizing these trends industry and research are defining standards and technologies for communicating between components of a DIS and for database access mechanisms. The emerging candidates for these middleware technologies include the OMGs CORBA specification and Microsofts proprietary solution known as DCOM. A key problem with such complex architectures is the performance issue. This paper presents a simulationbased workbench for predicting the performance of applications relying on these architectures. The proposed tool is based on providing end users with mechanisms to specify the essential characteristics of the application he/she is conceiving and the ability to match the software components with the operational environment (hardware and operating system).,10.1.1.1.2740,?,?
EPTD Discussion Paper No. 115,Environment And Production Frank Place Steve Franzel Qureish Noordin Bashir Jama,?,This case study explores the development dissemination adoption and impact of improved tree  fallows in rural western Kenya. The processes of technology development and dissemination  throughout the region are described and analyzed. To analyze adoption and impact the paper  applies a variety of different data collection methods as well as samples from both pilot areas  where researchers maintained a significant presence and non-pilot areas where farmers learned of  the technologies through other channels. Sample sizes for the quantitative analysis ranged from  almost 2000 households for measuring the adoption process to just over 100 households for  measuring impact indicators. Qualitative methods included long-term case studies for 40  households and focus group discussions involving 16 different groups. The paper describes the  ways in which farmers used and modified improved fallow practices. Discussion also examines  the types of households using fallows and benefiting from their use.    Empirical results suggest that improved fallows almost always double on-farm maize yields. In  addition the data indicates that poor households use improved fallows at much greater rate  (about 30 percent) than they do fertilizer (8 percent) though on average the size of fallow plots  remains small at 440m   . As a result despite these promising signs the improved fallow systems  were not found to be linked to improved household level food security or poverty indicators  primarily primarily because the size of the fields under the agroforestry systems was on average  quite small.      Conclusion    To conclude improved fallows represent a technically effective and financially profitable  technology that is attractive to poor households with little cash available for ...,10.1.1.1.2741,?,?
A Generic Reconfigurable Neural Network Architecture Implemented,As Network On T. Theocharides G. Link N. Vijaykrishnan M. J. Irwin,?,Neural Networks are widely used in pattern recognition security applications and data manipulation. We propose a novel hardware architecture for a generic neural network using Network on Chip (NoC) interconnect. The proposed architecture allows for expandability mapping of more than one logical unit onto a single physical unit and dynamic reconfiguration based on application-specific demands. Simulation results show that this architecture has significant performance benefits over existing architectures.,10.1.1.1.2742,?,?
Type Refinements,Robert Harper Frank Pfenning,2001,xpressed yet still be automatically verified. Through careful logically motivated design we hope to combine the best ideas from abstract interpretation automated program analysis type theory and verification. In the remainder of this section we explain and justify our approach in somewhat more detail before giving a research plan in the next section.  Types and Complete Specifications. Complete specifications of a programs behavior are generally not feasible for complex software systems. For some smaller programs or components where specification may be possible the e#ort required to formally prove adherence to the specification can be tremendous. Finally even if both specification and proof are undertaken for a given module it is exceedingly burdensome to maintain such a proof as the 1  program evolves in response to changing requirements. A combination of these factors means that complete specification and verification are rarely undertaken in practice.  Type systems as the,10.1.1.1.2743,?,?
TCP Throughput Analysis under Transmission Error and Congestion Losses,Francois Baccelli  Ki Baek Kim,2004,This paper analyzes the performance of a large population of long lived TCP flows experiencing random packet losses due to both random transmission errors and congestion created by the sharing of a common tail drop bottleneck router. We propose a natural and simple model for the joint throughput evolution of the set of TCP sessions under such a mix of losses. For the case of Poisson transmission errors we show that the asymptotic model where the population tends to infinity leads to a well defined and tractable dynamical system. In particular we get the mean value of the throughput of each session as a function of the transmission error rate and the synchronization rate in the bottleneck router. The large population asymptotic model has two interesting and non-intuitive properties:  1) there exists a positive threshold (given in closed form) on the transmission error rate above which there are no congestion losses at all in steady state  2) below this threshold the mean throughput of each flow is an increasing function of the transmission error rate so that the maximum mean value is in fact achieved when the transmission error rate is equal to this threshold.,10.1.1.1.2744,?,?
A Quantitative Approach to Noninterference for Probabilistic Systems,Alessandro Aldini  Alessandra Di Pierro,2003,We present a technique for measuring the security of a system which relies on a probabilistic process algebraic formalisation of noninterference. We define a mathematical model for this technique which consists of a linear space of processes and linear transformations on them. In this model the measured quantity corresponds to the norm of a suitably defined linear operator associated to the system. The probabilistic model we adopt is reactive in the sense that processes can react to the environment with a probabilistic choice on a set of inputs it is also generative in the sense that outputs autonomously chosen by the system are governed by a probability distribution. In this setting noninterference is formulated in terms of a probabilistic notion of weak bisimulation. We show how the probabilistic information in this notion can be used to estimate the maximal information leakage i.e. the security degree of a system against a most powerful attacker.,10.1.1.1.2747,Key words Probabilistic Noninterference Process Algebra Similarity Relation Weak Bisimulation,?
The Symbolic Computation of Vector Field Expressions,Robert Grossman Richard Larson,1991,This is an expository paper explaining how trees can be used to  compute e#ectively the vector field expressions which arise in nonlinear  control theory. It also describe the mathematical structure that sets  of trees carry.,10.1.1.1.2748,?,Springer-Verlag
On-line Estimation of Internet Path Performance: An Application Perspective,Shu Tao  Roch Guerin,2004,Estimating end-to-end packet loss on Internet paths is important not only to monitor network performance but also to assist adaptive applications make the best possible use of available network resources. There has been significant prior work on measuring and modeling packet loss in the Internet but most of those techniques do not focus on providing realtime information and on assessing path performance from an application standpoint. In this paper we present an on-line probing-based approach to estimate the loss performance of a network path and extend this estimate to infer the performance that an application using the path would see. The approach relies on a hidden Markov model constructed from performance estimates generated from probes which is then used to predict path performance as an application would experience. The accuracy of the model is evaluated using a number of different metrics including loss rate and loss burstiness. The sensitivity of the results to measurement and computational overhead is also investigated and an extension of the base approach using a layered model is explored as a possible solution to capturing time-varying channel behavior while keeping computational complexity reasonably low. The results we present show that the approach is capable of generating accurate real-time estimates of path performance and of predicting the performance that applications would experience if routed on the path.,10.1.1.1.2749,?,?
What Fraction of Images on the Web Contain Text?,Tapas Kanungo et al.,2001,Web search engines index text represented in symbolic form. However it is well known that a fraction of the text on the web is present in the form of images and the textual content of these images is not indexed by the search engines. This fact immediately raises a few questions: i) What fraction of the images on the web contain text? ii) What fraction of the text content of these images does not appear in the web page in symbolic form? Answers to these questions will give the web users an idea about the amount of information being missed by the search engines and justify whether or not Optical Character Recognition should be a standard part of search engine indexing. To answer these questions we statistically sample the images referenced in the web pages retrieved by a search engine for specific queries and then find the fraction of sampled images that contain text.,10.1.1.1.2750,?,?
Semantics of Time-Varying Attributes and Their Use for Temporal Database Design,Christian S. Jensen Richard T. Snodgrass,1995,This paper concerns the design of temporal relational database schemas. Normal forms,10.1.1.1.2751,?,Springer-Verlag
Effect of Large Buffers on TCP Queueing Behavior,Jinsheng Sun Moshe Zukerman King-tim Ko  Guanrong Chen Sammy Chan,2004,Using a simple model of saturated synchronized and homogeneous sources of TCP Reno with drop-tail queue management and a discrete-time framework we derive formulae for stationary as well as transient queueing behavior that shed light on the relationship between large buffers and work conservation (queue never empties). Using simulations the relevance of the results for the case of non-synchronized sources is demonstrated. In particular we demonstrate that a certain simple lower bound for the stationary queue length applies also to the case where the sources are non-stationary.,10.1.1.1.2753,?,?
Comparing Petri Net and Activity Diagram Variants for Workflow Modelling - A Quest for Reactive Petri Nets,Rik Eshuis Roel Wieringa,2002,Petri net variants are widely used as a workflow modelling  technique. Recently UML activity diagrams have been used for the same  purpose even though the syntax and semantics of activity diagrams has  not been yet fully worked out. Nevertheless activity diagrams seem very  similar to Petri nets and on the surface one may think that they are  variants of each other. To substantiate or deny this claim we need to  formalise the intended semantics of activity diagrams and then compare  this with various Petri net semantics. In previous papers we have defined  two formal semantics for UML activity diagrams that are intended for  workflow modelling. In this paper we discuss the design choices that underlie  these two semantics and investigate whether these design choices  can be met in low-level and high-level Petri net semantics. We argue  that the main di#erence between the Petri net semantics and our semantics  of UML activity diagrams is that the Petri net semantics models  resource usage of closed active systems that are non-reactive whereas  our semantics of UML activity diagrams models open reactive systems.,10.1.1.1.2754,?,Springer
A Database for Handwriting Recognition Research in Sinhala Language,Fernando Chandrika Sliit H. C. Fern N. D. Kodikara S. Hewavitharana,?,This article presents a database of images of handwritten city names. The aim is to provide a standard database for Sinhala handwriting recognition research. This database contains about 15000 images of about 500 city names of Sri Lanka. These images are obtained from the addresses of live mail so that the writers had no idea that they would be used for this purpose. Also these are unconstrained handwriting images unlike the images collected using prescribed forms in laboratory environment. The images are divided into two groups training set and testing set. This enables the comparison of results of different researches and serves the purpose of being a standard database.,10.1.1.1.2755,?,?
Effective Voting of Heterogeneous Classifiers,Grigorios Tsoumakas Ioannis Katakis Ioannis Vlahavas,2004,This paper deals with the combination of classification models  that have been derived from running di#erent (heterogeneous) learning  algorithms on the same data set. We focus on the Classifier Evaluation  and Selection (ES) method that evaluates each of the models (typically  using 10-fold cross-validation) and selects the best one. We examine  the performance of this method in comparison with the Oracle selecting  the best classifier for the test set and show that 10-fold cross-validation  has problems in detecting the best classifier. We then extend ES by applying  a statistical test to the 10-fold accuracies of the models and combining  through voting the most significant ones. Experimental results  show that the proposed method E#ective Voting performs comparably  with the state-of-the-art method of Stacking with Multi-Response Model  Trees without the additional computational cost of meta-training.,10.1.1.1.2756,?,?
A Hierarchical XCS for Long Path Environments,Alwyn Barry,2001,It has been noted (Lanzi 1997 Butz et al 2000)  that XCS (Wilson 1998) is unable to identify an  adequate solution to the Maze14 problem (Cliff  and Ross 1994) without the introduction of  alternative exploration strategies. The simple  expedient of allowing exploration to start at any  position in the Maze will allow XCS to learn in  such `difficult environments (Barry 2000b)  and Lanzi (1997) has demonstrated that his  `teletransportation mechanism achieves similar  results. However these approaches are in truth a  re-formulation of the problem. In many `real  robotic learning tasks there are no opportunities  available to `leapfrog to a new state. This paper  describes an initial investigation of the use of a  pre-specified hierarchical XCS architecture. It is  shown that the use of internal rewards allows  XCS to learn optimal local routes to each  internal reward and that a higher-level XCS can  select over internal sub-goal states to find the  optimum route across sub-goals to a global  reward. It is hypothesised that the method can be  expanded to operate within larger environments  and that an emergent approach using similar  techniques is also possible.,10.1.1.1.2757,?,?
An FIR Cascade Structure for Adaptive Linear Prediction,Paolo Prandoni Martin Vetterli,1998,An alternative structure for adaptive linear prediction is proposed in which the adaptive filter is replaced by a cascade of independently adapting low-order stages and the prediction is generated by means of successive refinements. When the adaptation algorithm for the stages is LMS the associated short filters are less affected by eigenvalue spread and mode coupling problems and display a faster convergence to their steady-state value. Experimental results show that a cascade of second-order LMS filters is capable of successfully modeling most input signals with a much smaller MSE than LMS or lattice LMS predictors in the early phase of the adaptation. Other adaptation algorithms can be used for the single stages whereas the overall computational cost remains linear in the number of stages and very fast tracking is achieved.,10.1.1.1.2758,?,Kluwer
A Variable Metric Probabilistic k-Nearest-Neighbours Classifier,Richard M. Everson Jonathan E. Fieldsend,?,The k-nearest neighbour (k-nn) model is a simple popular  classifier. Probabilistic k-nn is a more powerful variant in which the  model is cast in a Bayesian framework using (reversible jump) Markov  chain Monte Carlo methods to average out the uncertainy over the model  parameters.,10.1.1.1.2759,?,?
Sequential Pattern Mining with Approximated Constraints,Cláudia Antunes Arlindo L. Oliveira,2004,The lack of focus that is a characteristic of unsupervised pattern mining in sequential data represents one of the major limitations of this approach. This lack of focus is due to the inherently large number of rules that is likely to be discovered in any but the more trivial sets of sequences. Several authors have promoted the use of constraints to reduce that number but those constraints approximate the mining task to a hypothesis test task. In this paper,10.1.1.1.2760,Pattern Mining Sequential Pattern Mining Constraints Constraint Relaxations Deterministic Finite Automata,?
Reflections on the Huallaga Quechua dictionary:,Derived Forms As David J. Weber Together Félix Cayco Zambrano Teodoro Cayco Villar Marlene Ballena,2002,earlier versions. But dont blame them for my indiscretions.    It can be purchased in Peru at Javier Prado 200 Magdalena Lima. Sales to outside of Peru are handled by Seta Soledad Esteban of the Liberia Interregna bookstore Fax 426-2742.    I use lexicon (and lexicons not lexica) to refer to speakers knowledge of the lexical resources of their language lexical database to refer to an information structure that represents lexical information (reflecting characteristics of a lexicon) and dictionary to refer to a rendering of a lexical database whether printed on pages or displayed in some electronic form.    Tools like Shoebox [1] and the Making Dictionaries package [4] were developed to serve this approach.    This is not true for database programs that print information according to user-defined templates. However such programs present their own challenges most notably their proprietary data formats.  The Huallaga Quechua lexical database was stored as such a re,10.1.1.1.2761,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,We are developing interactive simulations of the National Institute of Standards and Technology (NIST) Reference Test Facility for Autonomous Mobile Robots (Urban Search and Rescue). The NIST USAR Test Facility is a standardized disaster environment consisting of three scenarios of progressive difficulty: Yellow Orange and Red arenas. The USAR task focuses on robot behaviors and physical interaction with standardized but disorderly rubble filled environments. The simulation will be used to test and evaluate designs for teleoperation interfaces and robot sensing and cooperation that will subsequently be incorporated into experimental robots. This paper describes our novel simulation approach using an inexpensive game engine to rapidly construct a visually and dynamically accurate simulation for both individual robots and robot teams.,10.1.1.1.2762,?,?
Interval in the Theory of Relativity,Streltsov Laboratory Of V. N. Strel’tsov,2001,Introduction  In the theory of relativity (TR) an interval (pseudo-distance) takes the place of the previous prerelativistic  invariant-distance (length). Therefore for example one should say more correctly about the (space-like) interval of a rod i.e. in essence in the non-relativistic limit their values coincide which ensures the succession of corresponding theories and the necessary uniqueness of the interval. Taking into account interval Lorenz invariance in a moving reference frame it leads only to the radar definition of the moving rod length (see e.g.[2]).  It should be emphasized that we deal with one the fundamental problems of physics here. Space dimensions or in general space correlations parallel with time ones serve as the basis for the description of all natural phenomena (by means of physical theories in particular). At the same time we come across a highly strange phenomenon just in TR. The thing is that two statements namely the demand of interval i,10.1.1.1.2763,?,?
Proposed Experiments to Determine if There is a Connection between Biological Nonlocality and Consciousness,Fred H. Thaheld,2001,This paper was written around the same time as Bells landmark paper which addressed the problem of nonlocality [4]. This question of nonlocality had first been raised by Einstein-Podolsky-Rosen (EPR) who claimed that if quantum mechanics were a complete model of reality then nonlocal interactions between particles had to exist [5]. Since they felt that  nonlocality was impossible quantum mechanics either had to be  wrong or at least incomplete. An experiment was later performed  which showed that nonlocal influences do exist once these particles interact and that one can test the explicit quantum nature of systems A  2001 C. Roy Keys Inc,10.1.1.1.2764,© 2001 C. Roy Keys Inc,?
Handheld Routers: Intelligent Bandwidth Aggregation for Mobile Collaborative Communities,Puneet Sharma Puneet Sharma Sung-ju Lee Sung-ju Lee Jack Brassil Jack Brassil Kang G. Shin Kang G. Shin,2003,Multi-homed mobile wireless computing and communication devices can spontaneously form communities to logically combine and share the bandwidth of each others wide-area communication links using inverse multiplexing. But membership in such a community can be highly dynamic as devices and their associated WAN links randomly join and leave the community. We identify the issues and tradeoffs faced in designing a decentralized inverse multiplexing system in this challenging setting and determine precisely how heterogeneous WAN links should be characterized and when they should be added to or deleted from the shared pool. We then propose methods of choosing the appropriate channels on which to assign newly-arriving application flows. Using video traffic as a motivating example we demonstrate how significant performance gains can be realized by adapting allocation of the shared WAN channels to specific application requirements. Our simulation and experimentation results show that collaborative bandwidth aggregation systems are indeed a practical and compelling means of achieving high-speed Internet access for groups of wireless computing devices beyond the reach of public or private access points.,10.1.1.1.2765,?,?
Inertial Induction and the Potential Energy Problem,Amitabha Ghosh Department Amitabha Ghosh,2001,this paper it has been shown that the potential energy of a particle of mass m in an infinite homogeneous Euclidean universe is not only finite but is exactly equal to -mc   . This implies that the total energy is zero a fact which may have many interesting implications. ,10.1.1.1.2766,?,?
Graphics Recognition - from Re-engineering to Retrieval,Karl Tombre  Bart Lamiroy,2003,In this paper we discuss how the focus in document analysis generally speaking and in graphics recognition more specifically has moved from re-engineering problems to indexing and information retrieval. After a review of ongoing work on these topics we propose some challenges for the years to come.,10.1.1.1.2767,?,?
Towards Seamless Integration in a Multi-modal Interface,Dennis Perzanowski   William Adams Alan C. Schultz Elaine Marsh,2000,We are designing and implementing a multi-modal  interface to an autonomous robot. For this interface we  have elected to use natural language and gesture. Gestures  can be either natural gestures perceived by a vision system  installed on the robot or they can be made by using a  stylus on a Personal Digital Assistant. In this paper we  describe how we are attempting to provide a seamless  integration of the various modes of input to provide a  multi-modal interface that humans can manipulate as they  desire. The interface will allow the user to choose  whatever mode or combination of modes seems  appropriate for interactions with the robot. The human  user therefore does not have to be limited to any one  mode of interaction but can freely choose whatever mode  is most comfortable or natural.,10.1.1.1.2768,?,AAAI Press
A Literature-Based Method For Assessing The Functional Coherence Of A Gene Group,Soumya Raychaudhuri  Russ B. Altman,2003,Motivation: Many experimental and algorithmic approaches in biology generate groups of genes that need to be examined for related functional properties. For example gene expression profiles are frequently organized into clusters of genes that may share functional properties. We evaluate a method neighbor divergence per gene (NDPG) that uses scientific literature to assess whether a group of genes are functionally related. The method requires only a corpus of documents and an index connecting the documents to genes.,10.1.1.1.2769,?,?
Anchored Opportunity Queueing: A Low-Latency Scheduler for Fair Arbitration among Virtual Channels,Salil S. Kanhere  Harish Sethu,?,This paper presents a novel scheduling strategy Anchored Opportunity Queueing (AOQ) which preserves the throughput and fairness characteristics of FBRR while significantly reducing the average delay experienced by packets. The AOQ scheduler achieves lower average latencies by trying as far as possible to complete the transmission of a complete packet before beginning the transmission of flits from another packet. The AOQ scheduler achieves provable fairness in the number of opportunities it offers to each of the virtual channels for transmissions of flits over the physical channel. We prove this by showing that the relative fairness bound a popular measure of fairness is a small finite constant in the case of the AOQ scheduler. Finally we present simulation results comparing the delay characteristics of AOQ with other schedulers for virtual channels. The AOQ scheduler is simple to implement in hardware and also offers a practical solution in other contexts such as in scheduling ATM cells in Internet backbone switches,10.1.1.1.2770,?,?
EPTD DISCUSSION PAPER NO. 69 CONSUMPTION EFFECTS OF GENETIC MODIFICATION: WHAT IF CONSUMERS ARE RIGHT?,Konstantinos Giannakas Murray Fulton,?,This paper develops a model of differentiated consumers to examine the consumption effects of genetic modification (GM) under alternative labeling regimes and segregation enforcement scenarios. Analytical results show that if consumers perceive GM products as being different than their traditional counterparts genetic modification affects consumer welfare and thus consumption decisions. When the existence of market imperfections in one or more stages of the supply chain prevents the transmission of cost savings associated with the new technology to consumers genetic modification results in welfare losses for consumers. The analysis shows that the relative welfare ranking of the no labeling and mandatory labeling regimes depends on: (i) the level of consumer aversion to genetic modification (ii) the size of marketing and segregation costs under mandatory labeling (iii) the share of the GM product to total production and (iv) the extent to which GM products are incorrectly labeled as non-GM products. CONTENTS 1. ,10.1.1.1.2771,?,?
Analyzis of Capacity in Ad Hoc Network with Variable Data Rates,Linda Farman  Ulf Sterner  Otto Tronarp,?,In this paper we present how the throughput in an ad hoc network is affected by using variable data rate. The study is based on four different systems with different routing and MAC protocols. We also study the imapct of different number of available data rates. The data rate lies between 100 kbit/s to 20 Mbit/s.,10.1.1.1.2772,?,?
Accuracy vs Lifetime: Linear Sketches for Appoximate Aggregate Range Queries in Sensor Networks,Konstantinos Kalpakis Vasundhara Puttagunta  Parag Namjoshi,2004,Query processing in sensor networks is critical for several sensor based monitoring applications and  poses several challenging research problems. The in--network aggregation paradigm in sensor networks  provides a versatile approach for evaluating simple aggregate queries in which an aggregation--tree is  imposed on the sensor network that is rooted at the base--station and the data gets aggregated as it gets  forwarded up the tree. In this paper we consider an two kinds of aggregate queries: value range queries  that compute the number of sensors that report values in the given range and location range queries  that compute the sum of values reported by sensors in a given location range. Such queries can be  answered by using the in--network aggregation approach where only sensors that fall within the range  contribute to the aggregate being maintained. However it requires a separate aggregate to be computed  and communicated for each query and hence does not scale well with the number of queries. Many,10.1.1.1.2775,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,This paper describes a new methodology to enable large scale high resolution environmental simulation. Unlike the vast majority of environmental modeling techniques that split the space into cells the use of a vector space is proposed here. A phenomena will then be described by its shape decomposed in several points that can move using a displacement vector. The shape also have a dynamic structure as each point can instantiate new point because of a change in the space properties or to obtain a better resolution model. Such vector models are generating less overhead because the phenomena is recomputed only if a part of it is entering into a different space entity with different attributes using cellular space the model would have been recomputed for each neighboring identical cells. This technique uses the DSDEVS formalism to describe discrete event models with dynamic structure and will be implemented in the JDEVS toolkit also presented.,10.1.1.1.2776,?,?
Query Optimization for XML,Jason Mchugh Jennifer Widom,1999,XML is an emerging standard for data representation  and exchange on the World-Wide Web. Due to  the nature of information on the Web and the inherent  flexibility of XML we expect that much of the  data encoded in XML will be semistructured:the  data may be irregular or incomplete and its structure  may change rapidly or unpredictably. This paper  describes the query processor of LoreaDBMS  for XML-based data supporting an expressive query  language. We focus primarily on Lores cost-based  query optimizer. While all of the usual problems  associated with cost-based query optimization apply  to XML-based query languages a number of additional  problems arise such as new kinds of indexing  more complicated notions of database statistics and  vastly different query execution strategies for different  databases. We define appropriate logical and  physical query plans database statistics and a cost  model and we describe plan enumeration including  heuristics for reducing the large search space. Our  optimizer is fully implemented in Lore and preliminary  performance results are reported.,10.1.1.1.2777,?,?
Designing Policy Research On Local,Organizations In Natural Sara J. Scherr Louise Buck Ruth Meinzen-dick Lee Ann Jackson Tony Bebbington Deborah Merrill-s Gill Shepherd Jalan Gunung Batu,?,As policy research on natural resource management (NRM) evolves new priorities  are emerging related to the strategy design and implementation of policies to support local  organizations (LOs) as managers of natural resources. However research on policies  affecting LOs is at a very early stage with no accepted body of indicators methodologies  and conceptual approaches and little documentation or critique of the research methods  that have been used. To address this gap and to lay the basis for a future program of  comparative research IFPRI CIFOR and ODI co-sponsored an international workshop  in October 1994 with experts from different disciplines and different resource domains.,10.1.1.1.2778,?,?
Word Segmentation of Handwritten Dates in Historical Documents by Combining Semantic A-Priori-Knowledge with Local Features,Markus Feldbach  Klaus D. Tönnies,?,The recognition of script in historical documents requires suitable techniques in order to identify single words. Segmentation of lines and words is a challenging task because lines are not straight and words may intersect within and between lines. For correct word segmentation the conventional analysis of distances between text objects needs to be supplemented by a second component predicting possible word boundaries based on semantical information. For date entries hypotheses about potential boundaries are generated based on knowledge about the different variations as to how dates are written in the documents. It is modeled by distribution curves for potential boundary locations. Word boundaries are detected by classification of local features such as distances between adjacent text objects together with location-based boundary distribution curves as a-priori knowledge. We applied the technique to date entries in historical church registers. Documents from the 18th and 19th century were used for training and testing. The data set consisted of 674 word boundaries in 298 date entries. Our algorithm found the correct separation under the best four hypotheses for a word sequence in 97% of all cases in the test data set.,10.1.1.1.2779,?,?
Gesture Recognition Using The XWand,Daniel Wilson Andy Wilson ,?,The XWand is a wireless UI device that enables styles of natural interaction with intelligent environments. The XWand system exploits human intuition allowing control of everyday objects through pointing and gesturing. We describe the hardware device and then examine several approaches to gesture recognition. We discuss results from experiments using a linear time warping method a dynamic time warping (DTW) method and a hidden Markov model-based method (HMM).,10.1.1.1.2780,?,?
Post-supervised Template Induction for Information Extraction from Lists and Tables in Dynamic Web Sources,Z. Shi  E. Milios N. Zincir-heywood,2003,Dynamic web sites commonly return information in the form of lists and tables. Although hand crafting an extraction program for a specific template is time-consuming but straightforward it is desirable to automatically generate template extraction programs from examples of lists and tables in html documents. Supervised approaches have been shown to achieve high accuracy but they require manual labeling of training examples which is also time consuming. Fully unsupervised approaches which extract rows and columns by detecting regularities in the data cannot provide su#cient accuracy for practical domains. We describe a novel technique Post-supervised Learning which exploits unsupervised learning to avoid the need for training examples while minimally involving the user to achieve high accuracy. We have developed unsupervised algorithms to extract the number of rows and adopted a dynamic programming algorithm for extracting columns. Our method achieves high performance with minimal user input compared to fully supervised techniques.,10.1.1.1.2781,Information extraction grammar induction template induction unsupervised learning c ? 2003 Kluwer Academic Publishers. Printed in the Netherlands. jiisRevisedNo 17/11/2003 12 29 p.1,?
Computational Sample Complexity,Scott E. Decatur Oded Goldreich Dana Ron,1998,In a variety of PAC learning models a tradeoff between time and information seems to exist: with unlimited time a small amount of information suffices but with time restrictions more information sometimes seems to be required. In addition it has long been known that there are concept classes that can be learned in the absence of computational restrictions but (under standard cryptographic assumptions) cannot be learned in polynomial time regardless of sample size. Yet these results do not answer the question of whether there are classes for which learning from a small set of examples is infeasible but becomes feasible when the learner has access to (polynomially) more examples. To address this question we introduce a new measure of learning complexity called computational sample complexity which represents the number of examples sufficient for polynomial time  learning with respect to a fixed distribution. We then show concept classes that (under similar cryptographic assumpti...,10.1.1.1.2782,Computational Learning Theory Information vs. Efficient Computation PseudoRandom Functions Error Correcting Codes Wire-Tap Channel,Press
A Reflective Study On The Use Of Caa To Test Knowledge,And Understanding Of Alan Boyle Alan Boyle,2002,Use of multiple choice question based computer aided assessment to assess level-one (first year) mineralogy produced a reliable assessment though with rather poor scores. The use of negative marking contributed to this and also drew negative comment from the student cohort. Reflection on these outcomes led to the use of multiple response questions which performed better and did not encourage negative student feedback. CAA performance does not equate very well with practical coursework assessment. However these two assessments are addressing different learning outcomes and so this disparity is not surprising. Statistical analysis suggests that these two forms of assessment give a truer indication of a students ability when they are combined. It enforces the conclusion that appropriate assessment tools should be used for stated learning outcomes and that multimodal assessment is best.,10.1.1.1.2783,?,?
Annotating With Uses:,Promising Way To,?,A@BC4D=/EB7A/=/)!%!!#B 2EF9BC G!H@0  EB/IB!(!##!7/J!5KL62EM*C6=N9B/ 4D#B*#O#B/)!P!%!#B4/.1QR+-SO79BSA!#PI26IP!#2O! 9B/T!H@SO%!#U/=?/V)9B!:9U92E69B/01 !#6!P!#BK(*C6!D.S==TIBCE*!CE10B62E#B/*UI=/U/)!CETQ  #B W0R*E76*!926=X9B/Y(CKZ.U-[U*//)!S4P/K 6 R \9B=]==B7U9/B9BIBCE*!CEB/CEB/Q  +-AIBI7/H=P6IIB*H#M \%!H@79G)!^6*  *9)!CQ(#B/^4  UIB/!#C4_!#YIBIB?6*#`4P6G6II=CE`  !4-I6a5/*!A=B7^!#B9!#/b^cedgfShXiPj%0XU7MO!  6!B7A!#B/9Y6 Xicgf_EB)*9U/)!/02EdhXi  $0U7  O!Y*/)!/)!F.26CE!/6= D692EBO92=kE)*/9U/)!/QGce 3!  A*/UI6^ !#BYII?6*#4DJ!#l!#BS46@/=6!CE^! !#BU$/()!*:+l/.0T4  G*/*/=92E%!#6!Y6K9BG6 PU/9*/ #B9B=3ELB6!H6!(!#G/9B*/0  E-!#26!G9*H#LB!HO!/0 6A!#BKLIBOEBEEBJ!=g@BC4D=/EB76.9!A!#BZ/9*/0 #B9B=3Em.*/UZI6! S!#B`$/(6!*N+l/.n6A/9B*/6  !#B/JeO4D1Q  1. ,10.1.1.1.2784,?,?
A Case for the Global Access to Large Distributed Data Sets Using Data Webs Employing Photonic Data Services,Dave Lillethun Robert Grossman Yunhong Gu Dave Hanley Xinwei Hong Jorge Levera  Marco Mazzucco Jeremy Weinberger Joe Mambretti,2003,We argue that data webs employing specialized path services network  protocols and data protocols can be an e#ective platform to analyze  and access millions of distributed Gigabyte (and larger) size data  sets. We have built a prototype of such a data web today and demonstrated  that it can e#ectively access analyze and mine distributed  Gigabyte size data sets even over thousands of miles by using specialized  network and data protocols. The prototype uses a server which  employs the DataSpace Transfer Protocol or DSTP. Our assumption  is that WSDL/SOAP/UDDI-based discovery and description services  will enable this same infrastructure to scale to millions of such DSTPServers.,10.1.1.1.2786,?,?
INS/Twine: A Scalable Peer-to-Peer Architecture for Intentional Resource Discovery,Magdalena Balazinska Hari Balakrishnan David Karger,2002,The decreasing cost of computing technology is speeding the  deployment of abundant ubiquitous computation and communication.,10.1.1.1.2787,?,Springer-Verlag
Hierarchical Recognition of Propositional Arguments with Perceptrons,Xavier Carreras  Lluis Marquez  Grzegorz Chrupala,2004,this paper translates these observations into constraints which are enforced to hold in a solution and guide the recognition strategy. A limitation of the system is that it makes no attempt to recognize arguments which are split in many phrases,10.1.1.1.2789,?,?
Workload Characterization of Elliptic Curve Cryptography and other Network Security Algorithms for Constrained Environments,A. Murat Fiskiran Ruby B. Lee,2002,In recent years some cryptographic algorithms have gained popularity due to properties that make them suitable for use in constrained environments like mobile information appliances where computing resources and power availability are limited. In this paper we select a set of public-key symmetric-key and hash algorithms suitable for such environments and study their workload characteristics. In particular we study elliptic-curve versions of public-key cryptography algorithms which allow fast software implementations while reducing the key size needed for a desired level of security compared to previous integer-based public-key algorithms. We characterize the operations needed by elliptic-curve analogs of Diffie-Hellman key exchange ElGamal and the Digital Signature Algorithm for public-key cryptography for different key sizes and different levels of software optimization. We also include characterizations for the Advanced Encryption Standard (AES) for symmetric-key cryptography and SHA as a hash algorithm. We show that all these algorithms can be implemented efficiently with a very simple processor.,10.1.1.1.2790,?,IEEE
Game Over: The Foci Approach to LTL Satisfiability and Model Checking,Christian Dax Martin Lange,2004,Focus games have been shown to yield game-theoretical characterisations for the satisfiability and the model checking problem for various temporal logics. One of the players is given a tool -- the focus -- that enables him to show the regeneration of temporal operators characterised as least or greatest fixpoints. His strategy usually is build upon a priority list of formulas and thus is not positional. This paper defines foci games for satisfiability of LTL formulas. Strategies in these games are trivially positional since they parallelise all of the focus players choices thus resulting in a 1-player game in e#ect. The games are shown to be correct and to yield smaller (counter-)models than the focus games. Finally foci games for model checking LTL are defined as well.,10.1.1.1.2791,Key words Verification Temporal Logic Tool Support,?
Supertree Algorithms for Ancestral Divergence Dates and Nested Taxa,Charles Semple  Philip Daniel  Wim Hordijk  Roderic D.M. Page  Mike Steel,2004,Motivation: Supertree methods have been often identified as a possible approach to the reconstruction of the `Tree of Life. However a limitation of such methods is that typically they use just leaf-labelled phylogenetic trees to infer the resulting supertree.,10.1.1.1.2792,?,?
Interactive Analysis of High-Dimensional Data Using Visualization,Helwig Hauser Robert Kosara,2004,... In this paper a few of the central concepts of InfoVis are introduced: (1) visualization with multiple views which often are (but not necessarily need to be) of different visualization types and which are visually linked to each other especially when used in conjunction with interactive brushing (linking and brushing LB) (2) focus-plus-context visualization (F+C visualization) as a means to jointly support zooming into the visual depiction of the data while at the same time maintaining the visual orientation of the visualization user to support navigation in the visualization and (3) the potential combination of visualization methods and such from statistics as an interesting perspective for future work.,10.1.1.1.2793,?,?
Variational Normal Meshes,Ilja Friedel  Andrei Khodakovsky Peter Schröder,?,... In this paper we propose a novel method to approximate a given mesh with a normal mesh. Instead of building an associated parameterization on the fly we assume a globally smooth parameterization at the beginning and cast the problem as one of perturbing this parameterization. Controlling the magnitude of this perturbation gives us explicit control over the range between fully constrained (only scalar coefficients) and unconstrained (3-vector coe#cients) approximations. With the unconstrained problem giving the lowest approximation error we can thus characterize the error cost of normal meshes as a function of the number of non-normal offsets---we find a significant gain for little (error) cost. Because the normal mesh construction creates a geometry driven approximation we can replace the difficult geometric distance minimization problem with a much simpler least squares problem. This variational approach reduces magnitude and structure (aliasing) of the error further. Our method separates the parameterization construction into an initial setup followed only by subsequent perturbations giving us an algorithm which is far simpler to implement more robust and significantly faster,10.1.1.1.2794,General Terms Surface approximation. Additional Key Words and Phrases semi-)regular meshes subdivision normal meshes hierarchy,?
A General Solution to the Graph History Interaction Problem,Akihiro Kishimoto  Martin Müller,2004,Since the state space of most games is a directed graph many  game-playing systems detect repeated positions with a transposition  table. This approach can reduce search effort by a  large margin. However it suffers from the so-called Graph  History Interaction (GHI) problem which causes errors in  games containing repeated positions. This paper presents a  practical solution to the GHI problem that combines and extends  previous techniques. Because our scheme is general  it is applicable to different game tree search algorithms and  to different domains. As demonstrated with the two algorithms   ## and df-pn in the two games checkers and Go our  scheme incurs only a very small overhead while guaranteeing  the correctness of solutions.,10.1.1.1.2795,GHI problem df-pn algorithm ?? algorithm,?
A Logical Framework For Reasoning About Logical Specifications,Alwen F. Tiu Padma Raghavan Stephen Simpson Frank Pfenning Raj Acharya,2004,We present a new logic Linc which is designed to be used as a framework for specifying and reasoning about operational semantics. Linc is an extension of firstorder intuitionistic logic with a proof theoretic notion of definitions induction and coinduction and a new quantifier  #.,10.1.1.1.2796,?,?
A Control Lyapunov Function Approach to Safeguarded Shared Control,Wei Ren  Randal W. Beard,2003,In this paper control Lyapunov functions are used to define static and dynamic safe regions for a system. Based on a control Lyapunov function a feasible input set is defined as all feasible controls for this CLF according to attractive behaviors and repulsive behaviors. If the system is within a specified safe region the human input will be used as the control input to the system. If the system is outside the specified safe region the human input will be snapped to the closest control element in the feasible input set. Behavior based strategies are applied to achieve smooth transition from human input to snapped control input so as to guarantee maximum flexibility for humans as well as system stability and minimum base-line performance. An illustrative example for a mobile robot shows the effectiveness of the approach.,10.1.1.1.2797,?,?
Input/Output Behavior of Supercomputing Applications,Ethan L. Miller Randy H. Katz,1991,This paper describes the collection and analysis of supercomputer I/O traces and their use in a collection of buffering and caching simulations. This serves two purposes. First it gives a model of how individual applications running on supercomputers request file system I/O allowing system designers to optimize I/O hardware and file system algorithms to that model. Second the buffering simulations show what resources are needed to maximize the CPU utilization of a supercomputer given a very bursty I/O request rate. By using read-ahead and write-behind in a large solid-state diskone or two applications were sufficient to fully maximize a Cray Y-MP CPU.,10.1.1.1.2798,?,ACM
Möbius transformations and ellipses,Adam Coffman Marc Frantz,2007,This expository article considers non-circular ellipses in the Riemann sphere and the action of the group of Mobius transformations.  In particular we find which Mobius transformations are symmetries of an ellipse and which take one ellipse to another.  We also survey some of the ``special plane curves which appear as inversive images of the ellipse.,10.1.1.1.2799,?,?
A Framework For Visual Information Retrieval,On The Web Adil Alpkoçak Esen Özkarahan Dokuz Eylül,?,Today on the Internet there is a wide variety of text based search  engines however the same is not true for searching visual information placed in  Internet Web pages. There is increased activity and research for querying such  databases especially for content based visual querying. The heterogeneous  distributed and transient nature of visual information lack of interoperable  retrieval systems and the limited bandwidth of Web environment presents  bottlenecks for such efforts. In this study the difficulties of visual information  retrieval on the Web are highlighted and a visual information retrieval system  in such an environment is presented.,10.1.1.1.2800,?,?
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros B. A. Peters J. S. Smith D. J. Medeiros M. W. Rohrer Christos Alexopoulos David Goldsman,?,Healthcare management operates in an environment of aggressive pricing tough competition and rapidly changing guidelines. Computer simulation models are increasingly used by large healthcare institutions to meet these challenges. However small healthcare facilities serving the poor are equally in need of meeting these challenges but lack the finances and personnel required to develop and implement their own simulation solutions. An academic medical center healthcare facilities that serve the poor and the local public health department formed a unique partnership to create low-cost tools to meet these challenges. This article describes the creation of a low-cost generic discrete-event simulation model populated by a workflow observation Excel spreadsheet that can be completed by clinic staff themselves thus customizing the simulation model for their own purposes. This initial model focuses on childhood immunization delivery services the intent is to develop a tool flexible enough to serve other health services delivery needs as well.,10.1.1.1.2801,?,?
Eukaryotic Regulatory Element Conservation Analysis and Identification Using Comparative Genomics,Yueyi Liu  Shirley Liu  Liping Wei Russ B. Altman Serafim Batzoglou,2004,this paper we presented  asyG:319LG analy31  of the conservation of  knownregulatory  S.cerevisZf by  comparison with other species. It would be desirable to repeat these comparisons for worms  (C.elegans    ) and diptera (DrosffDZf melanogas0M andAnopheles  gambiae the malaria mosquito)  but information on  theirregulatory  elements was too limited to allow  forany sy[:GG19 analyGG  Human--mouse comparisons were helpful in  differentiatingregulatory  elements from background sequences but    --S. pombe pairwise comparisons were not. Comparison of sequences from multiple species showed considerable promise in differentiating  S.cerevisZf knownregulatory  elements from background sequences. However the difference between the two distributions is not as significant as the one seen in human--mouse comparisons. For future work two strategies can be used to improve the separation. One is to use more sophisticated statistics such as those  usedby  Elnitski et al. (2003) to maximize the separation between known regulatory  elements and background sequences. The other strategy is to include more species (Cliften et al. 2003 Kellis et al. 2003). Once  knownregulatory  elements can  besufficiently  separated from background we can extend CompareProspector from Table 2. Motifs Discovered by  CompareProspectoron  the C. elegans PHA-4 Data Set  Motifiden13603  by  CompareProspector  (Number of sites reported)  (norte  of  sitesin  gens with  C.br27603  orthologs) Conologs)/3 of sites  by one nucleotide  127/38 4/38 are 100% conserved 4/38 differ  by one nucleotide  From the upstream sequences of the 211 pharyngeally expressed genes. CompareProspector correctly identified the PHA-4  motif with the consensus TGTTTGC. It also identified another motif with the consensus AGA...,10.1.1.1.2802,?,?
RDF-Based Retrieval of Information Extracted from Web Product Catalogues,Ondrej Svab  Martin Labsky  Vojtech Svatek,2004,Extraction of relevant data from the raw source of HTML pages poses specific requirements on their subsequent RDF storage and retrieval. We describe an application of statistical information extraction technique (Hidden Markov Models) on product catalogues followed with conversion of extracted data to RDF format and their structured retrieval. The domain-specific query interface built on the top of Sesame repository o#ers a simple form of navigational retrieval. Integration of further web-analysis methods within the Rainbow architecture is forthcoming.,10.1.1.1.2803,General Terms Algorithms Experimentation Languages Keywords RDF Information extraction Hidden Markov Models Product catalogues,?
Interactive Query Formulation using Spider Queries,H.A. Proper,1994,Effective information disclosure in the context of databases with a large conceptual  schema is known to be a non-trivial problem. In particular the formulation  of ad-hoc queries is a major problem in such contexts. Existing approaches  for tackling this problem include graphical query interfaces query by navigation  query by construction and point to point queries. In this article we propose the spider  query mechanism as a final corner stone for an easy to use computer supported  query formulation mechanism for InfoAssisant.,10.1.1.1.2804,?,?
Balancing Considered Harmful - Faster Photon Mapping using the Voxel Volume Heuristic -,Ingo Wald Johannes Günther  Philipp Slusallek,2004,Photon mapping is one of the most important algorithms for computing global illumination. Especially for efficiently producing convincing caustics there are no real alternatives to photon mapping. On the other hand photon mapping is also quite costly: Each radiance lookup requires to find the k nearest neighbors in a kd-tree which can be more costly than shooting several rays. Therefore the nearest-neighbor queries often dominate the rendering time of a photon map based renderer. In this paper we present a method that reorganizes - i.e. unbalances - the kd-tree for storing the photons in a way that allows for finding the k-nearest neighbors much more efficiently thereby accelerating the radiance estimates by a factor of 1.2-3.4. Most importantly our method still finds exactly the same k-nearest-neighbors as the original method without introducing any approximations or loss of accuracy. The impact of our method is demonstrated with several practical examples.,10.1.1.1.2805,Global Illumination photon mapping simulation caustics kd-tree nearest neighbor query Categories and Subject Descriptors (according to ACM CCS I.3.3 [Computer Graphics Global Illumination I.3.7 [Computer Graphics Raytracing,?
Power Optimization Using Coding Methods On Arithmetic Operators,Eduardo Costa Sergio Bampi José Monteiro,2001,This paper addresses the use of different coding methods for the arithmetic operators. Signal encoding is widely used to reduce the switching activity in buses. However the signals need to be encoded and decoded since signal processing is executed in binary. To avoid this step we investigate the viability of processing operators that use the same signal encoding as that used in the bus. Gray and a,10.1.1.1.2806,?,?
Information retrieval in Current Research Information,Systems Andrei Lopatenko Andrei S. Lopatenko,2001,In this paper we describe the functional requirements for research information systems and problems which arise in the development of such a system. Here is shown which problems could be solved by using knowledge markup technologies. In this article one DAML + OIL ontology for Research Information System is offered. The already developed ontologies for research analyzed and compared. The architecture based on knowledge markup for collecting research data and providing access to it is described. It is shown how RDF Query Facilities can be used for information retrieval about research data.,10.1.1.1.2807,Information Retrieval DAML RDF Knowledge Markup,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,Simulation-based wafer fabrication optimization models require extensive computational time to obtain accurate estimates of output parameters. This research seeks to develop goal-driven optimization methodologies for a variety of semiconductor manufacturing problems using appropriate combinations of resource-driven (R-D) job-driven (J-D) and Mixed (combination of R-D and J-D) models to reduce simulation run times. The initial phase of this research investigates two issues: a) the use of the R-D simulation control variates for the J-D simulation and b) development of metrics that calibrate the output from the R-D and J-D modeling paradigms. The use of the R-D model as a control variate is proposed to reduce the variance of J-D model output. Second in order to use the R-D model output to predict the J-D model output calibration metrics for the R-D and J-D modeling approaches were developed. Initial developments were tested using an M/M/1 queuing system and an M/D/1 queuing system.,10.1.1.1.2808,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,We consider importance sampling (IS) to increase the efficiency of Monte Carlo integration especially for pricing exotic options where the random input is multivariate Normal. When the importance function (the product of integrand and original density) is multimodal determining a good IS density is a difficult task. We propose an Automated Importance Sampling DEnsity selection procedure (AISDE). AISDE selects an IS density as a mixture of multivariate Normal densities with modes at certain local maxima of the importance function. When the simulation input is multivariate Normal we use principal component analysis to obtain a reduced-dimension approximate importance function which allows efficient identification of a good IS density via AISDE in original problem dimensions over 100. We present Monte Carlo experimental results on randomly generated option-pricing problems (including path-dependent options) demonstrating large and consistent efficiency improvement.,10.1.1.1.2809,?,?
Ground surveillance and fusion of ground target sensor data in a Network Based Defense.,Dr Hkan Warston,?,This paper outlines how a future ground surveillance   system can be designed and how such a system could work  within the framework of the Swedish Network Based Defense  (NBD) concept. The material presented in this paper is in part  an executive summary of the results from the project Fusion  node 2 within phase 1 of the Swedish LedsystT study.  The paper discusses the general demands that the NBD concept  will put on a ground surveillance system how such a network  based multisensor system should be designed and how the  creation of vital parts of a Recognized Ground Picture can be  achieved through a system for distributed sensor data fusion.  Furthermore an NBD ground picture simulator developed for  testing and demonstrating key issues in this field is presented.        1 ,10.1.1.1.2810,?,?
Educational Technology Society 3(4) 2000 ISSN 1436-4522 108,Large-Scale Local Evaluation Julie Ann Richardson Rd Floor Weston Education Centre St. Thomas Hospital Anthony Turner,?,Space and COSE (Creation of Study Environments) as part of its commitment to distributed learning. A  wide-reaching evaluation model has been designed aimed at appraising the quality of students learning  experiences using these VLEs. The evaluation can be considered to be a hybrid system with formative  summative and illuminative elements. The backbone of the model is a number of measuring instruments  that were fitted around the educational process beginning in Jan 1999.,10.1.1.1.2811,Individual differences Quality of learning Student-centred,?
A Virtual Machine for Interpreting Programs in Static Single Assignment Form,Jeffery von Ronne Ning Wang Alexander Apel Michael Franz,2003,Optimizing compilers including those in virtual machines commonly utilize Static Single Assignment Form as their intermediate representation but interpreters typically implement stack-oriented virtual machines. This paper introduces an easily interpreted variant of Static Single Assignment Form. Each instruction of this Interpretable Static Single Assignment Form including the Phi Instruction has self-contained operational semantics facilitating efficient interpretation. Even the array manipulation instructions possess directly-executable single-assignment semantics. In addition this paper describes the construction of a prototype virtual machine realizing Interpretable Static Single Assignment Form and reports on its performance. CONTENTS i  Contents  1 ,10.1.1.1.2812,?,?
Semantic Search,R. Guha Rob Mccool Eric M,2003,Activities such as Web Services and the Semantic Web are working to create a web of distributed machine understandable data. In this paper we present an application called Semantic Search which is built on these supporting technologies and is designed to improve traditional web searching. We provide an overview of TAP the application framework upon which the Semantic Search is built. We describe two implemented Semantic Search systems which based on the denotation of the search query augment traditional search results with relevant data aggregated from distributed sources. We also discuss some general issues related to searching and the Semantic Web and outline how an understanding of the semantics of the search terms can be used to provide better results.,10.1.1.1.2813,?,ACM
Audiovisual Perceptual Evaluation of Resynthesised Speech Movements,Matthias Odisio Erard Matthias Odisio Gérard Bailly,?,We have already presented a system that can track the 3D speech movements of a speakers face in a monocular video sequence. For that purpose speaker-specific models of the face have been built including a 3D shape model and several appearance models. In this paper speech movements estimated using this system are perceptually evaluated. These movements are re-synthesised using a Point-Light (PL) rendering. They are paired with original audio signals degraded with white noise at several SNR. We study how much such PL movements enhance the identification of logatoms and also to what extent they influence the perception of incongruent audio-visual logatoms. In a first experiment the PL rendering is evaluated per se. Results seem to confirm other previous studies: though less efficient than actual video PL speech enhances intelligibility and can reproduce the McGurk effect. In the second experiment the movements have been estimated with our tracking framework with various appearance models. No salient differences are revealed between the performances of the appearance models.,10.1.1.1.2814,?,?
IEEE COMMUNICATIONS LETTERS VOL. 7 NO. 6 JUNE 2003 293 A Bandwidth-Power Efficient Modulation Scheme,Based On Quaternary Youhan Kim Student Member Kyungwhoon Cheun Kyeongcheol Yang,2003,A novel modulation scheme suitable for noncoherent demodulation based on quaternary quasi-orthogonal sequences is proposed. Compared to orthogonal modulation the controlled quasi-orthogonality between the sequences allow significantly increased bandwidth efficiency with little or no degradation in power efficiency. A hardware efficient demodulator structure using fast Walsh transforms is also presented.,10.1.1.1.2815,?,?
Ontological Investigation of Ecosystem Hierarchies And Formal Theory for Multiscale Ecosystem Classifications,Alexandre Sorokine Re Sorokine Thomas Bittner  Chris Renschler,2004,This paper presents a formalized ontological framework for the analysis of multiscale classifications of geographic objects. We propose a set of logical principles that guide such geographic classifications. Then we demonstrate application of these principles on a practical example of the National Hierarchical Framework of Ecological Units. The framework has a potential to be used to facilitate interoperability between such geographic classifications,10.1.1.1.2816,?,?
State Space Abstraction Using Shape Graphs,Arend Rensink,2004,To represent the individual states of software systems we propose to use edge-labelled graphs:  nodes will stand for dynamically allocated entities (e.g. objects or method frames) and edges  for relations between those entities (e.g. arising from associations or variables). Obviously as  these graphs may in principle grow unboundedly the state space is generally infinite. In this  paper we present a technique to automatically obtain finite approximations of arbitrary state  spaces by recording only the local structure of the individual graphs: essentially for each node  we only store the approximate number of its neighbours according to each edge label. This gives  rise to a variant of shape graphs described elsewhere.,10.1.1.1.2817,?,Elsevier
Jena: Implementing the Semantic Web Recommendations,Jeremy J. Carroll Ian Dickinson Chris Dollin Andy Seaborne Kevin Wilkinson Dave Reynolds Dave Reynolds,2003,OWL have at their heart the RDF graph. Jena2 a secondgeneration RDF toolkit is similarly centered on the RDF graph. RDFS and OWL reasoning are seen as graph-to-graph transforms producing graphs of virtual triples. Rich APIs are provided. The Model API includes support for other aspects of the RDF recommendations such as containers and reification. The Ontology API includes support for RDFS and OWL including advanced OWL Full support. Jena includes the de facto reference RDF/XML parser and provides RDF/XML output using the full range of the rich RDF/XML grammar. N3 I/O is supported. RDF graphs can be stored in-memory or in databases. Jenas query language RDQL and the Web API are both offered for the next round of standardization.,10.1.1.1.2818,Algorithms Standardization Languages. Keywords Keywords are your own designated keywords,?
Experiments on Graph Clustering Algorithms,Ulrik Brandes Marco Gaertler Dorothea Wagner,2003,A promising approach to graph clustering is based on the  intuitive notion of intra-cluster density vs. inter-cluster sparsity. While  both formalizations and algorithms focusing on particular aspects of this  rather vague concept have been proposed no conclusive argument on  their appropriateness has been given.,10.1.1.1.2819,?,Springer-Verlag
EMMA -- A Query Algebra for Enhanced,Multimedia Meta Objects Sonja Zillner Utz Westermann Werner Winiwarter,2004,Enhanced Multimedia Meta Objects (EMMOs) are a novel  approach to multimedia content modeling combining media semantic  relationships between those media as well as functionality on the media  such as rendering into tradeable knowledge-enriched units of multimedia  content. For the processing of EMMOs and the knowledge they contain  suitable querying facilities are required. In this paper we present  EMMA an expressive query algebra that is adequate and complete with  regard to the EMMO model. EMMA o#ers a rich set of formally-defined  orthogonal query operators that give access to all aspects of EMMOs  enable query optimization and allow the representation of elementary  ontology knowledge within queries. Thereby EMMA provides a sound  and adequate foundation for the realization of powerful EMMO querying  facilities.,10.1.1.1.2820,?,?
Computing Preferred Safe Beliefs,Luis Angel Montiel Juan Antonio Navarro,?,We recently proposed a definition of a language for nonmonotonic reasoning  based on intuitionistic logic. Our main idea is a generalization of  the notion of answer sets for arbitrary propositional theories. We call this  extended framework safe beliefs. We present an algorithm based on the  Davis-Putnam (DP) method to compute safe beliefs for arbitrary propositional  theories. We briefly discuss some ideas on how to extend this  paradigm to incorporate preferences.,10.1.1.1.2821,Answer Sets Davis Putnam Safe Beliefs Preferences Algorithms,?
Contents,Dimitri A. Pissarenko,2002,this paper using the translitertation system known as The Library of Congress system (without diacritics). At the first occurence of a particular Russian word it is given both in Cyrillic characters and in a transliterated form. Subsequent references to the word are always written in transliterated form,10.1.1.1.2822,?,?
Character Recognition by Adaptive Statistical Similarity,Thomas Breuel Parc,2003,Handwriting recognition and OCR systems need to cope with a wide variety of writing styles and fonts many of them possibly not previously encountered during training. This paper describes a notion of Bayesian statistical similarity and demonstrates how it can be applied to rapid adaptation to new styles. The ability to generalize across different problem instances is illustrated in the Gaussian case and the use of statistical similarity Gaussian case is shown to be related to adaptive metric classification methods. The relationship to prior approaches to multitask learning as well as variable or adaptive metric classification and hierarchical Bayesian methods are discussed. Experimental results on character recognition from the NIST3 database are presented.,10.1.1.1.2823,?,?
Classification of Six-Point Metrics,Bernd Sturmfels  Josephine Yu,2004,There are 339 combinatorial types of generic metrics on six points. They correspond  to the 339 regular triangulations of the second hypersimplex #(6 2) which  also has 14 non-regular triangulations.,10.1.1.1.2824,?,?
Hw/Sw Codesign of an ATM Network Interface card starting,From System Level Nacer-eddine Zergainoh G. F. Marchioro A. A. Jerraya,?,This paper discusses the uses of SDL for the co-design of an ATM Network Interface Card (NIC). In this study the initial specification is given in SDL. The architecture generation is made using Cosmos a co-design tool for multiprocessor architecture. Several architectures are produced starting from the same initial SDL specification. The performance evaluation of these solutions was made using hardware/software cosimulation. This paper describes the experiment and the lessons learned about the capabilities and the restrictions of SDL and Cosmos for hardware/software co-design of distributed systems. The use of SDL allows for drastic reduction of the model size when compared to hardware/software model given in C/VHDL. SDL simulation may be 30 times faster than C/VHDL simulation.,10.1.1.1.2826,?,?
Building an intelligent system using modern Internet technologies,Goran Imic Vladan,2003,This paper is a detailed case study of building Code Tutor a Web-based intelligent tutoring system (ITS) in the domain of radio communications. It is ontologically founded and was built using CLIPS and Java-based expert system tools latest integrated graphical CASE tools for software analysis and design and Java servlets. In Code Tutor Apache HTTP Server stores and serves static HTML pages and Apache JServ Java package enables dynamic interpretation of user defined servlet classes and generation of active HTML pages. XML technology is used to generate files that Code Tutor uses to provide recommendations to the learners. Such a rich palette of integrated advanced technologies has greatly alleviated the system design and implementation and has also led to interesting solutions of a number of problems common to many ITSs. The paper describes these solutions and useful design decisions and discusses several practical issues related to architectures of intelligent Web-based applications.,10.1.1.1.2827,Expert systems Intelligent tutoring systems Knowledge representation Ontology,?
Accessing practical knowledge: how? why?,Alison L. Black Gail Halliwell,2000,Alternative forms of representation were employed to generate new insights into the knowledge teachers use to inform practice. Conversation drawing metaphor and story writing encouraged a group of teachers to make multiple probes into their ways of knowing how to manage the complexities of many everyday teaching situations. Sandys Story and comments from other teachers illustrate how these methods can enhance efforts to understand the ways that personal images enter into teaching decisions. Why teachers and researchers ought to inquire into this aspect of knowing how to teach is examined.,10.1.1.1.2828,Personal narratives Child care occupations Early childhood education Teachers Practical knowledge Representing data,?
Some isometry groups of Urysohn space,P. J. Cameron A. M. Vershik,2006,We construct various isometry groups of Urysohn space (the unique  complete separable metric space which is universal and homogeneous)  including abelian groups which act transitively and free groups which  are dense in the full isometry group.,10.1.1.1.2829,?,?
  P-TREES: CONCEPTS IMPLEMENTATION AND APPLICATION PROGRAMMING INTERFACE,n.n.,?,?,10.1.1.1.2830,?,?
Evolutionary Multiobjective Clustering,Julia Handl Julia H Joshua Knowles,2004,Clustering is a core problem in data-mining with innumerable applications spanning many fields. A key di#culty of e#ective clustering is that for unlabelled data a `good solution is a somewhat ill-defined concept and hence a plethora of valid measures of cluster quality have been devised. Most clustering algorithms optimize just one such objective (often implicitly) and are thus limited in their scope of application. In this paper we investigate whether an EA optimizing a number of di#erent clustering quality measures simultaneously can find better solutions. Using problems where the correct classes are known our results show a clear advantage to the multiobjective approach: it exhibits a far more robust level of performance than the classic k-means and average-link agglomerative clustering algorithms over a diverse suite of 15 real and synthetic data sets sometimes outperforming them substantially.,10.1.1.1.2831,?,Springer
Extending Existing Dependency Theory to Temporal Databases,Christian S. Jensen Richard T. Snodgrass Michael D. Soo Fredrik Bajers Vej E Dk– Aalborg Ø,1994,Normal forms play a central role in the design of relational databases. Several normal forms for temporal relational databases have been proposed. These definitions are particular to specific temporal data models which are numerous and incompatible.,10.1.1.1.2832,?,?
Complexity-Based Metrics for the Evaluation of the Program Organization,Rui Gustavo Crespo Ana Isabel Cardoso Peter Kokol,?,Programs are nowadays considered to be complex systems. Entropy and Correlation are the most widely used metrics available for the analysis of complex systems. This paper compares the application of these sorts of metrics in the evaluation of the program organization. We verify that the metrics based on the  correlation are the most valuable for the identification of the program organizations.,10.1.1.1.2833,?,?
High-Performance Communication Networks,Jean Walrand  Pravin Varaiya,?,Contents 1 Wireless Networks 1 1.1 Introduction ...................................... 1 1.1.1 History of Wireless Networks ........................ 2 1.1.2 Wireless Data Vision ............................. 5 1.1.3 Technical Challenges ............................. 7 1.2 The Wireless Channel ................................. 8 1.2.1 Path loss ................................... 9 1.2.2 Shadow Fading ................................ 10 1.2.3 Multipath Flat-fading and Intersymbol Interference ............. 11 1.2.4 Doppler Frequency Shift ........................... 12 1.2.5 Interference .................................. 13 1.2.6 Infrared versus Radio ............................ 13 1.2.7 Capacity Limits of Wireless Channels .................... 14 1.3 Link Level Design .................................. 15 1.3.1 Modulation Techniques ............................ 15 1.3.2 Channel Coding and Link Layer Retransmission .............. 16 1.3.3 Flat-Fading Countermeasures ..,10.1.1.1.2834,?,?
Current Topics,The Ribosome At Peter B. Moore,?,The publication of atomic resolution crystal structures for the large ribosomal subunit from  Haloarcula marismortui and the small ribosomal subunit from Thermus thermophilus has permanently  altered the way protein synthesis is conceptualized and experiments designed to address its unresolved  issues. The impact of these structures on RNA biochemistry is certain to be no less profound. The  background and substance of these developments are reviewed here.,10.1.1.1.2836,elongation factor 2 mRNA messenger RNA rRNA ribosomal RNA,?
Engineering Optimization Using a Simple Evolutionary Algorithm,Efren Mezura-Montes Carlos A. Coello Coello  Ricardo Landa-Becerra Ricardo L Sección De Computación,2003,This paper presents a simple  Evolution Strategy and three simple selection criteria to solve engineering optimization problems. This approach avoids the use of a penalty function to deal with constraints. Its main advantage is that it does not require the definition of extra parameters other than those used by the evolution strategy. A self-adaptation mechanism allows the algorithm to maintain diversity during the process in order to reach competitive solutions at a low computational cost. The approach was tested in four well-known engineering design problems and compared against several penalty-function-based approaches and other state-of-the-art technique. The results obtained indicate that the proposed technique is highly competitive in terms of quality robustness and computational cost. 1. ,10.1.1.1.2837,?,?
Spreading Out: A Local Approach to Multi-robot Coverage,Maxim A. Batalin Gaurav S. Sukhatme,2002,The problem of coverage without a priori global information about the environment is a key element of the general exploration problem. Applications vary from exploration of the Mars surface to the urban search and rescue (USAR) domain where neither a map nor a Global Positioning System (GPS) are available. We propose two algorithms for solving the 2D coverage problem using multiple mobile robots. The basic premise of both algorithms is that local dispersion is a natural way to achieve global coverage. Thus both algorithms are based on local mutually dispersive interaction between robots when they are within sensing range of each other. Simulations show that the proposed algorithms solve the problem to within 5-7% of the (manually generated) optimal solutions. We show that the nature of the interaction needed between robots is very simple indeed anonymous interaction slightly outperforms a more complicated local technique based on ephemeral identification.,10.1.1.1.2838,Coverage distributed mobile robots sensor network,?
Accuracy of Needle Implantation in Brachytherapy Using a Medical AR System - A phantom study,Stefan Wesarg  Evelyn A. Firle  Bernd Schwald  Helmut Seibert  Pawel Zogal  Sandra Roeddiger Ra Roeddiger D,2004,Brachytherapy is the treatment method of choice for patients with a tumor relapse after a radiation therapy with external beams or tumors in regions with sensitive surrounding organs-at-risk e. g. prostate tumors. The standard needle implantation procedure in brachytherapy uses pre-operatively acquired image data displayed as slices on a monitor beneath the operation table. Since this information allows only a rough orientation for the surgeon the position of the needles has to be verified repeatedly during the intervention.,10.1.1.1.2839,Brachytherapy augmented reality image-guided surgery navigation tracking computed tomogr,?
FCND DP No.144,Fcnd Discussion Paper David Coady Margaret Grosh John Hoddinott,?,This paper addresses the contested issue of the efficacy of targeting interventions  in developing countries using a newly constructed comprehensive database of 111  targeted antipoverty interventions in 47 countries. While the median program transfers 25  percent more to the target group than would be the case with a universal allocation more  than a quarter of targeted programs are regressive. Countries with higher income or  governance measures and countries with better measures for voice do better at directing  benefits toward poorer members of the population. Interventions that use means testing  geographic targeting and self-selection based on a work requirement are all associated  with an increased share of benefits going to the bottom two quintiles. Self-selection based  on consumption demographic targeting to the elderly and community bidding show  limited potential for good targeting. Proxy means testing community-based selection of  individuals and demographic targeting to children show good results on average but  with considerable variation. Overall there is considerable variation in targeting  performance when we examine experiences with specific program types and specific  targeting methods. Indeed a Theil decomposition of the variation in outcome shows that  differences between targeting methods account for only 20 percent of overall variation.  The remainder is due to differences found within categories. Thus while these general  patterns are instructive differences in implementation are also quite important  determinants of outcomes.    iii Contents  Acknowledgments.............................................................................................................. iv    1. ,10.1.1.1.2840,?,?
Virtual Prototyping For Modular And . . .,Carlos A. Valderrama Adel Changuel Ahmed A. Jerraya,1997,The goal of this work is to develop a methodology for fast prototyping of highly modular and flexible electronic systems including both software and hardware. The main contribution of this work is the ability to handle a wide range of architectures. We assume that hardware/software partitioning is already made. This stage of the codesign process starts with a virtual prototype an heterogeneous architecture composed of a set of distributed modules represented in VHDL for hardware elements and in C for software elements communicating through communication modules. This work concentrates on a modelling strategy that allow virtual prototype to be used for both cosynthesis (mapping hardware and software modules onto an architectural platform) and cosimulation (that is the joint simulation of hardware and software components) into an unified environment. The main contribution is the use of a multi-view library concept in order to hide specific hardware/software implementation details and communication schemes. In particular this approach addresses the problemof communication between the hardware and software modules.,10.1.1.1.2841,?,?
A Real-Time Rover Executive Based on Model-Bases Reactive Planning,M. Bernardine Dias  Solange Lemai  Nicola Muscettola,2003,This paper reports on the design and implementation of a multi-abstraction level autonomous control system using the Intelligent Distributed Execution Architecture (IDEA). The basic hypothesis of IDEA is that a large control system can be structured as a collection of interacting control agents each organized around the same fundamental structure. The control system consists of two IDEA agents a System level agent and a Mission level agent and operates the K9 planetary rover prototype in real-time. The system is evaluated in the scenario where the rover must acquire images from a specified set of locations. The IDEA agents are responsible for enabling the rover to achieve its goals while monitoring the execution and safety of the rover and recovering from dangerous states when necessary. Experiments carried out both in simulation and on the physical rover produced highly promising results. The rover successfully accomplished its goal while correctly responding to successive alarms. The performance analysis indicates that the system level agent can achieve a 1-2Hz control rate on a 300MHz Pentium adequate for slow-moving planetary rovers.,10.1.1.1.2842,Autonomous Control Onboard Planning and Execution,?
The Entropia Virtual Machine for Desktop Grids,Brad Calder Andrew Andrew A. Chien Ju Wang Don Yang,2004,Desktop distributed computing allows companies to exploit the idle cycles on pervasive desktop PC systems to increase the available computing power by orders of magnitude (10x - 1000x). Applications are submitted distributed and run on a grid of desktop PCs. Since the applications may be malformed or malicious the key challenges for a desktop grid are how to 1 control the distributed computing applications resource usage and behavior as it runs on the desktop PC 2) provide protection for the distributed applications program and its data run and 3) provide a virtualized execution environment decoupling correct application execution from desktop configuration heterogeneity. We describe the Entropia Virtual Machine and the solutions it embodies for each of these challenges. We first outline the distinct requirements for a virtual machine in a desktop grid environment which differ from web-based and hardware-level virtual machines. We then describe how the Entropia Virtual Machine (EVM) uses binary rewriting to solve each of these problems guaranteeing the usability and protection of the desktop machine in the face of malicious or malformed application code. We also show that our approach provides security for the application and their data. We also detail how the virtual machine supports a virtualized execution environment. We present performance results for the EVM which show its performance overhead is modest.,10.1.1.1.2843,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,Communicating Structures is a system abstraction that helps to model large-scale distributed systems whose performance mostly depends on how well the data and messages traffic is organized. The whole variety of traffic sensitive communicating systems can be modeled using just a small number of basic primitives which are common for all such systems. The system components are represented simply as nodes. Each node has memory that may contain items. Nets are sets of links that connect the nodes. The items are generated at some nodes and move from node to node along links with some delay. The item traffic models the message and data traffic in systems. Using uniform systematic composition of the basic primitives Communicating Structures are able to approximate the properties and behavior of a broad spectrum of large-scale communicating systems. Communicating Structures Library (CSL) is a core environment for the simulation of large communicating systems. CSL has been used to analyze the architecture of multiprocessor systems global enterprise intranets distributed mission-critical applications and the World-Wide Web.,10.1.1.1.2844,?,?
Reference Architecture Modeling with the UML and Vital: A Comparative Study,Willi Hasselbring,?,Software reference architectures aim at supporting software product lines describing the commonalities as well as the variabilities among individual products in a family. Many notations for architectural representation do exist but only a few explicitly support modeling of software reference architectures. The Variability and Dependency Model (Vital) offers such a notation which is specifically designed for describing software product line reference architectures [7]. Vital complements existing notations by focusing on issues only relevant to reference architectures and assuming that all other required architectural information is properly described by other means.,10.1.1.1.2846,Reference Architecture Architecture Description,?
Asynchronous Multi-Core Architecture For Level Set Methods,Eva Dejno Zkov Petr Dokládal,?,for embedded systems using partial differential equations -based image processing algorithms. The study of data flow and the timing analysis is carried out in order to reveal optimal global architecture specifications. The global architecture uses a semi-parallel approach with several processing units running in parallel and shared memory blocks. The results are illustrated by the implementation of a continuous watershed transform followed by a discussion of the measured execution time and the computational load to demonstrate the efficiency.,10.1.1.1.2847,?,?
Automatic Delineation of the Osseous Interface in Ultrasound Images by Information Fusion,Daanen Vincent  Jerome Tonetti  Jocelyne Troccaz,?,We present a new method for delineating the osseous interface in ultrasound images. Automatic segmentation of the bone-soft tissues interface is achieved by mimicking the reasoning of the expert in charge of the manual segmentation. Informations are modeled and fused by the use of fuzzy logic and the accurate delineation is then performed by using general a priori knowledge about osseous interface and ultrasound imaging physics. Results of the automatic segmentation are compared with the manual segmentation of an expert.,10.1.1.1.2848,Ultrasound imaging image processing segmentation,?
A Decidable Fragment of Separation Logic,Josh Berdine Cristiano Calcagno  Peter OHearn,2004,We present a fragment of separation logic oriented to linked lists and study decision procedures for validity of entailments. The restrictions in the fragment are motivated by the stylized form of reasoning done in example program proofs. The fragment includes a predicate for describing linked list segments (a kind of reachability or transitive closure). Decidability is first proved by semantic means: by showing a small model property that bounds the size of potential countermodels that must be checked. We then provide a complete proof system for the fragment the termination of which furnishes a second decision procedure.,10.1.1.1.2849,?,Springer
Perceptron-based Fusion of Multiple Fingerprint Matchers,Gian Luca Marcialis Fabio Roli,2003,In this paper a neural fusion rule for fingerprint verification is presented. The person to be identified submits to the system her/his fingerprint and her/his identity. Multiple fingerprint matchers provide a set of verification scores that are then fused by a perceptronbased method. The weights of such perceptron are explicitly optimised to increase the separation between genuine users and impostors (i.e. unknown users). To this end the perceptron learning algorithm was modified. Reported experiments show that such modified perceptron allows improving the performances and the robustness of the best individual fingerprint matcher and outperforming some simple fusion rules.,10.1.1.1.2850,?,?
Learning to Cluster Web Search Results,Hua-Jun Zeng Qi-Cai Hua-jun Zeng Qi-cai He Zheng Chen Wei-ying Ma Jinwen Ma,?,Organizing Web search results into clusters facilitates users quick browsing through search results. Traditional clustering techniques are inadequate since they dont generate clusters with highly readable names. In this paper we reformalize the clustering problem as a salient phrase ranking problem. Given a query and the ranked list of documents (typically a list of titles and snippets) returned by a certain Web search engine our method first extracts and ranks salient phrases as candidate cluster names based on a regression model learned from human labeled training data. The documents are assigned to relevant salient phrases to form candidate clusters and the final clusters are generated by merging these candidate clusters. Experimental results verify our methods feasibility and effectiveness.,10.1.1.1.2851,General Terms Algorithms Experimentation Keywords Search result organization document clustering regression,?
Mobile Agents For Wireless,Commerce Applications Mawa Mrs Esma Aimeur Hec Montréal Université De Montréal Christina Braz,?,?,10.1.1.1.2852,?,?
Simulation Based Multiobjective Schedule . . .,Gupta E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,2002,In semiconductor manufacturing it requires more than one objective such as cycle time machine utilization and due date accuracy to be kept in focus simultaneously while developing an effective scheduling. In this paper a near optimal solution which is not inferior to any other feasible solutions in terms of all objectives is generated with a combination of the analytically optimal and simulation based scheduling approach. First the job shop scheduling problem is modeled using the discrete event simulation approach and the problem is divided in to simulation clock based lot selection sub-problems. Then at each decision instant in simulated time a Pareto optimal lot is selected using the various techniques to deal with multiobjective optimization such as weighted aggregation approach global criterion method minimum deviation method and compromise programming. An illustration shows how these techniques work effectively in solving the multiobjective scheduling problem using discrete event simulation. 1 ,10.1.1.1.2853,?,?
BioMed Central,International Journal Of Karishma Busgeeth Ulrike Rivett Biomed Central,?,Background: South Africa is experiencing an HIV/AIDS pandemic of shattering dimensions. The  availability and provision of antiretroviral (ARV) drugs could bring relief to the situation but the  treatment is unfortunately complex with each patient being assigned a different antiretroviral  therapy varying in diet-medication regiment. The context of South Africa its variety of urban and  rural settings adds to the challenge of administering and monitoring the HIV+ person throughout  the treatment which will last for the rest of their lives. The lack of physical infrastructure reliable  statistics and adequate resources hinder the efficient management of HIV/AIDS.,10.1.1.1.2855,?,?
Wage Bargaining the Value of Unemployment and the Labor Share of Income,Eran Yashiv,2001,The paper estimates a wage bargaining equation set within a model of the aggregate labor  market with search and matching frictions. The equation posits that the wage is a function  of current productivity future productivity and the value of unemployment. The model is  estimated using aggregate Israeli labor market data.,10.1.1.1.2858,?,?
Adaptable Fault Tolerance Requirements on Component Models,Phuong-quynh Duong  Elizabeth Perez Cortes Christine Collet,2003,Our work aims to provide adaptable fault tolerance for component-based systems through frameworks. In order to implement this approach the underlying component model must fulfill some requirements. This paper focuses on the discussion of those requirements and the way current component models cope with. To motivate the discussion the paper also describes briefly the approach and the preliminary results of our work.,10.1.1.1.2859,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Charles Mclean Swee Leong Philomena M. Zimmerman,?,How could the manufacturing modeling and simulation  process be improved? Today simulation analysts typically   code their models from scratch and build custom data  translators to import required data. Manufacturing simulations often are built as single monolithic software systems.   The development of neutral vendor-independent data formats for storing simulation models and transferring data   could greatly improve the accessibility of simulation technology to industry. Simulation standards for these models  and data could help to accelerate the modeling process and  reduce modeling costs. How can we determine what simulation standards need to be developed? This panel will discuss simulation standards needs from the perspective of  users vendors academia and government.   1 ,10.1.1.1.2860,?,?
Processing Rate Allocation for Proportional Slowdown Differentiation on Internet Servers,Xiaobo Zhou  Jianbin Wei  Cheng-Zhong Xu,2004,A proportional differentiation model states that quality of service of different classes of Internet traffic should be kept proportional to their pre-specified differentiation parameters independent of the class loads. The model has been applied in the proportional queueing delay differentiation (PDD) in both network core and network edges. However in the server side an important and interesting performance metric is slowdown the ratio of a requests queueing delay to its service time. Slowdown is important because it is desirable that a requests delay be proportional to its processing requirement.,10.1.1.1.2861,?,?
Clause Alignment for Hong Kong Legal Texts: A Lexical-based Approach,Chunyu Kit Jonathan J. Webster  King Kui Sin  Haihua Pan  Heng Li King Kui Sin Haihua Pan Heng Li,2004,In this paper we report on our recent work in clause alignment for English-Chinese legal texts  using available lexical resources including a bilingual legal glossary and a bilingual dictionary for the  purpose of acquiring examples at various linguistic levels for example-based machine translation. We  present our formulation of an appropriate measure for the similarity of a candidate pair of clauses  with respect to matched lexical items and the corresponding implementation of an e#ective algorithm  for clause alignment based on this similarity measure. Experimental results show that the similarity  measure and the lexical-based clause alignment algorithm though very simple are very e#ective  with a performance of 94.6% alignment accuracy. It confirms our intuition that lexical information  gives a reliable indication of correct alignment. The significance of this lexical-based approach lies  in both its simplicity and e#ectiveness.,10.1.1.1.2862,?,?
Approaches to Congestion Control in Packet Networks,L. Mamatas V. Tsaoussidis  Chi Zhang,2004,We discuss congestion control algorithms using network awareness as a criterion to categorize di#erent approaches. The first category (the box is black) consists of a group of algorithms that consider the network as black box assuming no knowledge of its state other than the binary feedback upon congestion. The second category (the box is grey) groups approaches that use measurements to estimate available bandwidth level of contention or even the temporary characteristics of congestion. Due to the possibility of wrong estimations and measurements the network is considered a grey box. The third category (the box is green) contains the bimodal congestion control which calculates explicitly the fair-share as well as the network-assisted control where the network communicates its state to the transport layer the box now is becoming green.,10.1.1.1.2863,TCP Performance TCP-Friendly,?
N3 Rules Processing and HTML Translation for the Semantic web,Chun Yip Leung Chun Yip Leung,2003,The semantic web is an emerging technology that could totally change how web works. It is based on the Resource Description Framework (RDF) [0] which defines graphs to represent link s between data. RDF/XML is the common format to store RDF graphs while N3 is another instant to represent RDF and provides powerful function like rules representation. In this report we will discuss how to connect N3 rules to the Jena2s rule processing system and also use the new system to solve the visual representation problem on browsing RDF.,10.1.1.1.2864,N3 Forward Chained Rules RDF Translation Semantic Web,?
Testing for Difference between Two Groups of Functional Neuroimaging Experiments,Finn Årup Nielsen Andrew C. N. Chen Lars Kai Hansen,2004,We describe a meta-analytic method that tests for the di#erence between  two groups of functional neuroimaging experiments. We use kernel  density estimation in three-dimensional brain space to convert points representing  focal brain activations into a voxel-based representation. We  find the maximum in the subtraction between two probability densities  and compare its value against a resampling distribution obtained by permuting  the labels of the two groups. The method is applied on data  from thermal pain studies where hot pain and cold pain form the two  groups.,10.1.1.1.2865,?,?
Heterogeneous Modelling of Evolution for Socio-technical Systems,Stuart Anderson Massimo Felici,2004,systems. Although it is possible to identify an evolutionary space for socio-technical systems the methodologies that address the evolution of socio-technical systems are still patchy. Moreover it is still challenging to address multidisciplinarity in modelling methodologies. This paper addresses the heterogeneous modelling of the evolution of socio-technical systems. The analysis of a case study highlights how the combination of diverse models allows the characterisation of requirements evolution.,10.1.1.1.2866,?,?
Roles and Trust in Interorganizational Systems,Kai Wehmeyer  Kai Riemer  Bernd Schneider,2001,While trust is widely acknowledged as to be important for the efficient operation of interorganizational  business arrangements the formation of trust remains challenging. In  this paper we discuss the trust building potential of inter-firm coordination roles as organizational  means in virtual organizations. Thus we introduce the coordination role  concept and proceed by defining three different dimensions of trust in dynamic business  networks to explain the roles effects: (1) network trust (2) trust in coordination roles  and (3) the specific interorganizational trust. The work of two sociologists - Coleman  and Giddens -- serve as a basis for our assumption that coordination roles positively influence  overall trust in virtual organizations. We conclude with a discussion of factors  contributing to the perceived trustworthiness of roles and their occupants which is necessary  for the functioning of the concept.,10.1.1.1.2867,?,?
Effect of Channel Estimation Error on M-QAM BER Performance in . . . ,Xiaoyi Tang Mohamed-Slim Alouini Andrea J. Goldsmith,1999,We determine the bit-error rate (BER) of multilevel quadrature amplitude modulation (M-QAM) in flat Rayleigh fading with imperfect channel estimates. Despite its high spectral efficiency M-QAM is not commonly used over fading channels because of the channel amplitude and phase variation. Since the decision regions of the demodulator depend on the channel fading estimation error of the channel variation can severely degrade the demodulator performance. Among the various fading estimation techniques pilot symbol assisted modulation (PSAM) proves to be an effective choice. We first characterize the distribution of the amplitude and phase estimates using PSAM. We then use this distribution to obtain the BER of M-QAM as a function of the PSAM and channel parameters. By using a change of variables our exact BER expression has a particularly simple form that involves just a few finite-range integrals. This approach can be used to compute the BER for any value of  M. We compute the BER for 16-QAM and 64-QAM numerically and verify our analytical results by computer simulation. We show that for these modulations amplitude estimation error leads to a 1-dB degradation in average signal-to-noise ratio and combined amplitude-phase estimation error leads to 2.5-dB degradation for the parameters we consider.,10.1.1.1.2868,Index Terms — Channel estimation error M-QAM PSAM Rayleigh fading,?
In G. Kadoda (Ed). Proc. PPIG 13 Pages 311-321 13,Workshop Of The Colin Snook Michael Butler,2001,Formal languages enable the behaviour of a system to be precisely specified and verified. However even experienced users admit that creating useful models is difficult and this is a barrier to more widespread use. One reason for this is the lack of tools to assist in the modelling process. The process of formal specification is in many ways similar to that of programming where design notations and tools have evolved over many years. In this paper we suggest the adaptation of a graphical design notation (UML) for formal specification and support this with a prototype tool to perform automatic translation into a B specification.,10.1.1.1.2869,?,?
IEEE PERVASIVEcomputing 49,Wireless User Interface Kenneth P. Fishkin Kurt Partridge,?,mpo- nents increases the responsibility of each decreases. Instead of a one-size-fits-all set of components each component can tailor itself to one particular task and optimize its shape size and location accordingly. For example medical monitoring components such as heart monitors can be located close to the appropriate area of the body without dragging the rest of the system with them and the shape need only accommodate the monitoring function.   . Customization. Because components are specialized and removable they can also be tailored--- users can hot swap user interface components to fit their particular needs or preferences. For example a users WPAN might have several different feedback modules (tactile visual or auditory) for different contexts (as Rebecca Hansson and her colleagues suggest  6  ). The user can tailor each of those modules to the users preferences.  . Consolidation. Components can be easily shared among applications. For example there is no reason ,10.1.1.1.2870,?,?
Design of IGP Link Weight Changes For Estimation Of Traffic Matrices,Antonio Nucci rene Cruz Nuna Taft Christophe Diot,2004,We consider the traffic matrix estimation problem in IP backbone networks whose goal is to accurately estimate the volume of traffic traveling between network endpoints. Previous approaches to this problem involve measuring the volume of traffic on each link in the network during a time interval where the routing configuration is fixed and exploit a statistical model of the traffic in order to obtain an estimate of the traffic matrix. These previous approaches are prone to large estimation errors because the link measurements from a fixed routing scenario constitute a data set that is simply too limited to provide enough data to enable estimation procedures that yield very small errors. In this paper we propose the idea of collecting link measurements under multiple routing scenarios so that the traffic matrix can be determined very accurately. We present an algorithm for determining a sequence of routing configurations each of which is specified by a set of link weights. We incorporate carrier requirements into our algorithm so that our proposed routing configurations are operationally viable. We present the results of applying our algorithm to some representative IP backbone topologies and discuss the performance trade-offs that arise.,10.1.1.1.2872,Network Measurements Traffic Engineering Combinatorics,?
The Evolution of Social Dominance I: Two-Player Models,G. Sander Van Doorn G. Sander Van Doorn Geerten M. Hengeveld  Franz J. Weissing,2003,this paper we attempt to approach these questions by means of gametheoretical methods. We will develop an idealized model of repeated animal con# icts and analyse the conditions under which a dominance convention based on winner and loser effects may evolve. For the sake of our argument we concentrate initially on an extreme case in which there are no RHP differences at all between individuals. This allows us to investigate whether winner and loser effects can exist without such asymmetries. Moreover we focus our attention in this paper on rank differentiation within pairs of individuals. Therefore we restrict ourselves to the analysis of a two-player model. In a companion paper (Van Doorn et al. this issue) we extend our model to more than two players allowing us to investigate the formation of social hierarchies,10.1.1.1.2873,Also available online,?
PicoDBMS: Scaling down Database Techniques for the Smartcard  ,Christophe Bobineau Luc Bouganim Philippe Pucheral Patrick Valduriez,2000,?,10.1.1.1.2874,?,?
Offering a Precision-Performance Tradeoff for Aggregation Queries over Replicated Data,Chris Olston  Jennifer Widom,2000,Strict consistency of replicated data is infeasible or  not required by many distributed applications so current  systems often permit stale replicationinwhich  cached copies of data values are allowed to become  out of date. Queries over cached data return an answer  quickly but the stale answer may be unboundedly  imprecise. Alternatively queries over remote  master data return a precise answer but with potentially  poor performance. To bridge the gap between  these two extremes we propose a new class of replication  systems called TRAPP (Tradeoff in Replication  Precision and Performance). TRAPP systems  give each user fine-grained control over the tradeoff  between precision and performance: Caches store  ranges that are guaranteed to bound the current data  values instead of storing stale exact values. Users  supply a quantitative precision constraint along with  each query. To answer a query TRAPP systems automatically  select a combination of locally cached  bounds and exact master data stored remotely to deliver  a bounded answer consisting of a range that is  no wider than the specified precision constraint that  is guaranteed to contain the precise answer and that  is computed as quickly as possible. This paper defines  the architecture of TRAPP replication systems  and covers some mechanics of caching data ranges. It  then focuses on queries with aggregation presenting  optimization algorithms for answering queries with  precision constraints and reporting on performance  experiments that demonstrate the fine-grained control  of the precision-performance tradeoff offered by  TRAPP systems.,10.1.1.1.2875,?,?
Representation and Detection of Deformable Shapes,Pedro F. Felzenszwalb,2004,We describe some techniques that can be used to represent and detect deformable  shapes in images. The main di#culty with deformable template models is the very  large or infinite number of possible non-rigid transformations of the templates. This  makes the problem of finding an optimal match of a deformable template to an image  incredibly hard. Using a new representation for deformable shapes we show how  to e#ciently find a global optimal solution to the non-rigid matching problem. The  representation is based on the description of objects using triangulated polygons. Our  matching algorithm can minimize a large class of energy functions making it applicable  to a wide range of problems. We present experimental results of detecting shapes  in medical images and images of natural scenes. Our method does not depend on initialization  and is very robust yielding good matches even in images with high clutter.,10.1.1.1.2876,Shape representation Object recognition Deformable templates Chordal graphs Dynamic programming. 1,?
Design-Space Exploration of Power-Aware On/Off Interconnection Networks,Vassos Soteriou  Li-Shiuan Peh,?,With power a major limiting factor in the design of scalable interconnected systems power-aware networks will become inherent components of single-chip and multi-chip systems. As communication links consume significant power regardless of utilization we propose and investigate power-aware networks whose links are turned on and off in response to bursts and dips in traffic. We explore the design space of such on/off networks outlining a 5-step design methodology along with solutions at each step that can form the building blocks of numerous designs. Two specific designs targeting links with substantially different on/off times are then presented and evaluated. Our simulations show that up to 54.4% power savings can be achieved along with at most 7.5% increase in latency.,10.1.1.1.2877,?,?
Enabling Learning From Large Datasets: Applying Active Learning to Mobile Robotics,Cristian Dima  Martial Hebert  Anthony Stentz,2004,Autonomous navigation in outdoor off-road environments requires solving complex classification problems. Obstacle detection road following and terrain classification are examples of tasks which have been successfully approached using supervised machine learning techniques for classification. Large amounts of training data are usually necessary in order to achieve satisfactory generalization. In such cases manually labeling data becomes an expensive and tedious process.,10.1.1.1.2878,?,?
Approaches to digitization and annotation: A survey of language documentation materials in the Alaska Native Language Center Archive,Gary Holton University Gary Holton,2003,This paper describes the structure of existing documentary texts and recordings based on an informal survey of items in the Alaska Native Language Center (ANLC) archive. Knowledge of data in existing language archives is important in at least two respects. First any markup or encoding schemes will need to be robust enough to handle existing data so prior knowledge of some of the legacy data will assist with the eventual encoding of those data. Second and perhaps more important knowledge of existing data provides indirect but empirically valid insight into the way in which linguists approach language documentation. Theorizing about the structure of language documentation materials may unwittingly lead us to examine idealized models of language documentation. An example of such a model is the oft-cited three-line gloss a text-encoding format which is in practice much more diverse than might at first appear. Examining existing data permits the development of best practice to be grounded in what field linguists actually do rather than what we think they do. The ANLC archive contains approximately 10000 paper documents and 5000 recordings comprising nearly everything written in or about Alaska Native languages (cf. Krauss  McGary 1980). The archive also contains substantial holdings of materials on related languages spoken outside Alaska. Admittedly the archive still lacks geographic breadth in the sense that it does not represent a typologically broad sample of the worlds languages. The majority of Alaskas Native languages fall into one of two families: Eskimo-Aleut and Athabaskan-Eyak-Tlingit. However the time depth of the materials and the comprehensive nature of the coverage ensure that the archive is representative of a broad range of linguistic tradition...,10.1.1.1.2879,?,?
Topology Control in Heterogeneous Wireless,Networks Problems And,2004,Previous work on topology control usually assumes homogeneous wireless nodes with uniform transmission ranges. In this paper we propose two localized topology control algorithms for heterogeneous wireless multi-hop networks with nonuniform transmission ranges: Directed Relative Neighborhood Graph (DRNG) and Directed Local Minimum Spanning Tree (DLMST). In both algorithms each node selects a set of neighbors based on the locally collected information. We prove that (1) the topologies derived under DRNG and DLMST preserve the network connectivity (2) the out degree of any node in the resulting topology by DLMST is bounded while the out degree of nodes in the topology by DRNG is not bounded and (3) the topologies generated by DRNG and DLMST preserve the network bi-directionality.,10.1.1.1.2880,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,This introductory tutorial presents an over view of the process of conducting a simulation study of any discrete system. The basic viewpoint is that conducting such a study requires both art and science. Some of the issues addressed are how to get started the steps to be followed the issues to be faced at each step the potential pitfalls occurring at each step and the most common causes of failures.,10.1.1.1.2881,?,?
Implementing The Theory Of Constraints Philosophy In Highly Reentrant Systems,Clay Rippenhagen Shekar Krishnaswamy,1998,A significant challenge in implementing the Theory of Constraints in the semiconductor industry is the complex and reentrant nature of the manufacturing process. Managing a constraint or bottleneck in such processes is resultingly complex and is an ongoing topic of research. This paper describes a straightforward method to avoid starvation of possibly reoccurring bottleneck equipment. This method is not proximity sensitive meaning that it does not act on material only if it is within a specified proximity of the constraint. This method is capable of reacting to changes in product mix and can act to correct line imbalances since it is based on real time data from the floor control system. The assertion is also made that for the case where a bottleneck has several occurrences in the product flow all occurrences of the bottleneck must avoid starvation not just the overall equipment queue. This affects the ability of the primary constraint to feed itself.,10.1.1.1.2882,?,?
A Review to Model-Based User Interface,Development Technology Pedro,?,This position paper discusses the idea of the suitability of the Model Based User Interface Development (MB-UID) to develop commercial applications in industrial environments. Main problems advantages authors experiences and current trends are presented.,10.1.1.1.2883,?,?
The Mathematics of Halftoning,R. L. Adler  B. P. Kitchens  M. Martens  C. P. Tresser  C. W. Wu,2003,This paper describes some mathematical aspects of halftoning in digital printing. Halftoning is the technique of rendering a continuous range of colors using only a few discrete ones. There are two major classes of methods: dithering and error diffusion. Some discussion is presented concerning the method of dithering but the main emphasis is on error diffusion. ,10.1.1.1.2885,?,?
Improving the Compilation of Prolog to C Using Type Information: Preliminary Results,J. Morales M. Carro,?,We describe the current status and preliminary results of a  compiler of Prolog to C. This compiler can use high-level information  on the initial Prolog program in order to optimize the resulting C code  which is then fed into a o#-the-shelf C compiler. The basic translation  process basically mimics the unfolding of a C-coded bytecode emulator  with respect to the bytecode corresponding to the Prolog program. This  allows reusing a sizeable amount of the associated machinery: ancillary  pieces of C code data definitions memory management routines and  areas etc. We evaluate the performance of programs compiled both with  and without type information.,10.1.1.1.2886,?,?
Improving Firefighter,Communications Special Report,?,this report write to the United States Fire Administration 16825 South Seton Avenue Emmitsburg Maryland 21727 or via USFA WEB Page at http://www.usfa.fema.gov,10.1.1.1.2887,?,?
The MODIFY Project:,Combined Business And Artur Caetano António Rito Silva José Tribolet João Neves Pedro Sinogas,2000,This paper presents the research perspective of INESCs Organizational Engineering Center and the Software Engineering Group regarding the modeling and design of adaptable enterprise computing systems that support dynamic business requirements. We describe the objectives and working methodology of the MODIFY project which aims at defining a component-based solution to the design of enterprise computing systems using a combined business and system model.,10.1.1.1.2888,business engineering business modeling software engineering adaptability component,?
Petri Games are Monotone but Difficult to Decide,Jean-Francois Raskin Mathias Samuelides Laurent Van Begin,2003,In this paper we study two-player games played on infinite  but monotonic game structures. We concentrate on coverability games a  natural subclass of reachability games in the context of monotonic game  structures. On the negative side we show that surprisingly and contrary  to the one-player case coverability is undecidable on two-player monotonic  game structures. On the positive side we identify an interesting  subclass of two-player monotonic game structures for which coverability  is decidable and for which we can e#ectively construct winning strategies.,10.1.1.1.2889,?,?
Influence of Correlation on the Quality of Area Computation,Gerhard Navratil Claudia Claudia Achatschitz,?,The computation of areas is a standard task for computational geometry. Geographic  information systems (GIS) usually use a straightforward approach to represent geographic features:  Coordinates define locations of points points are connected by lines which then form polygons  and closed polygons represent pieces of land. Thus a GIS uses coordinates to compute areas for  pieces of land. The coordinates only have limited accuracy which is also valid for the  computations based on these coordinates. Accuracy investigations usually assume that all  coordinates used have been determined independent of each other. Unfortunately this is not the  case. We want to investigate in this paper how dependencies can be taken into consideration. The  results show that data quality measures increase if we model correlations.,10.1.1.1.2890,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Bruce Schmeiser,?,Stating a confidence interval is a traditional method of indicating the sampling error of a point estimator of a models performance measure. We propose a single dimensionless criterion inspired by Schrubens coverage function for evaluating and comparing the statistical quality of confidenceinterval procedures. Procedure quality is usually thought to be multidimensional composed of the mean (and maybe the variance) of the interval-width distribution and the probability of covering the performance measure (and maybe other values). Our criterion which we argue lies at the heart of what makes a confidence-interval procedure good or bad compares a given procedures intervals to those of an ideal procedure. For a given point estimator (such as the sample mean) and given experimental data process (such as a first-order autoregressive process with specified parameters) our single criterion is a function of only the sample size (or other rule that ends sampling).,10.1.1.1.2891,?,?
Page 14 APEIRON Nr.20 October 1994,Cosmology And Quantum Donald Gilbert Carpenter,2001,This paper gives more precise values for the magnitude of the redshift associated with the helium atom more details regarding the emission wavelengths of the two spin-reversal photons that carry away the energy lost by the redshifted photon and a crude time sequence of pertinent atomic events,10.1.1.1.2892,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Steven C. Hamoen,?,The logistic processes in most steel producing plants are very complex. To assist the decision makers in steel producing plants Incontrol Enterprise Dynamics have developed for and in cooperation with SMS Demag in Germany a simulator that can be used to rapidly model any steel plant. The Steel Plant Simulator has been built using the software package Enterprise Dynamics and allows for rapid insight into the influences of lay-out changes process and speed parameters length of production runs changes in planning and type of products that are being produced. The Simulator incorporates a dynamic scheduler to create a realistic production planning. Results include production Gantt charts time-path diagrams utilization figures and production statistics.,10.1.1.1.2893,?,?
USENIX Association,Th Annual Linux Brett Bode David M. Halstead Ricky Kendall Zhou Lei David Jackson Maui High,2000,The motivation for a stable efficient backfill scheduler that runs in a consistent manner on multiple hardware platforms and operating systems is outlined and justified in this work. The combination of the Maui Scheduler and the Portable Batch System (PBS) are evaluated on several cluster solutions of various size performance and communications profiles. The total job throughput is simulated in this work with particular attention given to maximizing resource utilization and to the execution of large parallel jobs.,10.1.1.1.2894,?,Press
Price-based Channel Time Allocation in Wireless LANs,Samarth H. Shah  Klara Nahrstedt,2004,In access-point based wireless networks employing the IEEE 802.11 protocol in DCF mode without bandwidth management and rate control users pump data into the network as fast as it is generated. This results in a loss of QoS for the user and performance degradation of the network. There is a need for bandwidth allocation and for users to cooperatively control their rates based on the allocated bandwidth. In this paper we use price as a signal for bandwidth allocation in wireless hot spot networks. We allocate more bandwidth to users that pay more. At the same time we also aim to maximize channel utilization and increase mean satisfaction across all the users.,10.1.1.1.2895,?,?
Decomposable Constraints,Ian Gent   Kostas Stergiou Toby Walsh,2000,Many constraint satisfaction problems can be naturally and  efficiently modelled using non-binary constraints like the all-different  and global cardinality constraints. Certain classes of these non-binary  constraints are network decomposable as they can be represented by  binary constraints on the same set of variables. We compare theoretically  the levels of consistency which are achieved on non-binary constraints to  those achieved on their binary decomposition. We present many new results  about the level of consistency achieved by the forward checking  algorithm and its various generalizations to non-binary constraints. We  also compare the level of consistency achieved by arc-consistency and  its generalization to non-binary constraints and identify special cases of  non-binary decomposable constraints where weaker or stronger conditions  than in the general case hold. We also analyze the cost in consistency  checks required to achieve certain levels of consistency.,10.1.1.1.2896,?,?
Second Order Statistics Based Blind Channel Equalization With Correlated Sources,Roberto López-Valcarce Soura Dasgupta,?,In this paper the blind equalization method of Tong Xu and Kailath which was derived under the assumption of a white transmitted sequence is generalized in order to include correlated sources. The resulting algorithm can be applied to arbitrarily colored sources assuming that the source second-order statistics are known. Because it makes explicit use of this information the new algorithm is expected to outperform subspace based methods which neither require nor exploit such knowledge. This is verified via simulations.   ,10.1.1.1.2897,?,?
The Effect of Internet Security Breach Announcements on Market Value of,Breached Firms And Huseyin Cavusoglu Birendra Mishra Srinivasan Raghunathan,2002,Assessing the value of information technology (IT) security investments by firms is a challenging task because of difficulties in the measurement of tangible and intangible benefits. Event study methodology that uses market valuations is a widely used in these cases. We employ the event study methodology to assess the impact of Internet security breaches on the market value of the breached firms. We also study the information transfer effect of security breaches namely the effect of security breaches of other firms on market values of firms that develop security technology. The results of our study show that the announcement of Internet security breach is negatively associated with the market value of the announcing firm. Compromised firms on average lose approximately 2.1% of their market values within two days surrounding the events. This translates into $ 1.65 billion average loss in market capitalization per incident. We find that firm type firm size and time are important factors that explain the crosssectional variations in abnormal returns. Our results also show that the effects of security breaches are not restricted to breached firms. The market values of security developers are positively associated with the disclosure of security breaches by other firms. Each security developer on average gains 1.36 % more than normal gain expected by market model. This translates into on average a total gain of $ 1.06 billion per security firm over a two-day period.,10.1.1.1.2898,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Chin Soon Chong,?,Bottleneck-based scheduling is a popular approach in production scheduling and it has achieved promising results in industry. To incorporate this approach in discrete event simulation tools is difficult since the approach requires multiple passes forward and backward to reach a good solution for the scheduling problem. In this paper we propose a two-pass scheduling approach using discrete-event simulation that takes bottlenecks into consideration. In the first pass a simulation run is performed and bottlenecks are determined. If significant bottlenecks are identified a second-pass simulation is performed to reduce the loading on bottlenecks through specific scheduling strategies.,10.1.1.1.2899,?,?
Genome Informatics 14: 250--259 (2003) A Domain Combination Based,Probabilistic Framework For Dongsoo Han Hong-soog Kim Jungmin Seo Woohyuk Jang,2003,In this paper we propose a probabilistic framework to predict the interaction probability of  proteins. The notion of domain combination and domain combination pair is newly introduced  and the prediction model in the framework takes domain combination pair as a basic unit of  protein interactions to overcome the limitations of the conventional domain pair based prediction  systems. The framework largely consists of prediction preparation and service stages. In the  prediction preparation stage two appearance probability matrices are constructed. Each matrix  holds information on appearance frequencies of domain combination pairs in the interacting and  non-interacting sets of protein pairs respectively. Based on the appearance probability matrix a  probability equation is devised. The equation maps a protein pair to a real number in the range  of 0 to 1. Two distributions of interacting and non-interacting sets of protein pairs are obtained  using the equation. In the prediction service stage the interaction probability of a protein pair  is predicted using the distributions and the equation. The validity of the prediction model is  evaluated for the interacting set of protein pairs in a Yeast organism and artificially generated noninteracting  set of protein pairs. When 80% of the set of interacting protein pairs in DIP (Database  of Interacting Proteins) is used as a learning set of interacting protein pairs very high sensitivity  (86%) and moderate specificity (56%) are achieved within our framework.,10.1.1.1.2900,domain combination domain combination pair protein-protein interaction prediction,?
Medical Analysis and Diagnosis by Neural Networks,Rüdiger Brause,2001,In its first part this contribution reviews shortly the application of neural  network methods to medical problems and characterizes its advantages and  problems in the context of the medical background. Successful application  examples show that human diagnostic capabilities are significantly worse  than the neural diagnostic systems. Then paradigm of neural networks is  shortly introduced and the main problems of medical data base and the basic  approaches for training and testing a network by medical data are described.,10.1.1.1.2901,Adaptive Prediction Neural Networks Neurofuzzy Medical Systems,Springer-Verlag
An Approach to the Intelligent Decision Advisor (IDA) for Emergency Managers,Adam M. Gadomski  Sandro Bologna Ro Bologna  Giovanni Di Costanzo  Anna Perini Marco Schaerf Allan Newell,1999,The paper presents a next ENEAs step towards development Intelligent Decision Support Systems (IDSS). The prototype IDA (Intelligent Decision Advisor) for emergency management in an oil port is analyzed as a test-case. The work was performed in frame of the national RD MICA project under the umbrella of the ENEAs long term strategic MINDES Program synchronized with indications of the worldwide GEMINI (Global Emergency Management Information Network Initiative) of the G7 Committee. IDA is an approach to the design of intelligent-agent based kernel of IDSS. In frame of the generic TOGA(Top-down Object-based Goal-oriented Approach) model of abstract intelligent agent IPK (Information Preferences Knowledge) architecture is employed. The IDA objectives were to develop and verify the properties of information managed agent and knowledge managed agent where the last should suggest an action or plan after every new significant event in the emergency domain. The IDA functional kernel is composed with three simple agents: -DirectAdvisor it interacts with human user and emergency domain -InfoProvider it manages of information and intervention goals and - IDAPlanner it plans adequate interventions. For the design UML (Unified Modeling Language) has been employed. MDP (Markov Decision Process) and CBR (Case Base Reasoning) are used for plans construction. Owing to a generic agent model and object-based conceptualization the IDA system should be adaptable to the different roles of emergency managers. The IDA conceptual solutions can be also seen as a successive step towards high-intelligent DSSs.,10.1.1.1.2903,?,?
Data Modelling in Complex Application Domains,A.H.M. ter Hofstede H. A. Proper  Th. P. van der Weide,1992,In many non trivial application domains object types with a complex structure occur. Data modelling techniques which only allow flat structures are not suitable for representing such complex object types. In this paper a general data modelling technique the Predicator Set Model is introduced which is capable of representing complex structures in a natural way. The expressiveness of the Predicator Set Model is illustrated by means of a number of examples. In those examples the Predicator Set Models expressiveness is related to the expressiveness of more traditional modelling techniques. Furthermore some notational conventions are defined which enable a more compact representation of complex structures.  ,10.1.1.1.2904,?,?
Ruthenberg H. 1980. Farmings systems of the tropics. Oxford: Clarendon Press.,Savenije And Huijsman Sara J. Scherr Peter B. R. Hazell,?,M. and M. Tiffen. 1993. Environmental change and dryland management  in Machakos district Kenya 1930-1990.  Noronha R. 1985. A review of the literature on land tenure systems in Sub-Saharan  Africa. Report no. ARU 43 Agriculture and Rural Development Department.  Washington DC: The World Bank.  Pearce D. E. Barbier and A. Markhandya. 1990. Sustainable development:  Economics and environment in the Third World. London: Earthscan  Publications Ltd.  Pingali P. L. Y. Bigot and H. P. Binswanger. 1987. Agricultural mechanization and  the evolution of farming systems in Sub-Saharan Africa. Baltimore Md.: Johns  Hopkins University Press.  Pingali P. L. P. F. Moya and L. E. Velasco. 1990. The post green revolution blues in Asian rice production: The diminished gap between experiment station and  farmer yields. Social Sciences Division Paper No. 90-01. Los Baos Laguna  Philippines: International Rice Research Institute (IRRI).  Place F. and P. Hazell. 1993. Productivity eff,10.1.1.1.2905,?,?
Storing XML Data In a Native Repository,Kamil Toman Dept Kamil Toman,?,This paper is concerned with storing XML data in a native  repository suitable for querying with modern languages such as XPath or  XQuery. It contains a description of the experimental database SXQ-DB  its basic principles and system internals. Some of query evaluation techniques  and problems related with those methods in relation to amount  of stored information are mentioned.,10.1.1.1.2906,?,?
Efficient Hierarchical MCMC for Policy Search,Malcolm Strens,2004,Many inference and optimization tasks in machine  learning can be solved by sampling approaches  such as Markov Chain Monte Carlo  (MCMC) and simulated annealing. These  methods can be slow if a single target density  query requires many runs of a simulation  (or a complete sweep of a training data  set). We introduce a hierarchy of MCMC  samplers that allow most steps to be taken  in the solution space using only a small sample  of simulation runs (or training examples).,10.1.1.1.2907,?,?
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros B. A. Peters J. S. Smith D. J. Medeiros M. W. Rohrer Justin Boesel Fred Glover,?,The combination of simulation and optimization essentially unheard of in practice a decade ago is much more accessible today thanks in large part to the development of commercial optimization software designed for use with existing simulation packages. Despite this growth untapped applications abound. This panel which includes developers of simulation -optimization packages will discuss this untapped potential barriers to broader applicability and approaches for overcoming these barriers. This paper starts off with a brief introduction by the panels organizer followed by position statements from the panelists.,10.1.1.1.2908,?,?
Performance Estimation of Embedded Software with Instruction Cache Modeling,Yau-Tsun Steven Li Sharad Malik Andrew Wolfe,1999,... In this paper we present a more effective method for modeling instruction cache activity and computing a tight bound on WCET. The method uses an integer linear programming formulation and does not require explicit enumeration of program paths. The method is implemented in the program cinderella and we present some experimental results of this implementation,10.1.1.1.2909,?,?
Permutation Operations in Block Ciphers,R. B. Lee R. B. Lee I  R.L. Rivest  M.J.B. Robshaw  Z.J. Shi  Y.L. Yin,?,Introduction  To support new user requirements such as digital multimedia processing and secure information processing the basic operations supported within new generation processors might evolve. For a general-purpose microprocessor it is desirable that any   This work was supported in part by National Science Foundation CCR-0105677    Princeton University Department of Electrical Engineering B-218 Engineering Quadrangle Princeton NJ 08544 U.S.A.  {rblee  zshi yyin}@princeton.edu    M.I.T. Computer Science and Artificial Intelligence Laboratory 545 Technology Square Cambridge MA 02139 U.S.A. rivest@theory.lcs.mit.com    Information Security Group Royal Holloway University of London Egham Surrey TW20 0EX U.K. m.robshaw@rhul.ac.uk  added instructions have multiple uses rather than being specific to only one algorithm or to one application. Since secure communications and networking have become critical features of many applications it would seem to be advantage,10.1.1.1.2910,?,?
Classroom Discussion: A Method of . . .,Bruce E. Larson,2000,The purpose of this paper is to examine teachers thinking about classroom discussion. Teachers have multiple conceptions of classroom discussion but these conceptions often intersect with two purposes for using classroom discussion: (1) discussion as a method of instruction where the purpose is to help engage students in a lesson and learn academic content by encouraging verbal interactions and (2) discussion competence as the subject matter where the desired outcome is for students to learn to discuss more effectively. To better understand teachers use of discussion in the classroom this study examined teachers thinking about discussion with these two purposes in mind. Six high school social studies teachers were purposively selected to permit data collection from a theoretically interesting sample. Data were collected through in-depth interviews and a think-aloud task and were analyzed using grounded theorys constantcomparative technique. Implications of these findings for teachers teacher educators and researchers interested in classroom discussion are examined. ,10.1.1.1.2911,Classroom discussion Teacher conceptions Social studies,?
Performance-Based Multi-Classifier Decision Fusion for Atlas-Based Segmentation of Biomedical Images,T. Rohlfing D. B. Russakoff  R. Brandt R. Menzel C. R. Maurer  Jr.,2004,Combinations of multiple classifiers have been found to be consistently more accurate than a single classifier. The construction of multiple independent classifiers however is typically a non-trivial problem. In atlas-based segmentation multiple classifiers arise naturally for example from using multiple atlases. This paper evaluates the application of performance-based decision fusion methods to multi-classifier atlas-based segmentation. In a leave-one-out study each of 20 subjects is segmented using each of the remaining 19 as the atlas. The resulting 19 segmentations per subject are combined into a final segmentation using three different methods: 1) simple decision fusion using the sum rule 2) using a binary classifier performance model 3) using a multi-label classifier performance model. The accuracy of each combined segmentation is computed by comparing it to the manual ground truth segmentation. The two methods that incorporate classifier performance outperform sum rule fusion with the multi-label model performing better than the binary model.,10.1.1.1.2912,?,?
The Current-Feedback Ota,Hanspeter Schmid Bernafon Hanspeter Schmid,2001,The current-feedback OTA (CFB OTA) recently appeared in a new classification of operational amplifiers. It is dual to the operational floating amplifier (OFA) so all OFA circuits can readily be transposed into CFB OTA circuits. This paper discusses the theoretical basis of the CFB OTA shows its relation to the OFA and compares their performance in a simple V--I converter by showing how both can be built with the same two transistor stages. The advantages and disadvantages of the CFB-OTA implementation are discussed as well but the main advantage of introducing the CFB OTA is that its introduction is virtually for free: most current opamps from the literature can be converted into CFB OTAs by re-wiring their input stage without adding or re-sizing a single transistor.,10.1.1.1.2913,?,?
Thoughts on Using Evolutionary Computation to Assemble Efficient Ecosystems,Frederik Vandecasteele Frederik P. J. V  Thomas Hess  Ronald Crawford,2004,Evolutionary computation techniques have recently been used for the first time to construct efficient real world biological ecosystems. These experiments have opened a whole new area of application of evolutionary computation. This paper discusses various aspects of this promising new type of ecological research.,10.1.1.1.2914,?,?
Service Differentiation of Communication-bound Processes,In Real-Time Operating D. Cotroneo S. Russo G. Ventre M. Ficco M. Gargiulo Consorzio Interuniversitario Nazionale Per L’informatica,2002,The majority of todays Internet-based services are generally not concerned about the level of Quality of Service (QoS) presented to their users. For many such services however the QoS perceived by users is becoming a critical success factor. The main QoS attributes include those related to the service availability and timeliness. Ensuring them is essential to many services. In our opinion this has to be achieved not only by providing services with appropriate access bandwidth or through QoS awareness of the network communication protocols used but also by means of a differentiation of the usage of system resources by server processes. In this paper we focus on Internet-based multimedia data delivery services (e.g. services provided by Web FTP and video-on-demand servers). These services are run by processes whose activity is typically dominated by network communication we call them communicationbound processes. We present the design and implementation of an operating system extension for quality-of-service differentiation among classes of communication-bound processes. The system allows to define classes of services with different quality attributes concerning the network data delivery performance. The proposed architecture provides server application developers with an object-based communication library (similar to the standard TCP/IP socket library)  that supports different classes of service. Implementation issues and optimization strategies are also discussed. Quantitative measures aimed at evaluating the effectiveness of the proposed architecture are provided.,10.1.1.1.2915,?,?
Complete Lax Logical Relations for Cryptographic Lambda-Calculi,Jean Goubault-larrecq David Nowak Yu Zhang,2004,Security properties are profitably expressed using notions of contextual equivalence and logical relations are a powerful proof technique to establish contextual equivalence in typed lambda calculi see e.g. Sumii and Pierces logical relation for a cryptographic lambda-calculus. We clarify Sumii and Pierces approach showing that the right tool is prelogical relations or lax logical relations in general: relations should be lax at encryption types notably. To explore the difficult aspect of fresh name creation we use Moggis monadic lambdacalculus with constants for cryptographic primitives and Starks name creation monad. We define logical relations which are lax at encryption and function types but strict (non-lax) at various other types and show that they are sound and complete for contextual equivalence at all types.,10.1.1.1.2916,Logical relations Monads Cryptographic lambda-calculus Subscone,Springer
WOLD: A Mixed-Initiative Wizard for Producing Multi-Platform User Interfaces,Julien Stocq  Jean Vanderdonckt,2004,WOLD (Wizard fOr Leveraging the Development of multi-platform user interfaces) helps designers to produce running user interfaces to data bases of information systems simultaneously for multiple computing platforms. This software consists of a wizard application guiding designers step by step according to a mixedinitiative approach of production rules structured in a decision tree for choosing appropriate design options covering user interfaces to be produced. The main goal of this software is to speed up the development life cycle according to a transformational approach spiral life cycle derivation of user interfaces from data bases structure and queries intelligent layout derived from data base structure and query. User interfaces are structured and described according to characteristics that remain independent of computing platforms.,10.1.1.1.2917,General Terms Algorithms Design Human Factors Languages. Keywords Data base decision tree design option layout algorithm mixedinitiative multi-platform,ACM Press
Scaling Heterogeneous Databases and the Design of Disco,Anthony Tomasic Louiqa Raschid Patrick Valduriez,1995,Access to large numbers of data sources introduces new problems for users of heterogeneous distributed databases. End users and application programmers must deal with unavailable data sources. Database administrators must deal with incorporating each new data source into the system. Database implementors must deal with the transformation of queries between query languages and schemas. The Distributed Information Search COmponent (DISCO) addresses these problems. Query processing semantics give meaning to queries that reference unavailable data sources. Data modeling techniques manage connections to data sources. The component interface to data sources flexibly handles different query languages and different interface functionalities. This paper describes in detail (a) the distributed mediator architecture of DISCO (b) its query processing semantics (c) the data model and its modeling of data source connections and (d) the interface to underlying data sources. We describe several advantages of our system and describe the internal architecture of our planned prototype.,10.1.1.1.2918,Key-words Heterogeneous Distributed Database Autonomous Mediator Wrapper Partial Evaluation Unavailable Data Database Implementation Query Optimization (Résumé tsvp,?
   Optimal Discrimination between Transient and Permanent Faults,M. Pizza L. Strigini A. Bondavalli F. Di Giandomenico,1998,An important practical problem in fault diagnosis is discriminating between permanent faults and transient faults. In many computer systems the majority of errors are due to transient faults. Many heuristic methods have been used for discriminating between transient and permanent faults however we have found no previous work stating this decision problem in clear probabilistic terms. We present an optimal procedure for discriminating between transients and permanent faults based on applying Bayesian inference to the observed events (correct and erroneous results). We describe how the assessed probability that a module is permanently faulty must vary with observed symptoms. We describe,10.1.1.1.2919,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,In simulation software selection problems packages are evaluated either on their own merits or in comparison with other packages. In either method a list of criteria for evaluation of simulation software is essential for proper selection. Although various simulation software evaluation checklists do exist there are differences in the lists provided and the terminologies used. This paper presents a comprehensive list of criteria structured in a hierarchical framework for simulation software evaluation consisting of seven main groups and several subgroups. An explanation for each criterion is provided and an analysis of the usability of the proposed framework is further discussed.,10.1.1.1.2921,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,In business today re-engineering has taken a great deal of the cost out of internal corporate processes. Our factories and internal support organizations have become much more efficient but there is still a great deal of unnecessary cost in the overall delivery system or the supply chain. Although your corporation does not own all of the supply chain the entire chain is responsible for product delivery and customer satisfaction. As one of several methodologies available for supply chain analysis simulation has distinct advantages and disadvantages when compared to other analysis methodologies. This paper discusses the reasons why one would want to use simulation as the analysis methodology to evaluate supply chains its advantages and disadvantages against other analysis methodologies such as optimization and business scenarios where simulation can find cost reductions that other methodologies would miss.,10.1.1.1.2922,?,?
Eptd Discussion Paper No. 100,Environment And Production Bonwoo Koo Philip G. Pardey Keming Qian Yi Zhang,?,Notwithstanding the ambiguous research and productivity promoting effects of plant  variety protections (PVPs) even in developed countries many developing countries have  adopted PVPs in the past few years to comply with their Trade-Related Aspects of  Intellectual Property Rights (TRIPS) obligations. Seeking and maintaining PVPs reserves  options to an expected revenue stream from the future sale of protected varieties the  value of which varies for a host of reasons. In this paper we empirically examine the  pattern of plant variety protection applications in China since its PVP laws were first  introduced in 1997. We place those PVP rights in the context of Chinas present and  likely future seed markets to identify the economic incentives and institutional aspects  that influence decisions to develop and apply for varietal rights.    Key Words: intellectual property rights crop improvement option value seed markets ii  TABLE OF CONTENTS       1. ,10.1.1.1.2925,TABLE OF CONTENTS,?
The effect of progressive hypoxia on swimming activity and schooling in Atlantic herring,P. Domenici J. F. Steffensen R. S. Batty,2000,xia occurs and the magnitude of the response  are related to the fishs preferred speed prior to severe hypoxia it is suggested that such a  preferred speed should be measured in experiments testing the eect of hypoxia on fish  behaviour. # 2000 The Fisheries Society of the British Isles  Key words: hypoxia behaviour swimming swimming activity swimming speed schooling  herring Clupea harengus.  INTRODUCTION  Oxygen availability is one of the main factors aecting the swimming activity of fish (Randall 1970 Bryan et al. 1990). The occurrence of hypoxic events in coastal environments has increased in recent years due to the continual development of human activities along the coasts (Orel et al. 1986 Baden et al. 1990). Although hypoxic conditions are found usually in coastal areas both benthic and pelagic fish may be subject to hypoxia at certain times of their lives or during certain seasons. For instance herring Clupea harengus L. a pelagic species may experience hy,10.1.1.1.2926,herring Clupea harengus,O
A Proposed Bluetooth Service-level Security,Fathi Taibi  Mazliza Othman,2001,Bluetooth security has become increasingly important since Bluetooth is going to be used as a standard technology in wireless personal communication. This is  especially true for Bluetooth applications that require strong security policies e.g. mobile commerce applications. In this paper a Bluetooth service-level security that allows easy implementation of flexible access policies is proposed. Security is enforced based on service security level and device trust level.,10.1.1.1.2927,Bluetooth service-level security,?
An Algebraic Geometric Approach to the Identification of a Class of Linear Hybrid Systems,Rene Vidal  Stefano Soatto Yi Ma Shankar Sastry,2003,We propose an algebraic geometric solution to the identification of a class of linear hybrid systems. We show that the identification of the model parameters can be decoupled from the inference of the hybrid state and the switching mechanism generating the transitions hence we do not constraint the switches to be separated by a minimum dwell time. The decoupling is obtained from the so-called hybrid decoupling constraint which establishes a connection between linear hybrid system identification polynomial factorization and hyperplane clustering. In essence we represent the number of discrete states n as the degree of a homogeneous polynomial  p and the model parameters as factors of p. We then show that one can estimate n from a rank constraint on the data the coe#cients of p from a linear system and the model parameters from the derivatives of p. The solution is closed form if and only if n    4. Once the model parameters have been identified the estimation of the hybrid state becomes a simpler problem. Although our algorithm is designed for noiseless data we also present simulation results with noisy data. 1 ,10.1.1.1.2930,?,?
Composition Reuse and Interaction Analysis of Stateful Aspects,Rémi Douence Pascal Fradet Mario Südholt,2004,Aspect-Oriented Programming promises separation of concerns at the implementation level. However aspects are not always orthogonal and aspect interaction is a fundamental problem. In this paper we extend previous work on a generic framework for the formal definition and interaction analysis of stateful aspects. We propose three important extensions which enhance expressivity while preserving static analyzability of interactions. First we provide support for variables in aspects in order to share information between different execution points. This allows the definition of more precise aspects and to avoid detection of spurious conflicts. Second we introduce generic composition operators for aspects. This enables us to provide expressive support for the resolution of conflicts among interacting aspects. Finally we o#er a means to define applicability conditions for aspects. This makes interaction analysis more precise and paves the way for reuse of aspects by making explicit requirements on contexts in which aspects must be used.,10.1.1.1.2931,of,ACM Press
Finding High-Frequent Synonyms of a Domain-Specific Verb in English Sub-Language of MEDLINE Abstracts Using WordNet,Chun Xiao  Dietmar Rösner Universität Magdeburg,2004,The task of binary relation extraction in IE [3] is based mainly on  high-frequent verbs and patterns. During the extraction of a specific relation from  MEDLINE    English abstracts it is noticed that besides the high-frequent verb itself  which represents the specific relation some other word forms such as the nominal  and adjective forms of this verb as well as its synonyms also play a very important  role. Because of the characteristics of the sub-language in MEDLINE abstracts  the synonym information of the verb can not be obtained directly from a lexicon  such as WordNet    [1]. In this paper an approach which makes use of both corpus  information and WordNet synonym set (WN-synset) information is proposed to find  out the synonyms of a domain-specific verb in a sub-language. Given a golden standard  synonym list obtained from the test corpus the recall of this approach achieved 60%  under the condition that the precision is 100%. The verbs corresponding to the 60%  recall cover 93.05% of all occurrences of verbs in the golden standard synonym list.,10.1.1.1.2932,?,?
A survey and experimental comparison of service level approximation methods for non-stationary M/M/s queueing systems ,Armann Ingolfsson Elvira Akhmetshina Susan Budge Yongyue Li   Xudong Wu,2005,We compare the performance of six methods in computing or approximating service levels for nonstationary M/M/s queueing systems: an exact method (a Runge Kutta ordinary differential equation solver) the randomization method a closure (or surrogate distribution) approximation a direct infinite server approximation a modified offered load infinite server approximation and an effective arrival rate approximation. We used all of the methods to solve the same set of 128 test problems. The randomization method was almost as accurate as the exact method and used less than half the computational time of the exact method. The closure approximation was less accurate and in many cases slower than the randomization method. The two infinite server based approximations and the effective arrival rate approximation had were less accurate but had computation times that were far shorter and less problem-dependent than for the other three methods.,10.1.1.1.2933,Queues Nonstationary Queues Algorithms Queues Approximations,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Martin J. Steele,?,We summarize our methodology for modeling space shuttle processing using discrete event simulation. Why the project was initiated what the overall goals were how it was funded and who were the members of the project team are identified. We describe the flow of the space shuttle flight hardware through the supporting infrastructure and how the model was created to accurately portray the space shuttle. The input analysis methodology that was used to populate the model elements with probability distributions for process durations is described in the paper. Verification validation and experimentation activities are briefly summarized.,10.1.1.1.2934,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,This paper re-introduces web-based simulation from a web development point of view by first comparing the goals structures operations and communication mechanisms on the web with those of current distributed simulation technology and then synthesizing a new web-based simulation paradigm that more closely resembles the technology found on the web than Java-HLA solutions. The resulting paradigm is expressed through the Simulation Reference Markup Language (SRML) and Simulation Reference Simulator (SR Simulator) developed through research at Boeing.,10.1.1.1.2935,?,?
Intl. Conf. RIVF04,February Hanoi Vietnam Evariste Valéry Bévo W Ghislain Lévesque Jean-guy Meunier,2004,One of the key parameters in estimation activities (effort costs) is the size. This important parameter can be expressed in terms of function points or lines of codes. The major advantage of software functional size measurement is the fact that it can be performed very early in the life cycle of the software (analysis or design). Despite significant improvement observed these last years (efforts in standardization for example) software functional size measurement remains a nonobvious activity especially when applying measurement methods. A proper expertise for each method is needed. The implementation of existing software functional size measurement systems in the industry has to deal with two major technical difficulties: the difficulty of applying measurement methods (which makes the task of the measurer tiresome and requires sometimes the help of one or several experts unfortunately not always available) [6] the lack of support tools to help measurers in their task. Relatively to this last point Sue Black  David Wigg [5] noticed that The software industry needs software measurement tools which can be used to compute measures across several platforms and languages to provide flexibility and usability. Today many research laboratories are working on the development of measurement tools for software functional size measurement [10][9][22]. The design of such tools is necessarily based on: (1) the identification of all the concepts handled in a methods measurement procedure as well as the relationships between these concepts (domain ontology) (2) the identification of all the tasks associated with a methods measurement procedure as well as the links between these tasks (tasks ontology). This paper adresses an ontological perception of a methods measuremen...,10.1.1.1.2936,?,?
Coupling of a local vision by Markov field and a global vision by Neural Network for the recognition of handwritten words,Christophe Choisy  Abdel Belaïd,?,In this paper an idea for the combination of global and local view models is presented. These two type of models have proved their capabilities independantly. Some combination were proposed using global view models for local analysis and local view models to synthetize local results. An opposite approach is proposed here : local view models are used as a normalization tool while global view models are used for the recognition of the normalized image. The use of local view models for normalization is justified by their capability to perform a non-linear normalization according to the image information. We propose Markov models as local view models and Neural Netwok as global view models. Using Markov models for the normalization increases results up to 3% better than a classical linear normalization. Global results are improved performing 2% better than the Markov model itself. The extension of the system to an analytic approach is discussed.,10.1.1.1.2937,?,?
On The Applicability To Correlated Sources Of A Blind Channel Equalization Method Robust To Order Overestimation,Roberto López-Valcarce,?,We consider the blind equalization problem in single-user FIR multichannel models from the second-order statistics of the channel output. In particular we focus on the case of a correlated channel input whose statistics are known to the receiver. The few algorithms that are able to handle colored sources usually require exact knowledge of the channel order. This is a major drawback since channel order determination is a difficult issue. Recently Gazzah et al. have presented an SOS-based multichannel estimation technique which is robust to order overestimation. Although their method was derived assuming uncorrelated sources we show that it can be suitably modified in order to handle colored channel inputs. In particular it is shown that the algorithm is still able to blindly compute a bank of FIR pre-equalizers such that the overall channel - pre-equalizer response reduces to an FIR transfer function. This transfer function depends only on the source statistics and in fact it is known a priori by the receiver up to a complex phase rotation. Therefore a post-equalizer can be designed in a blind straightforward manner. As expected the method remains robust to order overmodeling in the correlated source case.  ,10.1.1.1.2939,?,?
Factor analysed hidden Markov models for Speech Recognition,A-V. I. Rosti M. J. F. Gales,2004,Recently various techniques to improve the correlation model of feature vector elements in speech recognition systems have been proposed. Such techniques include semi-tied covariance HMMs and systems based on factor analysis. All these schemes have been shown to improve the speech recognition performance without dramatically increasing the number of model parameters compared to standard diagonal covariance Gaussian mixture HMMs. This paper introduces a general form of acoustic model the factor analysed HMM. A variety of configurations of this model and parameter sharing schemes some of which correspond to standard systems were examined. An EM algorithm for the parameter optimisation is presented along with a number of methods to increase the e#ciency of training. The performance of FAHMMs on medium to large vocabulary continuous speech recognition tasks was investigated. The experiments show that without elaborate complexity control an equivalent or better performance compared to a standard diagonal covariance Gaussian mixture HMM system can be achieved with considerably fewer parameters.,10.1.1.1.2940,Key words Hidden Markov models state space models factor analysis speech,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Felipe F. Baesler Hector E. Jahnsen,?,This work presents the results obtained after using a simulation model for estimating the maximum possible demand increment in an emergency room of a private hospital in Chile. To achieve this objective the first step was to create a simulation model of the system under study. This model was used to create a curve for predicting the behavior of the variable patients time in system and estimate the maximum possible demand that the system can absorb. Finally a design of experiments was conducted in order to define the minimum number of physical and human resources required to serve this demand.,10.1.1.1.2941,?,?
Offline Recognition of Large Vocabulary Cursive Handwritten Text,A. Vinciarelli  S. Bengio  H. Bunke,?,This paper presents a system for the offline recognition of cursive handwritten lines of text. The system is based on continuous density HMMs and Statistical Language Models. The system recognizes data produced by a single writer. No a-priori knowledge is used about the content of the text to be recognized. Changes in the experimental setup with respect to the recognition of single words are highlighted. The results show a recognition rate of #85% with a lexicon containing 50000 words. The experiments were performed over a publicly available database.,10.1.1.1.2942,?,?
A New Omnidirectional Vision Sensor for Monte-Carlo Localization,E. Menegatti A. Pretto  E. Pagello,2004,In this paper we present a new approach for omnidirectional  vision-based self-localization in the RoboCup Middle-Size League. The  omnidirectional vision sensor is used as a range finder (like a laser or a  sonar) sensitive to colors transitions instead of nearest obstacles. This  makes it possible to have a more reach information about the environment  because it is possible to discriminate between di#erent objects  painted in di#erent colors. We implemented a Monte-Carlo localization  system slightly adapted to this new type of range sensor. The system runs  in real time on a low-cost pc. Experiments demonstrated the robustness  of the approach. Event if the system was implemented and tested in the  RoboCup Middle-Size field the system could be used in other environments.,10.1.1.1.2943,?,Springer
Electronic Textiles for Motion Analysis,Joshua N. Edmison Joshua N. Edmison,2004,The union of electronics and textiles to form electronic textiles (e-textiles) provides a promising substrate upon which motion analysis applications can be developed and implemented. Familiarity with clothing allows sensors and computational elements to be naturally integrated into garments such that wearability and usability is preserved. The dynamics of the human body and the wide variety of sensor and processing choices render the typical prototype-based design methodology prohibitively di#cult and expensive. Simulation of e-textile systems not only reduces these problems but allows for thorough exploration of the design space faster design cycles and more robust applications. Gait analysis the measurement of various body motion parameters during walking for medical purposes and context awareness the recognition of user motions are two immediate applications that e-textiles can impact and emphasize the feasibility of e-textiles as a medium for sensor deployment on the human body. This thesis presents the design of a simulation environment for wearable e-textile systems and demonstrates the use of the simulation via a prototype pair of e-textile pants.,10.1.1.1.2944,Computational fabrics e-textiles gait analysis context awareness,?
Fuzzy Association Rules: A Two-Sided Approach,Martine De Cock  Chris Cornelis  Etienne E. Kerre M. De Cock C. Cornelis E. E. Kerre,2003,We bring to the surface the fundamental two-sidedness of knowledge in the framework of association rules until now only slumberingly present in the measures of support and confidence. We identify the set of positive as well as the set of negative examples which are not necessarily complementary. Taking this into account we introduce new quality measures comprising the existing ones. Finally we carefully examine the generalization of our findings to fuzzy association rules.,10.1.1.1.2945,fuzzy association rule support opposition positive example negative example,?
Estimating Curvatures and Their Derivatives on Triangle Meshes,Szymon Rusinkiewicz  ,2004,The computation of curvature and other differential properties of surfaces is essential for many techniques in analysis and rendering. We present a finite-differences approach for estimating curvatures on irregular triangle meshes that may be thought of as an extension of a common method for estimating per-vertex normals. The technique is efficient in space and time and results in significantly fewer outlier estimates while more broadly offering accuracy comparable to existing methods. It generalizes naturally to computing derivatives of curvature and higher-order surface differentials.,10.1.1.1.2947,?,?
INSITE: A Tool for Real-Time Knowledge Discovery from Users Web Navigation,Cyrus Shahabi  Adil Faisal  Farnoush Banaei Kashani  Jabed Faruque,2000,The major challenges in web mining are a) tracking the data accurately (as not everything is reported to the web server) b) real-time acquisition of the huge volume of data (435 Million visits to yahoo per day 2-4 GB clickstream data per hour) c) real-time interpretation of the data without compromising the privacy of the user (order of seconds for personalization and targeting information) and d) visualization of the data to facilitate policy making. To address these challenges we demonstrate an integrated software platform called INSITE -- a) to accurately track users interactions with a web space with minimum overhead and no voluntary user participation b) to generate individual and aggregate user profiles in real time (or off-line) through the use of a unique Connectivity Matrix Model (CM-model) c) to show the efficacy and scalability of the CM-model in capturing the essence of the users participatory attributes in the context of the web d) to visualize the result of clustering of users navigation paths in real time by leveraging on the CM-model and e) to execute a suite of queries (including temporal ones) and prove the utility of the captured data in making meaningful decisions about user interaction with a web site.,10.1.1.1.2948,?,?
Individualised Recommendations for Learning Strategy Use,Susan Bull,2000,This paper describes LS-LS: a system to raise awareness of language  learning strategies to help students become more effective learners. The focus is  the student model which contains representations of learning style and current  strategy use: information provided explicitly by the learner. LS-LS infers  additional strategies of potential interest to an individual based on the contents  of their student model. It also suggests computational learning environments  that a student might find useful to practise these new strategies based on  information provided by the (human) tutor about locally available software.,10.1.1.1.2950,?,?
EPTD DISCUSSION PAPER NO. 54 THE TIMING OF EVALUATION OF GENEBANK ACCESSIONS AND THE EFFECTS OF BIOTECHNOLOGY,Bonwoo Koo Brian D. Wright,?,The lack of ex-ante evaluation of germplasm in genebanks has been the single most prevalent and long-standing complaint of plant breeders about the management of genebanks. Advances in biotechnology offer the possibility of faster cheaper and more efficient evaluation methodologies. Will these new technologies favor ex-post evaluation as some expect or will it lead to more ex-ante evaluation? Will it also lead to earlier development of varieties with disease resistance traits in anticipation of actual infestations? Will the prospect of further advances in biotechnology favor delay of evaluation and development? This paper addresses these questions in the case of evaluation of germplasm for resistance to a disease. ii  CONTENTS Abstract ................................................................................................................................ i 1. ,10.1.1.1.2951,CONTENTS Abstract...................................................................................,?
The Firecracker Protocol,Philip Levis   David Culler,2004,We propose the Firecracker protocol for data dissemination in wireless sensor networks. Firecracker uses a combination of routing and broadcasts to rapidly deliver a piece of data to every node in a network. To start dissemination the data source sends data to distant points in the network. Once the data reaches its destinations broadcast-based dissemination begins along the paths like a string of firecrackers. By using,10.1.1.1.2952,?,?
ReQuest - Validating Semantic,Searches Norman Piedade Mestre Em Informática Norman Piedade De Noronha Norman Piedade De Noronha Norman Piedade De Noronha,?,ReQuest is a semantic search engine for specialized domains. It offers searches based on ontologies and resource description files (RDF). ReQuest was built to evaluate semantic searches against classic Information Retrieval searches. The results of a user survey in the newsdomain showed that the Semantic Web can improve searches.,10.1.1.1.2953,KEY-WORDS Semantic Web RDF Ontologies Search Engines User Relevance Acknowledgments,?
Phoenix : a Parallel Programming Model for Accommodating Dynamically Joining Resources,Kenjiro Taura Toshio Endo  Kenji Kaneda Akinori Yonezawa,2003,This paper proposes Phoenix a programming model for writing parallel and distributed applications that accommodate dynamically joining/leaving compute resources. In the proposed model nodes involved in an application see a large and fixed virtual node name space. They communicate via messages whose destinations are specified by virtual node names rather than names bound to a physical resource. We describe Phoenix API and show how it allows a transparent migration of application states as well as dynamically joining/leaving nodes as its by-product. We also demonstrate through several application studies that Phoenix model is close enough to regular message passing thus it is a general programming model that facilitates porting many parallel applications/algorithms to more dynamic environments. Experimental results indicate applications that have a small task migration cost can quickly take advantage of dynamically joining resources using Phoenix. Divide-and-conquer algorithms written in Phoenix achieved a good speedup with a large number of nodes across multiple LANs (120 times speedup using 169 CPUs across three LANs). We believe Phoenix provides a useful programming abstraction and platform for emerging parallel applications that must be deployed across multiple LANs and/or shared clusters having dynamically varying resource conditions.,10.1.1.1.2954,Categories and Subject Descriptors D.1.3 [Software Programming Techniques—concurrent programming,ACM
A Formal Correctness Proof for Code Generation from SSA Form in Isabelle/HOL,Jan Olaf Blech  Sabine Glesner,2004,Optimizations in compilers are the most error-prone phases in the compilation  process. Since correct compilers are a vital precondition for software correctness  it is necessary to prove their correctness. We develop a formal semantics for static single  assignment (SSA) intermediate representations and prove formally within the Isabelle  /HOL theorem prover that a relatively simple form of code generation preserves  the semantics of the transformed programs in SSA form. This formal correctness proof  does not only verify the correctness of a certain class of code generation algorithms but  also gives us a sufficient easily checkable correctness criterion characterizing correct  compilation results obtained from implementations (compilers) of these algorithms.,10.1.1.1.2955,?,?
Bootstrapping SVM Active Learning by Incorporating Unlabelled Images for Image Retrieval,Lei Wang  Kap Luk Chan  Zhihua Zhang,2003,The performance of image retrieval with SVM active learning is known to be poor when started with few labelled images only. In this paper the problem is solved by incorporating the unlabelled images into the bootstrapping of the learning process. In this work the initial SVM classifier is trained with the few labelled images and the unlabelled images randomly selected from the image database. Both theoretical analysis and experimental results show that by incorporating unlabelled images in the bootstrapping the efficiency of SVM active learning can be improved and thus improves the overall retrieval performance.,10.1.1.1.2956,?,?
A Scalable Overlay Multicast Architecture for Large-Scale Applications,Li Lao Jun-hong Cui  Mario Gerla,2004,We propose a two-tier overlay multicast architecture (TOMA) to provide scalable and efficient multicast support for a  variety of group communication applications. In TOMA multicast service overlay network (MSON) is advocated as the  backbone service domain while end users in the access domains form a number of small clusters in which an applicationlayer  multicast protocol is used for the communication between the clustered end users. Our two-tier architecture is able to  provide efficient resource utilization with less control overhead especially for large-scale applications. It also alleviates the  forwarding state scalability problem and simplifies multicast tree construction and maintenance when there are large numbers  of groups ongoing in the networks. To help the MSON provider efficiently plan backbone service overlay we provide several  dimensioning algorithms to locate proxies select overlay links and allocate link bandwidth. Based on our architecture we  also suggest a cost-based pricing model for the overlay ISP to charge multicast groups. This pricing model would provide  key incentives for both service providers and clients to adopt our proposed TOMA service. Extensive simulation studies are  conducted and the results demonstrate that TOMA performs well in several common scenarios it provides efficient multicast  transmission comparable to IP multicast and is scalable to group size as well as to the number of co-existing groups. We also  run experiments and show that our dimensioning algorithms could efficiently plan the network resources with little penalty.,10.1.1.1.2957,?,?
Routing Based Workflow for Construction of Distributed Applications*,Wanjun Huang Xinhua Zhang  Uwe Roth Christoph Meinel,2004,Dynamic reconfiguration is absorbing more and more research focus for its increasing demand in inconstant distributed application. In this paper we propose a routing based workflow to model the  dataflow runtime state and control management of  cooperating components. Routing based workflow successfully realizes dynamic reconfiguration by the way of modifying routing structure and simplifies the hard problem of maintaining consistence into rather easy issue of synchronization. A detailed analysis is also given to show the great flexibility for construction of software architecture and potential applications.,10.1.1.1.2958,?,?
Development and Complexity-Based Fitness Function Modifiers,Per Kristian Lehre Morten Hartmann,2004,Artificial Development is a promising approach to evolutionary  design optimization inspired by biological development. However  there is still no consensus as to which problem classes this approach has  a clear advantage over classical direct encodings. We attack this problem  by introducing the concept of fitness function modifiers based on  complexity. Our results indicate that using these modifiers we are able  to discriminate a developmental mapping from a direct encoding with  respect to their e#ciency at solving classes of problems defined by the  fitness modifiers.,10.1.1.1.2959,?,?
Stochastic evolution equations with fractional Brownian motion,S. Tindel C. A. Tudor F. Viens,2003,In this paper linear stochastic evolution equations driven by infinite-dimensional fractional Brownian motion are studied. A necessary and su#cient condition for the existence and uniqueness of the solution is established and the spatial regularity of the solution is analyzed separate proofs are required for the cases of Hurst parameter above and below 1/2. The particular case of the Laplacian on the circle is discussed in detail.,10.1.1.1.2960,1,?
Shape Representations and Algorithms for 3D Model Retrieval,Michael M. Kazhdan,2004,With recent improvements in methods for the acquisition and rendering of 3D models the need for retrieval of models from large repositories of 3D shapes has gained prominence in the graphics and vision communities. A variety of methods have been proposed that enable the efficient querying of model repositories for a desired 3D shape. Many of these methods use a 3D model as a query and attempt to retrieve models from the database that have a similar shape.,10.1.1.1.2961,?,?
An Implicit Surface Triangulator based on Exact Surface Curvature,Ioannis Pantazopoulos Spyros Tzafestas,?,A technique for generating a triangular net from an implicit surface description is presented. This  technique can be applied to 2nd-order differentiable functions - describing the surface - and is based  on finding the principal curvatures at each generated point. It is therefore well adapted to the shape  of the surface taking more samples in the areas with high curvature. The triangular net is competed  in a second phase where extra edges are added that connect the vertices already extracted.,10.1.1.1.2962,?,?
Model-Based Motion Filtering for Improving Arm Gesture Recognition Performance,Greg S. Schmidt  Donald H. House,2004,We describe a model-based motion filtering process that when applied to human arm motion data leads to improved arm gesture recognition. By arm gestures we mean movements of the arm (and positional placement of the hand) that may or may not have any meaningful intent. Arm movements or gestures can be viewed as responses to muscle actuations that are guided by responses of the nervous system. Our method makes strides towards capturing this underlying knowledge of human performance by integrating a model for the arm based on dynamics and containing a control system. We hypothesize that by embedding the human performance knowledge into the processing of arm movements it will lead to better recognition performance. We present details for the design of our filter our analysis of the filter from both expert-user and multiple-user pilot studies. Our results show that the filter has a positive impact on the recognition performance for arm gestures.,10.1.1.1.2963,?,Springer-Verlag
Property Rights In A Flea Market Economy,Marcel Fafchamps Bart Minten,1999,This paper studies liberalized grain markets in Madagascar and examines how property rights are protected and contracts are enforced among agricultural traders. We find that the incidence of theft and breach of contract is low and that the losses resulting from such instances are small. This however does not result from reliance on legal institutions -- actual recourse to police and courts is fairly rare except in cases of theft -- but from traders reluctance to expose themselves to opportunism. As a result Malagasy grain trade resembles a flea market with little or no forward contracting and high transactions costs. The dominant contract enforcement mechanism is trust-based relationships. Trust is established primarily through repeated interaction with little role for referral by other traders. Information on bad clients does not circulate widely hence severely limiting group punishments for non payment.,10.1.1.1.2964,?,?
Investigating the Mechanisms Underlying Cooperation in Viscous Population Multi-Agent Systems,James A. R. Marshall et al.,?,This paper presents a viscous population multi-agent  system which is claimed to provide scope for the  emergence of cooperation both through iterated interaction  and through kin selection. Theoretical examinations of  iterated interaction and kin selection within the model are  conducted and compared with empirical results. It is  concluded that the model does allow for the operation both  of iterated interaction and kin selection. The methods  presented in the paper allow the operation of the two  mechanisms to be distinguished in any instance of the  model.,10.1.1.1.2965,?,?
Discrete- and Continuous-Time Local Cosine Bases with Multiple Overlapping,Riccardo Bernardini  Martin Vetterli,1998,Cosine-modulated filter banks (CMFBs) are filter banks whose impulse responses are obtained by modulating a window with cosines. Among their applications are video and audio compression and multitone modulation. Their continuoustime counterpart is known as local cosine bases. Even though there is an extended literature on the discrete-time case both for single and multiple overlapping the continuous-time case has received less attention and only the single overlapping case has been solved. This work gives a solution to the problem of continuous-time local cosine bases with multiple overlapping via a general theory that emphasizes the deep connection between discrete and continuous time. A sampling theorem for local cosine basis and an efficient algorithm to compute the expansion of a signal are also given.,10.1.1.1.2966,?,?
Point-Light Biological Motion Perception Activates Human Premotor Cortex,Ayse Pinar Saygin  Stephen M. Wilson  Donald J. Hagler Jr  Elizabeth Bates  Martin I. Sereno Premotor Cortex,2004,gical motion premotor cortex functional MRI action observation motion frontal  Introduction  The perception of other individuals movements and actions is important for tracking and hunting prey detecting and avoiding predators and in many species social interaction. In humans and at least some other primates premotor areas are involved in the perception of others actions. Recent research has shown that there are mirror neurons in the macaque frontal cortex in area F5 that fire during both action production and action perception (Gallese et al. 1996 Rizzolatti et al. 1996a 2001 Ferrari et al. 2003). Studies on humans have also demonstrated the involvement of motor and premotor areas in action observation indicating that humans may use information from their own body representations in understanding the actions of others (Fadiga et al. 1995 Grafton et al. 1996 Rizzolatti et al. 1996b Decety et al. 1997 Iacoboni et al. 1999 Buccino et al. 2001 Grezes et al,10.1.1.1.2967,?,?
Turbo Detection for MIMO Systems: Bit Labeling and Pre-Coding,Stephan Bäro,2004,Bit-interleaved coded modulation with iterative detection for MIMO systems demands an  efficient APP detector that delivers soft information about the coded bits. The list-sequential  detector is a reduced-complexity approximation to an exhaustive APP detector. It uses a tree  search employing the stack algorithm to find dominant terms of the log-likelihood ratio. The  commonly used symbol-by-symbol Gray labeling is not necessarily the best approach to good  performance of iterative systems. We therefore consider different bit labelings and differential  pre-coding adapted to MIMO systems. With the help of EXIT charts and BER simulations  we show that symbol-by-symbol Gray labeling in combination with an outer Turbo code is a  good compromise for fast convergence and low error floor of MIMO systems with iterative  detection.,10.1.1.1.2968,?,?
Accountability and Control of Process Creation In Metasystems,Marty Humphrey Frederick Knabe Adam Ferrari Andrew Grimshaw,2000,The distinguishing feature of a metasystem is middleware that facilitates viewing a collection of large distributed heterogeneous resources as a single virtual machine where each user of the metasystem is identified by a unique metasystem-level identity. The physical resources of the metasystem can exist in multiple administrative domains each with different local security requirements and authentication mechanisms (e.g. Kerberos publickey) . The problem this paper addresses is how to map the metasystems-level identity to an appropriate account on each local physical machine for the purposes of process creation such that the access control and authentication policies of each local machine are not violated. This mapping must ensure the integrity of the local machines must ensure the integrity of the metasystem users data and must not unnecessarily burden either the metasystem users the metasystem system administrator or the local machine system administrators. Specific examples are drawn from experiences gained during the deployment of the Legion metasystem. For example Legion configurations for local sites with different access control mechanisms such as standard UNIX mechanisms and Kerberos are compared. Through analysis of these configurations the inherent security trade-offs in each design are derived. These results have practical importance to current and future metasystem users and to sites considering any future inclusion of local resources in a global virtual computer.,10.1.1.1.2969,?,?
RTL Level Preparation of High-Quality / Low-Energy / Low-Power BIST,M. B. Santos  J. P. Teixeira J. P. Teixeira  S. Manich  R. Rodriguez  J. Figueras,?,While high-quality BIST (Built-In Self Test) based on deterministic vectors often has a prohibitive cost pseudorandom based BIST may lead to low DC (Defects Coverage) values requiring however very long test sequences with the corresponding energy waste and possible overheating due to extra switching activity caused by test vectors. The purpose of this paper is to discuss how a recently proposed RTL (Register Transfer Level) test preparation methodology can be reused to drive innovative high-quality / low-energy / low-power BIST solutions. RTL test generation is carried out through the definition of partially defined test vectors (masks) that while targeting multiple detection of RTL faults lead to high DC values. An energy / power model is proposed to optimize the energy / power consumption of the test at RTL level. It is shown that the proposed method achieves better DC values with low-energy and low-power consumption when compared to pseudo-random test excitation. The usefulness of the methodology is ascertained using the ####### simulation environment in modules of the CMUDSP and TORCH ITC99 benchmark circuits.,10.1.1.1.2970,?,?
Best-Path vs. Multi-Path Overlay Routing,David G. Andersen Alex C. Snoeren Hari Balakrishnan,2003,Time-varying congestion on Internet paths and failures due to software hardware and configuration errors often disrupt packet delivery on the Internet. Many aproaches to avoiding these problems use multiple paths between two network locations. These approaches rely on a path-independence assumption in order to work well i.e. they work best when the problems on different paths between two locations are uncorrelated in time. This,10.1.1.1.2971,Measurement Multi-Path Routing Overlay Networks,ACM Press
Evaluation of a Method for Estimating Configuration Parameters in Bistatic Radars Using Directive Antennas,Xavier Neyt Fabian D. Lapierre  Jacques G. Verly,2004,The method proposed in this paper aims at performing an automatic estimation of the clutter power spectrum (PS) locus in order to perform an optimum rangedependence compensation to finally provide an estimate of the snapshot covariance matrix. The method is shown to estimate reliably the clutter PS locus even for complex bistatic scenarios involving directional antenna patterns. Performance of the method is analyzed first with respect to the required sample-support size and then in comparison to other methods.,10.1.1.1.2972,Radar bistatic STAP range-dependence,?
Medium Access Control with Coordinated Adaptive Sleeping for Wireless Sensor Networks,Wei Ye John Heidemann Deborah Estrin,2004,This paper proposes S-MAC a medium access control (MAC) protocol designed for wireless sensor networks. Wireless sensor networks use battery-operated computing and sensing devices. A network of these devices will collaborate for a common application such as environmental monitoring. We expect sensor networks to be deployed in an ad hoc fashion with nodes remaining largely inactive for long time but becoming suddenly active when something is detected. These characteristics of sensor networks and applications motivate a MAC that is different from traditional wireless MACs such as IEEE 802.11 in several ways: energy conservation and self-configuration are primary goals while per-node fairness and latency are less important. S-MAC uses a few novel techniques to reduce energy consumption and support self-configuration. It enables low-duty-cycle operation in a multihop network. Nodes form virtual clusters based on common sleep schedules to reduce control overhead and enable traffic-adaptive wake-up. S-MAC uses in-channel signaling to avoid overhearing unnecessary traffic. Finally S-MAC applies message passing to reduce contention latency for applications that require in-network data processing. The paper presents measurement results of S-MAC performance on a sample sensor node the UC Berkeley Mote and reveals fundamental tradeoffs on energy latency and throughput. Results show that S-MAC obtains significant energy savings compared with an 802.11-like MAC without sleeping.,10.1.1.1.2975,?,?
Using speech recognition to evaluate skills in,Spoken English Rebecca Hincks,2001,This paper analyzes some of the results of the use of PhonePass a telephone-based test of spoken English that uses automatic speech recognition. It finds that the test provides sensitive measures of speech rate and phonetic accuracy.,10.1.1.1.2976,?,?
Fastest mixing Markov chain on a path,Stephen Boyd Persi Diaconis Jun Sun Lin Xiao,2004,?,10.1.1.1.2977,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,This tutorial is for advanced simulation developers engaged in the use of object-oriented programming languages and libraries that support object-oriented discrete-event simulation. The tutorial is based on generic structure of the OpenSML simulation libraries in the .Net languages VB.Net C# and J# and the Silk libraries in Java. The focus of the tutorial is on the use of consistent design patterns that encourage usability reusability and crosslanguage compatibility. Particular emphasis is placed on designing and coding object-oriented simulation models to properly transfer simulation control between entities resources and system controllers and on techniques for obtaining a one-to-one correspondence between simulation code and system behavior.,10.1.1.1.2978,?,?
IEEE 22 Computer,Billion-Transistor Architectures There Doug Burger James R. Goodman,?,this article or one that has not yet been discovered the future for interesting architectures has never been more open,10.1.1.1.2979,?,?
Intelligent Elicitation of Military Lessons,Rosina Weber  David W. Aha,2002,We introduce LET (Lesson Elicitation Tool) which uses domain and linguistic knowledge to guide users during their submission of lessons learned. LET can detect a users need for instructions and disambiguates expressions while collecting taxonomic domain knowledge.,10.1.1.1.2981,active help,?
Guidelines for Building a Usable Animation in Computer-Aided Presentations,Jean Vanderdonckt,1999,Introduction  Office automation today provides a wide variety of software tools for multimedia sophisticated computer -aided presentations (e.g. Microsoft PowerPoint Aldus Persuasion Astound Harvard Graphics) . Although these software tools empower users with several dynamic multimedia capabilities such as multimedia incorporation text compilation screen transition (Fig. 1) predefined or personalized animations sound effects they do not support them when they face the problem of how to use them which one to use for which purpose. Moreover little or no support is given to choose a dynamic capability that is appropriate to the message to be conveyed and to the medium used (e.g. slides computer -aided presentations).  Figure 1. Some examples of screen transitions.  To help solving this problem three inspiration sources are possible:  1. some research is conducted in the domain of multimedia in general or in several aspects related to dynamic multimedia capabilities in parti,10.1.1.1.2982,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,Simulation is widely used to estimate losses due to default and other credit events in financial portfolios. The challenge in doing this efficiently results from (i) rare-event aspects of large losses and (ii) complex dependence between defaults of multiple obligors. We discuss importance sampling techniques to address this problem in two portfolio credit risk models developed in the financial industry with particular emphasis on a mixed Poisson model. We give conditions for asymptotic optimality of the estimators as the portfolio size grows.,10.1.1.1.2983,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Kazuo Miyashita,?,We develop a constant time interval production planning and control methodology called CONSTIN and its associated simulation system for a large-scale and unstable semiconductor manufacturing process. CONSTIN moves work-in-process inventories (WIP) between processes only at a constant time interval and consequently maintains a desirable level of WIP. Our theoretical and experimental analysis shows a clear relationship between WIP levels and the time interval in CONSTIN. Computational experiments with realistic wafer fabrication process data demonstrate that CONSTIN is comparable in simulation accuracy to a popular event-driven simulator and can run much faster. Additional experiments also manifest that with appropriate control rules CONSTIN can restore the desired levels of WIP from extreme deviations and maintain them. Therefore we conclude that CONSTIN is a promising methodology of production planning and WIP control for the semiconductor manufacturing process.,10.1.1.1.2984,?,?
A Data-Driven Reflectance Model,Wojciech Matusik   Hanspeter Pfister Matt Brand Leonard McMillan,2003,We present a generative model for isotropic bidirectional reflectance distribution functions (BRDFs) based on acquired reflectance data. Instead of using analytical reflectance models we represent each BRDF as a dense set of measurements. This allows us to interpolate and extrapolate in the space of acquired BRDFs to create new BRDFs. We treat each acquired BRDF as a single high-dimensional vector taken from a space of all possible BRDFs. We apply both linear (subspace) and non-linear (manifold) dimensionality reduction tools in an effort to discover a lowerdimensional representation that characterizes our measurements. We let users define perceptually meaningful parametrization directions to navigate in the reduced-dimension BRDF space. On the low-dimensional manifold movement along these directions produces novel but valid BRDFs.,10.1.1.1.2985,?,?
Linear Hash Functions,Noga Alon  Martin Dietzfelbinger Peter Bro Miltersen  Erez Petrank  Gábor Tardos,1999,Consider the set # of all linear (or affine) transformations between two vector spaces over a finite field F. We study how good # is as a class of hash functions namely we consider hashing a set S of size n into a range having the same cardinality n by a randomly chosen function from # and look at the expected size of the largest hash bucket. # is a universal class of hash functions for any finite field but with respect to our measure different fields behave differently. If the,10.1.1.1.2986,?,?
A Framework for Monitoring Program Execution,Clinton Lewis Jeffery,1993,This technical report has been submitted as a dissertation  to the faculty of the Department of Computer Science in  partial fulfillment of the requirements for the degree  of Doctor of Philosophy in the Graduate College of  the University of Arizona,10.1.1.1.2987,?,?
ASSAM: A Tool for Semi-Automatically Annotating Semantic Web Services,Andreas Heß Eddie Johnston Nicholas Kushmerick,2004,The semantic Web Services vision requires that each service  be annotated with semantic metadata. Manually creating such metadata  is tedious and error-prone and many software engineers accustomed to  tools that automatically generate WSDL might not want to invest the  additional e#ort. We therefore propose ASSAM a tool that assists a user  in creating semantic metadata for Web Services. ASSAM is intended for  service consumers who want to integrate a number of services and therefore  must annotate them according to some shared ontology. ASSAM is  also relevant for service producers who have deployed a Web Service and  want to make it compatible with an existing ontology. ASSAMs capabilities  to automatically create semantic metadata are supported by two  machine learning algorithms. First we have developed an iterative relational  classification algorithm for semantically classifying Web Services  their operations and input and output messages. Second to aggregate  the data returned by multiple semantically related Web Services we have  developed a schema mapping algorithm that is based on an ensemble of  string distance metrics.,10.1.1.1.2988,?,?
A Note on Parameter Values of REM with Reno-like Algorithms,Sanjeewa Athuraliya Networking Sanjeewa Athuraliya,2002,We explain the choice of parameter values for the REM implementation in ns-2.1b9 network  simulator and how it can be simplified when the TCP algorithm is Reno-like i.e. employs  additive-increase-multiplicative-decrease strategy.,10.1.1.1.2989,?,?
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros Sanjeewa Athuraliya,2001,In this paper we validate through simulations a duality model of TCP and active queue management (AQM) proposed earlier. In this model TCP and AQM are modeled as carrying out a distributed primal-dual algorithm over the Internet to maximize aggregate source utility. TCP congestion avoidance algorithms such as Reno and Vegas iterate on source rates the primal variable. AQM algorithms such as RED and REM iterate on marking probability the dual variable. 1 ,10.1.1.1.2990,?,?
FAST TCP: Motivation Architecture Algorithms Performance,C. Jin  D. X. Wei  S. H. Low,2004,We describe FAST TCP a new TCP congestion control algorithm for high-speed long-latency networks from design to implementation. We highlight the approach taken by FAST TCP to address the four difficulties at both packet and flow levels which the current TCP implementation has at large windows. We describe the architecture and characterize the equilibrium and stability properties of FAST TCP. We present experimental results comparing our first Linux prototype with TCP Reno HSTCP and STCP in terms of throughput fairness stability and responsiveness. FAST TCP aims to rapidly stabilize high-speed long-latency networks into steady efficient and fair operating points in dynamic sharing environments and the preliminary results are promising.,10.1.1.1.2991,?,?
A Case for Variable-Range Transmission Power,Control In Wireless Javier Gomez,2004,In this paper we study the impact of individual variable-range transmission power control on the physical and network connectivity network capacity and power savings of wireless multihop networks such as ad hoc and sensor networks. First using previous work by Steele [16] and Gupta [7] we derive an asymptotic expression for the average traffic carrying capacity of nodes in a multihop network where nodes can individually control the transmission range they use. For the case of a path attenuation factor # =2we show that this capacity remains constant even when more nodes are added to the network. Second we show that the ratio between the minimum transmission range levels obtained using common-range and variable-range based routing protocols is approximately 2. This is an important result because it suggests that traditional routing protocols based on common-range transmission can only achieve about half the traffic carrying capacity of variable-range power control approaches. In addition common-range approaches consume     2 # ) % more transmission power. Second we derive a model that approximates the signaling overhead of a routing protocol as a function of the transmission range and node mobility for both route discovery and route maintenance. We show how routing protocols based on common-range transmission power limit the capacity available to mobile nodes. The results presented in the paper highlight the need to design future wireless network protocols (e.g. routing protocols) for wireless ad hoc and sensor networks based not on common-range which is prevalent today but on variable-range power control.,10.1.1.1.2993,?,?
Multi-Classifier Framework for Atlas-Based Image Segmentation,Torsten Rohlfing Calvin R. Maurer  Jr.,2004,We develop and evaluate in this paper a multi-classifier framework for atlas-based segmentation a popular segmentation method in biomedical image analysis. An atlas is a spatial map of classes (e.g. anatomical structures) which is usually derived from a reference individual by manual segmentation. An atlas-based classification is generated by registering an image to an atlas that is by computing a semantically correct coordinate mapping between the two. In the present paper the registration algorithm is an intensitybased non-rigid method that computes a free-form deformation (FFD) defined on a uniform grid of control points. The transformation is regularized by a weighted smoothness constraint term. Different atlases as well as different parameterizations of the registration algorithm lead to different and somewhat independent atlas-based classifiers. The outputs of these classifiers can be combined in order to improve overall classification accuracy. In an evaluation study biomedical images from seven subjects are segmented 1) using three individual atlases 2) using one atlas and three different resolutions of the FFD control point grid 3) using one atlas and three different regularization constraint weights. In each case the three individual segmentations are combined by Sum Rule fusion. For each individual and for each combined segmentation its recognition rate (relative number of correctly labeled image voxels) is computed against a manual gold-standard segmentation. In all cases classifier combination consistently improved classification accuracy. The biggest improvement was achieved using multiple atlases a smaller gain resulted from multiple regularization constraint weights and a marginal gain resulted from multiple control point spacings. We con...,10.1.1.1.2994,?,?
 Using Philosophy to Improve the Coherence and Interoperability of Applications Ontologies: A Field Report on the Collaboration of IFOMIS and LC,Jonathan Simon Barry Smith,2004,  The collaboration of Language and Computing nv (LC) and the Institute for Formal Ontology and Medical Information Science (IFOMIS) is guided by the hypothesis that quality constraints on ontologies for software applications purposes closely parallel the constraints salient to the design of sound philosophical theories. The extent of this parallel has been poorly appreciated in the informatics community and it turns out that importing the benefits of philosophical insight and methodology into applications domains yields diverse improvements. LC’s LinKBase® is one of the world’s largest medical domain ontologies. Its current primary use pertains to natural language processing applications but it also supports intelligent navigation through a range of structured medical and bioinformatics information resources such as UMLS SNOMED Swiss-Prot and the Gene Ontology (GO). In this report we discuss how and why philosophical methods improve both the internal coherence of LinKBase® and its capacity to serve as a translation hub improving the interoperability of the ontologies it embeds.  ,10.1.1.1.2995,?,?
An Approach to Extracting the Target Text Line from a Document Image Captured by a Pen Scanner,Zhen-Long Bai Qiang Huo,2003,In this paper we present a new approach to extracting the target text line from a document image captured by a pen scanner. Given the binary image a set of possible text lines are first formed by nearest-neighbor grouping of connected components (CC). They are then refined by text line merging and adding the missed CCs. The possible target text line is identified by using a geometric feature based score function and fed to an OCR engine for character recognition. If the recognition result is confident enough the target text line is accepted. Otherwise all the remaining text lines are fed to the OCR engine to verify whether an alternative target text line exists or the whole image should be rejected. The effectiveness of the above approach is confirmed by experiments on a testing database consisting of 117 document images captured by C-Pen and ScanEye pen scanners.,10.1.1.1.2997,?,?
Efficient Multiscale Sampling from Products Of Gaussian Mixtures,Alexander Ihler Er T. Ihler  Erik Sudderth  William Freeman  Alan Willsky,2003,The problem of approximating the product of several Gaussian mixture  distributions arises in a number of contexts including the nonparametric  belief propagation (NBP) inference algorithm and the training of product  of experts models. This paper develops two multiscale algorithms  for sampling from a product of Gaussian mixtures and compares their  performance to existing methods. The first is a multiscale variant of previously  proposed Monte Carlo techniques with comparable theoretical  guarantees but improved empirical convergence rates. The second makes  use of approximate kernel density evaluation methods to construct a fast  approximate sampler which is guaranteed to sample points to within a  tunable parameter # of their true probability. We compare both multiscale  samplers on a set of computational examples motivated by NBP  demonstrating significant improvements over existing methods.,10.1.1.1.2998,?,MIT Press
Reliability-aware IBGP Route Reflection Topology Design,Li Xiao Jun Wang Klara Nahrstedt,2003,In the Internal Border Gateway Protocol (IBGP) route reflection is widely used as an alternative to full mesh IBGP sessions inside an AS for scalability reason. However some important issues such as the impact of route reflection on the reliability of IBGP and the construction of reliable reflection topology with unreliable routers or links have not been well investigated.,10.1.1.1.2999,?,?
A Simple Combinatorial Proof of Duality of Multiroute Flows and Cuts,Amitabha Bagchi Amitabh Chaudhary Petr Kolman  Jiri Sgall,2004,A classical ow is a nonnegative linear combination of unit ows along simple paths. A multiroute ow  rst considered by Kishimoto and Takeuchi generalizes this concept. The basic building blocks are not single paths with unit ows but rather tuples consisting of k edge disjoint paths each path with a unit ow. A multiroute ow is a nonnegative linear combination of such tuples.,10.1.1.1.3000,?,?
Enhanced Dominant Pruning Applied to the Route Discovery Process of On-demand Routing Protocols,Marco Aurelio Spohn  J.J. Garcia Luna-Aceves,2003,Dominant Pruning (DP) is a distributed connected dominating-set algorithm that can be used for reducing the impact of flooding in wireless ad hoc networks. We propose an enhanced dominant pruning (EDP) approach to be used in the route discovery process of on-demand routing protocols. To show the benefits of EDP we integrate EDP into the Ad-hoc On-demand Distance Vector (AODV) protocol. We present detailed simulation results showing that our approach improves standard AODV in most aspects and that it is simple and easy to implement. Our approach is compared against AODV and OLSR as good representatives of on-demand and proactive routing for ad-hoc wireless networks.,10.1.1.1.3001,?,?
The Use of Functional and Logic Languages,In Machine Learning Peter A. Flach,?,Traditionally machine learning algorithms such as decision tree learners  have employed attribute-value representations. From the early 80s on people  have started to explore Prolog as a representation formalism for machine learning  an area which came to be called inductive logic programming (ILP). With  hindsight however Prolog may not have been the best choice since it can be  argued that types and functions well known from functional programming are  essential ingredients of the individual-centred representations employed in machine  learning. Consequently a combined functional logic language is a better  vehicle for learning with a rich representation. In this talk I will illustrate this by  means of the higher-order functional logic programming language Escher.The  paper concentrates on giving a leisurely introduction to ILP.,10.1.1.1.3002,?,?
Cross-Lingual Validation of Multilingual Wordnets,Dan Tufis Radu Radu Ion Eduard Barbu Verginica Barbu,2004,Incorporating Wordnet or its monolingual followers in modern NLP-based  systems already represents a general trend motivated by numerous reports showing  significant improvements in the overall performances of these systems. Multilingual  wordnets such as EuroWordNet or BalkaNet represent one step further with great  promises in the domain of multilingual processing. The paper describes one possible  way to check the quality (correctness and completeness) of the interlingual alignments  of several wordnets and pinpoints the possible omissions or alignment errors.,10.1.1.1.3003,?,?
Unsupervised Non Stationary Image Segmentation Using Triplet Markov Chains,Pierre Lanchantin Wojciech Pieczynski,2004,This work deals with the unsupervised Bayesian hidden Markov chain restoration extended to the non stationary case. Unsupervised restoration based on ExpectationMaximization  (EM) or Stochastic EM (SEM) estimates considering the Hidden Markov Chain (HMC) model is quite efficient when the hidden chain is stationary. However when the latter is not stationary the unsupervised restoration results can be poor due to a bad match between the real and estimated models. In this paper we present a more appropriate model for non stationary HMC via recent Triplet Markov Chains (TMC) model. Using TMC we show that the classical restoration results can be significantly improved in the case of non stationary data. The latter improvement is performed in an unsupervised way using a SEM parameter estimation method. Some application examples to unsupervised image segmentation are also provided.,10.1.1.1.3005,?,?
Generalized Quotient Image,Haitao Wang Stan Haitao Wang Stan Z. Li Yangsheng Wang,2004,In this paper we present a unified framework for modeling intrinsic properties of face images for recognition. It is based on the quotient image (QI) concept in particular on the existing works of QI [1 2] Spherical Harmonic[13 14 15] [16 17] Image Ratio [3 5 6 7]and Retinex [4 9]. Under this framework we generalize these previous works into two new algorithms: (1) Non-Point Light Quotient Image (NPL-QI) extends QI to deal with non-point light sources by modeling non-point light directions using spherical harmonic bases (2) Self-Quotient Image (S-QI) extends QI to perform illumination subtraction without the need for alignment and no shadow assumption. Experimental results show that our algorithms can significantly improve the performance of face recognition under varying illumination conditions.,10.1.1.1.3006,?,?
 Towards automated proofs of observational properties,Narjes Berregeb Riadh Robbana Ashish Tiwari,2004,Observational theories are a generalization of first-order theories where two objects are observationally equal if they cannot be distinguished by experiments with observable results. Such experiments called contexts are usually infinite. Therefore we consider a special finite set of contexts called cover-contexts “covering” all the observable contexts. Then we show that to prove that two objects are observationally equal it is sufficient to prove that they are equal (in the classical sense) under these cover-contexts. We give methods based on rewriting techniques for constructing such cover-contexts for interesting classes of observational specifications.,10.1.1.1.3007,observational contexts rewriting,?
Adaptability Aspects: An Architectural Pattern for Structuring Adaptive Applications with Aspects,Ayla Dantas Paulo Borba,2003,This paper presents an architectural pattern for structuring adaptive applications using aspectoriented programming in order to obtain separation of concerns. It is composed of known and novel patterns organized so as to provide good maintainability and modularity.,10.1.1.1.3008,?,?
H.264/AVC Video Transmission over MBMS in GERAN,Hrvoje Jenkac Thomas Stockhammer  Guenther Liebl,?,In this work we investigate the integration of H.264/AVC based video into the Multimedia Broadcast/Multicast Service (MBMS). MBMS allows simultaneous distribution of live video with reasonable quality to several or even a large number of users within a serving area. We discuss several system design options and propose a simple but nevertheless efficient crosslayer design concept which helps to determine an optimal set of both application and transmission parameters for maximizing the quality at the user terminals for different link conditions. In order to validate our concept we present detailed performance results using realistic test conditions provided by 3GPP.,10.1.1.1.3009,?,?
ConQuer-92: Revised report on the conceptual query language LISA-D,H.A. Proper,2000,In this report the conceptual query language ConQuer-92 is introduced. This  query language serves as the backbone of InfoAssistants query facilities. Furthermore  this language can also be used for the specification of derivation rules (e.g.,10.1.1.1.3010,?,?
Semantic Information Portals,Dave Reynolds  Paul Shabajee  Steve Cayzer,2004,In this paper we describe the notion of a semantic information portal. This is a community information portal that exploits the semantic web standards to improve structure extensibility customization and sustainability. We are in the process of developing a prototype directory of environmental organizations as a demonstration of the approach and outline the design challenges involved and the current status of the work.,10.1.1.1.3011,Information Portals,?
Routing with Improved Communication-Space Trade-Off,Ittai Abraham Cyril Gavoille Dahlia Malkhi,2004,Given a weighted undirected network with arbitrary node names we present a family of routing schemes characterized by an integral parameter kappa ge 1. The scheme uses log D) space routing table at each node and routes along paths of linear stretch O(kappa) where D is the normalized diameter of the network. When D is polynomial in n the scheme has asymptotically optimal stretch factor. With the same memory bound the best previous results obtained stretch O(kappasup2). Of independent interest ...,10.1.1.1.3012,?,Springer
A Riemannian Framework for Tensor Computing,Xavier Pennec Pierre Fillard Nicholas Ayache,2006,Positive definite symmetric matrices (so-called tensors in this article) are nowadays a common source of geometric information. In this paper we propose to provide the tensor space with an affine-invariant Riemannian metric. We demonstrate that it leads to strong theoretical properties: the cone of positive definite symmetric matrices is replaced by a regular manifold of constant curvature without boundaries (null eigenvalues are at the infinity) the geodesic between two tensors and the mean of a set of tensors are uniquely defined etc. We have,10.1.1.1.3013,Key-words Riemannian geometry tensors fields PDE diffusion restoration,?
Effectiveness of Dynamic Resource Allocation for Handling Internet Flash Crowds,Abhishek Chandra Prashant Shenoy,2003,Internet data centers host multiple Web applications on shared hardware resources. These data centers are  typically provisioned to meet the expected peak demands of the hosted applications based on normal time-of-day  effects. Such an over-provisioning approach is not robust to flash crowd scenarios where the load increase of  some hosted applications is much higher than their expected peak loads. In such scenarios data centers can utilize  their resources better by employing dynamic resource allocation. In this paper we present a prototype data center  implementation that we use to study the effectiveness of dynamic resource allocation for handling flash crowds  with different characteristics. This prototype implements a multi-tiered server architecture along with mechanisms  for monitoring load detection load balancing and dynamic allocation. Our experiments with this prototype show  that a carefully designed dynamic allocation scheme can be effective for handling flash crowds. We show that in  order to handle very sharp growth in loads a dynamic allocation scheme must be either extremely responsive or  employ low overhead mechanisms such as using hot spare servers. On the other hand gradually increasing flash  crowds can be handled equally well with larger overheads and slower reaction times. We also show that even in the  presence of large allocation overhead it is possible to achieve the same application performance by either allocating  multiple servers simultaneously or allocating a few servers often. Using our results we conclude that even without  large-scale over-provisioning it is possible to effectively handle flash crowd conditions using a dynamic allocation  scheme that responds quickly to workload changes and that can mask large allocation ove...,10.1.1.1.3014,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,ALPHA/Sim is a general-purpose discrete-event simulation tool. ALPHA/Sim allows a user to graphically build a simulation model enter input data via integrated forms execute the simulation model and view the simulation results within a single graphical environment. In this paper we introduce ALPHA/Sim and describe how to use ALPHA/Sim to build simulate and analyze a simple manufacturing system. In addition we briefly describe some advanced features and list some sample applications.,10.1.1.1.3015,?,?
SiGe Prototype Chip Design Implementing CMOS Fixed Bit-Load Drivers and Receivers,For Next Generation Jason D. Bakos Amit Gupta Leo Salavo Donald Chiarulli,2004,We present our design and simulation results for a test chip that implements fixed bit-load drivers and receivers. The link architecture that is formed using these circuits offers several improvements over differential (LVDSstandard) links including a substantial decrease in die area and power consumption. These designs were fabricated as part of a multi-project die in IBMs .5um 5HP SiGe process.,10.1.1.1.3016,?,?
A Novel Protocol for Cooperative Diversity in Wireless Networks,Ernesto Zimmermann  Patrick Herhold Gerhard Fettweis,2004,Recently cooperative diversity has emerged as a means of providing gains from spatial diversity to devices with single antennas. Yet the performance of these protocols remains limited in symmetric networks. In this paper we investigate the performance of a novel detached cooperative diversity protocol that is designed for asymmetric networks both in terms of outage probability and frame error rate. The influence of data rate path loss and network geometry on the performance of the proposed protocol is studied and the usage region in which cooperative schemes outperform direct transmission is derived.,10.1.1.1.3017,?,?
Trajectory Based Forwarding and Its Applications,Dragos Niculescu Badri Nath,2002,Trajectory based forwarding (TBF) is a novel method to forward packets in a dense ad hoc network that  makes it possible to route a packet along a predefined curve. It is a generalization of source based routing  and Cartesian forwarding in that the trajectory is set by the source but the forwarding decision is based on  the relationship to the trajectory rather than the final destination. The fundamental aspect of TBF is that it  decouples path naming from the actual path thereby providing a common framework for applications such as:  flooding unicast multicast and multipath routing and discovery in ad hoc networks. TBF requires that nodes  know their position relative to a coordinate system. While a global coordinate system a#orded by a system  such as GPS would be ideal in this paper we propose Local Positioning System (LPS) a method that only  positions the nodes along the trajectory by making use of other node capabilities such as angle of arrival or  range estimations compasses and accelerometers. We explore several forwarding strategies that are appropriate  for these node capabilities.,10.1.1.1.3020,trajectory forwarding routing flooding discovery positioning local positioning system,?
The Optimal Group Size In Computer Mediated,Communica Ti On,?,Several researchers in the area of CMC (Computer Mediated Communication) have proposed that the optimal group size is different and larger in non-same time written computer mediated communication than in face-to-face communication. Below is two sections from my book Electronic mail which discusses this effect and its causes. Important in the sections is that this is not only an efficiency factor but also and very importantly a psychological factor.,10.1.1.1.3021,?,?
Performance Analysis of TDMA MAC Schemes for Ad-Hoc Networks with Topology Control,Konstantinos Oikonomou Nikos Pronios Ioannis Stavrakakis Senior Member,2004,Traditional omni-directional antennas result in increased mutliuser interference and are known to limit the performance of Medium Access Control (MAC) protocols for ad-hoc networks. Topology control is the capability of a node to control the set of neighbor nodes and in this paper the impact of using smart antennas and/or power control for topology control is investigated. The performance of TDMA MAC schemes with common frame for which the assignment of time slots to a node is not aware of the time slots assigned to the neighbor nodes (topology-unaware schemes like the Deterministic Policy and the Probabilistic Policy) is studied as well. A comparison based on analytical models reveals the advantages of topology control as well as its dependence on the mobility of the nodes and its resolution.Itis  shown that topology control with high resolution in highly mobile environments may not be effective and conditions are established under which topology control is beneficial. Simulation results for a variety of network topologies support the claims and the expectations of the aforementioned analysis and show that the system throughput achieved under topology control can be higher under both policies and especially under the Probabilistic Policy. Simulation results also show how mobility affects system throughput and that topology control may not be suitable for highly mobile environments.,10.1.1.1.3022,Index Terms — Ad-Hoc TDMA MAC Topology Control,?
Dynamic Resource Allocation for Shared Data Centers Using Online Measurements,Abhishek Chandra Weibo Gong Prashant Shenoy,2003,Since web workloads are known to vary dynamically with time in this  paper we argue that dynamic resource allocation techniques are necessary to provide  guarantees to web applications running on shared data centers. To address  this issue we use a system architecture that combines online measurements with  prediction and resource allocation techniques. To capture the transient behavior  of the application workloads we model a server resource using a time-domain  description of a generalized processor sharing (GPS) server. This model relates  application resource requirements to their dynamically changing workload characteristics.,10.1.1.1.3023,?,?
Modelling and Performance Evaluation of Optical Burst Switched Networks with Deflection Routing and Wavelength Reservation,Andrew Zalesky  Hai Le Vu Zvi Rosberg  Eric W. M. Wong Moshe Zukerman Arc Special,2004,Methods to resolve wavelength contention are needed to improve the performance of optical burst switched (OBS) networks. Network simulations and Markovian queuing models for nodes in isolation have suggested that deflection routing (alternate routing) may be a viable method to resolve wavelength contention. However we show that deflection routing may destabilise OBS networks operating at high loads. To prevent the destabilising effect of deflection routing we propose and analyse a technique called wavelength reservation to intentionally limit the amount of deflection at high loads. Wavelength reservation is analogous to trunk reservation in circuit switched networks. This paper is the first to present a new reduced load Erlang fixed point analysis of OBS networks with deflection routing and wavelength reservation. We apply the new analysis to evaluate the benefit of deploying deflection routing and wavelength reservation in a sample OBS network.,10.1.1.1.3024,?,?
Manipulating Temporal Dependencies In Compressed Video Data With Applications To Compressed-Domain Processing Of MPEG Video,Susie J. Wee,1999,The ability to manipulate the temporal dependencies in coded video data is important for a number of compresseddomain video processing tasks. This paper formulates the general problem and examines it in the context of MPEG. This is used to develop a method for performing frame conversions in MPEG coded video data. These frame conversions are used to develop compressed-domain video processing algorithms for performing temporal mode conversion frame-by-frame reverse play and frame-accurate splicing.,10.1.1.1.3025,?,?
Comparing Strength of Locality of Reference - Popularity majorization and some folk theorems,Sarut Vanichpun  Armand M. Makowski,2004,The performance of demand-driven caching depends on the locality of reference exhibited by the stream of requests made to the cache. In particular it is expected that the stronger the locality of reference the smaller the miss rate of the cache. For the Independent Reference Model this amounts to a smaller miss rate when the popularity distribution of requested objects in the stream is more skewed. In this paper we formalize this folk theorem through the companion concepts of majorization and Schur-concavity. This folk theorem is established for caches operating under a Random On-demand Replacement Algorithm (RORA). However the result fails to hold in general under the (popular) LRU and CLIMB policies but can be established when the input has a Zipf-like popularity pmf with large skewness parameter. In addition we explore how the majorization of popularity distributions translates into comparisons of three well-known locality of reference metrics namely the inter-reference time the working set size and the stack distance.,10.1.1.1.3026,?,?
The Role of Planning in Grid Computing,Jim Blythe Ewa Deelman  Yolanda Gil Carl Kesselman Amit Agarwal Gaurang Mehta Karan Vahi,2003,?,10.1.1.1.3027,?,?
 Capacity of Rayleigh Fading Channels under Different Adaptive Transmission and . . . ,Mohamed-Slim Alouini Andrea J. Goldsmith,1999,We study the Shannon capacity of adaptive transmission techniques in conjunction with diversity combining. This capacity provides an upper bound on spectral efficiency using these techniques. We obtain closed-form solutions for the Rayleigh fading channel capacity under three adaptive policies: optimal power and rate adaptation constant power with optimal rate adaptation and channel inversion with fixed rate. Optimal power and rate adaptation yields a small increase in capacity over just rate adaptation and this increase diminishes as the average received carrier-to-noise ratio (CNR) or the number of diversity branches increases. Channel inversion suffers the largest capacity penalty relative to the optimal technique however the penalty diminishes with increased diversity. Although diversity yields large capacity gains for all the techniques the gain is most pronounced with channel inversion. For example the capacity using channel inversion with two-branch diversity exceeds that of a single-branch system using optimal rate and power adaptation. Since channel inversion is the least complex scheme to implement there is a tradeoff between complexity and capacity for the various adaptation methods and diversity-combining techniques. ,10.1.1.1.3028,?,?
Modeling the Impact of Device and Pipeline Scaling on the Soft Error Rate of Processor Elements,Premkishore Shivakumar  Stephen W. Keckler Doug Burger  Michael Kistler Lorenzo Alvisi,2002,This paper examines the effect of technology scaling and microarchitectural trends on the rate of soft errors in CMOS memory and logic circuits. We describe and validate an end-to-end model that enables us to compute the soft error rates (SER) for existing and future microprocessor-style designs. The model captures the effects of two important masking phenomena electrical masking and latching-window masking which inhibit soft errors in combinational logic. We quantify the SER due to high-energy neutrons in SRAM cells latches and logic circuits for feature sizes from 600nm to 50nm and clock periods from 16 to 6 fan-out-of-4 inverter delays. Our model predicts that the SER per chip of logic circuits will increase nine orders of magnitude from 1992 to 2011 and at that point will be comparable to the SER per chip of unprotected memory elements. Our result emphasizes that computer system designers must address the risks of soft errors in logic circuits for future designs.,10.1.1.1.3029,?,?
SCULPTEUR: Multimedia Retrieval for Museums,Simon Goodall Paul H. Lewis Kirk Martinez Patrick A. S. Sinclair  Fabrizio Giorgini Matthew J. Addis Mike J. Boniface  Christian Lahanier  James Stevenson,?,The paper describes the prototype design and development  of a multimedia system for museums and galleries. Key elements in the  system are the introduction of 3-D models of museum artefacts together  with 3-D as well as 2-D content based retrieval and navigation facilities  and the development of a semantic layer centred on an ontology  for museums which aims to expose the richness of knowledge associated  with the museum collections and facilitate concept based retrieval and  navigation integrated with that based on content and metadata. Interoperability  protocols are designed to allow external applications to access  the collection and an example is given of an e-Learning facility which  uses models extracted to a virtual museum.,10.1.1.1.3030,?,?
Segmentation of Vessels: The Corkscrew Algorithm,Stefan Wesarg Evelyn A. Firle,2004,Medical imaging is nowadays much more than only providing data for diagnosis. It also links `classical diagnosis to modern forms of treatment such as image guided surgery. Those systems require the identification of organs anatomical regions of the human body etc. i. e. the segmentation of structures from medical data sets. The algorithms used for these segmentation tasks strongly depend on the object to be segmented.,10.1.1.1.3031,Segmentation vessel extraction medical imaging computed tomography cardiology coronary arteries,?
Linear Combiners for Classifier Fusion: Some Theoretical and Experimental Results,Giorgio Fumera Fabio Roli,2003,In this paper we continue the theoretical and experimental analysis  of two widely used combining rules namely the simple and weighted average  of classifier outputs that we started in previous works. We analyse and  compare the conditions which affect the performance improvement achievable  by weighted average over simple average and over individual classifiers under  the assumption of unbiased and uncorrelated estimation errors. Although our  theoretical results have been obtained under strict assumptions the reported  experiments show that they can be useful in real applications for designing  multiple classifier systems based on linear combiners.,10.1.1.1.3033,?,Springer
Diagnosis as Semiring-based Constraint Optimization,Martin Sachenbacher   Brian Williams,2004,Constraint optimization is at the core of many problems in Artificial Intelligence. In this paper we frame model-based diagnosis as a constraint optimization problem over lattices. We then show how it can be captured in a framework for soft constraints known as semiring-CSPs. The well-defined mathematical properties of a semiring-CSP allow to devise efficient solution methods that are based on decomposing diagnostic problems into trees and applying dynamic programming. We relate the approach to SAB and TREE* two diagnosis algorithms for tree-structured systems which correspond to special cases of semiring-based constraint optimization.,10.1.1.1.3034,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice David Bauer Garrett Yaun Christopher D. Carothers,?,research: network modeling simulation measurement and protocol design. ROSS.Net is a tool for computing large scale design of experiments through components such as a discrete-event simulation engine default and extensible model designs and a state of the art XML interface. ROSS.Net reads in predefined descriptions of network topologies and traffic scenarios which allows for in-depth analysis and insight into emerging feature interactions cascading failures and protocol stability in a variety of situations. Developers will be able to design and implement their own protocol designs network topologies and modeling scenarios as well as implement existing platforms within the ROSS.Net platform. Also using ROSS.Net designers are able to create experiments with varying levels of granularity allowing for the highest-degree of scalability.,10.1.1.1.3035,?,?
Observations of the Marinov Motor,Thomas E. Phipps  Jr.,2001,this paper we shall first apply the basic theoretical torque formula obtained by Wesley     without repeating his derivation of that result. The purpose will be to suggest some of the range of variations possible in the basic design of the resulting new class of motors. Then some experiments I did to test the torque formula will be described. No attempt will be made here to analyze specific embodiments of the Marinov motor---but any reader with engineering leanings will be able to fill-in that part of the story,10.1.1.1.3036,?,?
On the Feasibility of Peer-to-Peer Web Indexing and Search,Jinyang Li   Boon Thau Loo  Joseph M. Hellerstein M. Frans Kaashoek et al.,2003,This paper discusses the feasibility of peer-to-peer full-text keyword search of the Web. Two classes of keyword search techniques are in use or have been proposed: flooding of queries over an overlay network (as in Gnutella) and intersection of index lists stored in a distributed hash table. We present a simple feasibility analysis based on the resource constraints and search workload. Our study suggests that the peer-to-peer network does not have enough capacity to make naive use of either of search techniques attractive for Web search. The paper presents a number of existing and novel optimizations for P2P search based on distributed hash tables estimates their effects on performance and concludes that in combination these optimizations would bring the problem to within an order of magnitude of feasibility. The paper suggests a number of compromises that might achieve the last order of magnitude.,10.1.1.1.3037,?,?
An Automatic Weighting Scheme for Collaborative Filtering,Rong Jin  Joyce Y. Chai  Luo Si,2004,Collaborative filtering identifies information interest of a particular user based on the information provided by other similar users. The memory-based approaches for collaborative filtering (e.g. Pearson correlation coefficient approach) identify the similarity between two users by comparing their ratings on a set of items. In these approaches different items are weighted either equally or by some predefined functions. The impact of rating discrepancies among different users has not been taken into consideration. For example an item that is highly favored by most users should have a smaller impact on the user-similarity than an item for which different types of users tend to give different ratings. Even though simple weighting methods such as variance weighting try to address this problem empirical studies have shown that they are ineffective in improving the performance of collaborative filtering. In this paper we present an optimization algorithm to automatically compute the weights for different items based on their ratings from training users. More specifically the new weighting scheme will create a clustered distribution for user vectors in the item space by bringing users of similar interests closer and separating users of different interests more distant. Empirical studies over two datasets have shown that our new weighting scheme substantially improves the performance of the Pearson correlation coefficient method for collaborative filtering.,10.1.1.1.3038,memory-based approach leave one out method item,ACM Press
Spatial Fluctuation of the,Hubble Constant Jean-Claude Jean-claude Pecker Jean-pierre Vigier Toivo Jaakkola,2001,This article was written in 1975 and has remained unpublished until now,10.1.1.1.3039,?,?
Effectiveness of Keyword-Based Display and Selection,Of Retrieval Results Ezio Berenci Claudio Carpineto Vittorio Giannini Stefano Mizzaro,1999,We present an approach to increasing the effectiveness of ranked-output retrieval systems that relies on graphical display and user manipulation of views of retrieval results where a view is the subset of retrieved documents that contain a specified subset of query terms. This approach has been implemented in a system named VIEWER (VIEwing WEb Results) acting as an interface to available search engines. An experimental evaluation of the performance of VIEWER in contrast to AltaVista is the major focus of the paper. We first report the results of an experiment on single short query searches where VIEWER used as an interactive ranking system markedly outperformed AltaVista. We then concentrate on a more realistic searching scenario involving free query formulation unconstrained selection of retrieval results and possibility of query reformulation. We report the results of an experiment where the use of VIEWER compared to AltaVista seemed to shift the user effort from inspection to evaluation of results increasing retrieval effectiveness and user satisfaction. In particular we found that the VIEWER users retrieved half as many nonrelevant documents as the AltaVista users while retrieving a comparable number of relevant documents.,10.1.1.1.3040,?,?
On the Benefit of Tunability in Reducing Electronic Port Counts in WDM/TDM Networks,Randall Berry Eytan Modiano,2004,Abstract — In this paper we study the benefits of using tunable transceivers for reducing the required number of electronic ports in WDM/TDM networks. We show that such transceivers can be used to efficiently “groom ” sub-wavelength traffic in the optical domain and so can significantly reduce the number of electronic ports compared to the fixed tuned case. We provide a new formulation for this “tunable grooming ” problem. We show that in general this problem is NP-complete but we are able to efficiently solve it for many cases of interest. When the number of wavelengths in the network is not limited we show that each node only needs the minimum number of transceivers (i.e. no more transceivers than the amount of traffic that it generates). This holds regardless of the network topology or traffic pattern. When the number of wavelengths is limited we show an analogous result for both uniform and hub traffic in a ring. We also develop a heuristic algorithm for general traffic that uses nearly the minimum number of transceivers. In most cases tunable transceivers are shown to reduce the number of ports per node by as much as 60%. I.,10.1.1.1.3041,?,?
EPTD DISCUSSION PAPER NO. 39 TECHNOLOGICAL CHANGE TECHNICAL AND ALLOCATIVE EFFICIENCY IN CHINESE AGRICULTURE: THE CASE OF RICE PRODUCTION IN JIANGSU,Shenggen Fan,?,This paper develops a frontier shadow cost function approach to estimate empirically the effects of technological change technical and allocative efficiency improvement in Chinese agriculture during the reform period (1980-93). The results reveal that the first phase rural reforms (1979-84) which focused on the decentralization of the production system have had significant impact on technical efficiency but not allocative efficiency. During the second phase reforms which was supposed to focus on the liberalization of rural markets technical efficiency improved very little and allocative efficiency has increased only slightly however. In contrast the rate of technological change continued to increase although at a declining rate during the second phase reform. CONTENTS  1. ,10.1.1.1.3042,CONTENTS,?
An open distributed measurement system based on abstract client-server architecture,O Pianegiani David Macii Paolo Carbone F. Pianegiani D. Macii P. Carbone,2003,CLIENT-SERVER PARADIGMS  Fernando Pianegiani David Macii Paolo Carbone  April 2004  Technical Report # DIT-04-049  .,10.1.1.1.3043,Java distributed measurement system client-server,?
A Parallel Implementation of the Nonsymmetric QR Algorithm for Distributed Memory Architectures,Greg Henry David Watkins Jack Dongarra,2002,One approach to solving the nonsymmetric eigenvalue problem in parallel is to parallelize the QR algorithm. Not long ago this was widely considered to be a hopeless task. Recent efforts have led to significant advances although the methods proposed up to now have suffered from scalability problems. This paper discusses an approach to parallelizingthe QR algorithm that greatly improves scalability. A theoretical analysis indicates that the algorithm is ultimately not scalable but the nonscalability does not become evident until the matrix dimension is enormous. Experiments on the Intel Paragon system the IBM SP2 supercomputer the SGI Origin 2000 and the Intel ASCI Option Red supercomputer are reported.,10.1.1.1.3044,Key words. parallel computing eigenvalue Schur decomposition QR algorithm,?
On Robust Monetary Policy with Structural Uncertainty - Discussion of John C. Williams Robust Estimation and Monetary Policy with Unobserved Structural Change,See Hansen Francis X . Diebold,2004,plied challenge. That is realistic monetary policy environments may involve deviations from model certainty best characterized as global rather than local so that naive implementations and interpretations of robust control may promote an inappropriate complacency -- a feeling that the robustness problem has been fully solved and t hat monetary policy is now robust to mode l uncer tainty. 2. How Robust is Robust Control? Over the years we have made progress in acknowledging various forms of uncertainty in control environments: (1) Initially we acknowledged only parameter uncertainty that is we assumed the true model known but acknowledged that its parameters were estimated. (2) Next we acknowledged both model and parameter uncertainty we assumed the true model unknown but a member of a well-defined set and we acknowledged that the fitted models parameters were estimated. (3) Most recently -- in the present paper -- Williams treats model uncertainty parameter uncertainty an,10.1.1.1.3045,?,?
Towards Perceptually Realistic Talking Heads: Models Methods and,Mcgurk Darren Cosker Darren Cosker Susan Paddock David Marshall Paul L. Rosin,2004,Motivated by the need for an informative unbiased and quantitative perceptual method for the development and evaluation of a talking head we are developing we propose a new test based on the McGurk Effect. Our approach helps to identify strengths and weaknesses in underlying talking head algorithms and uses this insight to guide further development. The test also evaluates the realism of talking head behavior in comparison to real speaker footage painting an overall picture of a talking heads performance. By distracting a participants attention away from the true nature of the test we also obtain an unbiased view on talking head performance - since the participants prior concerning what is synthetic animation and what is real footage is not encouraged to develop.,10.1.1.1.3047,? D.P.Cosker Dave.Marshall,?
DNA-mediated artificial nanobiostructures: state of the art and future directions,R. Bashir,2001,This paper describes  the motivations and fundamentals behind these assembly concepts with a focus on DNA  hybridization-mediated assembly and presents the state of the art in this field. In addition  new ideas and directions for future research on DNA-mediated assembly of active devices  and DNA-based molecular devices are also presented,10.1.1.1.3048,?,?
Distributed STDMA in Ad Hoc Networks,Jimmi Grönkvist,?,Spatial reuse TDMA is a collision-free access scheme for ad hoc networks. The idea is to let spatially separated radio terminals reuse the same time slot when the resulting interferences are not too severe. In this paper we describe the properties a distributed STDMA algorithm must have to be efficient and describe the first step towards such an algorithm. Furthermore we evaluate this first step and show that it can give the same capacity as a a centralized reference algorithm.,10.1.1.1.3049,?,?
The 1998 Floods in Bangladesh - Disaster Impacts Household Coping Strategies and Response,Carlo Del Ninno Paul A. Dorosh Lisa C. Smith Dilip K. Roy Figures Ix,?,this report may be reproduced without the express  permission of but with acknowledgment to the International Food Policy Research Institute,10.1.1.1.3050,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,Several recent research efforts in visualizing construction are rooted in scheduling. They involve linking activitybased construction schedules and 3D CAD models of facilities to describe discretely-evolving construction product  visualizations called 4D CAD. The focus is on communicating what component(s) are built where and when. The construction processes or operations actually involved in building them are usually implied. Ongoing research at Virginia Tech focuses on designing automated simulationdriven methods to visualize in addition to evolving construction products the operations and processes that are performed in building them. In addition to what is built where and when the effort is concerned with visualizing who builds it and how by depicting the interaction between involved machines resources and materials. This paper expounds the differences in concept form and content between 4D CAD and dynamic 3D visualization of operations simulations. An example of a structural steel framing operation is presented to elucidate the comparison.,10.1.1.1.3051,?,?
MCMC data association algorithm applied to the French Over-The-Horizon Radar Nostradamus,David Bourgeois Christèle Morisseau Marc Flécheux,?,Over-The-Horizon(OTH) Radars provide a survey of wide areas using ionospheric reflections of the electromagnetic waves. Most of the time they have to face multipath problems: state estimation has to be done with measurements involving different observation models. To tackle this measurement-toobservation -model association problem the Monte Carlo Data Association (MCDA) algorithm and a derivative one the Iterated Conditional Mode Data Association (ICMDA) have been developed. They only applied in linear context. We propose new versions of these algorithms well adapted to non-linear problems. Our two algorithms are applied through numerical simulations to a concrete case: target tracking with the French OTH radar Nostradamus in clutter environment.,10.1.1.1.3052,?,?
A Study Case of Opportunistic Multihop,Communication Using Mobile,?,In this paper a sparse infrastructure relying on the mobility of multihops capable nodes is addressed. The performances in terms of relative delay to deliver a message maximum memory occupation and number of hops are presented for non delay sensitive services and with simple model of traffic and mobility.,10.1.1.1.3053,?,?
XML to Manage Source Engineering in Object-Oriented Development: an Example,Daniel Deveaux  Yves Le Traon Université De Bretagne Sud,2001,In software engineering XML to date has mostly been used to support three sub-activities: documentation management data interchange and lightweight data storage. In this position paper we give an example of using XML technology as the infrastructure for the integrated management of all core software development information.,10.1.1.1.3054,process testing and test tools,?
Weakly Useful Sequences,Stephen A. Fenner   Jack H. Lutz Elvira Mayordomo Patrick Reardon,2004,An infinite binary sequence x is defined to be (i) strongly useful if there is a computable time bound within which every decidable sequence is Turing reducible to x and (ii) weakly useful if there is a computable time bound within which all the sequences in a non-measure 0 subset of the set of decidable sequences are Turing reducible to x. Juedes,10.1.1.1.3055,?,?
Heuristic-Based Backtracking for Propositional Satisfiability,A. Bhalla I. Lynce  J.T. de Sousa  J. Marques-Silva,?,In recent years backtrack search algorithms for Propositional  Satisfiability (SAT) have been the subject of dramatic improvements.,10.1.1.1.3056,?,?
Implementing Agent-based Web Services,Jonathan Dale  Luigi Ceccaroni  Zou  Y. y Agam  A.,2003,As part of the Agentcities project we have developed a prototype of an Evening Organiser application which allows users to flexibly and dynamically schedule activities within an itinerary. The Evening Organiser and the Web-accessible restaurant and cinema services which it uses have been developed within a generic service environment and the implementation of this has been built using the April Agent Platform the DAML+OIL ontology language the DAML Query Language and the Java Theorem Prover. This service environment is populated with agents of different natures such as service instances and service finders. Service instances represent individual business entities such as restaurants and cinemas. Service finders represent aggregated views over service instances such as Yahoo!-hosted restaurants or Citysearch-hosted cinemas. The details of the implementation of these Web Services are described through the use of a motivating scenario.,10.1.1.1.3057,General Terms Algorithms Design Implementation Experimentation Languages. Keywords Agents Ontologies Agentcities FIPA DAML+OIL Web Services April,?
Reading Errors Made By Skilled and Unskilled Readers: Evaluating a System That Generates Reports for People With Poor Literacy,Sandra Williams Ehud Reiter,?,We describe part of an evaluation of a natural language generation system that generates literacy assessment reports for adults with poor basic skills. Research was focused on how to generate more readable documents. To evaluate readability of the systems output we previously measured comprehension and reading speed. Here we describe a post-hoc investigation where we measured reading errors and disfluencies. The aim was to find out if modifications the system makes for readability resulted in less errors and disfluencies when the output was read aloud. We found that poor readers make less substitution errors on reports generated using readability preference rules. ,10.1.1.1.3058,?,?
Fundamental Protocols for Wireless Sensor Networks,Raghuvel S. Bhuvaneswaran Jacir L. Bordim Jiangtao Cui Koji Nakano,2001,The main contribution of this work is to present energyefficient protocols that compute the sum of n numbers over any commutative and associative binary operator stored in n wireless sensor nodes arranged in a two-dimensional grid # n. We first present a protocol that computes the sum in O(r      3 ) time slots with no sensor node being awake for more than O(1) time slots where r is the transmission range of the sensor nodes. We then show a fault-tolerant protocol that computes the sum in the same number of time slots with no sensor node being awake for more than O(log r) time slots.,10.1.1.1.3059,?,?
The Role of Concept Management in System Development - A practical and a theoretical perspective,A. I. Bleeker H. A. Proper  S.J.B.A. Hoppenbrouwers,2004,In this article we argue the need for proper concept management during the  development of software systems. It is observed how during system development a lot of  concept handling occurs without proper management. We define concept management  as the deliberate activity of introducing evolving and retiring concepts. It is argued that  concept management plays an important role during the entire system development life  cycle.,10.1.1.1.3061,?,?
Stratified Rough Sets And Vagueness,Thomas Bittner John G. Stell,2003,The relationship between less detailed and more detailed versions of data is one of the major issues in processing geographic information. Fundamental to much work in model-oriented generalization also called semantic generalization is the notion of an equivalence relation. Given an equivalence relation on a set the techniques of rough set theory can be applied to give generalized descriptions of subsets of the original set. The notion of equivalence relation or partition has recently been significantly extended by the introduction of the notion of a granular partition. A granular partition provides what may be thought of as a hierarchical family of partial equivalence relations. In this paper we show how the mechanisms for making rough descriptions with respect to an equivalence relation can be extended to give rough descriptions with respect to a granular partition. In order to do this we also show how some of the theory of granular partitions can be reformulated this clarifies the connections between equivalence relations and granular partitions. With the help of this correspondence we then can show how the notion of hierarchical systems of partial equivalence classes relates to partitions of partial sets i.e. partitions of sets in which not all members are known. This gives us new insight into the relationships between roughness and vagueness. 1 ,10.1.1.1.3062,?,Springer
Methods for the Semantic Analysis of Document Markup,Petra Saskia Bayerl Harald Lüngen Daniela Goecke Andreas Witt Universität Bielefeld,?,We present an approach on how to investigate what kind of semantic information is regularly associated with the structural markup of scientific articles. This approach addresses the need for an explicit formal description of the semantics of text-oriented XML-documents. The domain of our investigation is a corpus of scientific articles from psychology and linguistics from both English and German online available journals.,10.1.1.1.3063,Theory Experimentation Keywords XML Semantic Analysis Prolog Information Extraction,?
Practical Mobile Robot Self-Localization,Jon Howell   Bruce Randall Donald,?,A mapmaking robot integrates accumulated sensor data into a data structure that can be used for future localization or planning operations. Localization is the process of determining the robots location within its environment. This paper describes experiments in which a robot simultaneously makes a map and localizes to that map. The map is a collection of tangent vectors constructed from stored sonar readings localized to a series of estimated poses. The vectors retain sensed surface normal information to improve accuracy. The localization scheme is a Hough transform into a space described by the robots current sonar scan. The Hough transform finds a best fit in the presence of both sporadic sensor noise and discretization error.,10.1.1.1.3064,?,IEEE Press
Extending Content-based Publish/Subscribe Systems with Multicast Support,Viktor S. Wold Eide Frank Eliassen Olav Lysne Ole-christoffer Granmo,2003,Event-based interaction is recognized as being well suited for loosely coupled distributed  applications. Current distributed content-based event notifications services are often architectured  to operate over WANs (wide area networks). Additionally one to one transport layer  communication primitives are used. As a result these services are not suitable for (parts of)  applications having a combination of high event notification rates and locally a large number  of interested parties for the same event notifications.,10.1.1.1.3066,?,?
Automatically Finding Good Clusters with Seed K-Means,Miyoung Shin  Eun Mi Kang  Seon Hee Park Kang Seon Hee Park,2003,Introduction  In finding biologically relevant groups of genes with gene expression data obtained by microarray technologies the k-means clustering method is one of the most popular approaches due to its easiness to use and simplicity to implement. However the randomness of k-means clustering method in choosing initial points to start with makes it impossible to obtain reliable results without much iteration of the entire clustering process [2]. Our goal here is to introduce a novel clustering method which we call it seed k-means clustering where a novel algorithm is employed to automatically find good initial seeds for k-means clustering.  2 Seed K-Means Clustering Method and Its Evaluation  2.1 Clustering Algorithm  The seed k-means clustering method is basically a two-phase process: seed extraction and cluster generation. Given the number of clusters k the first phase of seed extraction is to automatically select k good initial seeds of genes by analyzing their expression patt,10.1.1.1.3067,gene expression data analysis k-means clustering seed extraction,?
Real-World Problems of PKI Hierarchy,Daniel Cvrcek,?,This paper demons ra es ha he use of publ)4 key cryp ography is no easy and i is very difficul   o perform he above-men ioned ac ions in a way sa isfying some predefined securi y lsGLG4 The reason is in he compl(j y of   he probljL4  We are no   general--G able  o ensure he usage of sys ems abls o work wi h al( exis ing al s( hms key ly hs and forma s in he wholM publMM key infras ruc ure. Al.   some peopls0----)----s  he opinion ha   X.509 as a basis for PKI is obsol  e,10.1.1.1.3068,?,?
Eur. Phys. J. B 35 117--123 (2003),Doi Epjb The R. V. Solé A,?,The dynamics of cancer evolution is studied by means of a simple quasispecies model involving  cells displaying high levels of genetic instability. Both continuous mean-field and discrete bit-string models  are analysed. The string model is simulated on a single-peak landscape. It is shown that a phase transition  exists at high levels of genetic instability thus separating two phases of slow and rapid growth. The results  suggest that under a conserved level of genetic instability the cancer cell population will be close to the  threshold level. Implications for therapy are outlined.,10.1.1.1.3069,?,?
A Scalable Solution for Integrating Illustrated Parts Drawings into a Class IV,Interactive Electronic Technical Molly L. Boose David B. Shema Lawrence S. Baum,?,This paper discusses a scalable solution for integrating legacy illustrated parts drawings into a Class IV Interactive Electronic Technical Manual (IETM) [12]. An IETM is an interactive electronic version of a systems technical manuals such as for a commercial airplane or a military helicopter. It contains the information a technician needs to do her job including troubleshooting vehicle maintenance and repair procedures. A Class IV IETM is an IETM that is authored and managed directly via a database. The enduser system optimizes viewing and navigation minimizing the need for users to browse and search through large volumes of data.,10.1.1.1.3070,?,?
On the Relationship between Linear Programming Decoding and Min-Sum Algorithm Decoding,Pascal Vontobel  Ralf Koetter,2004,We are interested in the characterization of the decision regions when decoding a low-density parity-check code with the min-sum algorithm. Observations made in [1] and experimental evidence suggest that these decision regions are tightly related to the decision regions obtained when decoding the code with the linear programming decoder. We introduce a family of quadratic programming decoders that aims at explaining this behavior. Moreover we also point out connections to electrical networks.,10.1.1.1.3071,?,?
A Neuro-Fuzzy Approach as Medical Diagnostic Interface,R. Brause  F. Friedrich,2000,this paper. It is especially  useful in medical applications using the notation and habits of physicians  and other medically trained people. As an example a liver disease  diagnosis system is presented,10.1.1.1.3072,?,?
Representation and Reasoning for DAML-Based Policy and Domain Services in KAoS and Nomads,J. Bradshaw A. Uszok  R. Jeffers N. Suri  P. Hayes M. Burstein A. Acquisti  B. Benyo  M. Breedy M. Carvalho  D. Diller M. Johnson  S. S. Kulkarni J. Lott M. Sierhuis R. Van Hoof,2003,To increase the assurance with which agents can be deployed in operational settings we have been developing the KAoS policy and domain services. In conjunction with Nomads strong mobility and safe execution features KAoS services and tools allow for the specification management conflict resolution and enforcement of DAML-based policies within the specific contexts established by complex organizational structures. In this paper we will discuss results issues and lessons learned in the development of these representations tools and services and their use in military and space applications  Keywords  social order conventions norms social control cultural norms and institutions ontologies for agents and social modeling ontologies in agent-based information systems and knowledge management DAML policy domains KAoS Nomads human-agent teamwork adjustable autonomy coalition augmented cognition cognitive prosthesis  1. ,10.1.1.1.3073,coalition,Press
Direct Anisotropic Quad-Dominant Remeshing,Martin Marinov Leif,2004,We present an extension of the anisotropic polygonal remeshing technique developed by Alliez et al. Our algorithm does not rely on a global parameterization of the mesh and therefore is applicable to arbitrary genus surfaces. We show how to exploit the structure of the original mesh in order to perform efficiently the proximity queries required in the line integration phase thus improving dramatically the scalability and the performance of the original algorithm. Finally we propose a novel technique for producing conforming quad-dominant meshes in isotropic regions as well by propagating directional information from the anisotropic regions.,10.1.1.1.3074,?,?
Retiming Sequential Circuits for Low Power,Jose Monteiro Srinivas José Monteiro Srinivas Devadas,1993,Switching activity is the primary cause of power dissipation in CMOS combinational and sequential circuits. We give a method of estimating power in pipelined sequential CMOS circuits that accurately models the correlation between the vectors applied to the combinational logic of the circuit.,10.1.1.1.3075,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,Certifying that a large-scale complex modeling and simulation (MS) application can be used for a set of specific purposes is an onerous task which involves complex evaluation processes throughout the entire MS development life cycle. The evaluation processes consist of verification and validation activities quality assurance assessment of qualitative and quantitative elements assessments by subject matter experts and integration of disparate measurements and assessments. Planning managing and conducting the evaluation processes require a disciplined life-cycle approach and should not be performed in an ad hoc manner. The purpose of this tutorial paper is to present structured evaluation processes throughout the entire MS development life cycle. Engineers analysts and managers can execute the evaluation processes presented herein to be able to formulate a certification decision for a large-scale complex MS application.,10.1.1.1.3076,?,?
Combination of Type III Digit Recognizers using the Dempster-Shafer Theory of,Evidence Catalin Tomai Catalin I. Tomai Sargur N. Srihari,2003,We investigate the combination of Type-III classifiers using the Dempster-Shafer Theory of Evidence. Various methods of building BPAs for each classifier using both global and local classifier information are explored. We propose modifications to two established BPAcomputation methods to make them better suited for combining Type-III classifiers. We also show the effectiveness of using compound hypotheses when a classifier cannot confidently choose between the top two returned classes. Experimental tests demonstrate the superiority of some of the approaches proposed here on the numeral recognition problem when combining three different character recognizers with Type-III classification engines.,10.1.1.1.3077,?,?
Balanced Multiwavelets Theory and Design,Jérôme Lebrun Martin Vetterli,1998,This correspondence deals with multiwavelets which are a recent generalization of wavelets in the context of time-varying filter banks and with their applications to signal processing and especially compression. By their inherent structure multiwavelets are fit for processing multichannel signals. This is the main issue in which we will be interested here. The outline of the correspondence is as follows. First we will review material on multiwavelets and their links with multifilter banks and especially time-varying filter banks. Then we will have a close look at the problems encountered when using multiwavelets in applications and we will propose new solutions for the design of multiwavelets filter banks by introducing the so-called balanced multiwavelets.,10.1.1.1.3078,?,?
Tobias Scheer Universit de Nice,What Final Empty Tobias Scheer Université De Nice,?,inal consonants cannot belong to Codas in these languages. Since the mainstream interpretation cannot conceive of final consonants being an Onset it declares them extrasyllabic. Extrasyllabicity supposes that syllable structure is achieved through some syllabification algorithm and also that extrasyllabic items are reintegrated into the prosodic structure at some later derivational stage. This is the reason why nothing of that kind may exist in Government Phonology: strings are fully syllabified in the lexicon and there is no serialism. Hence if word-final consonants are no Codas they must belong to Onsets which in turn supposes the existence of a following empty Nucleus.  This move however dismisses the very simple fact that there are many segmental processes that affect both internal and final Codas alike and both internal and final closed syllables alike. For instance the same processes mentioned earlier l-vocalisation and closed syllable shortening are very often obse,10.1.1.1.3079,?,?
Context Sensitive Anomaly Monitoring of Process Control Flow To Detect Mimicry Attacks and Impossible Paths,Haizhi Xu  Wenliang Du Steve J. Chapin,2004,Many intrusions amplify rights or circumvent defenses by issuing system calls in ways that the original process did not. Defense against these attacks emphasizes preventing attacking code from being introduced to the system and detecting or preventing execution of the injected code. Another approach where this paper fits in is to assume that both injection and execution have occurred and to detect and prevent the executing code from subverting the target system. We propose a method using waypoints: marks along the normal execution path that a process must follow to successfully access operating system services. Waypoints actively log trustworthy context information as the program executes allowing our anomaly monitor to both monitor control flow and restrict system call permissions to conform to the legitimate needs of application functions. We describe our design and implementation of waypoints and present results showing that waypoint-based anomaly monitors can detect a subset of mimicry attacks and impossible paths.,10.1.1.1.3080,anomaly detection context sensitive waypoint control flow monitoring mimicry attacks impossible,Springer
Managing Intervals Efficiently in Object-Relational Databases,Hans-Peter Kriegel   Marco Pötke Thomas Seidl,2000,Modern database applications show a growing demand  for efficient and dynamic management of intervals  particularly for temporal and spatial data  or for constraint handling. Common approaches  require the augmentation of index structures  which however is not supported by existing relational  database systems. By design the new Relational  Interval Tree (RI-tree) employs built-in  indexes on an as-they-are basis and is easy to implement. Whereas,10.1.1.1.3081,?,?
Machine Learning in Computer Chess: Genetic Programmig and KRK,David Gleich,2003,In this paper I describe genetic programming as a machine learning paradigm and evaluate its results in attempting to learn basic chess rules. Genetic programming exploits a simulation of Darwinian evolution to construct programs. When applied to the King-Rook-King (KRK) chess endgame problem genetic programming shows promising results in spite of a lack of significant chess knowledge.,10.1.1.1.3082,?,?
Providing Multidatabase Access -- an Association Approach,Paolo Missier   Marek Rusinkiewicz Avi Silberschatz  ,1995,One of the major tasks in the design of a multidatabase system (MDBS) is the definition and  maintenance of the global schema. Traditionally this is accomplished by requiring the local  databases participating in the MDBS to provide export schemas that are merged into a global  schema. Resolution of schema and data incompatibilities and mapping between local and global  schemas are in general very difficult tasks that must be performed at the multidatabase level. We believe,10.1.1.1.3083,?,?
Constrained Coverage for Mobile Sensor Networks,Sameera Poduri Gaurav S. Sukhatme,2004,We consider the problem of self-deployment of a mobile sensor network. We are interested in a deployment strategy that maximizes the area coverage of the network with the constraint that each of the nodes has at least K neighbors where K is a user-specified parameter. We propose an algorithm based on artificial potential fields which is distributed scalable and does not require a prior map of the environment. Simulations establish that the resulting networks have the required degree with a high probability are well connected and achieve good coverage. We present analytical results for the coverage achievable by uniform random and symmetrically tiled network configurations and use these to evaluate the performance of our algorithm.,10.1.1.1.3084,?,?
Autonomous Characters in Virtual Environments: The technologies involved in artificial life and their affects of perceived intelligence and playability of computer games,Oliver Edward Wood,2004,Computer games are viewed by academics as un-grounded hack and patch experiments    . Academic artificial intelligence is often viewed as un-implementable  and narrow minded by the majority of non-AI programmer    .,10.1.1.1.3085,?,?
DGMonitor: a Performance Monitoring Tool for Sandbox-based Desktop Grid Platforms,P. Cicotti M. Taufer A. Chien,2004,Accurate continuous resource monitoring and profiling are critical for enabling performance tuning and scheduling optimization. In desktop grid systems that employ sandboxing these issues are challenging because (1) subjobs inside sandboxes are executed in a virtual computing environment and (2) the state of the virtual computing environment within the sandboxes is reset to empty after each subjob completes.,10.1.1.1.3086,Performance monitoring and profiling sandboxing techniques distributed,IEEE Computer Society
Cycle-true simulation of the ST10 microcontroller including the core and the,Peripherals Lovic Gauthier Lovic Gauthier Ahmed Amine Jerraya,?,With the rising complexity of electronic systems containing more and more both hardware and software parts it becomes necessary to simulate simultaneously hardware and software parts at whatever abstraction level. These simulation techniques called co-simulation require fast and flexible simulators. In this paper we introduce the elaboration of a microcontroller simulator including the core and the peripherals for an accurate hardware/software cosimulation at the clock-cycle level. It is our goal to have a simulator which is fast enough to simulate a few minutes of real time execution within a reasonable laps of time. To be more precise we deal here with the realization of a simulator for the ST10 microcontroller and its integration into a co-simulation environment. This paper gives our global approach and explains our techniques in detail. It also presents new tracks to obtain improved performances with this kind of simulators.,10.1.1.1.3087,?,?
Proceedings of the 2002 Winter Simulation Conference,E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,This paper describes the application of distributed discrete event simulation in the study of an automated container terminal. The new model was developed to continue the study of large and complex logistic systems. In a previous study a stand-alone model of the terminal was used that included all the characteristics of container handling between the ships and the container stack. A new distributed simulation model was developed by decomposing the original model into a distributed structure of communicating small sub models. It is shown that with relative little effort and hardly any programming overhead a complex stand-alone model can be decomposed into small easy to understand sub models. The new distributed structure improves the transparency and maintainability of the simulation model while guaranteeing the original benefits of the stand-alone model and the required reproducibility of the experiments.,10.1.1.1.3088,?,?
Towards context awareness using Symbol Clustering Map  ,J. Himberg J. A. Flanagan J. Mäntyjärvi,2003,Recognizing the context of use is important in making mobile devices simple to use. The device and the underlying mobile service can provide a personalized user interface that adapts to the usage situation. The device can infer parts of the context of the user from features extracted from on-board measurements of acceleration noise level luminosity humidity etc. In this paper we consider context recognition by fusing and clustering these context features using a recently introduced method the Symbol Clustering Map. As such it can be used for finding static patterns but a suitable transformation of the data allows identifying also temporal patterns.,10.1.1.1.3089,symbol clustering map mobile computing context awareness,?
Vascular Atlas Formation Using a Vessel-to-Image Affine Registration Method,Dini Chillet Julien Jomier Derek Cool Stephen R. Aylward,2003,We have developed a method for forming vascular atlases using vascular distance maps and a novel vascular model-to-image registration method. Our atlas formation process begins with MR or CT angiogram data from a set of subjects. We extract blood vessels from those data using our tubular object segmentation method. One subjects vascular network model is then chosen as a template and its vascular distance map (DM) image is computed. Each of the remaining vascular network models is then registered with the DM template using our vascular model-to-image a#ne registration method. The DM images from the registered vascular models are then computed. The mean and variance images formed from those registered DM images are the vascular atlas. In this paper we apply the atlas formation process to build atlases of normal brain and liver vasculature. We use Monte Carlo simulations to demonstrate the reliability of the underlying registration method. Additionally we explain the clinical potential of those atlases and conduct z -score analyses to compare individuals with the atlases to detect abnormal vessels.,10.1.1.1.3090,?,?
Experiments With,Electronic Examinations Over Blaine Price Marian Petre Linda Carswell Mike Richards Pete Thomas Pete Thomas,2001,The UKs Open University (OU) has been using the Internet on a regular basis for transporting student assignments (homework) between student tutor and the university. Tutor marked assignments are a major part of the OUs assessment system but all courses also have an examinable component that often takes the form of a three-hour closed-book examination taken under supervised conditions. Our aim has been to investigate the extent to which we could use the Internet to automate the examination process. In this paper we discuss the results of two experiments that we have carried out so far and discuss how examinations might be carried out electronically in a distance education setting.,10.1.1.1.3091,?,?
Leveraging the Multi in Secure Multi-Party Computation,Jaideep Vaidya Chris Clifton,2003,Secure Multi-Party Computation enables parties with private data to collaboratively compute a global function of their private data without revealing that data. The increase in sensitive data on networked computers along with improved ability to integrate and utilize that data make the time ripe for practical secure multi-party computation. This paper surveys approaches to secure multi-party computation and gives a method whereby an e#cient protocol for two parties using an untrusted third party can be used to construct an e#cient peer-to-peer secure multi-party protocol.,10.1.1.1.3092,Secure Multi-party Computation Secure Distributed,?
Coupled Signature and Specification Matching for Automatic Service Binding,Michael Klein Birgitta König-Ries,2004,Matching of semantic service descriptions is the key to automatic  service discovery and binding. Existing approaches split the matchmaking process in two step: signature and specification matching. However this leads to the problem that o#ers are not found although they are functionally suitable if their signature is not fitting the requested one. Therefore,10.1.1.1.3093,Automatic Service Discovery/Invocation Matching Semantic Service Descriptions OWL-S,Springer
Down With the Bureaucracy of Syntax!,Pattern Matching For,?,to proof trees for classical linear logic which bears a close resemblance to the way that pattern matching is used in programming languages. It equates the same proofs that are equated by proof nets in the formulation of proof nets introduced by Dominic Hughes and Rob van Glabbeek and goes beyond that formulation in handling exponentials and units. It provides a symmetric treatment of all the connectives and may provide programmers with improved insight into connectives such as par and why not that are difficult to treat in programming languages based on an intuitionistic formulation of linear logic.,10.1.1.1.3094,?,?
Construction of Genetic Network Using Evolutionary Algorithm and Combined Fitness Function,Ando Shin Hitoshi Iba,2003,This paper proposes a method to capture the dynamics in gene expression data using S-system  formalism and construct genetic network models. Our purposed method exploits the probabilistic  heuristic search and divide-and-conquer approach to estimate the network structure. In evaluating  the network structure we attempt a primitive integration of other knowledge to the statistical  criterion. The Z-score is used to analyze the robust and significant parameters from stochastic  search results. We evaluated the proposed method on artificially generated data and E.coli mRNA  expression data.,10.1.1.1.3095,?,?
Departement Informationstechnologie Elektrotechnik,Professur Fur Technische Departement Informationstechnologie Professur Für Technische Informatik Professor Dr Bernhard Plattner Nicolas Cedraschi D-itet Daniel Grob D-itet Prof Dr B. Plattner Daniel Grob Nicolas Cedraschi,?,The goal of this semester thesis was to develop a mobile Access Point for Wireless LAN (IEEE 802.11b) applicable in the shuttle bus that connects the two campi ETH Zentrum and ETH Honggerberg. A proper large range wireless connection system was evaluated. The bridge between the two systems and the Access Point were implemented on an embedded device. The system characteristics were tested and evaluated.,10.1.1.1.3096,?,?
Super-Distributed RFID Tag Infrastructures,Juergen Bohn Friedemann Mattern,2004,With the emerging mass production of very small cheap Radio Frequency Identification (RFID) tags it is becoming feasible to deploy such tags on a large scale. In this paper we advocate distribution schemes where passive RFID tags are deployed in vast quantities and in a highly redundant fashion over large areas or object surfaces. We show that such an approach opens up a whole spectrum of possibilities for creating novel RFID-based services and applications including a new means of cooperation between mobile physical entities. We also discuss a number of challenges related to this approach such as the density and structure of tag distributions and tag typing and clustering. Finally we outline two prototypical applications (a smart autonomous vacuum cleaner and a collaborative map-making system) and indicate future directions of research.,10.1.1.1.3097,?,?
Departmentof Computer Science,University Of Aarhus Niels Olof Bouvin Ann Christina Nielsen Christian Mulvad Sejersen,1988,this document use `he as pronoun as we in this respect support ourselves on The Elements of Style:  The use of he as pronoun for nouns embracing both genders is a simple  practical convention rooted in the beginnings of the English language. He has  lost all suggestion of maleness in these circumstances. The word was  unquestionably biased to begin with (the dominant male) but after hundreds of  years it has become seemingly indispensable. It has no pejorative connotation  it is never incorrect. Substitutinghe or she in its place is the logical thing to do  if it works. But it often doesnt work if only because repetition makes it sound  boring or silly. [...] No need fear to use he if common sense supports it,10.1.1.1.3098,?,?
Enterprise Security Aspects,Ron Bodkin New,2004,This report surveys common security requirements for enterprise  applications and analyzes how aspects can meet these. It analyzes how largescale  applications of aspects to security can work. It is intended to stimulate  discussion by complementing research that looks at small-scale security aspects.,10.1.1.1.3099,?,?
Heterozygote Advantage Fails to Explain the High Degree of . . .,Rob J. De Boer  Michiel van Boven  Franz J. Weissing  Can Kesmir  Jose A. M. Borghans F. J. Weissing,2004,Major histocompatibility (MHC) molecules are encoded by extremely polymorphic genes and play a crucial role in vertebrate immunity. Natural selection favors MHC heterozygous hosts because individuals heterozygous at the MHC can present a larger diversity of peptides from infectious pathogens than homozygous individuals. Whether or not heterozygote advantage is sufficient to account for a high degree of polymorphism is controversial however. Using mathematical models we studied the degree of MHC polymorphism arising when heterozygote advantage is the only selection pressure. We argue that existing models are misleading in that the fitness of heterozygotes is not related to the MHC alleles they harbor. To correct for this we have developed novel models in which the genotypic fitness of a host directly reflects the fitness contributions of its MHC alleles. The mathematical analysis suggests that a high degree of polymorphism can only be accounted for if the different MHC alleles confer unrealistically similar fitnesses. This conclusion was confirmed by stochastic simulations including mutation genetic drift and a finite population size. Heterozygote advantage on its own is insufficient to explain the high population diversity of the MHC.,10.1.1.1.3100,?,?
C. Roy Keys Inc.,Comment On The Vladimir Onoochin,?,This paper is in certain contrast with the  majority view that the relativistic theory is an internally consistent theory which can only be falsified by experiment. However the author states that the relativistic theory has some internal inconsistency. So this paper should attract some attention but first of all there appear some questions about correctness of the procedure of calculations developed by the author. To my point of view this paper * Sirius 3A Nikoloyamski lane Moscow 109004 Russia. E-Mail:  a33am@dol.ru  I  2001 C. Roy Keys Inc,10.1.1.1.3101,?,?
LOMAC: Low Water-Mark Integrity Protection for COTS Environments,Timothy Fraser,2000,We hypothesize that a form of kernel-resident access-control-based integrity protection can gain widespread acceptance in Commercial Off-The-Shelf (COTS) environments provided that it couples some useful protection with a high degree of compatibility with existing software configurations and practices. To test this hypothesis we have developed a highly-compatible free open-source prototype called LOMAC and released it on the Internet. LOMAC is a dynamically loadable extension for COTS Linux kernels that provides integrity protection based on Low Water-Mark access control. We present a classification of existing access control models with regard to compatibility concluding that models similar to Low Water-Mark are especially wellsuited to high-compatibility solutions. We also describe our practical strategies for dealing with the pathological cases in the Low Water-Mark models behavior which include a small extension of the model and an unusual application of its concepts.,10.1.1.1.3102,?,IEEE Computer Society
Fir Filter Design Using Low Power Arithmetic Operators,Eduardo Costa  Sergio Bampi José Monteiro,?,This paper addresses the use of architectural transformations techniques  for the low power realization of FIR filters on dedicated architectures. We  experiment a new encoding for the operators called the Hybrid encoding which  is a compromise between the minimal input dependency offered by the Binary  encoding and the low switching characteristic of the Gray encoding. The results  show that with the use of Hybrid operators in FIR architectures power savings  of up to 25% are possible together with a 14% delay improvement and an area  penalty of 28%.,10.1.1.1.3104,?,?
Bipartite Graphs as Intermediate Model for RDF,Jonathan Hayes  Claudio Gutierrez,2004,RDF Graphs are sets of assertions in the form of subjectpredicate  -object triples of information resources. Although for simple  examples they can be understood intuitively as directed labeled graphs  this representation does not scale well for more complex cases particularly  regarding the central notion of connectivity of resources.,10.1.1.1.3105,RDF Model RDF Graph RDF Databases Bipartite Graph,Springer-Verlag
On validation of XML streams using finite state machines,Cristiana Chitic Daniela Rosu,2004,We study validation of streamed XML documents by means of finite state machines. Previous work has shown that validation is in principle possible by finite state automata but the construction was prohibitively expensive giving an exponential-size nondeterministic automaton. Instead we want to find deterministic automata for validating streamed documents: for them the complexity of validation is constant per tag. We show that for a reading window of size one and nonrecursive DTDs with one-unambiguous content (i.e. conforming to the current XML standard) there is an algorithm producing a deterministic automaton that validates documents with respect to that DTD. The size of the automaton is at most exponential and we give matching lower bounds. To capture the possible advantages offered by reading windows of size k we introduce k-unambiguity as a generalization of one-unambiguity and study the validation against DTDs with k-unambiguous content. We also consider recursive DTDs and give conditions under which they can be validated against by using one-counter automata.,10.1.1.1.3106,?,ACM Press
Summarization of Spacecraft Telemetry Data by Extracting Significant Temporal Patterns,Takehisa Yairi  Shiro Ogasawara Koichi Hori Shinichi Nakasuka Naoki Ishihama,2004,This paper presents a method to summarize massive spacecraft telemetry  data by extracting significant event and change patterns in the lowlevel  time-series data. This method first transforms the numerical timeseries  into a symbol sequence by a clustering technique using DTW distance  measure then detects event patterns and change points in the sequence.,10.1.1.1.3107,?,?
Teachers Instructional Perspectives And Use Of Educational Software,Dale S. Niederhauser Trish Stoddart,2001,It has been argued that technology will promote the use of constructivist approaches to teaching and learning advocated by the current reform movement. Yet computer technology in and of itself does not embody a single pedagogical orientation. Di!erent types of software can be used to address di!erent educational goals. This article examines relationships between teachers instructional perspectives and their use of technology in instruction. Findings indicate that views about e!ective computer-based pedagogy are related to the types of software teachers report using with their students. Addressing these perspectives about e!ective instruction is necessary if computers are to reach their educational potential. ,10.1.1.1.3108,Instructional technology Teacher perspectives Constructivist approaches Transmission approaches,?
Efficient Management of Multi-Linked Negotiation Based on a Formalized Model,Xiaoqin Zhang Department Xiaoqin Zhang Victor Lesser Sherief Abdallah,2005,A Multi-linked negotiation problem occurs when an agent needs to negotiate with multiple other agents about different subjects (tasks  conflicts or resource requirements) and the negotiation over one subject has influence on negotiations over other subjects. The solution  of the multi-linked negotiations problem will become increasingly important for the next generation of advanced multi-agent systems.,10.1.1.1.3109,multiple related negotiations agent reasoning and control conflict resolution performance optimization,?
Endurants and Perdurants in Directly Depicting Ontologies,Thomas Bittner Maureen Donnelly Barry Smith ,2004,?,10.1.1.1.3111,ontology spacetime endurants perdurants temporal mereology substances,Press
All in-Focus View Synthesis from Under-Sampled Light Fields,Keita Takahashi  Akira Kubota Takeshi Naemura Takeshi Naemura,2003,Light field rendering (LFR) is a fundamental method for generating new views from a set of pre-acquired images. We use densely-aligned cameras for the process of acquiring the set of images. In most practical cases the density of the aligned cameras is not high enough to synthesize appropriate views. This under-sampling condition causes focus-like effects in the synthesized views. This paper proposes a new method for solving this problem. First a set of differently focused views is synthesized from the undersampled set of pre-acquired images. Then an all in-focus view is generated from the set of differently focused views. This is based on a new focus measurement algorithm specialized for light field rendering and plenoptic sampling theory. Experimental results show the effectiveness of our approach.,10.1.1.1.3112,Key words Light Field Rendering Focal Plane All-in Focus Focus Measure Plenoptic Sampling,?
Quality of Service for the Last Mile,Murali Mohan Madav Murali Mohan Madav Shankar Rangaprabhu Parthasarathy Surendranath Ramasubbu,?,As broadband access to the Internet is expected to become widely available to customers over the last-mile the need for providing Quality of Service (QoS) classifications over lastmile links is keenly felt. This report deals with a broad set of last-mile technologies from the perspective of their respective abilities to support QoS. A brief overview of the QoS characteristics standards defined and unresolved issues with respect to each last mile technology is presented.,10.1.1.1.3113,?,?
Medical Video Mining for Efficient Database Indexing Management and Access,Xingquan Zhu  Walid G. Aref  Jianping Fan  Ann C. Catlin  Ahmed K. Elmagarmid ,2003,To achieve more efficient video indexing and access we introduce a video database management framework and strategies for video content structure and events mining. The video shot segmentation and representative frame selection strategy are first utilized to parse the continuous video stream into physical units. Video shot grouping group merging and scene clustering schemes are then proposed to organize the video shots into a hierarchical structure using clustered scenes scenes groups and shots in increasing granularity from top to bottom. Then audio and video processing techniques are integrated to mine event information such as dialog presentation and clinical operation from the detected scenes. Finally the acquired video content structure and events are integrated to construct a scalable video skimming tool which can be used to visualize the video content hierarchy and event information for efficient access. Experimental results are also presented to evaluate the performance of the proposed framework and algorithms.,10.1.1.1.3114,?,?
Instant and Incremental Transformation of Models,Sven Johann Alexander Alexander Egyed,2004,This paper introduces a framework for the instant and incremental transformation of changes among models. It can be configured to understand where and when changes happen in a given source model and the impact these changes have onto a given target model. It can also be configured to select translation rules as needed to update the target model. Incremental transformation is an alternative to the batch transformation and is significantly more efficient in maintaining the synchronicity among large-scale models.,10.1.1.1.3115,?,?
Balancing spectra between different speaking styles,Gunilla C. Thunberg,2003,Introduction  The concept of spectral balance is fairly young within speech research. During the past decade the linguistic use of energy enhancement in the upper part of the speech spectrum has been empirically explored (Sluijter  van Heuven 1993 1996 Campbell 1995 Sluijter Shattuck-Hufnagel Stevens  van Heuven 1995 Sluijter van Heuven  Pacilly 1997 Heldner 2003). It has been shown that spectral balance may be employed for linguistic purposes at the word or phrase level (often in interaction with other features such as duration or intonational gestures). However changes in the spectral energy balance may be employed also for non-linguistic or extralinguistic purposes. When utilized over longer stretches of speech where a whole utterance or even an entire monologue might be characterized by consistent enhancement of the upper parts of the spectrum this feature would be regarded as being indicative of voice quality rather than having a direct linguistic function.  1.,10.1.1.1.3116,?,?
Adaptive Data Partitioning Using Probability Distribution,Xipeng Shen Yutao Zhong Chen Ding,2003,Many computing problems benefit from dynamic data partitioning---dividing a large  amount of data into smaller chunks with better locality. When data can be sorted two  methods are commonly used in partitioning. The first selects pivots which enable balanced  partitioning but cause a large overhead of up to half of the sorting time. The  second method uses simple functions which is fast but requires that the input data confirm  to a uniform distribution. In this paper we propose a new method which partitions  data using the cumulative distribution function. It partitions data of any distribution in  linear time independent to the number of sublists to be partitioned into. Experiments  show 10-30% improvement in partitioning balance and 20-70% reduction in partitioning  overhead. The new method is more scalable than existing methods. It yields greater  benefit when the data set and the number of sub-lists grow larger. By applying this  method our sequential sorting beats Quick-sorting by 20% and parallel sorting exceeds  the previous sorting algorithm by 33-50%.,10.1.1.1.3117,?,?
Routing And Data Compression in . . . ,Anna Scaglione,2003,?,10.1.1.1.3118,?,?
FCND DP No. 114 FCND DISCUSSION PAPER NO. 114 DISTRIBUTION GROWTH AND PERFORMANCE OF MICROFINANCE INSTITUTIONS IN AFRICA ASIA AND LATIN AMERICA,Cécile Lapenu Manfred Zeller,?,How many microfinance institutions (MFIs) exist in the developing world? What are their current performances? In 1999 an International Food Policy Research Institute (IFPRI) team on microfinance conducted a survey on MFIs in Asia Africa and Latin America in order to offer a new in-depth analysis on the distribution and performances of MFIs at the international level. A systematic sampling has been adopted through the contacting of international NGOs and networks supporting various MFIs. The information has been complemented by a review of publications and technical manuals on microfinance. The database of MFIs from 85 developing countries shows 1500 institutions (790 institutions worldwide plus 688 in Indonesia) supported by international organizations. They reach 54 million members 44 million savers (voluntary and compulsory savings) and 23 million borrowers. The total volume of outstanding credit is $18 billion. The total savings volume is $12 billion or 72 percent of the volume of the outstanding loans. MFIs have developed at least 46000 branches and employ around 175000 staff. The IFPRI database underlines the presence of a multitude of MFIs that except in unstable countries are widespread with no forgotten regions. MFIs are very diverse in terms of lending technologies and legal status which allows room for innovation but they remain highly concentrated. The data are analyzed by type of MFIs and by geographic regions. The results presented give an overview of the current development of MFIs and offer a benchmark for comparisons. iii CONTENTS Acknowledgments............................................................................................................... v 1. ,10.1.1.1.3119,1. Introduction,?
Inferring 3D Structure with a,Statistical Image-Based Shape Kristen Grauman Gregory Shakhnarovich Trevor Darrell,2003,We present an image-based approach to infer 3D structure parameters using a probabilistic shape+structure model. The 3D shape of a class of objects may be represented by sets of contours from silhouette views simultaneously observed from multiple calibrated cameras. Bayesian reconstructions of new shapes can then be estimated using a prior density constructed with a mixture model and probabilistic principal components analysis. We augment the shape model to incorporate structural features of interest novel examples with missing structure parameters may then be reconstructed to obtain estimates of these  parameters. Model matching and parameter inference are done entirely in the image domain and require no explicit 3D  construction. Our shape model enables accurate estimation of structure despite segmentation errors or missing views in the  input silhouettes and works even with only a single input view. Using a dataset of thousands of pedestrian images generated from a synthetic model we can perform accurate inference of the 3D locations of 19 joints on the body based on observed silhouette contours from real images.,10.1.1.1.3120,?,?
General Mechanics of a Photon in the Gravitational Field of a Stationary Homogeneous Spherical Body,Howusu Department Of S. X. K. Howusu,2001,this paper it is shown how a photon is accelerated according to the Theory of General Mechanics. 1. ,10.1.1.1.3121,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,This paper presents EarthMover a discrete-event special-purpose simulation modeling tool for earthwork planning geared towards practitioners. The paper explores the capabilities of the system by modeling an earth moving operation of moderate complexity. The operation is initially modeled with default parameters and is sucessively improved based on insights obtained from the static and dynamic outputs of the previous model. The paper also describes the tools and techniques that were used to develop the simulator.,10.1.1.1.3123,?,?
FCND DISCUSSION PAPER NO. 76 RAISING PRIMARY SCHOOL ENROLMENT IN DEVELOPMENT COUNTRIES: THE RELATIVE IMPORTANCE OF SUPPLY AND DEMAND,Sudhanshu Handa,?,Few policies are as universally accepted as raising primary school enrolment in developing countries but the policy levers for achieving this goal are not straight forward. This paper merges household survey data with detailed school supply characteristics from official sources in order to estimate the relative impact of demandand supply-side determinants of rural primary school enrolment in Mozambique. Policy simulations based on a set of plausible interventions show that demand-side interventions particularly those aimed at raising rural adult literacy will have the biggest impact on primary school enrolment rates. vi CONTENTS Acknowledgments.......................................................................................................... vii 1. ,10.1.1.1.3124,CONTENTS,?
User-Centric Analysis of Perceived QoS in 4G IP,Mobile Wireless Networks C Gran Capità F. Bader C. Pinart C. Christophi E. Tsiakkouri I. Ganchev V. Friderikos C. Bohoris L. Correia L. Ferreira,2003,This paper presents the emerging requirements users are imposing upon the evolving world of heterogeneous 4G mobile/wireless networks through their perception of final services. The mapping proposed in this paper groups together these user requirements in three main and distinguishable categories: service provision connectivity and adaptability and reconfigurability by describing system concepts for each category from user terminal to network and services/applications.,10.1.1.1.3125,QoS IP networks mobile/wireless networks 4G systems reconfigurability,?
On Blind Equalization of Rank Deficient Nonlinear Channels,Roberto Lopez-Valcarce  Soura Dasgupta,?,We consider the problem of blind equalization of nonlinear channels from the second-order statistics of the channel output. The channel model is linear in the parameters with additive terms that are nonlinear functions of the transmitted symbols. All previous approaches assume that the corresponding channel matrix has full column rank which ensures the existence of linear FIR zero forcing equalizers. We show that this assumption is not necessary and that under certain circumstances linear FIR equalizers can be found despite the violation of this assumption. An important consequence of this fact is that equalization can be effected with a smaller level of diversity. In this paper necessary and sufficient conditions on the channel matrix are given. An algorithm for the computation of the equalizers is also given for those channels satisfying these conditions assuming an i.i.d. symbol sequence and memory dominance of the linear part. 1. ,10.1.1.1.3126,?,?
Principles of Distributed Test Synthesis based on True-Concurrency Models,Claude Jard,2002,Automatic synthesis of test cases for conformance testing has been principally developed with the objective of generating sequential test cases. In the distributed system context it is worth extending the synthesis techniques to the generation of multiple testers. We base our work on our experience in using model-checking techniques as successfully implemented in the TGV tool. Continuing the works of A. Ulrich and H. Knig we propose to use a trueconcurrency model based on graph unfolding. The article presents the principles of a complete chain of synthesis starting from the definition of test purposes and ending with a projection onto a set of testers.,10.1.1.1.3128,Key words Test Distributed systems Synthesis True-concurrency models,Kluwer Academic publishers
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros B. A. Peters J. S. Smith D. J. Medeiros M. W. Rohrer,?,This paper presents the verification and validation (VV) of simulation model with the emphasis on the possible modification. Based on the analysis a new framework is proposed and new terms are defined. An example is employed to demonstrate how the framework and terms related are used in verifying and validating an existing model.,10.1.1.1.3129,?,?
Operator Patterns for Analysis of Composite Events in Timed Automata,Annmarie Ericsson Robert,?,Event-triggered real-time systems interact with the environment by executing actions in response to monitored events. Such systems may be implemented using event condition action (ECA) rules which execute an action if the associated event occurs and a specified condition is true. However the ECA rule paradigm is known to be hard to analyze with respect to correctness and timeliness which is not conducive to the high predictability requirements typically associated with real-time systems. To still take advantage of the ECA rule paradigm when event-triggered real-time systems are developed we propose an approach where systems are specified and analyzed in a high-level formal language (timed automata) and later transformed into the ECA rule paradigm. We especially focus on a high-level approach for specifying and analyzing composite event occurrences in timed automata.,10.1.1.1.3130,?,?
Multilingual Website Usability: Cultural Context,Mathew Hillier,2002,This research in progress paper draws evidence from the anthropological worldviews and systems design literature to show how culture and context play a significant role in the way people perceive and approach their interaction with a multilingual e-commerce website. In doing so this paper shows that a relationship exists between language cultural context and usability. Some suggestions are provided for how the author might conduct useful research that will lead to some Argyris [1] style actionable knowledge which designers can use as `rules of thumb.,10.1.1.1.3132,multicultural website design usability culture context e-commerce,?
Autonomous Characters in Virtual Environments: The technologies involved in artificial life and their affects of perceived intelligence and playability of computer games,Oliver Edward Wood,?,Computer games are viewed by academics as un-grounded hack and patch experiments. Academic artificial intelligence is often viewed as un-implementable  and narrow minded by the majority of non-AI programmer.,10.1.1.1.3134,?,?
Component-Based Approach for Embedded Systems,Ivica Crnkovic,2004,This paper addresses component-based approach for embedded systems. Due to the specific characteristics of embedded systems the general-purpose component technologies such as COM .NET or EJB have not been the most appropriate choices for their development. Although attractive component-based approach has not been successful in this domain as in other domains. However in recent years the interest for component-based approach in embedded systems increases. The experience has shown that existing technologies cannot be used or at least used directly. On the other hand an increasing understanding of principles of component-based approach makes it possible to utilize these principles in implementation of different component-based models more appropriate for embedded systems. This paper gives an overview of basic characteristics of embedded systems their requirements and constraints and the implications to component models for these systems.,10.1.1.1.3135,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Is It Only A Special Case Of Software Testing,?,Effective testing of software is an important concern in the software engineering community. While many techniques regularly used for testing software apply equally well to testing the implementations of simulation models we believe that testing simulations often raises issues that occur infrequently in other types of software. We believe that many code characteristics that commonly occur in simulation code are precisely those that the software testing community has identified as making testing challenging. We discuss many of the techniques that software engineering community has developed to deal with those features and evaluate their applicability to simulation development.,10.1.1.1.3136,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Corné Versteegt Alexander Verbraeck,?,Control systems for logistic and transport systems are among the most complex control systems in existence. Currently control systems are only fully tested at the shop floor after commissioning. This means a lot of costly failures occur at the startup stages of control systems. The goal of this paper is to describe the extended role that simulation can play in evaluating of fully automated logistic systems and their control systems before commissioning. We followed a three-step approach in evaluating both logistic and logistic control systems. A simulated control system was used to control simulated emulated and real prototypes of logistic resources. Three different simulation packages have been used Simple++ AutoMod Arena. The control system was implemented in all three simulation packages to control logistic resources at the Connekt TestSite. The TestSite is a special laboratory for testing new technologies in logistic automation.,10.1.1.1.3137,?,?
Livestock Intensification and Smallholders: A Rapid Reconnaissance of the . . .,Agnes Rola Walfredo Rola Marites Tiongco Christopher Delgado,2003,This essay describes the views of Philippines livestock sector stakeholders  concerning the events and issues associated with the rapid rise in hog and poultry  production based on rapid reconnaissance interviews and gray literature from studies in  Southern Luzon Iloilo and Northern Mindanao and the impressions of the authors.  Changing demographic patterns decentralized eco-governance trade liberalization and  health and environmental policies have major impacts on further livestock intensification  and on increasing scale of operations. Six factors appear to affect small farmers  decisions to intensify or raise livestock or remain in the livestock industry. These are 1)  access to financial capital 2) technical knowledge about livestock production and their  sources of information 3) social capital expressed as trust in integrators in the primary  buyers of the livestock and in government 4) demographic characteristics such as  gender and age 5) farmer perceptions of the policy environment (prices feeds health  and environmental policies and the local ordinances affecting the livestock sector) and  6) access to reliable markets for outputs across the year.            iii   TABLE OF CONTENTS     1. ,10.1.1.1.3138,?,?
The Case Study of Application of Advanced Gesture Interface and Mapping,Interface Virtual Musical Suguru Goto,2004,We will discuss the case study of application of the Virtual Musical Instrument and Sound Synthesis. Doing this application the main subject is advanced Mapping Interface in order to connect these. For this experiment our discussion also refers to Neural Network as well as a brief introduction of the Virtual Musical Instrument Le SuperPolm and Gesture Controller BodySuit.,10.1.1.1.3139,Gesture Controller Mapping Interface,?
Blind Signal Separation In Noisy Environments Using A Three-Step Quantizer,Heinz Mathis  Marcel Joho,2002,componentanalysi i noiy channels needsspeciA consifxkSdAWW sins standard solutird leadto abik i theestifff of the parameters. We show three diAGSEf approaches tomiE#E#d the e#ects ofaddiTTT noi i the transfermedife A prifG#d component subspace methodcan reduce thenoiW to more favorable levels so that anyfollowi# algori# shows reducedbic e#ects. Although stochastiESAdTGS algoriti formaxiSxxdTGSkdi solutixx to the problem caneasiT be found they arecomputati#kTSE prohiati#k A very successful approachir therefore to assume zero noid power for the deriT#Wd of theadaptif algorifW andsubsequentlytryib to compensate for any bid id#T ucedby such asolutid The thresholdnonlixxkEd (three-stepquantiste i suinti for theblifAxfdxfW of a large class of sub-Gaussi# d ixTWGdWAfk StabiGd regiG are exploredfollowedbyalgoridfol extensifo to suppress the bidi the estixASd of the separati matria c   2002Elsevix Scivi B.V. All rildx reserved. Keywozip UnbidfdfdidAAdfdi separatidi Noia ICA MLsolutiTd OverdetermiG#fdWTxESdidid ThresholdnonlixESdi  1. I330-111 Bliifdfdf separatif usia an adaptiG algorixd i atechnid that has become icomedxxxkE icomedxx for a vast range ofappliTdGkG i acoustiG communiGkGxdi   Correspondii author.Unir.dWGW ofAppliS SciiSA (HSR) Oberseestrasse 10 CH-8640Rapperswi# Swiperswi# Tel.: +41-55-222-45-95 fax: +41-55-222-44-00 .,10.1.1.1.3140,Unbiasedblindsignal separation Noisy ICA ML solution Overdeterminedblindseparation Thresholdnonlinearity,?
FCND DP No. 89 FCND DISCUSSION PAPER NO. 89 THE ROLE OF THE STATE IN PROMOTING MICROFINANCE INSTITUTIONS,Cécile Lapenu,?,In a context of liberalized financial systems microfinance allows millions of households usually excluded from classical financial services to begin or reinforce their own activities and become microentrepreneurs. Yet in spite of the success of numerous microfinance institutions (MFI) many difficulties remain which must be urgently resolved in view of their ambitious objectives. First a large number of the rural households still lack access to financial services. Second most of the existing MFI are not yet financially sustainable. Finally while funds from governments and donors are rapidly increasing financial institutions still need solid foundations to avoid management failures. These issues raise questions of the role of the state to promote MFI including (1) which state-owned institutions may be necessary? (2) which level and type of subsidization of the financial institutions can be accepted? (3) what can be the choice for the state between alternative investments in financial institutions or complementary services? (4) what are the necessary conditions for creating a favorable environment? This paper presents the evolution of views on the role of the state in the financial system including theoretical and empirical points of view from the interventionist period of the 1960s and 1970s to the current period of liberalization. Based on country case studies illustrating the divergent role of the state in the development of the rural financial system the paper reviews the respective role of the state the NGO and the private commercial banks in increasing their outreach and in adopting microfinance innovations. It also analyzes different issues regarding regulation of MFI. iv The paper concludes with a discussion of the necessary roles of the state to promote...,10.1.1.1.3141,?,?
A Platform for Secure Mobile Agents,Johan Arthursson Jakob Engblom  Ing-Marie Jonsson Rehan Mirza Gustaf Naeser Mikael Olsson Robert Ottenhag  Dan Sahlin Maria Schmid  Bertil Spolander Elham Zolfonoon Ericsson Telecom,1997,A secure system for mobile agents written in    a real time high-level functional language with processes and message passing is described. The emphasis for this system is on security with reasonably secure nodes and secure agent communication something which is often ignored in most agent systems but crucial for an open agent system.,10.1.1.1.3142,?,?
Generating And E-Mailing,Feedback To Students Philip Denton Philip Denton L Af,2001,An MS-based system for generating and returning feedback to students has been utilised by tutors at Liverpool John Moores University (JMU). The technique uses Office 97 to generate feedback reports that can include the students mark position in the class and a series of statements selected from a bank of comments inputted by the tutor. In addition to allowing feedback to be printed and distributed via e-mail the software also reports the frequency with which particular comments were used. This valuable information can be used by students to direct their learning and by tutors to inform future teaching strategies. The procedure is particularly suited to large classes and can make the process of returning feedback to students considerably less onerous. The operation of Version 8 of the software is described and the responses of staff and students to the procedure are reported.,10.1.1.1.3143,MS Word MS Excel e-Mail,?
Digit Classification on Signboards for Telephone Number Recognition,Takuma Yamaguchi   Yasuaki Nakano Minoru Maruyama Hidetoshi Miyao Toshihiro Hananoi,2003,This paper presents a digits classification system to recognize telephone numbers written on signboards. Candidate regions of digits are extracted from an image through edge extraction enhancement and labeling. Since the digits in the images often have skew and slant the digits are recognized after the skew and slant correction. To correct the skew Hough transform is used and the slant is corrected using the method of circumscribing digits with tilted rectangles. In experiments we tested a total of 1332 images of signboards with 11939 digits. We obtained a digit extraction rate of 99.2% and a correct digit recognition rate of 98.8%.,10.1.1.1.3144,?,IEEE Press
Delay Budget Partitioning to Maximize Network Resource Usage Efficiency,Kartik Gopalan Tzi-cker Chiueh  Yow-Jian Lin,2004,Provisioning techniques for network flows with endto -end QoS guarantees need to address the inter-path and intra-path load balancing problems to maximize the resource utilization efficiency. This paper focuses on the intra-path load balancing problem: How to partition the end-to-end QoS requirement of a network flow along the links of a given path such that the deviation in the loads on these links is as small as possible? We propose a new algorithm to solve the end-to-end QoS partitioning problem for unicast and multicast flows that takes into account the loads on the constituent links of the chosen flow path. This algorithm can simultaneously partition multiple end-to-end QoS requirements such as the end-to-end delay and delay violation probability bound. The key concept in our proposal is the notion of slack which quantifies the extent of flexibility available in partitioning the end-to-end delay requirement across the links of a selected path (or a multicast tree). We show that one can improve network resource usage efficiency by carefully selecting a slack partition that explicitly balances the loads on the underlying links. A detailed simulation study demonstrates that compared with previous approaches the proposed delay budget partitioning algorithm can increase the total number of long-term flows that can be provisioned along a network path by up to 1.2 times for deterministic and 2.8 times for statistical delay guarantees.,10.1.1.1.3145,?,?
3D-TV - The Future of Visual Entertainment,M. Magnor Mpi Informatik,2003,This paper intends to give an overview of current research in 3D-TV acquisition coding and display,10.1.1.1.3146,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,We consider a system with two types of traffic and two types of agents. Outbound calls are served only by blend agents whereas inbound calls can be served by either inboundonly or blend agents. Our objective is to allocate a number of agents such that some service requirement is satisfied. We have taken two approaches in analyzing this staffing problem: We developed a simulation model of the call center which allows us to do a what-if analysis as well as continuous-time Markov chain (CTMC) queueing models which provide approximations of system performance measures. We describe the simulation model in this paper. 1 ,10.1.1.1.3147,?,?
Integrating Handhelds into Environments of Cooperating Smart Everyday Objects,Frank Siegemund  Tobias Krauer,2004,Because of their severe resource-restrictions and limited user  interfaces smart everyday objects must often rely on remote resources  to realize their services. This paper shows how smart objects can obtain  access to such resources by spontaneously exploiting the capabilities of  nearby mobile user devices. In our concept handhelds join a distributed  data structure shared by cooperating smart objects which makes the  location where data are stored transparent for applications. Smart objects  then outsource computations to handhelds and thereby gain access  to their resources. As a result this allows smart items to transfer a  graphical user interface to a nearby handheld and facilitates the collaborative  processing of sensory data because of the more elaborate storage  and processing capabilities of mobile user devices. We present a concrete  implementation of our concepts on an embedded sensor node platform  the BTnodes and illustrate the applicability of our approach with two  example applications.,10.1.1.1.3148,?,?
Why Computational Science and Engineering Should be of Interest to Computer Scientists,Lasse Natvig Group Lasse Natvig,?,This paper briefly introduces the field computational science and engineering (CSE) and is an attempt to get other computer scientists more interested in CSE related activities. It starts by giving a short outline of the increased international activity in the field. Several of the definitions of CSE that have been given are presented with an emphasis on how the field is related to computer science. The role of supercomputers is discussed and we try to identify important challenges for future CSE education and research again with a hope to attract computer scientists.,10.1.1.1.3149,computational science and engineering scientific computing supercomputing high performance computing (HPC education computer science,?
 Coupling Information Retrieval and Information Extraction: A New Text Technology for Gathering Information from the Web ,Robert Gaizauskas Alexander M. Robertson,1997,The techniques of information retrieval and information extraction are complementary but to date there has been little concrete work aimed at integrating the two. We describe how each of these techniques contributes to the process of transferring information from generator to user summarise the issues which must be addressed if they are to work together and report the results of some preliminary experiments on coupling them which indicate that these technologies can be jointly used to construct a structured data resource from free text on the WWW.,10.1.1.1.3150,Information retrieval Information extraction Text filtering World-Wide Web,?
Towards a Data Consistency Modeling and Testing Framework for MOF Defined Languages,Jan Pettersen Nytun  Christian S. Jensen Vladimir A. Oleshchuk,2003,The number of online data sources is continuously increasing and related  data are often available from several sources. However accessing data from  multiple sources is hindered by the use of different languages and schemas  at the sources as well as by inconsistencies among the data. There is thus a  growing need for tools that enable the testing of consistency among data from  different sources.,10.1.1.1.3151,?,?
Intl. Conf. RIVF04,February Hanoi Vietnam Minh-quang Vu Laurent Besacier Eric Castelli Brigitte Bigi Hervé Blanchon,2004,This paper relates a methodology to include some semantic information early in the statistical language model for Automatic Speech Recognition (ASR). This work is done in the framework of a global speech-to-speech translation project. An Interchange Format (IF) based approach representing the meaning of phrases independently of languages is adopted. The methodology consists in introducing semantic information by using a class-based statistical language model for which classes directly correspond to IF entries. With this new Language Model the ASR module can analyze into IF an important amount of dialogue data: 35% dialogue words 58% speaker turns. Among these 58% turns directly analyzed 84% are properly analyzed.,10.1.1.1.3152,?,?
Mobile Music Making,Atau Tanaka Sony,2004,We present a system for collaborative musical creation on mobile wireless networks. The work extends on simple peerto -peer file sharing systems towards ad-hoc mobility and streaming. It extends upon music listening from a passive act to a proactive participative activity. The system consists of a network based interactive music engine and a portable rendering player. It serves as a platform for experiments on studying the sense of agency in collaborative creative process and requirements for fostering musical satisfaction in remote collaboration.,10.1.1.1.3153,Creative Commons,?
Designs for Ramp-Constrained Day-Ahead Auctions,Shmuel Oren Ieor Shmuel S. Oren Ieor Dept,2002,Some electric power markets allow bidders to specify constraints on ramp rates for increasing or decreasing power production. We show in a small example that a bidder could use an overly restrictive constraint to increase profits and explore the cause by visualizing the feasible region from the linear program corresponding to the power auction. We propose two penalty approaches to discourage bidders from such a tactic: one based on duality theory of Linear Programming the other based on social cost differences caused by ramp constraints. We evaluate the two approaches using a simplified scaled model of the California power system with actual 2001 California demand data.,10.1.1.1.3154,Index Terms — Auction Design Ramp constraints Power,?
In Proc. Int. Symp. on Microarchitecture pages 271278 Nov.95 Ann Arbor MI.,Ieee Personal Use Lucas Roh Walid A. Najjar,1995,Multithreaded execution models attempt to combine some aspects of data#ow-like execution with von Neumann model execution. Their main objective is to mask the latency of inter-processor communications and remote memory accesses in large scale multiprocessors. An important issue in the analysis and evaluation of multithreaded execution is the design and performance of the storage hierarchy.,10.1.1.1.3155,?,?
Predicting Users Requests on the WWW,I. Zukerman D. W. Albrecht A. E. Nicholson,1999,We describe several Markov models derived from the behaviour patterns of  many users which predict which documents a user is likely to request next. We then present  comparative results of the predictive accuracy of the different models and based on these  results build hybrid models which combine the individual models in different ways. These  hybrid models generally have a greater predictive accuracy than the individual models. The  best models will be incorporated in a system for pre-sending WWW documents.,10.1.1.1.3156,?,?
Melodic Similarity: Looking for a Good Abstraction Level,Maarten Grachten  Josep-Lluis Arcos  Ramon Lopez de Mantaras,2004,with diverse musical applications ranging from music analysis to content-based retrieval. Choosing the appropriate level of representation is a crucial issue and depends on the type of application. Our research interest concerns the development of a CBR system for expressive music processing. In that context a well chosen distance measure for melodies is a crucial issue. In this paper we propose a new melodic similarity measure based on the I/R model for melodic structure and compare it with other existing measures. The experimentation shows that the proposed measure provides a good compromise between discriminatory power and the level of abstraction of melody representation. 1.,10.1.1.1.3157,?,?
A Formulation of the Gravitational Equation of Motion,T. Chang,2001,this paper we emphasize that constraints on coordinate conditions are imposed by the principle of equivalence. Einstein (1916) illustrated the principle of equivalence using the following simple example. Let S be an inertial reference system let another system K be uniformly accelerated with respect to S . Then relative to K all free bodies have equal and parallel accelerations. They behave just as if a gravitational field were present and K were unaccelerated. In order to formulate the above simple equivalent gravitational field suggested by Einstein let us start with an inertial system S . Let X     cT X Y Z cT       = R be the pseudo-Cartesian coordinate in the system S . Then the 4-D line element takes a form d d d d d s c T X Y Z  2 2 2 2 2  = - - -   (1) We now consider a system K with coordinates x     ct x y z x       = r  which has a constant acceleration a  with respect to S . Since the Lorentz transformations are not valid between S and K the following quasi-Galilean transformations are usually introduced (Mller 1972)  R r a = + =    t T t  (2) A simple calculation for Eqs.(1) and (2) gives   at c x t c  2 2  1 2 = -  H G I K  - -   a r r (3) We substitute these components of g n into the geodesic equation  d d d d   x x x   rl  r l  t t t  + = G 0 (4) In the case of a low velocity approximation Eq.(4) reduces to d d   r a t   = - . This indicates that a free particle with a rest mass m o in a uniformly accelerated system should experience a uniformly inertial force -m o a   . Although this result is well known the above calculation shows that certain constraints on space-time coordinates and transformations should be imposed by the principle of equivalence,10.1.1.1.3159,?,?
A Class of Stochastic Programs with Decision Dependent Uncertainty  ,Vikas Goel Ignacio E. Grossmann,2005,The standard approach to formulating stochastic programs is based on the assumption that the stochastic process is independent of the optimization decisions. We address a class of problems where the optimization decisions influence the time of information discovery for a subset of the uncertain parameters. We extend the standard modeling approach by presenting a disjunctive programming formulation that accommodates stochastic programs for this class of problems. A set of theoretical properties that lead to reduction in the size of the model is identified. A Lagrangean duality based branch and bound algorithm is also presented. ,10.1.1.1.3161,?,?
An Overview of Classifier Fusion Methods,Dymitr Ruta  Bogdan Gabrys,2000,This paper gives an overview of classifier fusion methods and attempts to identify new trends that may dominate this area of research in future. A taxonomy of fusion methods trying to bring some order into the existing pudding of diversities is also provided,10.1.1.1.3162,?,?
An Analysis of Web Services Workflow Patterns in Collaxa,Martin Vasko Schahram Dustdar,?,Web services have a substantial impact on todays distributed software systems especially on the way they are designed and composed. Specialization of different services is leading to a multitude of applications ultimately providing complex solutions. The interaction and modeling aspects of Web services is increasingly becoming important. Based on the needs for Web services conversations process modeling and composition a variety of languages and technologies for Web services composition have evolved. This case study is focused on a systematic evaluation of the support for workflow patterns and their BPEL (Business Process Execution Language for Web Services) implementation in Collaxa a leading BPEL process modeling and enactment engine for Web services processes.,10.1.1.1.3163,Workflow patterns composition BPEL,Springer LNCS
FCNDP No. 167,Fcnd Discussion Paper Rasmus Heltberg Kenneth Simler Finn Tarp,?,Poverty reduction strategies often highlight public spending to improve health and  education focusing on investments in human capital among poorer members of society.  In addition debt relief programs such as the enhanced Highly Indebted Poor Countries  (HIPC) initiative often require increased spending on health and education in return for  debt cancellation. Mozambiques poverty reduction strategy is closely integrated with  the government expenditure program yet up to now little is known about the extent to  which public spending is targeted toward the poor in Mozambique. This paper assesses  whether public expenditures on education and health are successful at reaching the poorer  segments of the Mozambican population. Standard nonbehavioral benefit-incidence  methodology is applied combining individual client information from survey data with  provincial-level data on the cost of service provision. Most of the public services we are  able to measure are moderately progressive although some of the instruments we could  not measure are probably less equally distributed. In Mozambique it appears that  regional and gender imbalances in health and education are more significant than incomebased differences. Nevertheless increased public expenditures on health and  educationsuch as that related to the HIPC initiativeare likely to have significant  poverty-reducing effects.        iii Contents   Acknowledgments............................................................................................................... v    1. ,10.1.1.1.3164,1. Introduction.....................................................................................,?
Drawing Graphs on Two and Three Lines,Sabine Cornelsen Thomas Schank Dorothea Wagner,2002,We give a linear-time algorithm to decide whether a graph has a planar LL-drawing i.e. a planar drawingo two parallel lines. This has previo)L/ beenkno wnoLq fo trees. We utilize this resultto oult planar drawings on three lines for a generalization of bipartite graphs also in linear time. ,10.1.1.1.3165,?,Springer-Verlag
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson,?,The regenerative method of simulation output analysis exploits the regenerative structure of a stochastic process to break up a path into independent and identically distributed cycles based on a sequence of regeneration times. If a process is regenerative with respect to more than one sequence of regeneration times the classical regenerative method does not exploit the additional structure. In a previous paper we introduced an efficiency-improvement technique for regenerative simulation of processes having two sequences of regeneration times based on permuting regeneration cycles associated with the second sequence of regeneration points. In this paper we show how the same basic idea can be extended to exploit more than two regeneration sequences. In particular for birth-death Markov chains the regenerations associated with hitting times to each state can all be exploited. We present empirical results that show significant variance reductions in some cases.,10.1.1.1.3167,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,The word scalability is used in a variety of ways by different simulation communities. This paper describes some of the more common usages and presents a general unifying definition of simulation scalability which addresses the intent of these differing usages. Many common definitions of scalability can be viewed as simple restrictions of this multivariate scalability function to some subset of the variables in its domain. The quantitative nature of this definition allows systems to be compared based on their scalability instead of their relative performance at some level of capability. The utility of the proposed general and restricted definitions of scalability is discussed.,10.1.1.1.3168,?,?
Establishing a Mobile Conference Call under Delay and Bandwidth Constraints,Amotz Bar-noy  Zohar Naor,2004,The issue of tracking a group of users is discussed in this study. Given the condition that the search is over only after all the users in the group are found this problem is called the Conference Call Search (CCS) problem. The goal is to design efficient CCS strategies under delay and bandwidth constraints. While the problem of tracking a single user has been addressed by many studies to the best of our knowledge this study is one of the first attempts to reduce the search cost for multiple users. Moreover as oppose to the single user tracking for which one can always reduce the expected search delay by increasing the expected search cost for a multiple users search the dependency between the delay and the search cost is more complicated as demonstrated in this study. We identify the key factors affecting the search efficiency and the dependency between them and the search delay. Our analysis shows that under tight bandwidth constraints the CCS problem is NP-hard. We therefore propose a search method that is not optimal but has a low computational complexity. In addition the proposed strategy yields a low search delay as well as a low search cost. The performance of the proposed search strategy is superior to the implementation of an optimal single user search on a group of users.,10.1.1.1.3169,Location management Mobile Computing Wireless Networks,?
CONTENTS,Berkeley Calif University Daniel G. Maxwell,?,insecurity and vulnerability in drought-affected regions of Burkina Faso. In Seasonal variability in Third World agriculture: The consequences for food security ed. D. E. Sahn. Baltimore Md. U.S.A.: John Hopkins University Press for the International Food Policy Research Institute. Reardon T. P. Matlon and C. Delgado. 1988. Coping with household-level food insecurity in drought-affected areas of Burkina Faso. World Development 16 (9): 1065-1074. Sen A. K. 1981. Poverty and famines: An essay on entitlement and deprivation.  Oxford: Clarendon Press. Teklu T. 1992. Household response to declining food entitlement: The experience in western Sudan. Quarterly Journal of International Agriculture 31 (3): 247261.  Tshirley D. and M. Weber. 1992. The determinants of household income and consumption in rural Nampula Province: Implications for food security and agricultural policy reform. AEC Staff Paper #92-96 Department of Agricultural Economics Michigan State University East Lansi,10.1.1.1.3170,?,?
Towards Quantum Template Matching,Daniel Curtis David A. Meyer,2003,We consider the problem of locating a template as a subimage of a larger image. Computing the maxima of the correlation function solves this problem classically. Since the correlation can be calculated with the Fourier transform this problem is a good candidate for a superior quantum algorithmic solution. We outline how such an algorithm would work.,10.1.1.1.3171,image processing Fourier transform phase-only correlation,?
Distributed Scheduling of Recording Tasks with Interconnected Servers,Sergios Soursos George D. Stamoulis Theodoros Bozios,2004,We consider a system with multiple interconnected video servers storing TV programs that are received through satellite antennas. Users equipped with set-top boxes submit requests for TV programs to each of which they assign a utility value according to their preferences. We develop a distributed scheduling algorithm that selects the programs to be recorded and the servers to store them so that a high total utility is generated to the users population. Our scheduling algorithm is based on the programs broadcasting information the users preferences the constraints regarding the capabilities of simultaneous recordings and storage and the systems topology. In fact servers belonging to the same cluster co-operate in order to attain increased e#ciency by exchanging content through streaming or replication. The e#cient performance of our scheduling algorithm is shown by means of experiments. The algorithm constitutes a practically applicable solution already implemented and integrated in the testbed of the IST project UP-TV.,10.1.1.1.3172,?,?
Methodology for Reliable Schema Development and Evaluation of Manual Annotations,Petra S. Bayerl  Harald Lüngen Ulrike Gut  Karsten I. Paul,2003,The quality of manual annotations of linguistic data depends on the use of reliable coding schemas as well as on the ability of human annotators to handle them appropriately. As is well known from a wide range of previous experiences annotations using highly complex coding schemas often lead to unacceptable annotation quality. Reducing complexity might make schemas easier to handle but in this way valuable information needed for more sophisticated applications is excluded as well. In order to deal with this problem we developed a systematic approach to schema development which allows for developing coding schemas for fine-grained semantic annotations while systematically securing the quality of such annotations. For illustration we present examples from two projects where text and speech data are annotated.,10.1.1.1.3173,?,?
The Meaning and Role of Value in Scheduling Flexible Real-Time Systems,A. Burns  D. Prasad  A. Bondavalli  F. Di Giandomenico  K. Ramamritham  J. Stankovic  L. Strigini,2000,The real-time community is devoting considerable attention to flexible scheduling and adaptive systems. One popular means of increasing the flexibility and hence effectiveness of real-time systems is to use value-based scheduling. It is surprising however how little attention has been devoted in the scheduling field to the actual assignment of value. This paper deals with value assignment and presents a framework for undertaking value-based scheduling and advises on the different methods that are available. A distinction is made between ordinal and cardinal value functions. Appropriate techniques from utility theory are reviewed. An approach based on constant value modes is introduced and evaluated via a case example.,10.1.1.1.3174,Flexible scheduling Utility of service Value assignment,?
Performance Evaluation by Simulation,Helmut Hlavacs  Christoph W. Ueberhuber,2001,In this report the paradigms for simulating the performance of parallel hardware and software are investigated and the principles of discrete event and parallel and distributed simulation are explained in this context.,10.1.1.1.3175,?,?
Scrap Your Boilerplate: A Practical Design Pattern for Generic Programming,Ralf Lämmel Simon Peyton Jones,2003,We describe a design pattern for writing programs that traverse data structures built from rich mutually-recursive data types. Such programs often have a great deal of boilerplate code that simply walks the structure hiding a small amount of real code that constitutes the reason for the traversal. Our technique allows most...,10.1.1.1.3176,Design Languages Keywords Generic programming traversal rank-2 types type cast,ACM Press
On the Interaction between Data Aggregation and Topology Control in Wireless Sensor Networks,Vijay Erramilli  Ibrahim Matta  Azer Bestavros,2004,Wireless sensor networks are characterized by limited energy resources. To conserve energy application-specific aggregation (fusion) of data reports from multiple sensors can be beneficial in reducing the amount of data flowing over the network. Furthermore controlling the topology by scheduling the activity of nodes between active and sleep modes has often been used to uniformly distribute the energy consumption among all nodes by de-synchronizing their activities. We present an integrated analytical model to study the joint performance of in-network aggregation and topology control. We define performance metrics that capture the tradeoffs among delay energy and fidelity of the aggregation. Our results indicate that to achieve high fidelity levels under medium to high event reporting load shorter and fatter aggregation/routing trees (toward the sink) offer the best delay-energy tradeoff as long as topology control is well coordinated with routing.,10.1.1.1.3177,?,?
Proceedings Of Iscas Geneva 2000,Monte Carlo Analysis,2000,In this paper we formulate and solve a new type of Monte Carlo problem for a resistive network. Given lower and upper bounds on the value of each resistor but no probability distribution we consider the problem of finding the expected value for a designated gain. In view of the fact that no apriori probability distributions for the uncertain resistors are assumed a certain type distributional robustness is sought. To this end a new paradigm from the robustness literature is particularized to circuits and results are provided in this context. Some of the performance bounds obtained via this new approach differ considerably from those which result from a more conventional Monte Carlo simulation.,10.1.1.1.3178,?,?
First Workshop on,Productivity And Performance Program Chair Ram Rajamony John Grosh Osd,2004,The enormous increase in computing power over the  last forty years has opened up new opportunities to  analyze and solve important problems that face society.,10.1.1.1.3179,?,?
Fast Panoramic Stereo Matching Using Cylindrical and Maximum Surfaces,Changming Sun Shmuel Peleg,2004,This paper presents a fast panoramic stereo matching algorithm using a cylindrical maximum surface technique. The disparity for a pair of panoramic images is found in a cylindrical shaped correlation coefficient volume by obtaining the maximum surface rather than simply choosing a position that gives the maximum correlation coefficient value. The use of our cylindrical maximum surface technique ensures that the disparities obtained at the left and the right columns of the panoramic stereo images are properly constrained. Typical running time for a pair of 1324120 images is about one third of a second on a 1.7GHz PC. A variety of real images have been tested and good results have been obtained.,10.1.1.1.3180,?,?
Semantic Annotation of Image Collections,Laura Hollink Guus Schreiber  Jan Wielemaker Bob Wielinga,2003,In this paper we discuss a tool for semantic annotation and search in a collection of art images. Multiple existing ontologies are used to support this process including the Art and Architecture Thesaurus WordNet ULAN and Iconclass. We discuss knowledge-engineering aspect such as the annotation structure and links between the ontologies. The annotation and search process is illustrated with an application scenario.,10.1.1.1.3181,?,?
The Minimum Manhattan Network Problem - A Fast Factor-3 Approximation,Marc Benkert  Florian Widmann  Alexander Wolff Er Wolff,2004,this paper we investigate how the extra degree of freedom in routing edges can be used to construct Manhattan networks of minimum total length socalled  minimum Manhattan networks (MMN). The MMN problem may have applications in city planning or VLSI layout. It has been considered before but until now its complexity status is not known. Gudmundsson et al. [2] have proposed an O(n log n)- time factor-8 and an O(n    )-time factor-4 approximation algorithm. Later Kato et al. [3] have given an O(n    )-time factor-2 approximation algorithm. However their correctness proof is incomplete,10.1.1.1.3182,?,?
Performance Monitoring of Service Level Agreements for Utility Computing using the Event Calculus,Andrew D.H. Farrell Andrew D H Farrell  David Trastour David Trastour Athena Christodoulou Athena Christodoulou,2004,Utility Computing (UC) is concerned with the provisioning of computational resources (compute-power storage network bandwidth) on a per-need basis to corporate businesses. Service-level Agreements (SLAs) - contracts between a provider and a customer - are a sine qua non in the deployment of UC. A crucial stage in the life-cycle of contracts (such as SLAs) is their automated performance monitoring at run-time.,10.1.1.1.3183,?,IEEE
Apparent Super-luminal Jets as a Test of Special Relativity,Curt Renshaw President,2001,this paper demonstrates that such is not necessarily the case. Determining the angle of the 1 10 100 Theta (degrees)  Apparent Velocity (times c) 2.5 7.5 12.5 17.5 22.5 27.5 32.5 37.5 42.5 47.5 52.5 57.5 62.5 67.5 72.5 77.5 82.5 87.5  Apparent Velocity vs. Angle of Jet Apparent velocities above shaded region represent a violation of SRT Figure 2 - Apparent velocity versus angle of jet with respect to line-of-sight jet is in many cases problematical and may sometimes be erroneously derived by working backwards from the assumption that the jet must have a velocity with respect to its source that is less than c. One must guard against the researchers tendency to do such backsolving. The analysis presented in this paper clearly warrants a search of all such apparently super-luminal jets to determine whether under SRT any of them require a velocity with respect to their host greater than  c as in the 79 degree case presented. If any are found that meet this criteria then clearly the second postulate and with it SRT are invalidated. Possibly more difficult but of potentially greater value is an analysis of the energy available to produce the observed jets. In the case of GRS 1915+105 the energy required under SRT is more than three times greater than that required under any of the Galilean invariant alternatives referenced herein. A careful study of the source might indicate that there is simply not enough energy available to produce the jets observed under the assumptions of SRT. Other orientations of jet to lineof -sight produce even greater energy differentials and thus provide even stronger tests,10.1.1.1.3184,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,We review two types of adaptive Monte Carlo methods for rare event simulations. These methods are based on importance sampling. The first approach selects importance sampling distributions by minimizing the variance of importance sampling estimator. The second approach selects importance sampling distributions by minimizing the cross entropy to the optimal importance sampling distribution. We also review the basic concepts of importance sampling in the rare event simulation context. To make the basic concepts concrete we introduce these ideas via the study of rare events of M/M/1 queues.,10.1.1.1.3185,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,The objective of this article is to present the results obtained after using a simulation optimization methodology applied to a production line from a secondary manufacturing wood processing plant of a well known Chilean mill. For this reason a simulation model constructed in ARENA was integrated to a genetic algorithms heuristic. The results obtained show that using a different configuration of the plant resources it is possible to reduce the total average cycle time in 18%. The resource configuration needed to reach this result was obtained evaluating just 1.6% of the total number of possible combinations.,10.1.1.1.3186,?,?
Algebraic and Model Theoretic Techniques for Fusion Decidability in Modal Logics,Silvio Ghilardi Luigi Santocanale Università Studi Di Milano Université Bordeaux,2003,We introduce a new method (derived from model theoretic  general combination procedures in automated deduction) for proving fusion  decidability in modal systems. We apply it to show fusion decidability  in case not only the boolean connectives but also a universal  modality and nominals are shared symbols.,10.1.1.1.3187,?,Springer
Artificial Intelligence Labs OntoText Lab. Bulgaria.,Final Report Dieter Dieter Fensel Frank Van Harmelen Ying Ding Michel Klein Peter Mika Hans Akkermans Jeen Broekstra Arjohn Kampman Jos Van Der Meer Thorsten Lau Ulrich Reimer Ian Horrocks Schweizerische Lebensversicherungs- Und Contact Person R. Studer,?,This document is part of a research project funded by the IST Programme of the Commission of the European Communities as project number IST/1999/10132. The partners in this project are: Vrije Universiteit Amsterdam (VU) (co-ordinator) NL the University of Karlsruhe Germany Schweizerische Lebensversicherungs- und Rentenanstalt / Swiss Life Switzerland British Telecommunications plc UK CognIT a.s Norway EnerSearch AB Sweden AIdministrator Nederland BV NL and Sirma AI Ltd. - Artificial Intelligence Labs OntoText Lab. Bulgaria,10.1.1.1.3188,?,?
Developing a Practical Programming by Demonstration Tool,Gordon W. Paynter   Ian H. Witten,2000,Many iterative tasks in direct manipulation interfaces cannot be automated with standard application tools forcing users to repeat the same interface actions again and again. We describe a domain-independent programming by demonstration system that learns iterative tasks in a range of widely-used applications on a popular computer platform. An evaluation showed that users are capable of using the agent to automate iterative tasks and will choose to do so in many circumstances. It also found many shortcomings which were corrected in a new version of the interface. This paper recounts the design process the first interface the evaluation and consequent revisions.,10.1.1.1.3189,programming by demonstration user interface,?
The Journal of Experimental Biology 205 1253–1263 (2002) Printed in Great Britain © The Company of Biologists Limited 2002,Mpf Swimming Is Keith E. Korsmeyer John Fleng Steffensen Jannik Herskin,?,MPF swimming are presumably advantageous for movement through structurally complex habitats such as coral reefs where many 1253 The Journal of Experimental Biology 205 1253--1263 (2002)  Printed in Great Britain The Company of Biologists Limited 2002  JEB3973  To determine the energetic costs of rigid-body median or paired-fin (MPF) swimming versus undulatory bodycaudal fin (BCF) swimming we measured oxygen consumption as a function of swimming speed in two MPF swimming specialists Schlegels parrotfish and Picasso triggerfish. The parrotfish swam exclusively with the pectoral fins at prolonged swimming speeds up to 3.2 total lengths per second (L s     30 min critical swimming speed U crit ). At higher speeds gait transferred to a burst-andcoast BCF swimming mode that resulted in rapid fatigue. The triggerfish swam using undulations of the soft dorsal and anal fins up to 1.5 L s     beyond which BCF undulations were recruited intermittently. BCF swimming was used continuou,10.1.1.1.3190,?,?
Michelson-Morley Experiments Revisited and . . . ,Reginald T. Cahill Kirsty Kitto,2003,?,10.1.1.1.3191,Michelson interferometer Cosmic Background Radiation (CBR,?
Geographic Random Forwarding with Hybrid-ARQ for Ad Hoc Networks with Rapid Sleep Cycles,Bin Zhao  Rohit Iyer Seshadri Matthew C. Valenti Harbinger). Like Geraf Harbinger Assumes That,2004,This paper proposes and analyzes a new crosslayer protocol for ad hoc and sensor networks that unifies the concepts of Geographic Random Forwarding (GeRaF) and hybrid-ARQ. The protocol is given the descriptive name Hybrid ARq-Based Intra-cluster GEographically-informed Relaying (HARBINGER). Like GeRaF HARBINGER assumes that each node knows its own position and that messages are addressed by location. As is common for sensor networks the nodes cycle on-and-o# according to a sleep schedule. Unlike GeRaF which returns to the initial transmission state if no active node is within range the nodes in HARBINGER combine transmissions thereby achieving an additional timediversity benefit. With HARBINGER a lower density of active nodes will achieve almost the same delay and energy e#ciency as GeRaF implying that a lower duty cycle sleep schedule could be used to prolong the useful lifetime of the network. The paper gives detailed analysis of a version of the protocol (Fast-HARBINGER) whereby the sleep states of the network are synchronized with the data packet transmission rate of the network.,10.1.1.1.3192,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Charles Mclean Guodong Shao,?,Perhaps the most significant discriminating factor to be considered in developing a classification system for manufacturing simulation is industry market sector. The sector identifies the end-products that are to be manufactured. The hierarchy of organizations systems and processes are often unique to individual manufacturing sectors. Thus the models and data required for a simulation case study are determined first by the sector and next by the manufacturing hierarchical level.,10.1.1.1.3193,?,?
Putting MAIDs in Context,Mark Crowley Department,?,Multi-Agent Influence Diagrams (MAIDs) are a compact  modelling language for representing game theoretic settings.,10.1.1.1.3194,?,?
Model checking SPKI/SDSI,S. Jha T. Reps,2004,SPKI/SDSI is a framework for expressing naming and authorization issues arising in...,10.1.1.1.3195,?,?
1. Introduction From algorithms to generative grammar and back again,John Goldsmith,2004,this paper was presented: does not the message offered here risk making linguistics more dependent on the vagaries of the current computer metaphor at a time when we would prefer to have our notions be motivated by strictly linguistic concerns? The answer to this (quite reasonable) concern I suggested is that linguistics already is heavily dependent on the vagaries of current 5.1 Why dont we really try to minimize our grammar lengths? So why dont we really try to minimize the length of the grammars we write? Oddly enough I think this brings us to the heart of the question and Ill give a simple answer to this question. The answer is: it doesnt do any good to try to minimize the length of your grammar unless you add the restriction that your grammar is responsible for dealing with  all of the data where all of the data is established in some fashion antecedently to the analysis -- typically by collecting a corpus of data ahead of time. If you dont set such a condition then it is truly inevitable that the analysis will be given free rein to pick and choose the data that it analyses best and that is tantamount to giving the analysis permission to make itself very short. The demand to make the grammar compact makes sense and works only if we set a condition that the grammar must deal with all of the data and that includes the data that seems somehow wrong and it also includes all of the data that lies inbetween the data that is handled very well and the data that seems really wrong. It is sometimes surprising just how much data lies in that inbetween area in many cases it is the bulk of the data. If we are interested in morphology then we need a morphology of the data that analyzes every word in the corpus if syntax then a grammar that includes ever...,10.1.1.1.3196,?,?
User Expertise Modelling and Adaptivity in a Speech-based E-mail System,Kristiina Jokinen  Kari Kanto Hämeentie C,2004,This paper describes the user expertise model  in AthosMail a mobile speech-based e-mail  system. The model encodes the systems  assumptions about the user expertise and  gives recommendations on how the system  should respond depending on the assumed  competence levels of the user. The  recommendations are realized as three types of  explicitness in the system responses. The  system monitors the users competence with  the help of parameters that describe e.g. the  success of the users interaction with the  system. The model consists of an online and  an offline version the former taking care of  the expertise level changes during the same  session the latter modelling the overall user  expertise as a function of time and repeated  interactions.,10.1.1.1.3197,?,?
Bodily Sensations as an Obstacle for Representationism,Ned Block Nyu Ned Block,?,of thinking of something that could be called the representational content of experience have little to do with phenomenology or with the kind of properties that the representationist takes the phenomenology to constitutively represent. Thus the representationist thesis involves a partially stipulated notion of representational content. This is not in itself a criticism but as I shall argue there is a problem about how the stipulation should go in the case of pain. Thus in my view the dispute between Tye and Colin McGinn over whether pain even has representational content is not a dispute about a matter of fact but a dispute about how to talk. The same applies to Tyes claim that a referred pain (e.g. a pain in the inside of the left arm caused by malfunction in the heart or a pain in the groin caused by malfunction in the kidney) is non-veridical. Pretheoretically we might (might!) regard such a pain as misleading but not false or inaccurate or non-veridical. We are willing to ,10.1.1.1.3198,?,?
Strategies for Simulating Poverty- . . . ,Steven Haggblade Peter Hazell Thomas Reardon,2002,?,10.1.1.1.3199,?,?
Speaking and Acting -- Interacting Language and Action,For An Expressive Y Louchart Daniela Romano Ruth Aylett Jonathan Pickering,2004,We discuss the FearNot! application demonstrator currently being  developed for the EU framework V project VICTEC. It details the language  structure content interactions management and design of the FearNot!  Demonstrator as well as presenting the VICTEC project and its motivations.,10.1.1.1.3200,?,?
Symbolic Negotiation with Linear Logic,Peep Kungas And Peep Küngas Mihhail Matskin,2004,Negotiation over resources and multi-agent planning are important  issues in multi-agent systems research. It has been demonstrated [19]  how symbolic negotiation and distributed planning together could be  formalised as distributed Linear Logic (LL) theorem proving. LL has  been chosen mainly because of its expressive power for representation  of resources and its computation-oriented nature. This paper extends  the previous work by taking advantage of a richer fragment of LL and  introducing two sorts of nondeterministic choices into negotiation. This  allows agents to reason and negotiate under certain degree of uncertainty.,10.1.1.1.3202,?,Springer-Verlag
A Procedure For High Reproducible . . .,Emilia Nunzi Paolo Carbone Dario Petri,2004,The evaluation of spectral parameters characterizing analog--to--digital converters (ADC) is addressed  by applying a single or dual tone generator to the device input and by properly processing its output data  stream. The coherent sampling condition highly recommended by the IEEE standards 1057 and 1241 which  list the most effective ADC testing procedures is usually difficult to achieve and sometimes even unfeasible.,10.1.1.1.3203,?,?
Bumper Crops Producer Incentives and Persistent Poverty: Implications for,Paul Dorosh Paul Dorosh Quazi Shahabuddin Quazi Shahabuddin M. Abdul Aziz M. Abdul Aziz Naser Farid Naser Farid Contact Candice Cohen Contact Candice Cohen,?,iii 1.,10.1.1.1.3205,BUMPER CROPS PRODUCER INCENTIVES AND PERSISTENT POVERTY IMPLICATIONS FOR FOOD AID PROGRAMS IN BANGLADESH,?
Process Group Management in Cross-Layer Adaptation,Wanghong Yuan Klara Nahrstedt,2004,Our previous MMCN03 paper reported a cross-layer adaptation framework GRACE-1 that coordinates the adaptation of CPU frequency/voltage CPU scheduling and application quality. GRACE-1 assumes that all application processes (or threads) are independent from each other and adapt individually. This assumption however is invalid for multithreaded applications that include dependent and cooperative processes. To support the joint performance requirements of such dependent processes this paper extends GRACE-1 with a process group management mechanism. The enhanced framework called GRACE-grp introduces a new OS abstraction group control block to provide the OS-level recognition and support of process groups. Through a group control block dependent processes can explicitly set up a group and specify their dependency in the OS kernel. Consequently GRACE-grp schedules and adapts them in a synchronized and consistent manner thereby delivering joint performance guarantees. We have implemented and evaluated the GRACE-grp framework. Our experimental results show that compared to GRACE-1 GRACE-grp provides better support for the joint quality of dependent processes and reduces CPU energy consumption by 6.2% to 8.7% for each process group.,10.1.1.1.3206,Adaptation Process Group Management Energy Saving Quality of Service,?
A Comparative Assessment of Peer-to-Peer and Server-Based Configuration Management System,Carlo Bellettini Lorenzo Capra  Mattia Monga,?,Configuration management tools are traditionally server-based applications. To deal with the new issues emerging from the current (and future) cooperative work scenarios in which connectivity is intrinsically transient new applications based on of a fully decentralized peer-to-peer architecture were proposed. In this paper we analyze these two architectures leveraging on Stochastic Well-Formed Nets (SWN) models in order to compare the impact of the two alternative protocols on the collaborative work.,10.1.1.1.3207,?,?
Bridging Router Performance and Queuing Theory,Hohn Veitch Department N. Hohn D. Veitch C. Diot,2004,This paper provides an authoritative knowledge of through-router packet delays and therefore a better understanding of data network performance. Thanks to a unique experimental setup we capture all packets crossing a router for 13 hours and present detailed statistics of their delays. These measurements allow us to build the following physical model for router performance: each packet experiences a minimum router processing time before entering a fluid output queue. Although simple this model reproduces the router behaviour with excellent accuracy and avoids two common pitfalls. First we show that in-router packet processing time accounts for a significant portion of the overall packet delay and should not be neglected. Second we point out that one should fully understand both link and physical layer characteristics to use the appropriate bandwidth value.,10.1.1.1.3208,C.2.3 [Computer-communications Networks Network Operations – Network monitoring General Terms Measurement Theory Keywords Packet delay analysis router model,?
The Translation Power of the Futamura Projections,Robert Glück,2003,Despite practical successes with the Futamura projections  it has been an open question whether target programs produced by specializing  interpreters can always be as e#cient as those produced by  a translator. We show that given a Jones-optimal program specializer  with static expression reduction there exists for every translator an interpreter  which when specialized can produce target programs that are  at least as fast as those produced by the translator. This is not the  case if the specializer is not Jones-optimal. We also examine Ershovs  generating extensions give a parameterized notion of Jones optimality  and show that there is a class of specializers that can always produce  residual programs that match the size and time complexity of programs  generated by an arbitrary generating extension. This is the class of generation  universal specializers. We study these questions on an abstract  level independently of any particular specialization method.,10.1.1.1.3209,?,?
Pattern Recognition 33 (2000) 1919}1925,Mrf Parameter Estimation Lei Wang Jun Liu Stan Z. Li,?,Markov random eld (MRF) modeling is a popular pattern analysis method and MRF parameter estimation plays an important role in MRF modeling. In this paper a method based on Markov Chain Monte Carlo (MCMC) is proposed to estimate MRF parameters. Pseudo-likelihood is used to represent likelihood function and it gives a good estimation result. # 2000 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.,10.1.1.1.3210,MRF MCMC Least-squares quott Parameter estimation Pseudo-likelihood,?
Exercises 131 The dynamic semantics is given by the following transition rules:,Unbox Box Unbox,?,re expression box(m) is a value that contains an unevaluated  impure expression m the expression m is said to be boxed. Boxed expressions can be used as ordinary values without restriction. The expression  unbox(e) opens the box and evaluates the impure expression inside it is therefore itself an impure expression.  The static semantics of this extension is given by the following rules:    m : #    box(m) : ! #    e : ! #    unbox(e) : #  15.1 Monadic MinML 129 Most of the rules are as for MinML the main differences are given below.  # f :# 1 # # 2  x:# 1    m : # 2    fun f (x:# 1 ):# 2 ismend : # 1 # # 2    e 1 : # 2 # # #      apply(: #)        return e : #    m 1 : # 1 # x:# 1    m 2 : # 2    bindx:# m 1 inm 2 : # 2    e : bool #    m 1 : # #    m 2 : #    if # e thenm 1 elsem 2 fi : #  So far we have not presented any mechanisms for engendering effects! Monadic MinML is rather a framework for a wide variety of effects that we will instantiate to the case of mutable storag,10.1.1.1.3211,?,?
An Efficient Image Reconstruction Algorithm For A,Multiple Hydrophone Array P. T. Gough M. P. Hayes D. R. Wilkinson,2000,This paper shows how data from a multiple-hydrophone SAS may be combined efficiently for use with single-hydrophone image reconstruction procedures like the wavenumber algorithm. Example code in Matlab shows the importance of program efficiency in applying this algorithm,10.1.1.1.3213,?,?
Displaying Aggregate Data Interrelated Quantities and Data Trends in Electric,Power Systems Ray Ray Klump,2003,This paper describes a number of effective techniques for visualizing some of the more complex data relationships that characterize an electric power system in real time. Power systems are large dynamic physical entities that are constantly changing. While SCADA systems capture the quantitative aspects of these changes visualizing their magnitudes pinpointing their locations and interpreting their collective significance for the current and future security of the interconnection pose tremendous challenges for system operators. This paper describes how advanced visualization techniques such as area tie diagrams calculated data analogs historical trend animations and three-dimensional views clarify the complex relationships aggregate subsystem characteristics and emerging trends that describe the current state of the interconnection and help predict its future evolution. The paper provides a number of illustrations that demonstrate the effectiveness of the proposed techniques.,10.1.1.1.3216,?,?
Content-Based Retrieval of Technical Drawings,Manuel J. Fonseca Alfredo Ferreira Joaquim A. Jorge,2004,This paper presents a new approach to classify index and retrieve technical draw-ings by content. Our work uses spatial relationships shape geometry and high-dimensional indexing mechanisms to retrieve complex drawings from CAD databa-ses. This contrasts with conventional approaches which use mostly textual metadata for the same purpose. Creative designers and draftspeople often re-use data from previous projects publications and libraries of ready-to-use components. Usually retrieving these drawings is a slow complex and error-prone endeavor requiring either exhaustive visual examination a solid memory or both. Unfortunately the widespread use of CAD systems while making it easier to create and edit drawings exacerbates this problem insofar as the number of projects and drawings grows enormously without providing adequate searching mechanisms to support retrieving these documents. We describe an approach that supports automatic indexation of technical drawing databases through drawing simplification feature extraction and efficient algorithms to index large amounts of data. We describe in detail all the steps of our classification 1 process to content-based retrieval of technical drawings (CAD) and present results from usability tests on our prototype.,10.1.1.1.3217,Content-Based Retrieval High-Dimensional Indexing Graph Spectra Po- lygon Detection Feature Extraction,?
Agreement-Based Interactions for Experimental,Science Katarzyna Keahey Katarzyna Keahey Takuya Araki Peter Lane,2004,Enabling quality of service (QoS) in the Grids requires not only  resource management strategies but also the development of protocols enabling  structured negotiation for the use of resources. Such protocols will allow the  creation of policies dynamically and automatically broadening the scope of  Grid applications. In this paper we describe design implementation and  application of an agreement-based infrastructure. We then discuss its use in the  virtual control room developed for the National Fusion Collaboratory.,10.1.1.1.3218,?,?
A Distributed Content-Based Search Engine Based on Mobile Code,Volker Roth  Ulrich Pinsdorf  Jan Peters,2005,Current search engines crawl the Web download content and digest this content locally. For multimedia content this involves considerable volumes of data. Furthermore this process covers only publicly available content because content providers are concerned that they otherwise loose control over the distribution of their intellectual property. We present the prototype of our secure and distributed search engine which dynamically pushes content based feature extraction to image providers. Thereby the volume of data that is transported over the network is significantly reduced and the concerns mentioned above are alleviated. The distribution of feature extraction and matching algorithms is done by mobile software agents. We give a description of the search engines architecture and implementation quantitative evaluation results and a discussion of related security mechanism for content protection and server security.,10.1.1.1.3219,Search process H.3.4 [Systems and Software] Distributed systems Information networks H.3.7 [Digital Libraries Content based retrieval mobile agents,ACM Press
Seasonal Undernutrition in Rural Ethiopia Magnitude Correlates and Functional Significance,In Rur Al Anna Ferro-luzzi Saul S. Morris Samson Taffesse Tsegaye Demissie,?,this report may be  reproduced without the express permission of but with  acknowledgment to the International Food Policy  Research Institute,10.1.1.1.3220,List of Figures v,?
A Simple Algorithm for Topic Identification in 0-1 Data,Jouni K. Seppänen Ella Bingham Heikki Mannila,2003,Topics in 0-1 datasets are sets of variables whose occurrences are positively connected together. Earlier we described a simple generative topic model. In this paper we show that given data produced by this model the lift statistics of attributes can be described in matrix form. We use this result to obtain a simple algorithm for finding topics in 0-1 data. We also show that a problem related to the identification of topics is NP-hard. We give experimental results on the topic identification problem both on generated and real data.,10.1.1.1.3221,?,Springer-Verlag
Calcul De Routages Equitables Dans Les REseaux Internet, Nhat Linh Doan et al.,2003,In this paper we consider the problem of fair routing in multicommodity networks. We present here an algorithm for calculating fair routing in a network where the available resources are shared among competing flows according to a max-min share criterion. Our main interest is computing optimal routing paths with regard to max-min fairness in stable and known traffic conditions. It is a linear programming based approach which permits a lexicographical maximization of vector of fair-share attributed to the connections competing for network resources.,10.1.1.1.3222,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson Deborah L. Heflin Charles R. Harrell,?,The ProModel Optimization Suite is a powerful yet easyto -use simulation tool for modeling all types of manufacturing systems ranging from small job shops and machining cells to large mass production flexible manufacturing systems and supply chain systems. ProModel is a Windows based system with an intuitive graphical interface and object-oriented modeling constructs that eliminate the need for programming. It combines the flexibility of a general-purpose simulation language with the convenience of a data-driven simulator. In addition ProModel utilizes an optimization tool called SimRunner that performs sophisticated what-if analysis by running automatic factorial design of experiments on the model providing the best answer possible. This tutorial provides an overview of the ProModel Optimization Suite and presents its modeling analysis and optimization capabilities.,10.1.1.1.3223,?,?
Accurate Minkowski Sum Approximation of Polyhedral Models,Gokul Varadhan Dinesh Manocha Brake Hub Rod Brake Hub Rod Bunny Bunny Offset,2004,We present an algorithm to approximate the 3D Minkowski sum of polyhedral objects. Our algorithm decomposes the polyhedral objects into convex pieces generates pairwise convex Minkowski sums and computes their union. We approximate the union by generating a voxel grid computing signed distance on the grid points and performing isosurface extraction from the distance field.,10.1.1.1.3224,?,?
Composite Mouse Gestures: Toward an Easier Tool for Behavior Authoring,Edward Yu-Te Shen Shen Kuei-yuan Zheng Bing-yu Chen,?,Introduction  An authoring tool with graphical user interface has been a longunsolved problem in behavioral animation production. We propose a solution by introducing a breakthrough of utilizing mouse gestures - Composite Mouse Gestures (CMG).  2 Behavior Authoring  Behavioral animation design acts an important part in animation production. Authoring behaviors for virtual characters means to specify how and when actions take place such that autonomous interactive and lifelike behaviors can be brought. Previous works for behavior authoring (also referred to as behavior modeling) can be broadly categorized into two divisions including script languages and learning approaches. Script languages such as CML (Cognitive Modeling Language) [Funge et al. 1999] provide high-level syntaxes that benefit programmers to describe behaviors more easily than using conventional languages. Learning approaches on the other hand attempt to generate behaviors with nearly no programming interventions ,10.1.1.1.3225, Composite Mouse Gestures (CMG,?
Inlier Modeling for Multimedia Data Analysis,Rozenn Dahyot Niall Niall Rea Anil Kokaram,2004,This paper presents a robust method to estimate the unknown standard deviation of a centred normal distribution from a mixture density. This method is applied to different signal processing problems. The first one concerns silence segmentation from audio data. The second application deals with colour class parameter extraction. In this later case the mean is also estimated from the observations.,10.1.1.1.3226,?,?
Software Component Technologies for Real-Time Systems - An Industrial Perspective,Anders Möller  Mikael Åkerholm  Johan Fredriksson  Mikael Nolin,1992,In this paper we compare existing component technologies for embedded systems with respect to requirements captured from the vehicular industry.,10.1.1.1.3227,?,?
Wavelet Based Texture Synthesis,Claire Gallagher  Anil Kokaram,2004,This paper presents a new algorithm for synthesising image texture. Texture synthesis is an important  process in image post-production. The best previous approaches have used non-parametric  methods for synthesising texture. Unfortunately these methods generally suffer from high computational  cost and difficulty in handling scale in the synthesis process. This paper introduces a new idea  of using wavelet decomposition as a basis for non-parametric texture synthesis. The results show an  order of magnitude improvement in computational speed and a better approximation of the dominant  scale in the synthesised texture.,10.1.1.1.3228,Texture Synthesis Complex Wavelet Transform Image Processing Non-parametric Image Modeling. Figure 1 Texture synthesis Given an example texture Ie as an input (left the algorithm aims to reproduce new,?
Weber-type Laws of Action-at-a-Distance in Modern Physics,Thomas E. Phipps  Jr.,1990,this paper. The law is a modernized version previously suggested (Phipps to be published) of Webers original force law modified to circumvent the Helmholtz objection and to express the existence of a limiting relative charge velocity c. It conforms to the original Weber method in using purely relative quantities in the description of the fundamental charge pair: source charge and test charge. If we know all there is to know about this fundamental pair do we not know all that is needed for (near-zone) electrodynamics? Do we also need field theory? Surely npt for describing force actions. (Here one must re-emphasize the profound physical distinction between force and radiation. There has been altogether too much feckless unification for the health of physics. If we could get a theory that would do one thing right would be a step forward.)  The salient feature of Weber-type laws is that they rigorously obey Newtons third law and agree with Amperes law of ponderomotive action between current elements. The latter is the important new constraint that viable physical theory must obey---and that field theories and established relativity theory based on the Lorentz force law violate. Rather it is an ancient constraint (over 160 years old) the empirical validity of which has been ignored until recently... and it remains controversial (Christodoulides 1987 1988 Jolly 1985 Ternan 1985),10.1.1.1.3229,?,?
Graph Complexity of Chemical Compounds in Biological Pathways,Atsuko Yamaguchi Kiyoko F. Aoki Hiroshi Mamitsuka,2003,Introduction  Graph theory for chemical compounds is often studied for the fact that labeled graphs are suited to express the connectivity of chemical compounds [4]. However in the field of chemoinformatics methods using graph algorithms have not entered the mainstream because graph problems comparing two graphs are often intractable. For example the problem of finding the maximum common subgraph of two graphs is known to be NP-hard [1] even for two graphs of bounded degree [3]. Therefore we focus on chemical compounds in biological pathways and analyze the characteristics of the chemical compounds to reduce the problem space to allow for tractable comparisons of graphs.  In analyzing these characteristics we can focus on consistent measures for estimating the similarity of chemical compounds. Such measures are essential for gaining an understanding of the structural aspects of chemical compounds. They also assist in useful tasks such as querying chemical databases. As an example,10.1.1.1.3230,chemical compounds molecular graph graph theory tree-width,?
Improving Transfer Rates in Brain Computer Interfacing: A Case Study,Peter Meinicke Matthias Kaper  Florian Hoppe Manfred Heumann Helge Ritter,2003,In this paper we present results of a study on brain computer interfacing.,10.1.1.1.3232,?,MIT Press
Controlling Spam by Secure Internet Content Selection,Amir Herzberg,2004,Unsolicited and undesirable e-mail (spam) is a growing problem for Internet users and service providers. We present the Secure Internet Content Selection (SICS) protocol an efficient cryptographic mechanism for spam-control based on allocation of responsibility (liability). With SICS e-mail is sent with a content label and a cryptographic protocol ensures labels are authentic and penalizes falsely labeled e-mail (spam). The protocol supports trusted senders (penalized by loss of trust) and unknown senders (penalized financially). The recipient can determine the compensation amount for falsely labeled e-mail (spam)). SICS is practical with negligible overhead gradual adoption path and use of existing relationships it is also flexible and appropriate for most scenarios including deployment by end users and/or ISPs and support for privacy and legitimate properly labeled commercial e-mail. SICS improves on other crypto-based proposals for spam controls and complements non-cryptographic spam controls.,10.1.1.1.3233,?,?
Incorporating Biology into Discrete Event Simulation Models of Organ Allocation,E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Jennifer Kreke Andrew J. Schaefer,2002,We describe a discrete event simulation model of the national liver allocation system. This model differs from previous modeling efforts in that it considers the natural history of the disease independently of any particular patient priority scheme thus allowing an unbiased appraisal of various allocation schemes. We provide the basic structure of the model which consists of patient and organ generators a survival module and a disease progression module. The model provides various outputs such as patient survival financial cost and the number of wasted organs. We describe our model of patient survival with and without a transplant. We discuss some difficulties estimating model parameters due to a lack of appropriate medical data and how these difficulties were overcome. We close with conclusions and directions for further research.,10.1.1.1.3234,?,?
Scalable View Expansion in a Peer Mediator System,Timour Katchaounov  Vanja Josifovski  Tore Risch,2003,To integrate many data sources we use a peer mediator framework where views defined in the peers are logically composed in terms of each other. A common approach to execute queries over mediators is to treat views in data sources as black boxes. The mediators locally decompose queries into query fragments and submit them to the data sources for processing. Another approach used in distributed DBMSs is to treat the views as transparent boxes by importing and fully expanding all views and merge them with the query. The black box approach often leads to inefficient query plans. However in a peer mediator framework full view expansion (VE) leads to prohibitively long query compilation times when many peers are involved. It also limits peer autonomy since peers must reveal their view definitions. We investigate in a peer mediator framework the tradeoffs between none partial and full VE in two different distributed view composition scenarios. We show that it is often favorable with respect to query execution and sometimes even with respect to query compilation time to expand those views having common hidden peer subviews. However in other cases it is better to use the black box approach in particular when peer autonomy prohibits view importation. Based on this a hybrid strategy for VE in peer mediators is proposed.,10.1.1.1.3235,?,?
K-Nearest Neighbor Classification on Spatial Data Streams Using P-Trees,Maleq Khan   Qin Ding William Perrizo,2002,Classification of spatial data has become important due to the fact that there are huge volumes of spatial data now available holding a wealth of valuable information. In this paper we consider the classification of spatial data streams where the training dataset changes often. New training data arrive continuously and are added to the training set. For these types of data streams building a new classifier each time can be very costly with most techniques. In this situation k-nearest neighbor (KNN) classification is a very good choice since no residual classifier needs to be built ahead of time. For that reason KNN is called a lazy classifier. KNN is extremely simple to implement and lends itself to a wide variety of variations. The traditional k-nearest neighbor classifier finds the k nearest neighbors based on some distance metric by finding the distance of the target data point from the training dataset then finding the class from those nearest neighbors by some voting mechanism. There is a problem associated with KNN classifiers. They increase the classification time significantly relative to other non-lazy methods. To overcome this problem in this paper we propose a new method of KNN classification for spatial data streams using a new rich data-mining-ready structure the Peano-count-tree or Ptree. In our method we merely perform some logical AND/OR operations on P-trees to find the nearest neighbor set of a new sample and assign the class label. We have fast and efficient algorithms for AND/OR operations on P-trees which reduce the classification time significantly compared with traditional KNN classifiers. Instead of taking exactly the k nearest neighbors we form a closed-KNN set. Our experimental results show closed-KNN yields higher classification ac...,10.1.1.1.3236,Data Mining K-Nearest Neighbor Classification P-tree Spatial Data Data Streams. 1 Patents are pending on the bSQ and Ptree,?
Quality Approach of Web Documents by an Evaluation of Structure Relevance,Antoine Gagneux Vronique Antoine Gagneux Véronique Eglin Hubert Emptoz,2001,In this paper we present a user approach to evaluate a commercial web site quality. Due to the difficulty to define a web site the associated quality can be evaluated from different information. We chose to study the behavior of an observer during the exploration of the page and to convert it with a specific analysis of the document structure. In this paper we propose a definition of quality in relation with a retrieval information goal included designers intentions and users need. The visual scanpath studied with an eye-tracker. We will explain and show the link between the visual quality and gaze movement obtained from oculometric data. Finally the structure of document will show its strong connection with the web site visual quality.,10.1.1.1.3237,?,?
Multimedia Object Modelling and Content-Based Querying,Anastasia Analyti  Stavros Christodoulakis,1995,Multimedia Database Systems (MMDS) support rich data types such as text images video and sound. Queries in MMDSs may refer to the content of the stored multimedia objects. This is called content-based querying. However manual entry of content descriptions is very difficult and subjective.,10.1.1.1.3238,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,The stochastic root finding problem (SRFP) involves finding points in a region where a function attains a prespecified target value using only a consistent estimator of the function. Due to the properties that the SRFP contexts entail the development of good solutions to SRFPs has proven difficult at least in the multi-dimensional setting. This paper discusses certain key issues insights and complexities for SRFPs. Some of these are important in that they point to phenomena that contribute to the difficulties that arise in the development of efficient algorithms for SRFPs. Others are simply observations sometimes obvious but important for providing useful insight into algorithm development.,10.1.1.1.3239,?,?
Proceedings of the 2003 Winter Simulation Conference S. Chick P. J. Snchez D. Ferrin and D. J. Morrice eds.,Simulation Of Freeway S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Daiheng Ni,?,Hurdle and Son (Son 1996 Hurdle and Son 2000)  tested the accuracy of Newells theory and the adequacy of  its underlying assumption the triangular flow-density relationship with real data collected from freeways in the San  Francisco Bay Area. The test results support the validity of  Newells theory and show that the theory works best under  over-saturated conditions. Leonard (1997) coded Newells  theory into software GTWaves which bridges the theory  and its application.  Simplified theory of kinematic waves was proposed by  Newell and uses cumulative arrival and departure counts to  describe kinematic waves of freeway traffic. The original  paper deals only with traffic on freeway mainline. It is of  great interest at least practically to investigate whether the  simplified theory can be used to simulate freeway traffic  merging and diverging behavior. In his paper Newell assumed that on-ramp traffic always has the priority and can  bypass queues if any. This assumption will be released so  that traffic from the mainline and the on-ramp will have to  compete for downstream supply. For off-ramps Newell  assumed that all vehicles that want to exit can always be  able to do so. Again this assumption is also released so  that queues from either downstream can build up and block  upstream traffic.   Though Newell confined his theory to freeway  mainline it is possible to describe freeway merging and diverging behavior after relaxing some of its assumptions.  This has important practical implications because the extension would allow analysis of alternate diversion strategies  (in case of incidents on the freeway) and ramp metering  strategies (to minimize the overall system-wide delay) if a  queuing model computing delays on ramps is incorporated.   2 SUMMAR...,10.1.1.1.3240,?,?
How Many Ways Can Things Be The Same? Set Theory For Multiple-Site Surveys ,Richard G. Clegg,2004,This paper describes a rigorous set-theoretic framework for analysing the result of surveys which take place over multiple sites and where the surveyor needs to match surveyed items between more than two of those sites. In the analysis of roadside survey data it is often desirable to analyse matches between several data sets simultaneously. For example we might wish to answer questions of the general type How many drivers are seen at point A point B and point C? or How many vehicles are seen on all five survey days? This paper attempts to create a general framework for the analysis of matching between data from more than two surveys. The framework is then applied to the specific case of false matching in partial licence plate surveys (that is non-matches which are mistaken for matches because only part of the licence plate is observed). It should be stressed throughout that the framework outlined is applicable to any data series where matches are sought between two or more distinct data sets. In the first,10.1.1.1.3242,?,?
Modeling the Impact of Device and Pipeline Scaling on the Soft Error Rate of Processor Elements,Premkishore Shivakumar  Stephen W. Keckler Doug Burger  Michael Kistler Lorenzo Alvisi,2002,This paper examines the effect of technology scaling and microarchitectural trends on the rate of soft errors in CMOS memory and logic circuits. We describe and validate an end-to-end model that enables us to compute the soft error rates (SER) for existing and future microprocessor-style designs. The model captures the effects of two important masking phenomena electrical masking and latching-window masking which inhibit soft errors in combinational logic. We quantify the SER due to high-energy neutrons in SRAM cells latches and logic circuits for feature sizes from 600nm to 50nm and clock periods from 16 to 6 fan-out-of-4 inverter delays. Our model predicts that the SER per chip of logic circuits will increase nine orders of magnitude from 1992 to 2011 and at that point will be comparable to the SER per chip of unprotected memory elements. Our result emphasizes that computer system designers must address the risks of soft errors in logic circuits for future designs.,10.1.1.1.3243,?,?
Population Pressure Land Tenure And Tree,Resource Management In Frank Place Keijiro Otsuka,?,This study uses aerial photographs and survey data from sixty four parishes in eastcentral Uganda to identify the factors affecting conversion of woodlands and traditional grazing areas to agriculture. Regression analysis shows that customary land tenure institutions greater population pressure and poor access to markets are significant causes of land conversion to agriculture and hence to loss of trees. Private ownership of converted land promotes greater integration of trees and crops and leads to the highest density of trees on agricultural land. Given that continuing population growth will lead to further land conversion to agriculture the best prospect for maintaining or increasing tree populations lies with agroforestry on cultivated land.,10.1.1.1.3244,?,?
BootCaT: Bootstrapping Corpora and Terms from the Web,Marco Baroni  Silvia Bernardini,2004,This paper introduces the BootCaT toolkit a suite of perl programs implementing an iterative procedure to bootstrap specialized corpora and terms from the web. The procedure requires only a small set of seed terms as input. The seeds are used to build a corpus via automated Google queries and more terms are extracted from this corpus. In turn these new terms are used as seeds to build a larger corpus via automated queries and so forth. The corpus and the unigram terms are then used to extract multi-word terms. We conducted an evaluation of the tools by applying them to the construction of English and Italian corpora and term lists from the domain of psychiatry. The results illustrate the potential usefulness of the tools.,10.1.1.1.3245,?,?
Improved Detection of Low-Profile . . .,William W. Streilein Robert K. Cunningham Seth E. Webster,2001,We present enhancements to our network-based intrusion detection system which makes use of multiple neural network classifiers to accurately detect several classes of attacks including stealthy probes and novel denial-of-service attacks. An intrinsic representation of the local network and detection features derived from network traffic enable the system to detect entire attack classes. Improvements to our system include enhanced robust TCP session reconstruction handling simplex and duplex traffic modes an expanded feature vector that includes measures of inter-packet delays and counts of anomalous TCP sessions and binary tree-based internal data structures which are faster and less vulnerable to attack. Our system achieves a detection rate of 100% with a false alarm rate of .1% when tested against stealthy attacks in the DARPA 1999 IDS Evaluation. It also performs well on a moderately loaded research network.,10.1.1.1.3246,?,?
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros B. A. Peters J. S. Smith D. J. Medeiros M. W. Rohrer Leonardo Chwif,?,Over the past years there has been a growth in simulation courses both at undergraduate and postgraduate levels. A discrete event simulation course as with any non-basic course has some prerequisites that must be satisfied by students before attending classes. Statistics computer programming and modeling are the most important together with knowledge on the specific field being simulated (manufacturing logistics etcetera). Are students sufficiently prepared to follow a course on simulation? This work is related to the construction application and analysis of an assessment instrument to evaluate student prerequisite knowledge for a discrete event simulation course. The proposed questionnaire was given to the 5    year engineering students at the beginning of our first year (72 hours) discrete event simulation introductory course at Mau School of Engineering. The results obtained show the importance of making an assessment evaluation in order to improve the quality of simulation learning.,10.1.1.1.3247,?,?
DL-Lite: Practical Reasoning for Rich DLs,Diego Calvanese Giuseppe De Giacomo Maurizio Lenzerini Riccardo Rosati Guido Vetere,2004,In this paper we study a DL rich enough to express UML class diagrams  including ISA and disjointness between classes (but not covering constraints)  typing of associations and participation and functional cardinality constraints. For such a ,10.1.1.1.3248,?,?
Prototype Based Recognition of Splice Sites,Barbara Hammer Marc Strickert Thomas Villmann,?,Introduction  Rapid advances in biotechnology have made massive amounts of biological data available so that automated analyzing tools constitute a prerequisite to cope with  huge and complex biological sequence data. Machine learning tools are used for  widespread applications ranging from the identification of characteristic functional  sites in genomic DNA [39] the prediction of protein secondary structure and higher structures [53] to the classification of the functionality of chemical compounds [5]. Here we will deal with a subproblem in de novo gene finding in DNA sequences of a given species the problem of splice site recognition. For higher eukaryotic mechanisms gene finding requires the identification of the start and stop codons and the recognition of all introns i.e. non-coding regions which are spliced out before transcription that means all donor and acceptor sites of the sequence.  The biological splicing process is only partially understood [64]. Fig. 1 depicts a sc,10.1.1.1.3249,?,Springer-Verlag
VOD services for mobile wireless devices,Bruneo Villari Zaia D. Bruneo M. Villari A. Zaia A. Puliafito,?,Wireless devices are becoming very popular and powerful enough to be commonly adopted to access distributed services. More and more sophisticated applications are being developed and a very promising market is quickly being established where mobile users may access multimedia data while roaming from a cell to another anytime and everywhere. Such scenario requires a strong infrastructure in order to adequately manage all the di#erent issues related with high level service provisioning. QoS represents one of the most crucial issues as it involves many di#erent aspects and directly impacts the user satisfaction. In order to achieve this target we propose an architecture which allows mobile devices to access advanced services available in the wired part of the network. This architecture based on mobile agents technology assumes the presence of a VOD Virtual Server. The strategy adopted is to hide all the basic mechanisms inside a middleware layer that provides the necessary interfaces to allow a simple interaction between the user on the one side and the network and the distributed services on the other. The overall architecture that is currently being implemented and tested has been used as an experimental environment to provide mobile users with a new service to access MPEG-4 flows.,10.1.1.1.3250,?,?
Integrating Query Processing and Data Mining in Relational DBMSs,Qiang Ding   William Perrizo Victor Shi Kirk Scott,?,In a database system careful selection  project and join (SPJ) optimisation methods are  needed to achieve good performance. This is an  area of much research in the past two decades  yet much remains to be done. Also researchers  have begun to view data mining as being an  integral part of query processing thus the two are  intended to be jointly optimised. Data mining is  at one end of the query spectrum and standard  SPJ queries are at the other in terms of request  definiteness (?). In SPJ queries the desired  result is fully describable ahead of time as one  relation while in data mining the desired result  can only be described after the fact as rules  decision trees partitions or similar constructs  (??). Nonetheless in both cases the user desires  to extract information from relational data and  very often the desired information involves both  SPJ querying and data mining (e.g. find all  association rules on a relation that is the result of  an SPJ query on several base relations). In this  paper we introduce a mechanism to facilitate  efficient SPJ query processing and data mining in  a unified fashion. Using a compression method  called Peano Trees (P-trees) I/O can be reduced  to an absolute minimum (??) indexes can be  eliminated entirely and query processing is  optimized with data mining effectively.,10.1.1.1.3252,?,?
Information Retrieval on the Semantic Web,Urvi Shah  Tim Finin  Anupam Joshi R. Scott Cost,2002,We describe an approach to retrieval of documents that contain of both free text and semantically enriched markup. In particular we present the design and implementation prototype of a framework in which both documents and queries can be marked up with statements in the DAML+OIL semantic web language. These statements provide both structured and semi-structured information about the documents and their content. We claim that indexing text and semantic markup together will signi  cantly improve retrieval performance. Our approach allows inferencing to be done over this information at several points: when a documentisindexed  when a query is processed and when query results are evaluated.,10.1.1.1.3253,ÀÝ?Ö? ? ÁÒ?ÓÖÑ?Ø?ÓÒ Ê?ØÖ??Ú?Ð,ACM Press
Calligraphic Interfaces: Mixed Metaphors for Design,João P. Pereira Joaquim A. Jorge Vasco A. Branco F. Nunes Ferreira,2003,CAD systems have yet to become usable at the early stages of  product ideation where precise shape definitions and sometimes even design  intentions are not fully developed. To overcome these limitations new  approaches which we call Calligraphic Interfaces use sketching as the main  organizing paradigm. Such applications rely on continuous input modalities  rather than discrete interactions characteristic of WIMP interfaces. However  replacing direct manipulation by sketching alone poses very interesting  challenges. While the temptation to follow the paper-and-pencil metaphor is  great free-hand sketch recognition remains an elusive goal. Further using  gestures to enter commands and sketches to draw shapes requires users to learn  a command set -- sketches do not enjoy the self-disclosing characteristics of  menus. Moreover the imprecise nature of interactions presents additional  problems that are difficult to address using present-day techniques. In this paper,10.1.1.1.3254,?,?
Spatiotemporal Forward Solution of the EEG and MEG Using Network Modeling,Viktor K. Jirsa  Kelly J. Jantzen Armin Fuchs J. A. Scott Kelso,2002,Dynamic systems have proven to be well suited to describe a broad spectrum of human coordination behavior such synchronization with auditory stimuli. Simultaneous measurements of the spatiotemporal dynamics of electroencephalographic (EEG) and magnetoencephalographic (MEG) data reveals that the dynamics of the brain signals is highly ordered and also accessible by dynamic systems theory. However models of EEG and MEG dynamics have typically been formulated only in terms of phenomenological modeling such as fixed-current dipoles or spatial EEG and MEG patterns. In this paper it is our goal to connect three levels of organization that is the level of coordination behavior the level of patterns observed in the EEG and MEG and the level of neuronal network dynamics. To do so we develop a methodological framework which defines the spatiotemporal dynamics of neural ensembles the neural field on a sphere in three dimensions. Using magnetic resonance imaging we map the neural field dynamics from the sphere onto the folded cortical surface of a hemisphere. The neural field represents the current flow perpendicular to the cortex and thus allows for the calculation of the electric potentials on the surface of the skull and the magnetic fields outside the skull to be measured by EEG and MEG respectively. For demonstration of the dynamics we present the propagation of activation at a single cortical site resulting from a transient input. Finally a mapping between finger movement profile and EEG/MEG patterns is obtained using Volterra integrals.,10.1.1.1.3256,?,?
The Beginnings of a Logical Semantics,Framework For The,?,The integration of spatial datasets from di#erent sources is becoming  an increasingly important issue. It is very desirable to have a  rigorous approach to integration as an ad hoc approach can easily lead  to incorrect inferences. This paper takes a formal approach giving the  beginnings of a logical semantics framework which allows meaning to  be defined mathematically for spatial datasets which represent certain  types of thematic map data. The basic idea is to interpret the datasets  as summarisations of spatial variables which are in turn interpreted  as sets of possible worlds (ways the world could be). This semantics  approach can give a formal meaning to pairs (or sets) of such datasets  which can then be used to determine the valid inferences from an integrated  dataset.,10.1.1.1.3257,?,?
Statistical Synopses for Graph-Structured XML Databases,Neoklis Polyzotis  Minos Garofalakis,2002,Effective support for XML query languages is becoming increasingly important with the emergence of new applications that access large volumes of XML data. All existing proposals for querying XML (e.g. XQuery) rely on a pattern-specification language that allows path navigation and branching through the XML data graph in order to reach the desired data elements. Optimizing such queries depends crucially on the existence of concise synopsis structures that enable accurate compile-time selectivity estimates for complex path expressions over graph-structured XML data. In this paper we introduce a novel approach to building and using statistical summaries of large XML data graphs for effective path-expression selectivity estimation. Our proposed graph-synopsis model (termed XSKETCH) exploits localized graph stability to accurately approximate (in limited space) the path and branching distribution in the data graph. To estimate the selectivities of complex path expressions over concise XSKETCH synopses we develop an estimation framework that relies on appropriate statistical (uniformity and independence) assumptions to compensate for the lack of detailed distribution information. Given our estimation framework we demonstrate that the problem of building an accuracy-optimal XSKETCH for a given amount of space is ### -hard and propose an efficient heuristic algorithm based on greedy forward selection. Briefly our algorithm constructs an XSKETCH synopsis by successive refinements of the label-split graph the coarsest summary of the XML data graph. Our refinement operations act locally and attempt to capture important statistical correlations between data paths. Extensive experimental results with synthetic as well as real-life data sets verify the effectiveness of our app...,10.1.1.1.3258,?,?
Using Constraints to Develop and Deliver Adaptive,Tests Sophiana Chua Sophiana Chua Abdullah Roger E. Cooley,2000,This paper shows how the techniques used to develop knowledge-based systems can be applied to the construction of adaptive tests. It reports on an experimental approach to the construction of adaptive tests and it draws on work in the fields of Intelligent Tutoring Systems Expert Systems and Constraint Logic Programming.,10.1.1.1.3260,?,?
Marek Makowski,Andrzej Wierzbicki Modelling Marek Makowski Andrzej P. Wierzbicki,?,After recalling the concepts of networked society information society and knowledge-based economy the paper concentrates on problems of sharing or exchanging knowledge in information society. In order to analyse these problems the concept of knowledge must be first more precisely defined and distinguished from the concepts of data arts wisdom and skills. In computerised form knowledge can be represented either as learned texts or as computerised models or systems of models. Classical models in knowledge engineering take the logical form of patterns discerned in data with the help e.g. of data mining. However there are also many other mathematical models used to express knowledge in a computerised form: each discipline of science or engineering has its own tradition of representing knowledge with specific class of mathematical models. This fact makes it difficult to exchange or share knowledge in this form. A new possibility of overcoming this difficulty is offered by the concept of grid middleware a layer of software supporting integration of knowledge developed and stored with diverse standards and providing for co-operation of diverse software entities. The paper shows an example how the concept of grid middleware can be used to help in exchanging or sharing knowledge in computerised model form. Conclusions of the paper relate to problems of science policy particularly for countries in economic transition resulting from the problems of transition towards knowledge-based economy and sharing or exchanging knowledge.,10.1.1.1.3261,?,?
RF/Wireless Interconnect for Inter- and,Intra-Chip Communications Mau-Chung Mau-chung Frank Chang Vwani P. Roychowdhury Liyang Zhang Hyunchol Shin Yongxi Qian Senior Member,2001,this paper we address issues relevant to the signal channeling of the RF/wireless interconnect and discuss its advantages in speed signal integrity and channel reconfiguration. The electronic overhead required in the RF/wireless-interconnect system and its compatibility with the future ULSI and MCM (multi-chip-module) will be discussed as well. Keywords---Adaptive networking bidirectional interconnect fault-tolerant computing interconnect reconfiguration inter- and intra-chip communications multi-I/O interconnect RF/wireless interconnect ultrabroad bandwidth,10.1.1.1.3263,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,This paper compares Monte Carlo methods lattice rules and other low-discrepancy point sets on the problem of evaluating asian options. The combination of these methods with variance reduction techniques is also explored.,10.1.1.1.3264,?,?
Sentences 92,Semantic Networks Semiotic Selmer Bringsjord David Ferrucci,?,al nets 26 31 36--38 52  neuroscience 58  Noel R. xiii  OConnell R. xi  OSCAR 6  Papadias D. 59  paragraph grammar 194  Peck M. 101  Piaget J. 60  pictorial reasoning 34  pictorial representation 34  pictorialism 46  Pinker S. 59  Plato xviii  plot generation 191  PoirotH.147  Pollock J. 6  PoltrinoT.xii  Porush D. xii  proactive behavior 179 191  process level 165  production rules 173  Propp V. 154  Psotka J. 50  Racter 22  Rapaport W. 76  reactive behavior 178 191  reader response theory xiii  register machines 38  ROALD 151  robots xvi xvii 6 7 21 34 57 63  house-cleaning xviii  Sancho Panza 92  scenario 194  SchwartzD.56  Searle J. 53 55 68  self-reference  familiar reference 188  Ferrucci D. xi 10  Fetzer J. xiv  fiction  belletristic xii xv xxiv  152  Fleming I. 157 159  FLEX 170  Ford  K .  x i v  Fort i er S. 56  free will xii  Freud S. xv  Fuentes  C .  64  Funt  B .  61  Galbraith M.,10.1.1.1.3265,?,?
Toward IP Virtual Private Network Quality of Service: A Service Provider Perspective,Jingdi Zeng A Service Provider Perspective,2003,To complement classical enterprise wide area network infrastructures IP (based) virtual private networks have been gaining ground with the capability of offering cost-effective secure and private-network-like services. In order to provision the equivalent quality of service of legacy connection-oriented layer 2 VPNs IP VPNs have to overcome the intrinsically best effort characteristics of the Internet in this multimedia era. This article discusses the IP VPN QoS issue from a service provider point of view where QoS guarantees are carried out at the network level as well as at the node level. It presents the whole picture by highlighting and stitching together various QoS enabling technologies from recent research and engineering work.,10.1.1.1.3266,?,?
Using a Multi-Frequency Synthetic Aperture Sonar for Bathymetry,P.J. Barclay M. P. Hayes  P.T. Gough,2001,This paper describes the implementation of a bathymetric synthetic aperture sonar and presents imagery from preliminary sea trials of the sonar. The sonar is designed for high resolution seafloor imaging in a shallow water environment. To estimate seafloor topology the sonar ssytem uses the phase difference between elements of a vertical hydrophone array.,10.1.1.1.3268,?,?
VIPER: A VIsual Protocol EditoR,C. F. B. Rooney R. W. Collier  G. M. P. OHare G. M. P. O’hare,2004,Agent interactions play a crucial role in Multi-Agent Systems.,10.1.1.1.3269,?,Springer Verlag
A Framework for QoS Support in the UMTS/GPRS Backbone Network Using DiffServ,Farshid Agharebparast Victor C. M. Leung,2002,A distinguishing feature of the Universal Mobile Telecommunications System (UMTS) is the support of different levels of quality of service (QoS) as required by subscribers and their applications. To provide QoS the UMTS backbone network needs an efficient QoS mechanism to provide the demanded level of services on a UMTS core network. This paper presents a methodology of provisioning QoS in this backbone network based on the Differentiated Services (DiffServ) model. DiffServ is a relatively simple but scalable IP-based technology which can efficiently provide QoS in networks of DiffServ supporting routers. This is accomplished by defining a framework for setting a DiffServ-based UMTS backbone router as well as the requisite mapping function for interworking between a DiffServ domain and UMTS. Efficient schemes are presented for the scheduling and buffer management components of the backbone router supporting DiffServ. The performance of this system for provisioning UMTS primary QoS classes is evaluated by computer simulations. The results show that DiffServ can be an effective candidate for UMTS backbone bearer service.,10.1.1.1.3270,?,?
Genome Informatics 14: 514--515 (2003) Predict Functionally Important Residues Responsible,For Estrogen Receptor Feng Wang Hirohisa Kishino Yasuhiko Wada,?,Introduction  The estrogen receptor (ER) is a ligand-activated transcription factor that mediates the physiological e#ects of the female sex steroid hormone 17 beta estradiol (E2) and regulates the expression of genes involved in the growth development and function of a diverge range of tissues. The ER is a member of nuclear receptor (NR) superfamily which shares a common structural organization including six independent but interacting functional domains. Two ER subtypes although related are separate genes and code for proteins of di#ering lengths. We are interested in the selection constraint acting on the functional domains of ER subtypes after gene duplication. Because the sequence di#erences of ER subtype in ligand binding domain (LBD) provide the molecular basis for the subtype physiological function it is necessary to identify those functional related sites in order to investigate the functional divergence between two subtypes. In this study we utilize the evolutionary ra,10.1.1.1.3271,estrogen receptor functional divergence functional residues structural mapping,?
Accurate Power Estimation Using Circuit Partitioning,Ana Freitas Atf Ana T. Freitas,?,Recently a probabilistic approach that uses a simple but powerful formalism for exact power estimation taking into account word level input correlations has been proposed.,10.1.1.1.3272,?,?
Design And Construction Of High-Frequency Multitone,Police Security Siren,2003,This research project is based on signal processing using common laboratory electronic chips. The generated signals were caused to pass through appropriate electronic circuit compartments to obtain the desired signal waves that produced siren effects. Two unique design methods were tried with success. The first employed the use of transistors and resistors with appropriate capacitor values for their timing constants and presented in astable multivibrator circuit. The second involved the configuration of astable multivibrator into 555IC timer circuit which produced the same effects with improved frequency. The designs deviate from the customary in the sense that they could be used in both survey and practical course. Hence the project satisfies the increasing students curiosity in electronics which creates such awareness that the primary forces impelling social and cultural changes are largely the result of technological innovation. Keywords  System clocking Duty cycle Synchronization Sampling method Audio digital mixing.,10.1.1.1.3273,Duty cycle Synchronization Sampling method Audio,?
A Prototype English-Arabic Dictionary Based on WordNet,William Black And William J. Black Sabri El-kateb,2004,We report on the design and partial implementation of a bilingual EnglishArabic  dictionary based on WordNet. A relational database is employed to store the  lexical and conceptual relations giving the database extensibility in either language.,10.1.1.1.3274,?,?
Secure Routing in Wireless Sensor Networks: Attacks and Countermeasures,Chris Karlof David Wagner,2003,We  consider routing  security in wireless sensor networks. Many sensor  network routing  protocols have been proposed but none of them have been designed with security as agq1( We propose  securitygcur forrouting  in sensor networks show how attacks agacks ad-hoc and peer-to-peer networks can be adapted into powerful attacks agacks  sensor networks introduce two classes of novel attacks agacks sensor networks----sinkholes and HELLO floods and analyze the security of all the major sensor  networkrouting  protocols. We describe crippling  attacks against all of them and sug@(5 countermeasures anddesig considerations. This is the first such analysis of  secure routing  in sensor networks.,10.1.1.1.3275,Sensor networks Security Secure routing,?
A Unified Algebraic Approach to 2-D and 3-D Motion Segmentation,René Vidal Yi Ma,2004,We present an analytic solution to the problem of estimating multiple  2-D and 3-D motion models from two-view correspondences or optical flow. The  key to our approach is to view the estimation of multiple motion models as the  estimation of a single multibody motion model. This is possible thanks to two important  algebraic facts. First we show that all the image measurements regardless  of their associated motion model can be fit with a real or complex polynomial. Second we show,10.1.1.1.3276,?,?
Probabilistic Finite-State Machines - Part I,E. Vidal F. Thollard C. De La Higuera F. Casacuberta R. C. Carrasco,?,Probabilistic finite-state machines are used today in a variety of areas in pattern recognition or  in fields to which pattern recognition is linked: computational linguistics machine learning time  series analysis circuit testing computational biology speech recognition and machine translation  are some of them. In part I of this paper we survey these generative objects and study their  definitions and properties. In part II we will study the relation of probabilistic finite-state automata  with other well known devices that generate strings as hidden Markov models and n-grams and  provide theorems algorithms and properties that represent a current state of the art of these objects.,10.1.1.1.3277,I.2.6.g Language acquisition (I.2.6.h Language models (I.2.7.c Language parsing and under,?
OIKOS 74: 218--224. Copenhagen 1995,On Evolutionarily Stable Sido D. Mylius Odo Diekmann,?,This paper was written during a workshop in Les Houches France which was an activity of the ESF network Dynamics of Complex Systems in Biosciences. We thank Guillemette Duchateau-Nguyen and Grard Weisbuch for organizing a workshop during which one could really work. Our thinking was greatly influenced by many inspiring conversations with Hans Metz. Ian C.W. Hardy Patsy Haccou and Ron Otten helped improve the readability of the manuscript. The work of Sido Mylius was supported by the Life Sciences Foundation (SLW) which is subsidized by the Netherlands Organization for Scientific Research (NWO),10.1.1.1.3278,?,?
A Multi-Agent System Environment for Modelling Cell and Tissue,Biology Eunice Santos Eunice E. Santos Donghang Guo Eugene Santos Jr. William Onesty,?,Tissue simulation at the cellular level is very important to medical research especially in understanding tumor cell evolution. Although many approaches have been proposed for tissue simulation they are overly simplistic or too specialized. In this paper we formulate the first comprehensive design of a multiagent system for modelling tissue systems at the cellular level. We present our design concerns and our analyses of system features in detail. We believe our system provides a software model and foundation for the study of tissue biology.,10.1.1.1.3279,mobile multi-agent system distributed,?
Input Modeling,Lawrence Leemis,2003,Most discrete-event simulation models have stochastic elements that mimic the probabilistic nature of the system under consideration. A close match between the input model and the true underlying probabilistic mechanism associated with the system is required for successful input modeling. The general question considered here is how to model an element (e.g. arrival process service times) in a discrete-event simulation given a data set collected on the element of interest. For brevity it is assumed that data is available on the aspect of the simulation of interest. It is also assumed that raw data is available as opposed to censored data grouped data or summary statistics. This example-driven tutorial examines introductory techniques for input modeling. Most simulation texts (e.g. Law and Kelton 2000) have a broader treatment of input modeling than presented here. Nelson and Yamnitsky (1998) survey advanced techniques.,10.1.1.1.3280,?,?
Aggregation-based Approaches to Honey-pot Searching with Local Sensory Information,Bhaskar Dasgupta  Joao P. Hespanha Eduardo Sontag,2004,We investigate the problem of searching for a hidden target in a bounded region by an autonomous agent that is only able to use limited local sensory information. We propose an aggregation-based approach to solve this problem in which the continuous search space is partitioned into a finite collection of regions on which we define a discrete search problem. A solution to the original problem is then obtained through a refinement procedure that lifts the discrete path into a continuous one. The resulting solution is in general not optimal but one can construct bounds to gauge the cost penalty incurred.,10.1.1.1.3281,?,?
Boosting as a Regularized Path to a Maximum Margin Classifier,Saharon Rosset  Ji Zhu Trevor Hastie Robert Schapire,2004,In this paper we study boosting methods from a new perspective. We build on recent work by Efron  et al. to show that boosting approximately (and in some cases exactly) minimizes its loss criterion  with an l 1 constraint on the coefficient vector. This helps understand the success of boosting with  early stopping as regularized fitting of the loss criterion. For the two most commonly used criteria  (exponential and binomial log-likelihood) we further show that as the constraint is relaxed---or  equivalently as the boosting iterations proceed---the solution converges (in the separable case) to an  l 1 -optimal separating hyper-plane. We prove that this l 1 -optimal separating hyper-plane has the  property of maximizing the minimal l 1 -margin of the training data as defined in the boosting literature.,10.1.1.1.3282,boosting regularized optimization support vector machines margin maximization,?
Joint Bayesian Model Selection and Estimation of Noisy Sinusoids via Reversible Jump MCMC,Christophe Andrieu  Arnaud Doucet,1999,In this paper the problem of joint Bayesian model selection and parameter estimation for sinusoids in white Gaussian noise is addressed. An original Bayesian model is proposed that allows us to define a posterior distribution on the parameter space. All Bayesian inference is then based on this distribution. Unfortunately a direct evaluation of this distribution and of its features including posterior model probabilities requires evaluation of some complicated high-dimensional integrals. We develop an efficient stochastic algorithm based on reversible jump Markov chain Monte Carlo methods to perform the Bayesian computation. A convergence result for this algorithm is established. In simulation it appears that the performance of detection based on posterior model probabilities outperforms conventional detection schemes.,10.1.1.1.3283,Index Terms — Bayesian methods MCMC model selection,?
Mobile E-Services and Their Challenges to Data Warehousing,Christian S. Jensen Torben Bach Pedersen,2001,Continued advances in hardware technologies combine to create a new class of information services termed  mobile e-services or simply m-services which exploits the advances in among others wireless communications positioning  and miniaturization. Because the users do not merely interact with the services from behind stationary desktop  computers but from a variety of increasingly unobtrusive information appliances while on the move location information  plays a fundamental role and new types of services become of interest. Such services include tracking way-finding  traffic management safety-related services and mixed-reality games to name but a few. Data,10.1.1.1.3285,?,?
Dsgd Discussion Paper No. 3,Development Strategy And Samuel Morley Valeria Piñeiro,?,this paper.   iii   TABLE OF CONTENTS   ACKNOWLEDGEMENTS ................................................................................................. I  TABLE OF CONTENTS................................................................................................... III  LIST OF TABLES ............................................................................................................. IV  EXECUTIVE SUMMARY ................................................................................................ V  1. ,10.1.1.1.3286,?,?
Strategies for Sustainable Agricultural Development in the . . .,Pender John Pender Berhanu Gebremedhin Berhanu Gebremedhin Samuel Benin Samuel Benin Simeon Ehui Simeon Ehui,1999,This paper investigates the impacts of population growth market access agricultural credit and technical assistance programs land policies livelihood strategies and other factors on changes in land management natural resource conditions and human welfare indicators since 1991 in the northern Ethiopian highlands based on a survey of 198 villages. We find that population growth has contributed significantly to land degradation poverty and food insecurity in this region. In contrast better market access and some credit and technical assistance programs were associated with improvement (or less decline) in land quality wealth and food security suggesting the possibility of winwin -win development outcomes with appropriate interventions. Land redistribution was associated with adoption of inorganic fertilizer but also with declining use of fallow and declining soil fertility. We find also that different land management practices are adopted where different livelihood strategies are pursued suggesting the importance of considering livelihood strategies in technical assistance programs. Development strategies should be tailored to the different comparative advantages of different locations no one-size-fits-all strategy will work everywhere. KEYWORDS: Land degradation sustainable agriculture population pressure Ethiopian highlands ii  ACKNOWLEDGMENTS The authors gratefully acknowledge the financial support of the Swiss Agency for Development and Cooperation and the Norwegian Ministry of Foreign Affairs for this research. STRATEGIES FOR SUSTAINABLE AGRICULTURAL DEVELOPMENT IN THE ETHIOPIAN HIGHLANDS  Land degradation is a severe problem in the Ethiopian highlands. Soil erosion has been estimated to average 42 tons per hectare per year on cultivated land in th...,10.1.1.1.3288,i,John
Design and development of a Jxta middleware for mobile ad-hoc networks,Mario Bisignano Andrea Calvagna  Giuseppe Di Modica Orazio Tomarchio,?,The combination of personal computing devices and wireless ad-hoc networks allows the concept of mobile ad-hoc information system consisting of a highly dynamic decentralized and self-organizing network of autonomous and mobile devices that interacts as peers. Application developers have to deal with a new set of problem peculiar of these systems due to user and terminal mobility to low bandwidth to transient loss of connectivity and to lack of centralized infrastructure. Starting from an existing open software framework for P2P systems JXTA in this work we tried to define a new middleware named Expeerience to face with these problems. The introduction of a mobile code service is one of the main innovation introduced allowing the dynamic services deployment at runtime. An example application is finally presented showing the benefit of the new middleware mechanisms introduced and the low overhead needed for developing an application for adhoc environments.,10.1.1.1.3289,KEY WORDS MANET P2P mobile computing JXTA mobile code,?
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros,?,Spreadsheet simulation refers to the use of a spreadsheet as a platform for representing simulation models and performing the simulation experiment. This tutorial explains the reasons for using this platform for simulation discusses why this is frequently an efficient way to build simulation models and execute them discusses how to setup a spreadsheet simulation and finally examines when a spreadsheet is not an appropriate platform for simulation.,10.1.1.1.3290,?,?
On Network Correlated Data Gathering,R?zvan Cristescu Baltasar Beferull-lozano Martin Vetterli,2004,We consider the problem of correlated data gathering by a network with a sink node and a tree communication structure where the goal is to minimize the total transmission cost of transporting the information collected by the nodes to the sink node. Two coding strategies are analyzed: a SlepianWolf model where optimal coding is complex and transmission optimization is simple and a joint entropy coding model with explicit communication where coding is simple and transmission optimization is difficult. This problem requires a joint optimization of the rate allocation at the nodes and of the transmission structure. For the Slepian-Wolf setting we derive a closed form solution and an efficient distributed approximation algorithm with a good performance. For the explicit communication case we prove that building an optimal data gathering tree is NPcomplete and we propose various distributed approximation algorithms.,10.1.1.1.3292,Graph Theory Combinatorics Information Theory,?
A Highly Configurable Cache Architecture for Embedded Systems,Chuanjun Zhang Frank Vahid Walid Najjar,2003,Energy consumption is a major concern in many embedded computing systems. Several studies have shown that cache memories account for about 50% of the total energy consumed in these systems. The performance of a given cache architecture is largely determined by the behavior of the application using that cache. Desktop systems have to accommodate a very wide range of applications and therefore the manufacturer usually sets the cache architecture as a compromise given current applications technology and cost. Unlike desktop systems embedded systems are designed to run a small range of well-defined applications. In this context a cache architecture that is tuned for that narrow range of applications can have both increased performance as well as lower energy consumption. We introduce a novel cache architecture intended for embedded microprocessor platforms. The cache can be configured by software to be direct-mapped two-way or four-way set associative using a technique we call way concatenation having very little size or performance overhead. We show that the proposed cache architecture reduces energy caused by dynamic power compared to a way-shutdown cache. Furthermore we extend the cache architecture to also support a way shutdown method designed to reduce the energy from static power that is increasing in importance in newer CMOS technologies. Our study of 23 programs drawn from Powerstone MediaBench and Spec2000 show that tuning the caches configuration saves energy for every program compared to conventional four-way set-associative as well as direct mapped caches with average savings of 40% compared to a four-way conventional cache.,10.1.1.1.3293,energy,?
Simple Feasibility Rules and Differential Evolution for Constrained Optimization,Efren Mezura-Montes Carlos A. Coello Coello  Edy I. Tun-Morales Sección De Computación Villahermosa Tabasco,2004,In this paper we propose a differential evolution algorithm to solve  constrained optimization problems. Our approach uses three simple selection  criteria based on feasibility to guide the search to the feasible region. The proposed  approach does not require any extra parameters other than those normally  adopted by the Differential Evolution algorithm. The present approach was validated  using test functions from a well-known benchmark commonly adopted to  validate constraint-handling techniques used with evolutionary algorithms. The  results obtained by the proposed approach are very competitive with respect to  other constraint-handling techniques that are representative of the state-of-the-art  in the area.,10.1.1.1.3294,?,Springer Verlag
Designs of High Quality Streaming Proxy Systems,Songqing Chen  Bo Shen  Susie Wee  Xiaodong Zhang,2004,Researchers often use segment-based proxy caching strategies to deliver streaming media by partially caching media objects. The existing strategies mainly consider increasing the byte hit ratio and/or reducing the client perceived startup latency (denoted by the metric delayed startup ratio). However these efforts do not guarantee continuous media delivery because the to-be-viewed object segments may not be cached in the proxy when they are demanded. The potential consequence is playback jitter at the client side due to proxy delay in fetching the uncached segments which we call proxy jitter. Thus for the best interests of clients a correct model for streaming proxy system design should aim to minimize proxy jitter subject to reducing the delayed startup ratio and increasing the byte hit ratio. However we have observed two major pairs of conflicting interests inherent in this model: (1) one between improving the byte hit ratio and reducing proxy jitter and (2) the other between improving the byte hit ratio and reducing the delayed startup ratio. In this study we first propose an active prefetching method for in-time prefetching of uncached segments which provides insights into the first pair of conflicting interests. Second we further improve our lazy-segmentation scheme [1] which effectively addresses the second pair of the conflicting interests. Finally considering our main objective of minimizing proxy jitter and optimizing the two trade-offs we propose a new streaming proxy system called Hyper Proxy by effectively coordinating both prefetching and segmentation techniques. Synthetic and real workloads are used to systematically evaluate our system. The performance results show that the Hyper Proxy system generates minimum proxy jitter with a low delayed st...,10.1.1.1.3295,System Design Content Distribution Streaming Media Proxy Caching,?
Synergies Between Interactive Training Simulations And Digital Storytelling: A Component-Based Framework,Ralf Dörner Paul Grimm Daniel F. Abawi,2002,A vital requirement for a successful software framework for digital storytelling is that it takes the abilities and backgroundof the story authors into account. Dedicatedtools shouldsupport authors in expressing their stories within this framework at an adequate level and point out an according authoring process for digital stories. The software framework shouldprovide communication interfaces between technology experts storytelling experts andapplication domain-experts. These requirements are similar to the ones already encountered when setting up a framework for interactive training applications. We present a concept how component andframework methodologies from software engineering as well as concepts from artificial intelligence can foster the design of such a software framework. The software architecture of our proposed framework is discussed as well as the according authoring process and tools. An implementation of our concept is described and lessons learned during using this framework in the application domain of emergency training are addressed. Although the framework has been applied for training purposes in particular it can be usedas a basis for a digital storytelling framework in general. r 2002 Elsevier Science Lt . All rights reserve . 1.,10.1.1.1.3296,?,?
Design Patterns Application in UML,Gerson Sunyé Alain Le Guennec Jean-Marc Jézéquel,2000,The Unified Modeling Language (UML) currently proposes  a mechanism to model recurrent design structures: the parameterized  collaborations. The main goal of this mechanism is to model the structure  of Design Patterns. This is an interesting feature because it can help  designers to point out pattern application without spending time with  intricate design details. Moreover it can also help designers to better  document their systems and to manage their own design pattern library  which could be used in di#erent systems or projects. However from a tool  perspective the semantics associated to parameterized collaborations is  still vague. To put it more precisely the underlying representation of a  design pattern and of its application and the binding between these two  levels is not exactly defined and therefore can be interpreted in different  ways. This article has two purposes. First we point out ambiguities and  clarify some misunderstanding points concerning parameterized collaborations  in the official UML literature. We also show the limits of  this mechanism when effectively modeling design patterns. Second we  propose some workarounds for these limits and describe how a tool integrating  this mechanism could help with the semi-automatic application  of design patterns.,10.1.1.1.3297,?,Lecture
Two Further Links Between Mp And Ml Under The Poisson Model ,Mike Steel David Penny,2003,Maximum parsimony and maximum likelihood are two contrasting  approaches for reconstructing phylogenetic trees from sequence and character  data. We establish analytic links between these methods (extending connections  reported earlier) under the simple Poisson model of substitutions in two  settings. First we show that if the underlying state space is sufficiently large  then the maximum likelihood estimate phylogenetic tree is always a maximum  parsimony tree for the data. Second we show that a sufficiently dense sampling  of sequences ensures that the most parsimonious likelihood tree is always  a maximum parsimony tree.,10.1.1.1.3298,?,?
The FTLambda-FRLambda AWG Network: A Practical Single-Hop Metro WDM Network for Efficient Uni- and Multicasting,Chun Fan  Martin Reisslein,2004,Single--hop WDM networks with a central Passive Star Coupler (PSC) as well as single--hop networks with a central Arrayed--Waveguide Grating (AWG) and a single transceiver at each node have been extensively studied as solutions for the quickly increasing amounts of unicast and multicast traffic in the metropolitan area. The main bottlenecks of these networks are the lack of spatial wavelength reuse in the studied PSC based networks and the single transceiver in the studied AWG based metro WDM networks. In this paper we develop and evaluate the FT      AWG network which is based on a central AWG and has arrays of fixed--tuned transmitters and receivers at each node. Transceiver arrays are a mature technology making the proposed network practical. In addition the transmitter arrays allow for high speed signaling over the AWG while the receiver arrays relieve the receiver bottleneck arising from multicasting in conjunction with spatial wavelength reuse on the AWG. Our results from probabilistic analysis and simulation indicate that the FT      AWG network gives particularly good throughput--delay performance for multicast traffic with small multicast group sizes or localized destination nodes as well as for a mix of unicast and multicast traffic.,10.1.1.1.3299,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,This paper describes an advanced simulation environment that has been used to examine validate and predict the performance of Protocols for IP Mobility Support. It overcomes many limitations found in existing network simulators and it provides more support on mobile-related issues. It contains several components that are common to all evaluations of IP mobility which can model arbitrary network -topologies arbitrary movement pattern and arbitrary calling patterns. It also provides a set of protocol implementations that are necessary to simulating the Internet. The environment offers several desirable features including: 1) flexible metrics collection for both predefined and customized ones 2) reuse of calling patterns moving patterns network topologies etc. and 3) automatic generation of mobility pattern. Several research contributions had been made with the help of this simulation environment and it would be useful for refining various aspects of IP mobility support.,10.1.1.1.3300,?,?
A Novel Modular Neural Architecture for Rule-based and Similarity-based Reasoning,Rafal Bogacz  Christophe Giraud-Carrier,2000,Hybrid connectionist symbolic systems have been the subject  of much recent research in AI. By focusing on the implementation of high-level  human cognitive processes (e.g. rule-based inference) on low-level  brain-like structures (e.g. neural networks) hybrid systems inherit both  the efficiency of connectionism and the comprehensibility of symbolism. This paper presents,10.1.1.1.3301,?,Springer-Verlag
A Polynomial Time Algorithm for the Multidimensional Assignment Problem in Multiple Sensor Environments,H. W. de Waard A. Capponi ,?,This is the first half of a two-part paper devoted to the multidimensional assignment problem (MDA) in multiple target tracking. Here a new polynomial-time algorithm for solving the MDA problem is proposed. The dimension of the formulated assignment problem is given by two parameters: the number of available sensors and the last time instant when association decisions are revokable. This algorithm is then used in the companion paper [4] where a decomposition approach aiming at reducing the number of candidate associations and then creating independent MDA subproblems is proposed. The algorithm proposed here is applied inside each independent MDA subproblem.,10.1.1.1.3302,Data association problem clustering tracking filtering. 1 Formulation of the MDA problem,?
Logical Systems: Towards Protocols for Web-Based Meaning Negotiation,James Farrugia,2002,Our thesis is that before Web-based agents can negotiate  meanings they need to agree on high-level protocols based  on logical systems. The Semantic Web community is setting  the stage for semantic interoperability among Web-based  software agents by developing standard languages with  well-defined semantics. But exactly how these languages  might be used to negotiate meanings is an open question.,10.1.1.1.3303,?,?
Java Applet Correctness: a Developer-Oriented Approach,L. Burdy A. Requet J. -l. Lanet La Vigie,2003,This paper presents experiments on formal validation of Java  applets. It describes a tool that has been developed at the Gemplus  Research Labs. This tool allows to formally prove Java classes annotated  with JML an annotation language for Java that provides a framework  for specifying class invariants and methods behaviours. The foundations  and the main features of the tool are presented. The most innovative part  of the tool is that it is tailored to be used by Java programmers without  any particular background in formal methods. To reduce the di#culty  of using formal techniques it aims to provide a user-friendly interface  which hides to developers most of the formal features and provides a  Java style view of lemmas.,10.1.1.1.3304,Java Correctness Proof Proof User Interface,Springer
Accurate Power Estimation Using Circuit Partitioning,Ana T. Freitas  Arlindo L. Oliveira  Horacio C. Neto,?,Recently a probabilistic approach that uses a simple but powerful formalism for exact power estimation taking into account word level input correlations has been proposed.,10.1.1.1.3305,?,?
Automatic Segmentation and Recognition System for Handwritten Dates on Canadian Bank Cheques,Bank Cheques Qizhi Xu  Louisa Lam  Ching Y. Suen,2002,This paper describes a system being developed to recognize date information handwritten on Canadian bank cheques. A segmentation based strategy is adopted in this system. In order to achieve high performances in terms of efficiency and reliability a knowledge-based module is proposed for the date segmentation and a cursive month word recognition module is implemented based on a combination of classifiers. The interaction between the segmentation and recognition stages is properly established by using multihypotheses generation and evaluation modules. As a result promising performance is obtained on a test set from a reallife standard cheque database.,10.1.1.1.3306,?,?
Distributed Probabilistic Model-Building Genetic Algorithm,Tomoyuki Hiroyasu  Mitsunori Miki Masaki Sano Hisashi Shimosaka Shigeyoshi Tsutsui Jack Dongarra,2003,In this paper a new model of Probabilistic Model-Building  Genetic Algorithms (PMBGAs) Distributed PMBGA (DPMBGA) is  proposed. In the DPMBGA the correlation among the design variables  is considered by Principal Component Analysis (PCA) when the o#-  springs are generated. The island model is also applied in the DPMBGA  for maintaining the population diversity. Through the standard test functions  some models of DPMBGA are examined. The DPMBGA where  PCA is executed in the half of the islands can find the good solutions in  the problems whether or not the problems have the correlation among  the design variables. At the same time the search capability and some  characteristics of the DPMBGA are also discussed.,10.1.1.1.3307,?,?
Despotic Societies Sexual Attraction And,The Emergence Of Charlotte K. Hemelrijk,?,this paper a simpler hypothesis is proposed on the basis of an individual-based model (called DomWorld): male `tolerance towards females arises in `despotic artificial societies as a kind of `respectful timidity because sexual attraction automatically increases female dominance over males as a side-effect. The model consists in a homogeneous virtual world with agents that group and perform dominance-interactions in which the effects of victory and defeat are self-reinforcing. The artificial sexes differ in that VirtualMales have a higher intensity of aggression they start with a greater capacity to win conflicts than VirtualFemales and they are especially attracted to the opposite sex during certain periods whereas VirtualFemales are not. I shall explain how the introduction into DomWorld of the attraction of VirtualMales by VirtualFemales leads to female dominance why it does so only in despotic but not in egalitarian societies and how it leads to other phenomena that are relevant to the study of primate behaviour,10.1.1.1.3308,sexual attraction sexual exchange male ‘tolerance’ female dominance egalitarian and despotic society paternity,?
Manifold Learning and Applications in Recognition,Junping Zhang Stan Z. Li  Jue Wang,2004,this paper recognition can be achieved by comparing the probability metric between each unknown sample and corresponding auto-associative sample with di#erent NAMs. Without loss of generality the probability metric (in this paper we use Gaussian function) between each sample x # and auto-associative sample x # (i) of the ith NAM is given by: P (x # (i)|x #  NAM i ) = exp  (-#x #  -x  # (i)#     x #  x # (i)       i = 1  where x # i means the auto-associative sample through the ith NAM given unknown sample x # . It is no di#cult to see that when the reconstructed sample is the same as the original sample P (x # (i)|x #  NAM(i)) is equal to 1 whereas if the reconstructed sample is far away from the original sample P (x # (i)|x #  NAM i ) will decreased to zero rapidly with respect to the properties of gaussian function,10.1.1.1.3309,?,Springer-Verlag
Linear Algebra Operators for GPU Implementation of Numerical Algorithms,Jens Krüger Rüdiger Westermann,2003,In this work the emphasis is on the development of strategies to realize techniques of numerical computing on the graphics chip. In particular the focus is on the acceleration of techniques for solving sets of algebraic equations as they occur in numerical simulation. We introduce a framework for the implementation of linear algebra operators on programmable graphics processors (GPUs) thus providing the building blocks for the design of more complex numerical algorithms. In particular we propose a stream model for arithmetic operations on vectors and matrices that exploits the intrinsic parallelism and efficient communication on modern GPUs. Besides performance gains due to improved numerical computations graphics algorithms benefit from this model in that the transfer of computation results to the graphics processor for display is avoided. We demonstrate the effectiveness of our approach by implementing direct solvers for sparse matrices and by applying these solvers to multi-dimensional finite difference equations i.e. the 2D wave equation and the incompressible Navier-Stokes equations.,10.1.1.1.3310,Numerical Simulation Graphics Hardware,?
Collision Detection Algorithm for Deformable Objects Using OpenGL,Shmuel Aharon  Christophe Lenglet,2002,This paper describes a collision detection method for polygonal deformable  objects using OpenGL which is suitable for surgery simulations. The  method relies on the OpenGL selection mode which can be used to find out  which objects or geometrical primitives (such as polygons) in the scene are  drawn inside a specified region called the viewing volume. We achieve a significant  reduction in the detection time by using a data structure based on an  AABB tree. The strength of our method is that it doesnt require the AABB hierarchy  tree to be updated from bottom to top. We are using only a limited set  of bounding volumes which is much smaller than the objects number of polygons.,10.1.1.1.3311,?,Online]. Available: citeseer.ist.psu.edu/aharon02collision.html
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,Human performance is a critical aspect of system performance. Recently tools and methods for modeling the human in systems have begun to receive widespread attention. These tools and methods are consistent with other types of models and simulations that are used to model other system components. In this paper the basic approaches to modeling human performance are discussed along with a brief case study.,10.1.1.1.3312,?,?
A Decomposed Symbolic Approach to Reactive Planning,Seung H. Chung  Brian C. Williams,2003,Autonomous systems in uncertain dynamic environments  must reconfigure themselves in response to unanticipated events and  goals in real-time. We present an approach to reactive configuration  planning based on the principle of decomposition. Reactive plans are  susceptible to exponential state space explosion. We address this problem  through transition-based decomposition by generating compact decomposed  goal-directed plans. We further minimize state explosion by  adopting a symbolic representation based on Ordered Binary Decision  Diagrams. We demonstrate our reactive planner on representative spacecraft  subsystem models.,10.1.1.1.3313,?,?
Email Prioritization: reducing delays on legitimate mail caused,Junk Mail Richard Richard Daniel Twining A Mowbray Dan Twining Matthew M. Williamson Matthew M. Williamson A J. F. Mowbray Maher Rahmouni Maher Rahmouni,2004,In recent years the volume of junk email (spam virus etc.) has increased dramatically. These unwanted messages clutter up users mailboxes consume server resources and cause delays to the delivery of mail. This paper presents an approach that ensures that non-junk mail is delivered without excessive delay at the expense of delaying junk mail.,10.1.1.1.3314,?,?
Steven J. Simske Margaret Sturgill,Imaging Systems Laboratory Steven J. Simske Steven J. Simske Margaret Sturgill Margaret Sturgill,2003,We present design strategies implementation preferences and throughput results obtained in deploying a UI-based ground truthing engine as the last step in the quality assurance (QA) for the conversion of a large out-of-print book collection into digital form. A series of automated QA steps were first performed on the document. Five distinct zoning analysis options were deployed and the PDF output thence generated was used to regenerate TIFF files for comparison to the originals. Regenerated TIFFs failing automated QA or a separate visual QA were tagged for ground truthing. Less than 3% of the pages in a 1.2x10    required ground truthing resulting in a throughput rate of fully-proofed pages of 2x10    pages/manweek. Among the design advantages crucial for this throughput rate was the use of the identical zoning engine for the original production workflow and for the ground truthing engine.,10.1.1.1.3315,?,ACM Press
Lane Data Fusion for Driver Assistance Systems,Albrecht Klotz  Jan Sparbert  Dieter Hötzer Robert Bosch Gmbh,?,The objective of the presented fusion algorithms is to supply driver assistance systems (DAS) e.g. an advanced adaptive cruise control (ACC) with one ore more hypotheses of the possible lane layout in front of the own vehicle. Different sources of information are considered namely line markings detected by a video-sensor information derived from trajectories of moving objects and data from a digital map. These data sets are described and fused mathematically closed and consistent widely independent of the DAS. The fusion algorithm relies on mathematical modelling taking the relative accuracy of the different sensor sources into account. Additionally a priori and heuristic knowledge of the input data is used in creating hypotheses. The fused lane-data can be used in an ACC-system for a better prediction of the own vehicles course. This allows a more robust and dynamical system application as well as predictive system intervention without the need of combining these data within the ACC-system itself.,10.1.1.1.3316,Driver assistance system course prediction lane,?
Adaptive Resource Management for,Scalable Network--Attached Storage Konstantinos Kalpakis Koustuv Dasgupta Shamit Patel,2002,The growth in the commercial use of the Internet and the proliferation of data-intensive network services have heightened the demand for large--scale storage systems. Over the last few years Network--Attached Storage has emerged as a basic tenet for simplified storage management and improved scalability reliability and performance of storage systems.,10.1.1.1.3317,resource management replication hashing load balancing Network–Attached Storage,?
Alias Types,Frederick Smith David Walker  Greg Morrisett,1999,Linear type systems allow destructive operations such as object deallocation and imperative  updates of functional data structures. These operations and others such as the ability to reuse  memory at di#erent types are essential in low-level typed languages. However traditional linear  type systems are too restrictive for use in low-level code where it is necessary to exploit pointer  aliasing. We present a new typed language that allows functions to specify the shape of the store  that they expect and to track the flow of pointers through a computation. Our type system is  expressive enough to represent pointer aliasing and yet safely permit destructive operations.,10.1.1.1.3318,?,Springer-Verlag
Debugging Support for an Optimized Modelica Compiler,Kaj Nyström,2003,?,10.1.1.1.3319,iv,?
Genome Informatics 14: 627--628 (2003) 627 Quantifying the Spiral Leaf Trait of Arabidopsis from,The Shape Model Eli Kaminuma Naohiko Heida Yuko Tsumoto Minami Matsui Tetsuro Toyoda Akihiko Konagaya,?,this report we focus on the spiral leaf trait [3 4] as one of 3D-specific traits at rosette leaves and propose a quantitative definition of the spiral leaf trait. Through an experiment to extract the quantitative spiral leaf trait at a wild-type and a mutant line we exhibit the importance for quantifying traits precisely towards computational screens based on the 3D reconstructed model,10.1.1.1.3320,Arabidopsis thaliana functional genomics mutant screening phenotype 3D spiral leaf,?
A Process for Transitioning to Object-Oriented Technology,  David Diskin,1996,?,10.1.1.1.3321,EXECUTIVE SUMMARY...................................................................................,?
Measuring Notification Loss in Publish/Subscribe Communication Systems,R. Baldoni R. Beraldi S. Tucci Piergiovanni A. Virgillito,2004,A publish/subscribe communication system (PSS) realizes a many-to-many anonymous interaction among its participants. Producers of information (publishers) issue notifications to the PSS. These are delivered by the PSS to all subscribers that declared interest in it. However this decoupled form of interaction introduces delays between i) the production of a notification and its delivery to subscribers (diffusion delay) and ii) the declaration of interest by a subscriber and its registration in the PSS (subscription/unsubscription delay). Such delays could lead to notification loss scenarios where an event is not delivered to an intended subscriber even though it was issued when the subscription was active. This paper studies this notification loss phenomenon by presenting a simulation study of a PSS and an analytical model. The latter measures the percentage of notifications guaranteed by a PSS implementation to a subscriber. To our knowledge this is the first paper that addresses such a QoS issue. The model is based on a formal framework of a distributed computation. The framework abstracts the PSS through the two delays defining safety and liveness properties that precisely characterize the semantics of the PSS.,10.1.1.1.3322,?,?
Transient activation of a somatosensory area in painful hallucinations shown by fMRI,Karl-Jürgen Bär  Christian Gaser Ca Christian Gaser Igor Nenadic Heinrich Sauer,2002,INTRODUCTION  Schizophrenia like many other psychiatric disorders is accompanied by disturbance of somatosensory function which is often minute. This includes compromised somatosensory feedback and action monitoring [1] as well as pathological pain perception for example abnormal pain thresholds [2] or painful somatosensory hallucinations i.e. spontaneous perception of pain without adequate external stimuli. Co-enaesthetic hallucinations (from co-aneasthesia [34]) are encountered in a small subset of patients with schizophrenia. The main symptoms of this sub-syndrome include tactile hallucinations and itching or burning sensations which are often painful [5]. This syndrome is relatively rare compared to auditory hallucinations in schizophrenia and its biological basis is mostly unexplored [6]. It is unclear which particular brain areas are involved in the generation of hallucinations of pain in this condition.  Functional neuroimaging could provide a useful method to detect ,10.1.1.1.3324,Key words Co-enaesthesia Functional magnetic resonance imaging (fMRI Hallucination Pain Schizophrenia Somatosensory,?
Protection Mechanisms for Application Service Hosting Platforms,Xuxian Jiang Xuxian Jiang Dongyan Rudolf Eigenmann,2004,The Application Service Hosting Platform (ASHP) has recently received tremendous attention from both industry and academia. An ASHP provides a shared highperformance infrastructure to host different Application Services (AS) outsourced by Application Service Providers (ASP). In this paper we focus on the protection of ASHP which has inherent requirement of sharing openness and mutual isolation. Different from a dedicated server platform which is analogous with a private house an ASHP is like an apartment building involving the `host - the ASHP infrastructure and the `tenants - the AS. Strong protection and isolation must be provided between the host and the tenants as well as between different tenants.,10.1.1.1.3325,?,?
Hardware/Software Co-design,Of An Atm Jean-marc Daveau Gilberto Marchioro Ahmed Amine Jerraya,1998,This paper discusses a case study the co-design of an ATM Network Interface Card (NIC). The NIC is aimed to interface applications with the physical network line. It is composed of a stack of four protocol layers: TCP IP AAL and ATM.,10.1.1.1.3326,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice E. Jack Chen,?,Two-stage indifference-zone selection procedures have been widely studied and applied. It is known that most indifference-zone selection procedures also guarantee multiple comparisons with the best confidence intervals with half-width corresponding to the indifference amount. We provide the statistical analysis of multiple comparisons with a control confidence interval that bounds the difference between each design and the unknown best and multiple comparisons with the best confidence intervals. The efficiency of selection procedures can be improved by taking into consideration the differences of sample means using the variance reduction technique of common random numbers and using sequentialized selection procedures. An experimental performance evaluation demonstrates the validity of the confidence intervals and efficiency of sequentialized selection procedures.,10.1.1.1.3327,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Sugree Phatanapherom Putchong Uthayopas Voratas Kachitvichyanukul,?,Therefore a simulator is the most important tool for the evaluation of grid scheduling heuristics. A good simulator allows researchers to explore more alternatives and give an accurate statistically valid results. Furthermore the simulator can be used to study many heuristics which have their own different system model and application model.,10.1.1.1.3328,?,?
An Extension of Rate-Adaptive MAC Protocol for NS2 Simulator,Mingzhe Li Emmanuel Agu,?,The IEEE 802.11 wireless media access standard supports multiple data rates at the physical layer. Moreover various auto rate adaptation mechanisms at the medium access layer have been proposed to utilize this multi-rate capability by automatically adapting the transmission rate to best match the channel conditions. However there is little available simulation implementation available for the multi-rate adaptation research purpose. In this project an extension of rate-adaptive MAC protocol based on the Receiver-Based Auto-Rate (RBAR) was developed to enable the multi-rate simulation in NS2 simulator. Related simulation results and performance evaluation such as rate adaptation throughput delay and etc. are also presented to validate the simulation module.,10.1.1.1.3329,?,Worcester Polytechnic Institute
Job Creation and Job Destruction in the Russian Federation,Trinity Economic Paper Alessandro Acquisti Jel Classification P Hartmut Lehmann,?,We study Russian job dynamics in transition using micro-level data sets from the December 1996 and June 1997 administrative records of firms in manufacturing mining trading and construction for a pool of representative regions. We show that in 1997 small firms were the most successful at creating jobs while medium and large firms were mainly destroying them. Privatised firms fared no better than state-owned firms whilst de novo private firms had a considerably superior record relative to other firms with respect to job creation. However much of this superior performance was related to labour market entry.,10.1.1.1.3330,?,?
Seminar on Algorithms and Models for Railway Optimization Crew scheduling,Crew Scheduling Jasper Möller,2002,Crew scheduling is an important part of the railway optimization process. Unfortunately  it is also a difficult one to solve due to both the size of the problem and the complexity of the  real life constraints. In this paper an overview of the problem is given and several solution  methods are presented. In the second part a specific approach based on the decomposition  of the problem into two phases the crew scheduling phase and the crew rostering phase is  covered in detail and various graph theoretic representations of the two phases are shown.,10.1.1.1.3331,?,?
Energy-Balanced Task Allocation for Collaborative,Processing In Networked Yang Yu Viktor K. Prasanna,?,Categories and Subject Descriptors  ##############  ### ############  ##### ######### ######### ### ######## ######## #####  #### ## ########### ####################### ####  General Terms    #### #### ## ######### ############### ##### #### ###### ### ############# ####### ##### ######## ### #################  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies...,10.1.1.1.3332,?,?
Designing Incentives for Peer-to-Peer Routing,Alberto Blanc Electrical Alberto Blanc,2004,In a peer-to-peer network each node is typically required to route packets on behalf of other nodes. We study the problem of designing incentives to ensure that nodes carry out this responsibility. We model the interactions between nodes as a random matching game and describe a simple reputation system that can provide incentives for good behavior. Using simulations we investigate the robustness of this scheme in the presence of noise and malicious nodes and we attempt to quantify some of the design trade-offs.,10.1.1.1.3333,?,?
T h e T h e E p h e m e r E p h e m e r i s i s,Focus And Books,2001,This paper was returned by the AGU referee with the comment Mr,10.1.1.1.3334,?,?
Design Development of a Stream Service in a Heterogeneous Client Environment,N. Pappas   S. Christodoulakis,2000,Most research in the area of designing and  implementing continuous media servers which  support delay-sensitive data like audio and  video has assumed either clients with very small  memory sizes for buffering and no secondary  storage (thin clients) or a homogeneous client  environment where all clients have exactly the  same performance characteristics. Both  assumptions are radically changing due to the  availability of inexpensive storage as well as the  great diversity of clients that exist now and will  exist in the future. In this work we look more  closely at the implications that the existence of  clients with diverse performance characteristics  may have in the server design. Our approach is  experimental. We use conventional hardware for  servers and clients and examine bottlenecks and  optimization options systematically in order to  reduce jitter and increase the maximum number  of clients that the system can support. We show  that the diversity of client performance  characteristics can be taken into account so that  all clients are well supported for delay-sensitive  retrieval in a heterogeneous environment. We  also show that their characteristics can be  exploited to maximize server throughput under  server memory constrains.,10.1.1.1.3335,?,?
Trust in Software Component Marketplaces,Thomas List  Jörg Köller,2001,In electronic commerce trust building measures are one way to make a marketplace more attractive for suppliers and potential customers. Often trust on marketplaces is built up through external trusted third parties (TTPs). TTPs are organizations that deal with various trust-related problems and are themselves trusted by the customers. This paper describes the different trust problems that arose when designing a marketplace for (very specific) software components in the chemical engineering domain. To overcome these problems different types of trust-building features will be included in the marketplace each requiring different TTPs.,10.1.1.1.3336,?,?
Does Geographic Targeting Of Nutrition Interventions Make Sense In Cities? Evidence From Abidjan And Accra,Saul Morris Carol Carol Levin Margaret Armar-klemesu Daniel Maxwell Marie T. Ruel,1999,Although most developing country cities are characterized by pockets of substandard housing and inadequate service provision it is not known to what degree low incomes and malnutrition are confined to specific neighborhoods. This analysis uses representative household surveys of Abidjan and Accra to quantify small-area clustering in service provision demographic characteristics consumption and nutrition. Both cities showed significant clustering in housing conditions but not in nutrition while income was clustered in Abidjan but less so in Accra. This suggests that neighborhood targeting of poverty-alleviation or nutrition interventions in these and similar cities could lead to undercoverage of the truly needy. CONTENTS Acknowledgments .................................................... vii 1. ,10.1.1.1.3337,Acknowledgments.................................................... vii,?
Overlay Mesh Construction Using Interleaved Spanning Trees,Anthony Young Jiang Chen Zheng Ma Arvind Krishnamurthy  Larry Peterson  Randolph Y. Wang,2004,In this paper we evaluate a method of using interleaved spanning trees to compose a resilient high performance overlay mesh. Though spanning trees of arbitrary type could be used to construct an overlay mesh we focus on a distributed algorithm that computes k minimum spanning trees on an arbitrary graph. The principal motivation behind this strategy is to provide applications with a k-redundant high quality mesh suitable for demanding applications like A/V broadcast video conferencing data collection multi-path routing and file mirroring/transfer. We elaborate details of k-MST pointing out advantages and potential problem points of the protocol and then analyze its performance using a variety of metrics with simulation as well as a functional PlanetLab implementation.,10.1.1.1.3338,System design Experimentation with real networks/Testbeds,?
Maximum and Asymptotic UDP Throughput under CHOKe,Jiantao Wang Ao Tang Steven H. Low,2002,A recently proposed active queue management CHOKe aims to protect TCP from UDP flows. Simulations have shown that as UDP rate increases its bandwidth share initially rises but eventually drops. We derive an approximate model of CHOKe and show that provided the number of TCP flows is large the UDP bandwidth share peaks at (e+1) -1 = 0.269 when the UDP input rate is slightly larger than the link capacity and drops to zero as UDP input rate tends to infinity regardless of the TCP algorithm.,10.1.1.1.3339,?,?
Evolution of trading rules for the FX market,Or How To Hakan Jonsson Payam Madjidi,?,Genetic programming is used to search for trading rules for the foreign  exchange market using very high frequency data. Trading systems  with retraining at regular intervals are studied with particular focus  on the generalization from training to test data. These are found to  generate higher returns than buy-and-hold and other algorithmically  simple profitable strategies for these data.,10.1.1.1.3340,?,?
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros B. A. Peters J. S. Smith D. J. Medeiros M. W. Rohrer,?,Production homebuilders operate in a sales-driven environment characterized by a varying demand for homes that is at odds with the homebuilders and their trade contractors requirement for work flow consistency. This paper presents a simulation-based approach for studying the production flow issues that production homebuilders face. Seven scenarios representing different practices and possibilities that the homebuilders have are simulated using Simphony a simulation platform intended for building Special Purpose Simulation (SPS) tools. The results of this study indicate that simulation can indeed be used to shed light on the work flow issues that production homebuilders face.,10.1.1.1.3341,?,?
Performance Analysis of Topology-Unaware TDMA MAC Schemes for Ad-Hoc Networks with Topology Control,Konstantinos Oikonomou  Nikos Pronios  Ioannis Stavrakakis,2004,Traditional omni-directional antennas result in increased mutliuser interference and are known to limit the performance of Medium Access Control (MAC) protocols for ad-hoc networks. Topo l ogy contro l is the capability of a node to control the set of neighbor nodes and in this paper the impact of using smart antennas and/or power control for topology control is investigated. The performance of TDMA MAC schemes with common frame for which the assignment of time slots to a node is not aware of the time slots assigned to the neighbor nodes (topology-unaware schemes like the Deterministic Policy and the Probabilistic Policy) is studied as well. A comparison based on analytical models reveals the advantages of topology control as well as its dependence on the mobility of the nodes and its resolution.Itisshown  that topology control with high resolution in highly mobile environments may not be e#ective and conditions are established under which topology control is beneficial. Simulation results for a variety of network topologies support the claims and the expectations of the aforementioned analysis and show that the system throughput achieved under topology control can be higher under both policies and especially under the Probabilistic Policy. Simulation results also show how mobility a#ects system throughput and that topology control may not be suitable for highly mobile environments.,10.1.1.1.3342,?,?
Characterizing Customer Groups for an E-commerce Website,Qing Wang  Dwight J. Makaroff  H. Keith Edwards,2004,In conventional commerce customer groups with similar interests or behaviours can be observed. Similarly customers in E-commerce naturally form groups. These groups allow the organization to provide quality of service (QoS) and perform capacity planning. From a system point of view overall server performance can be improved and resources managed considering customer session behaviour.,10.1.1.1.3343,Applications,?
Tracking And Motion Analysis Of The Left Ventricle With Deformable Superquadrics,Eric Bardinet  Laurent D. Cohen Nicholas Ayache,1996,We present a new approach to analyse the deformation of the left ventricle of the heart based on a  parametric model that gives a compact representation of a set of points in a 3-D image. We present  a strategy for tracking surfaces in a sequence of 3-D cardiac images. Following tracking we then  infer quantitative parameters which characterize: left ventricle motion volume of left ventricle  ejection fraction amplitude and twist component of cardiac motion. We explain the computation  of these parameters using our model. Experimental results are shown in time sequences of two  modalities of medical images nuclear medicine and X-ray computed tomography (CT). Video  sequences presenting these results are on the CD-ROM.,10.1.1.1.3344,Parametric models tracking left ventricle motion quantitative analysis of motion,?
Workplace Applications of Sensor Networks,Steven Conner John John Heidemann Lakshman Krishnamurthy Xi Wang Mark Yarvis,2004,Introduction  The current generation of interactive devices and networks foster a wide class of interactive ubiquitous computing applications [7]. The recent trend to integrate wireless networking into interactive devices such as PDAs cellular phones and portable computers has led to the availability of information such as news and stock quotes as well as services such as email appointment tracking and multimedia content from any location at any time. These applications have significantly improved workplace productivity despite the fact that human participation is often required in the compute loop. These applications have traditionally interacted with virtual content such as email financial records and text documents. Today millions of sensors are scattered throughout workplaces in both industrial and non-industrial office environments. These sensors include HVAC-monitoring devices such as thermometers barometers and moisture gauges safety monitors such as carbon monoxide a,10.1.1.1.3345,?,?
The Similarity Metric,Ming Li Xin Chen  Xin Li Bin Ma Paul M. B. Vitányi,2003,A new class of distances appropriate for measuring similarity relations between sequences say one type of similarity per distance is studied. We propose a new normalized information distance based on the noncomputable notion of Kolmogorov complexity and show that it is in this class and it minorizes every computable distance in the class (that is it is universal in that it discovers all computable similarities). We demonstrate that it is a metric and call it the similarity metric. This theory forms the foundation for a new practical tool. To evidence generality and robustness we give two distinctive applications in widely divergent areas using standard compression programs like gzip and GenCompress. First we compare whole mitochondrial genomes and infer their evolutionary history. This results in a first completely automatic computed whole mitochondrial phylogeny tree. Secondly we fully automatically compute the language tree of 52 different languages.,10.1.1.1.3346,?,?
The Orchestration of Behaviours Using Resources and Priority Levels,F. Lamarche S. Donikian,2001,Reproducing daily behaviours requires the ability to schedule behaviours depending  on resources (body parts for example) and priority (intentions or physiological  parameters) constraints. A simple way is to say that behaviours which are  using the same resources are mutually exclusive. This approach is not sufficient  to achieve realism purpose as in real life we are able to combine them in a much  microscopic way. All day long we mix different behaviours as for example  reading a newspaper while drinking a coffee and smoking a cigarette. If all behaviours  using common resources were mutually exclusive an agent could not  reproduce this example except if a specific behaviour is created. This solution  becomes rapidly too complex and has motivated the work presented in this paper.,10.1.1.1.3347,?,?
Formal System Development Using Method Integration: a Case Study,Demissie B. Aredo Demissie B. Aredo Olaf Owe,2004,In this paper we demonstrate feasibility of a development framework that integrates  semi-formal graphical modeling techniques with formal methods (FMs). In  particular the framework integrates the Unified Modeling Language (UML) with  the PVS environment to exploit the synergy between them. System descriptions  are given in the graphical UML notations and translated into PVS specifications  based on semantic definitions which we have proposed for the UML notations.,10.1.1.1.3348,Formal Methods UML OCL OUN PVS Method Integration,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Jakša Cvitani?,?,We consider the problem of a mutual fund manager that maximizes the present value of expected fees and has to decide the level of fee to impose on the fund. The fee will be paid by a risk averse investor that maximizes expected utility over final wealth. This investor can invest either in an indexed fund or in a managed fund. The manager has superior ability and as a result of it the fund offers a higher expected return. However the investor has incomplete information about the ability of the fund manager. The investor has priors about this ability that are upgraded according to the performance of the fund. At some optimal level the investor decides to switch from the market portfolio to the mutual fund. Our problem does not have a closed form solution but we can compute optimal fees using simulation.,10.1.1.1.3350,?,?
Universal Re-encryption for Mixnets,Philippe Golle   Markus Jakobsson Ari Juels Paul Syverson,2002,We introduce a new cryptographic technique that we call  universal re-encryption. A conventional cryptosystem that permits reencryption  such as ElGamal does so only for a player with knowledge of  the public key corresponding to a given ciphertext. In contrast universal  re-encryption can be done without knowledge of public keys. We propose  an asymmetric cryptosystem with universal re-encryption that is half as  efficient as standard ElGamal in terms of computation and storage. While,10.1.1.1.3351,?,Springer-Verlag
A Level Set Method for Three-dimensional Paraxial Geometrical Optics with Multiple Sources,Shingyu Leung   Jianliang Qian Stanley Osher,2004,We apply the level set method to compute the three dimensional multivalued geometrical optics term in the paraxial formulation. The paraxial formulation is obtained from the 3-D stationary eikonal equation by using one of the spatial directions as the artificial evolution direction. The advection velocity field used to move level sets is obtained by the method of characteristics therefore the motion of level sets is defined in a phase space. The multivalued traveltime and amplitude-related quantity are obtained from solving advection equations with source terms. We derive an amplitude formula in the reduced phase space which is very convenient to use in the level set framework. By using a semi-Lagrangian method in the paraxial formulation the method has O(N²) rather than O(N^4) memory storage requirement in the five dimensional phase space where N is the number of mesh points along one direction. Although the computational complexity is still O(MN^4) where M is the number of steps in the ODE solver for the semi-Lagrangian scheme this disadvantage is largely overcome by the fact that up to O(n²) multiple sources can be treated simultaneously. Three dimensional numerical examples demonstrate the efficiency and accuracy of the method. ,10.1.1.1.3352,?,?
A Realtime Software Solution for Resynchronizing Filtered MPEG2 Transport Stream (Extended Abstract),Bin Yu  Klara Nahrstedt,?,Bin Yu Klara Nahrstedt  Department of Computer Science  University of Illinois at Urbana-Champaign  binyuklara@cs.uiuc.edu  ABSTRACT  streaming applications over the current Internet manipulating MPEG streams in a realtime software manner is gaining more and more importance. In this work we studied the resynchronization problem that arises when a gateway changes the data content carried in an MPEG2 Transport stream. In short the distance between original timestamps is changed non-uniformly and decoders will fail to reconstruct the encoding clock from the resulting stream. We propose a cheap software realtime approach to solve this problem. Experimental results from a realtime HDTV stream lter shows that our approach is correct and ecient.,10.1.1.1.3353,?,?
Intrusion Detection Systems - Technologies . . .,Handledare Michaela Fatouros Examinator Viiveke Fåk X Examensarbete Arvidson Martin Arvidson Martin Arvidson Markus Carlbark Markus Carlbark Markus Carlbark,2003,Traditionally firewalls and access control have been the most important components used in order to secure servers hosts and computer networks. Today intrusion detection systems (IDSs) are gaining attention and the usage of these systems is increasing. This thesis covers commercial IDSs and the future direction of these systems. A model and taxonomy for IDSs and the technologies behind intrusion detection is presented. Today many problems exist that cripple the usage of intrusion detection systems. The decreasing confidence in the alerts generated by IDSs is directly related to serious problems like false positives. By studying IDS technologies and analyzing interviews conducted with security departments at Swedish banks this thesis identifies the major problems within IDSs today. The identified problems together with recent IDS research reports published at the RAID 2002 symposium are used to recommend the future direction of commercial intrusion detection systems.,10.1.1.1.3354,IDS intrusion detection taxonomy weaknesses Intrusion Detection Systems – Technologies Weaknesses and Trends,?
Estimation of Generalized Mixture in the Case of Correlated Sensors,A. Chorin A. Majda  and Christophe Michel Wojciech Pieczynski Julien Bouvrais Christophe Michel,1995,This paper deals with unsupervised Bayesian classification of multidimensional data. We propose an extension of a recent method of generalized mixture estimation to correlated sensors case. The method proposed is valid in the independent data case as well as in the hidden Markov chain or field model case with known applications in signal processing particularly speech or image processing. The efficiency of the method proposed is shown via some simulations concerning hidden Markov fields with application to unsupervised image segmentation.,10.1.1.1.3355,?,?
Axioms and Variational Problems in Surface Parameterization,Ulrich Clarenz  Nathan Litke  Martin Rumpf,?,For a surface patch on a smooth two-dimensional surface in IR     low-distortion parameterizations  are described in terms of minimizers of suitable energy functionals. Appropriate distortion measures are derived from principles of rational mechanics closely related to the theory of non-linear elasticity. The parameterization can be optimized with respect to the varying importance of conformality length preservation and area preservation. A finite element discretization is introduced and a constrained Newton method is used to minimize a corresponding discrete energy. Results of the new approach are compared with other recent parameterization methods.,10.1.1.1.3356,Key words Surface Parameterization Non-linear Elasticity Variational Methods Finite Element Methods,?
Finding Longest Increasing and Common Subsequences in Streaming Data,David Liben-nowell Erik Vee An Zhu,2003,In this paper we present algorithms and lower bounds for the Longest Increasing Subsequence  (LIS) and Longest Common Subsequence (LCS) problems in the data streaming model.,10.1.1.1.3357,?,?
A Game Tree Strategy for Automated Negotiation,Alan Karp Alan H. Karp Ren Wu Ren Wu  Kay-Yut Chen Kay-yut Chen  Alex Zhang Alex Zhang,2003,We present a strategy for automatic negotiation that takes the same approach  as computer programs that play games such as chess we build the  game tree. For every o#er we look at every countero#er every countero#er to  each of them and so on. The strategy then selects the countero#er that has  the largest expected payo#.,10.1.1.1.3358,?,?
Module 20 Medical Imaging case CAFCR Illustration,Gerrit Muller,2004,This module provides a complete illustration of the CAFCR based architecting method. The case is a Medical Imaging Workstation created in the early nineties.,10.1.1.1.3359,?,?
Astrology: The Study of Astro Teller,Stuart Andrews  Lijuan Cai David Gondek Amy Greenwald Daniel Grollman Arni Mar Jonsson Keith Hall Matthew Lease  Bryant Ng John Raiti  Victoria Sweetser Jenine Turner,2004,In this paper we describe how we address the ICML 2004 Physiological Data Modeling Contest. For  the gender prediction task we employ 5 o#-the-shelf machine learning methods: decision tree neural  networks naive bayes logistic regression and Support Vector Machines. We use neural networks for the  context prediction tasks. Most of the methods perform reasonably well acknowledging the success of  machine learning as a field. Moreover we point out that characteristic attributes are highly correlated  to the gender in the training data. Hence we argue if using characteristics for the gender prediction will  generalize well.,10.1.1.1.3360,?,?
Conservation farming in Zambia,Steven Haggblade  Gelson Tembo,2003,this paper jointly with funding from IFPRIs  Successes in African Agriculture Project and from Michigan State Universitys Zambia  Food Security Research Project (FSRP) which USAID/Zambia supports through the Food  Security III Cooperative Agreement between AID/Global Bureau and the Department of  Agricultural Economics at Michigan State University. Consequently this paper is being  distributed concurrently as an IFPRI discussion paper as well as FSRP Working Paper  Number 8.  The authors would like to thank Peter Aagaard George Allison Dutch Gibson  Mukelabai Ndiyoi and Ron Landless for the extensive insights they provided into the  agronomy history and evolution of conservation farming. We are likewise grateful to  Reuben Banda and his colleagues at CLUSA who provided highly professional field  assistance in conducting our on-farm surveys as well as in the laborious but meticulous  processing of the crop cut samples. Charles Hayward and Mike Burgess of Dunavant  Cotton provided invaluable cooperation and support without which our census of  Dunavant distributors would not have been possible. We likewise extend many thanks to  Stephen Kabwe a Research Assistant at Food Security Research Project (FSRP) for his  help during survey data cleaning and to Dr. Fusya Goma and Dr. Mumba of the Animal  Production Health of the Ministry of Agriculture and Cooperatives for providing data and  interpretation of animal draft statistics. Cynthia Donovan helped us considerably in  tracking down useful comparative literature and in providing valuable detailed comments  on our original draft.  Conference participants at the IFPRI Analytical Team Workshop in Lusaka in  June 2002 offered highly constructive feedback on our original draft paper. In addition  we have received insigh...,10.1.1.1.3361,?,?
Genome Informatics 14: 615--616 (2003) 615 Xenopus Cell Cycle Pathway for Simulating Cell,Division Processes By Mika Matsui Sachie Fujita Shun-ichi Suzuki Hiroshi Matsuno Satoru Miyano,?,This paper proposed a new method for modeling cell division processes with using a famous multicellular phenomenon the changes in cell division cycles from synchronous to asynchronous in Xenopus and succeeded in simulating this phenomenon with GON,10.1.1.1.3362,Petri net Xenopus cell cycle Genomic Object Net,?
Labeled Trees and the Efficient Computation of Derivations,Robert Grossman Richard G. Larson,2004,This paper is concerned with the effective parallel symbolic computation of operators under composition. Examples include differential operators under composition and vector fields under the Lie bracket. In general such operators do not commute. An important problem is to find efficient algorithms to write expressions involving noncommuting operators in terms of operators which do commute. If the original expression enjoys a certain symmetry then naive rewriting requires the computation of terms which in the end cancel. In [8] we gave an algorithm which in some cases is exponentially faster than the naive expansion of the noncommutating operators. The purpose of this paper is show how that algorithm can be naturally parallelized. In section 2 we give a careful...,10.1.1.1.3363,?,?
On the Existence of Universal Nonlinearities for Blind Source Separation,Heinz Mathis Scott C. Douglas Senior Member,2002,Many density-based methods for blind signal separation employ one or more models for the unknown source distribution (s). This paper considers the issue of density model mismatch in maximum likelihood (ML)-type blind signal separation algorithms. We show that the score function nonlinearity which was previously derived from the standpoint of statistical efficiency is also the most robust in maintaining a separation solution for the ML algorithm class. We also consider the existence of a universally applicable nonlinearity for separating all signal types deriving two results. First among nonlinearities with a convergent Taylor series a single fixed nonlinearity for universal separation using the natural gradient algorithm cannot exist. Second among nonlinearities with a single adjustable parameter a recently proposed threshold nonlinearity can separate all signals with symmetric amplitude distributions as long as the threshold parameter is properly chosen. The design of difficult-to-separate signal distributions is also discussed.,10.1.1.1.3364,?,?
A Cinematography System for Virtual Storytelling,Nicolas Courty Fabrice Lamarche  Stephane Donikian  Eric Marchand,2003,In this paper we introduce a complete framework to automatically generate cinematographic view of  highly dynamic scenes in real-time. The main goal of such a system is to provide a succession of shots and sequences  (of virtual dynamic scenes) that can be related to pure cinema. Several major difficulties are to be considered. Above  all the real-time constraint makes impossible to consider scripted actions or planned phases that are common in  real cinema (storyboards). Thus one should consider on one hand the use of cinematographic rules (idioms) as  a basis to describe camera behaviors and on the other hand camera control modules that can cope with dynamic  scenes. Our system is based on the use of an image-based control of the camera that allows different levels of visual  tasks and a multi-agent system that controls those cameras and selects the type of shot that has to be performed  in order to fulfill the constraints of a given idiom. This capacity of adaptation constitutes the major novelty of our  system. Moreover it stands for a convenient tool to describe cinematographic idioms for real-time narrative virtual  environments.,10.1.1.1.3366,?,Springer
On Generalized Gossiping and Broadcasting,Samir Khuller Yoo-ah Kim  Yung-Chun (Justin) Wan,2003,The problems of gossiping and broadcasting have been widely studied. The basic  gossip problem is defined as follows: there are n individuals with each individual having an  item of gossip. The goal is to communicate each item of gossip to every other individual.,10.1.1.1.3367,?,Springer-Verlag
An experiment using DLV-K,Rocío Santillán Alejandra López,2004,The Traffic World is an action domain proposed by Erik Sandewall. We represented part of this domain in the logic-based planning language DLVK. Throughout this article we discuss the pros and cons of our approach using this language.,10.1.1.1.3368,?,?
Optimization Flow Control I: Basic Algorithm and Convergence,Steven H. Low David E. Lapsley,1999,We propose an optimization approach to flow control where the objective is to maximize the aggregate source utility over their transmission rates. We view network links and sources as processors of a distributed computation system to solve the dual problem using gradient projection algorithm. In this system sources select transmission rates that maximize their own benefits utility minus bandwidth cost and network links adjust bandwidth prices to coordinate the sources decisions. We allow feedback delays to be different substantial and time-varying and links and sources to update at different times and with different frequencies. We provide asynchronous distributed algorithms and prove their convergence in a static environment. We present measurements obtained from a preliminary prototype to illustrate the convergence of the algorithm in a slowly time-varying environment.,10.1.1.1.3369,gradient projection asynchronous algorithm,?
Enabling Secure Ubiquitous Interactions,Kevin Eustice   Shane Markstrum Venkatraman Ramakrishna Peter Reiher Leonard Kleinrock Gerald Popek,2003,Future ubiquitous computing environments will require devices to be  automatically and safely configured together to perform important tasks for the  users they support. Security concerns based on known vulnerabilities of the  Internet make it clear that any widely deployed new computing infrastructure  must be designed with substantially more security. The highly dynamic relationship  between applications devices and environments defies existing security  models and requires new techniques to deal with its unique demands. We  propose a new paradigm for creating and maintaining safe ubiquitous computing  environments based around the novel idea of organizing related devices  into spheres of influence a concept used to capture both geographical and semantic  groupings. Spheres are used to encapsulate policy and provide well-defined  boundaries for interactions. Intra-sphere interaction requires policy-based  negotiation between principals.,10.1.1.1.3370,?,?
FCND DP No.152,Fcnd Discussion Paper Lire Ersado,?,The paper examines taking into account the urban-rural divides the changes and  welfare implications of income diversification in Zimbabwe following macroeconomic  policy changes and droughts of the early 1990s. Data from two comparable national  income consumption and expenditure surveys in 1990/91 and 1995/96 show that the  percentage of households earning income from private and informal sources grew  considerably while that from government and formal sources declined. In general rural  households tend to have a more diversified portfolio of income compared to urban and  the degree of income diversification decreases with the level of urbanization. However  there are important differences in the level of diversification within the rural and urban  areas depending on wealth: while the relatively better-off households have a more  diversified income base in rural areas it is the poor that pursue multiple income sources  in urban areas. A decomposition of changes in welfare indicates that the total  contribution of income diversification is large and increased between 1990/91 and  1995/96 in both urban and rural areas. On the other hand there were significant declines  in returns to human and physical capital assets during the same period. The findings  suggest that households with a more diversified income base are better able to withstand  the unfavorable impacts of the policy changes and weather shocks. The fact that  relatively better-off households have a more diversified income base following the  shocks implies that the poor are more vulnerable to economic changes unaccompanied by  well-designed safety nets.      iii Contents   Acknowledgments............................................................................................................... v...,10.1.1.1.3371,?,?
A Scalable Workbench for Implementing and Evaluating Distributed Applications in Mobile Ad-hoc Networks,Johannes K. Lehnert  Daniel Görgen Hannes Frey Peter Sturm,2004,This work presents a Java-based development platform aimed to ease the task of building applications for mobile multihop ad-hoc networks. The platform follows a threetier development principle composed of simulation emulation and deployment on real mobile devices. Opposed to pure network simulators this development environment primarily focuses on an easy to use event-based programming model and scalability regarding simulating thousands of mobile devices. Additionally utmost code reuse is provided since attaching real hardware to the simulation and running the application on real devices are an integral part of the workbench. Performance evaluation by means of a benchmark application demonstrates that simulating over ten thousand mobile devices can be performed faster than in real-time. Also experiences gained from implementing a mobile auction system for ad-hoc networks proved that the integral parts for emulating and deployment are of high value when building real life applications for mobile multihop ad-hoc networks.,10.1.1.1.3372,?,?
Hierarchical Compact Cube for Range-Max Queries,Sin Yeung Lee Lee Tok Wang Ling Huagang Li,2000,A range-max query finds the maximum value  over all selected cells of an on-line analytical  processing (OLAP) data cube where the  selection is specified by ranges of contiguous  values for each dimension. One of the  approaches to process such queries is to precompute  a prefix cube (PC) which is a cube of  the same dimensionality and size as the original  data cube but with some pre-computed results  stored in each cell.,10.1.1.1.3373,?,?
An Efficient and Robust Computational Framework for Studying Lifetime and Information Capacity in Sensor Networks,Enrique J. Duarte-Melo   Mingyan Liu Archan Misra,2004,In this paper we investigate the expected lifetime and information capacity defined as the maximum amount of data (bits) transferred before the first sensor node death due to energy depletion of a data-gathering wireless sensor network. We develop a fluid-flow based computational framework that extends the existing approach which requires precise knowledge of the layout/deployment of the network i.e. exact sensor positions. Our method on the other hand views a specific network deployment as a particular instance (sample path) from an underlying distribution of sensor node layouts and sensor data rates. To compute the expected information capacity under this distribution-based viewpoint we model parameters such as the node density the energy density and the sensed data rate as continuous spatial functions. This continuous-space flow model is then discretized into grids and solved using a linear programming approach. Numerical studies show that this model produces very accurate results compared to averaging over results from random instances of deployment with significantly less computation. Moreover we develop a robust version of the linear program which generates robust solutions that apply not just to a specific deployment but also to topologies that are appropriately perturbed versions. This is especially important for a network designer studying the fundamental lifetime limit of a family of network layouts since the lifetime of specific network deployment instances may di#er appreciably. As an example of this models use we determine the optimal node distribution for a linear network and study the properties of optimal routing that maximizes the lifetime of the network.  ,10.1.1.1.3374,?,?
A possibilistic approach to restore consistency in Answer Set Programming,Pascal Nicolas  Laurent Garcia  Igor Stephan,2004,In Answer Set Programming it is not possible to deduce  any conclusion from an inconsistent program (ie: a program  that has no model). The same issue occurs in classical  logic where there exist some techniques to handle  this inconsistency. In this work we propose to manage  inconsistent logic programs in a similar way as possibilistic  logic does for classical logic. We compute a consistent  subprogram keeping the most important rules of  the original program. This importance is described by a  necessity degree assigned to each rule.,10.1.1.1.3375,?,?
A Feedback-Based Approach for Data Contention Control,Kyoung-Don Kang Phil Phil H. Sin Dong Kook Shin,?,this paper we present a control theoretic approach for a database to autonomously-without substantial human interventions for (re)tuning the database-control data conflicts by adjusting the multiprogramming level even when the workload varies dynamically. To apply control theoretic approaches we mathematically model the relation between the multiprogramming level and data conflicts. Based on the model a feedback control framework is developed to maintain data conflicts if any below the threshold. Admission control and transaction cancellation are applied to enforce the required multiprogramming level adjustment computed in the feedback loop if necessary to control data conflicts. In this way data conflicts can be controlled to be below the threshold even when the system is under a transient state subject to substantial data conflicts. Hence the availability of database service can be significantly improved,10.1.1.1.3376,?,?
Ampere Tension and Newtons Laws,Thomas Phipps Jr,2001,metry does not suffice for cruciality and that a different type of asymmetry is needed:  Theorem (shape-independence). For the electromagnetic force laws (cf. Whittaker 1960) of Lorentz (Grassmann BiotSavart)  Ampere-Weber Gauss-Riemann and all others differing only by additive exact differential quantities the longitudinal force component (if any) acting along the length of a straight current-carrying test element T exerted by currents flowing in an external partial circuit C of given shape joining fixed endpoints E E (E E and C being nowhere coincident with T) is independent of the shape of C and depends only on the configuration of the gaps E--T and E--T i.e. on the spatial locations of E E relative to T.  Proof. For simplicity we limit consideration to filamentary circuits. Given fixed relative positions of E E T consider two alternative partial circuit shapes C C connecting E E as in Figure 1. Suppose that C C each carries a current I in the same sens,10.1.1.1.3377,?,?
Exploring Gradient-based Face Navigation Interfaces,Tzu-pei Grace Chen,2004,We have created a gradient-based face navigation interface that allows users to explore a large face space based on an eigenface technique. This approach to synthesizing faces contrasts with more typical techniques for forming composite faces based on the blending of facial features. We compare three ways of moving through the face space using two types of sliders and a face-wheel. These are adapted from typical color space interfaces since they are commonly used. However eigenface dimensions do not have meaningful text labels unlike primary colors necessitating the use of faces themselves for the labels of the navigation axes. Results suggest that users can navigate with face-labelled axes. They find slider interfaces best suited to finding the neighborhood of a target face but that the face-wheel is better for refinement once inside the neighborhood.,10.1.1.1.3378,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,Simulation is widely used for performance analysis of Personal Communication Systems due to their inherent complexity. However resource demands (cpu-time and memory requirements) for this type of simulation are often high. Consequently simulation fidelity demands must be carefully weighed against available computer resources in modeling. In models including measurements of interference from other transmitters one question that arises is up to what distance other transmitters must be included. This parameter has a direct impact on the amount of work performed in each interference calculation and is also of great importance for parallel and distributed models since it influences partitioning. In this paper the impact of the interference (or interaction) radius on fidelity and execution time is studied for a case model.,10.1.1.1.3379,?,?
Applications of Antenna Arrays to Mobile Communications Part I: Performance Improvement Feasibility and System Considerations,Lal C. Godara,1997,The demand for wireless mobile... This paper is the first of a two-part study. It provides a comprehensive treatment at a level appropriate to nonspecialists of the use of an antenna array to enhance the efficiency of mobile communications systems. It presents an overview of mobile communications as well as details of how an array may be used in various mobile communications systems including land-mobile indoor-radio and satellite-based systems. It discusses advantages of an array of antennas in a mobile communications system highlights improvements that are possible by using multiple antennas compared to a single antenna in a system and provides details on the feasibility of antenna arrays for mobile communications applications.,10.1.1.1.3380,multiple access,?
On-Road Vehicle Detection Using Optical Sensors: A Review,Zehang Sun George Bebis  Ronald Miller,2004,As one of the most promising applications of computer vision vision-based vehicle detection for driver assistance has received considerable attention over the last 15 years. There are at least three reasons for the blooming research in this field: first the startling losses both in human lives and finance caused by vehicle accidents second the availability of feasible technologies accumulated within the last 30 years of computer vision research and third the exponential growth of processor speed has paved the way for running computation-intensive video-processing algorithms even on a low-end PC in realtime. This paper provides a critical survey of recent vision-based on-road vehicle detection systems appeared in the literature (i.e. the cameras are mounted on the vehicle rather than being static such as in traffic/driveway monitoring systems).,10.1.1.1.3381,?,?
EMMA -- Towards a Query Algebra for Enhanced Multimedia Meta Objects,Sonja Zillner Utz Utz Westermann Werner Winiwarter,?,For efficient access to multimedia content the media data has to be enriched with additional information about the contents semantic description and functionality e.g. style sheets for rendering. Current approaches for semantic modeling of multimedia content store the information about the contents semantics and functionality in different files and at different locations which makes the retrieval and reuse of multimedia content very difficult. We have proposed Enhanced Multimedia Meta Objects (EMMOs) as a new means for semantic multimedia modeling that indivisibly combines multimedia content with its description and functionality. In this paper we introduce EMMA a query algebra which is adequate and complete with regard to the EMMO model enables query optimization allows the integration of ontology knowledge and supports distributive collaborative authoring.,10.1.1.1.3382,?,?
Axioms for Parthood and Containment Relations in Bio-Ontologies,Thomas Bittner,2004,To fix the semantics of different kinds of parthood relations we require axioms which go beyond those characterizing partial orderings. I formulate such axioms and show their implications for bio-ontologies. Specifically I discuss parthood relations among masses for example among body substances such as blood and portions thereof and among components of complexes for example between your stomach and your gastro-intestinal system. I contrast these with the relation of being contained in (as your lungs are contained in your thorax).,10.1.1.1.3383,?,?
Mobile Robot Navigation using a Sensor Network,M. Batalin  M. Hattig Gaurav S. Sukhatme,2003,We describe an algorithm for robot navigation using a sensor network embedded in the environment. Sensor nodes act as signposts for the robot to follow thus obviating the need for a map or localization on the part of the robot. Navigation directions are computed within the network (not on the robot) using value iteration. Using small low-power radios the robot communicates with nodes in the network locally and makes navigation decisions based on which node it is near. An algorithm based on processing of radio signal strength data was developed so the robot could successfully decide which node neighborhood it belonged to. Extensive experiments with a robot and a sensor network confirm the validity of the approach.,10.1.1.1.3384,?,?
Generating Natural Language Aggregations Using a Propositional Representation of Sets,Susan Haller Barbara Di Eugenio Michael Trolio,?,We present a method for aggregating information from an internal machine representation and building a text structure that allows us to express aggregations in natural language. Features of the knowledge...,10.1.1.1.3386,?,?
Realistic Synthesis of Novel Human Movements from a Database of Motion,Capture Examples Luis Luis Molina Tanco Adrian Hilton,2000,In this paper we present a system that can synthesise novel motion sequences from a database of motion capture examples. This is achieved through learning a statistical model from the captured data which enables realistic synthesis of new movements by sampling the original captured sequences. New movements are synthesised by specifying the start and end keyframes. The statistical model identifies segments of the original motion capture data to generate novel motion sequences between the keyframes. The advantage of this approach is that it combines the flexibility of keyframe animation with the realism of motion capture data.,10.1.1.1.3387,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Robert J. Burnside George H. Tompkins,?,Due to changes in production requirements the current facility was no longer adequate. A simulation study was conducted to help quantify the impacts of additional capacity when that capacity should be brought online and how to manage production in the interim before the new facility is available.,10.1.1.1.3388,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,A medium sized UK based academic publishers own a subsidiary printing business. Presently the Academic Printers (AP) is experiencing productions line flow problems reducing the efficiency of the operation. Most of the problems are generated by the imbalanced workflow through the system. By implementing a JIT production planning system it is hoped that some of the production problems can be resolved. Using the simulation software a model was created to investigate the performance of the AP under a variety of operating conditions. Results showed that operating the system with JIT control would not produce economic performance improvements due to constraints applied by the printing process.,10.1.1.1.3389,?,?
Annotations in the Wild,Laurent Denoue And,?,We believe that storing web annotations on annotation servers limits the widespread adoption of web annotation technology. Instead of relying on annotation servers we propose to encode annotations as an extended URL. Because they follow the standard URL encoding these extended URLs can be readily used and embedded in Web documents. We then envision specific search engines that would be able to index these extended URLs and provide interesting new services.,10.1.1.1.3390,?,?
Transport pathways for Asian pollution outflow over the Pacific:,Interannual And Seasonal Hongyu Liu Daniel J. Jacob Isabelle Bey Robert M. Yantosca Bryan N. Duncan Glen W. Sachse,2003,n pollution signal.  Spring 2001 (La Nina) was characterized by unusually frequent cold surge events in the  Asian Pacific rim and strong convection in Southeast Asia leading to unusually strong  boundary layer outflow of anthropogenic emissions and convective outflow of biomass  burning emissions in the upper troposphere. The Asian outflow flux of CO to the Pacific is  found to vary seasonally by a factor of 3 -- 4 (maximum in March and minimum in  summer). The March maximum results from frequent cold surge events and seasonal  biomass burning emissions. INDEX TERMS: 0368 Atmospheric Composition and Structure:  Troposphere---constituent transport and chemistry 0365 Atmospheric Composition and Structure:  Troposphere---composition and chemistry 3364 Meteorology and Atmospheric Dynamics: Synoptic-scale  meteorology KEYWORDS: pollution transport outflow pathways carbon monoxide biomass burning  interannual variability  Citation: Liu H. D. J. Jacob I. Bey R. M. Yantosca B. N.,10.1.1.1.3391,?,?
FIPA-compliant MAS development for road traffic management with a Knowledge-Based approach: the TRACK-R agents,A. M. Garcia-Serrano  D. Teruel Vioque,2003,In this paper we describe our work in the design of agent-based systems using available standards and our previous experiences in the development of knowledge-based applications in the domain of road traffic management. Our main goal in this first step has been to join the development of FIPA compliant agents with the use of knowledge-based techniques during design and a logic programming language. The result of this work has been reflected on the TRACK-R agents responsible of a geographical area that has to communicate in order to provide traffic routes recommendations for humans or other agents. Currently we have three agents running that allows a simple human request for recommendation as well as other TRACK-R agents requests. This work has been funded by the proyects DAMMAD (TIC20001370 -C04) and Agentcities.NET (IST-2000-28384).,10.1.1.1.3392,General Terms Design Languages Standardization. Keywords Multiagent systems traffic management prolog FIPA Agentcities. 1. INTRODUCTION,?
Applying Business Process Modeling,To Organizationalchange Ricardo Ricardo Mendes João Mateus Eduardo Silva José Tribolet Centro De Engenharia Organizacional Inesc Inovação,1993,Organizational change can be regarded as a process that changes the state of the organization. This simple  yet powerful idea is the ground basis for the work being presented in this paper.,10.1.1.1.3393,Business Process Modeling Organizational Change UML Process Re-engineering Process Improvement Business Strategy,Publishing
Tobias Scheer Nice,The Rhythmic Law Edited Gerhild Zybatow Uwe Junghans Grit Mehlhorn Luka Szucsich Frankfurt Am Main Lang Tobias Scheer Nice,?,this paper is to evidence two intricate distributional regularities of Czech that have not been identified so far. First I show that the length of vowel-final prefixes depends on the kind of suffix attached to the stem. Namely if the first suffix is of nominal character the prefix shows length. If on the other hand a verbal suffix is added the prefixal vowel is short. The second generalisation I bring to light is a sub-regularity of the first: once it is understood that words of verbal character (e.g. verbs participles) are not eligible for prefixal length it appears that being a nominal item (nouns adjectives) is just a necessary condition for provoking prefixal length. The sufficient condition is of phonological nature: nominal items exhibit prefixal length only if their root-vowel is short. In other words there is an absolute prohibition of two consecutive long vowels cohabitating in the particular morphological site [prefix+root]. Elsewhere in the language there is no restriction on sequences of long vowels: zskvn dk#vzdn.   This generalisation is obviously parallel to what is known as the Rhythmic Law in Slovak  and possibly both are an instatiation of the same phonological mechanism. The Rhythmic   Law (e.g. Rubach 1993) states that a long vowel is shortened if it is preceded by another long   vowel. It does make no reference to morphological information at all. At first glance the   Czech situation seems to be the reverse: when two long vowels meet the fist one is shortened.  I show that both sets of data may be unified if morphological structure is taken into account:  all instances of the Rhythmic Law concern sequences of long vowels whereby the first is rootinternal and the second of suffixal nature. Hence the Czech and Slovak situation may be  ...,10.1.1.1.3395,?,?
The Effect of Identifying Vulnerabilities and Patching Software on the Utility of Network Intrusion Detection,Richard Lippmann  Seth Webster  Douglas Stetson,2002,Vulnerability scanning and installing software patches for known  vulnerabilities greatly affects the utility of network-based intrusion detection  systems that use signatures to detect system compromises. A detailed timeline  analysis of important remote-to-local vulnerabilities demonstrates (1) Vulnerabilities  in widely-used server software are discovered infrequently (at most 6  times a year) and (2) Software patches to prevent vulnerabilities from being exploited  are available before or simultaneously with signatures. Signature-based  intrusion detection systems will thus never detect successful system compromises  on small secure sites when patches are installed as soon as they are available.,10.1.1.1.3396,intrusion detection vulnerability attack network signature false alarm scan probe DoS worm exploit Internet patch,?
Classification of Boolean Cubic Forms in Nine Variables,Eric Brier  Philippe Langevin,2003,We describe a new invariant that we have used to obtain the  complete classification of the cubic forms of nine variables. In particular  we compute the covering radius of RM(2 9) into RM(3 9).,10.1.1.1.3397,?,Press
Design of Structure and Realisation of Game Rules Database of Robot-Soccer Game,Bohumil Horak  Vaclav Snasel,?,In this paper we developed system for coordinatization the robot-soccer game. This coordinatization we want to use for strategy extraction. The robot soccer is bimilar ant-like systems which take advantage of agents situatedness to reduce or eliminate the need for centralized control or global knowledge. This reduces the need for complexity of individuals and leads to robust scalable systems. Such insect-inspired situated approaches have proven e#ective both for task performance and task allocation. The desire for general principled techniques for situated interaction has led us to study the exploitation of abstract situatedness -- situatedness in non-physical environments. The port-arbitrated behavior-based control approach provides a well-structured abstract behavior space in which agents can participate in situated interaction. We focus on the problem of role assumption distributed task allocation in which each agent selects its own task-performing role. This paper details our discretization the robot-soccer game.,10.1.1.1.3398,mobile robotics multi-robot coordination behavior-based control,?
Distance to the Drip Lines,Alejandro Rivero July Alejandro Rivero,?,It can be found that with the adequate measure the beta stability line  is equidistant from neutron and proton drip lines. We explore this fact  and its predictive potentiality in the simplest case the classic liquid drop  formula.,10.1.1.1.3399,?,?
Virtual Fashion- Tracking and Analyzing Cultural Dispersion on the World Wide Web,School Of Architecture Judith S. Donath Ta-gang Chiou Ta-gang Chiou,?,In the real world people clothe themselves in garments whose cut and design encodes information about their social identity. This encoding changes temporally as the design spreads throughout a population: this is the basis of fashion. A similar sense of fashion has emerged on the World Wide Web (WWW) as people embellish their homesites with links pictures and other objects that exhibit similar patterns of dispersion. I have developed tools and algorithms for tracking and analyzing this virtual fashion. The initial approach is to examine a set of selected homesites each week and track the spread of links. By developing a system for collecting and analyzing the data this research provides both macro and micro readings of the phenomenon of virtual fashion. The system shows what is popular ways that things are related and what is emerging online. I also use data collected by the system to think about existing social theories of fashion and see how they may help develop models of virtual fashion. This research helps people further understand how the WWW functions as a social environment. Thesis Supervisor: Judith S. Donath Title: Assistant Professor of Media Arts and Sciences Ta-gang Chiou The following people served as readers for this thesis:  Pattie Maes  Associate Professor Software Agents Group MIT Media Laboratory  Henry Jenkins  Associate Professor of Literature MIT Acknowledgements I am grateful for the help of many people who have made this work possible. I really appreciate the support I have received from my advisor Professor Judith Donath. Judith has always provided great input to this research. Her keen insight into online social spaces has always been of great help to me. I would like to thank the readers of this thesis Professor Pattie Maes and P...,10.1.1.1.3400,Ta-gang Chiou,?
Visualization Designs for Constraint Logic Programming,Manuel Carro Manuel Hermenegildo,?,We address the design and implementation of visual paradigms for observing the execution  of constraint logic programs aiming at debugging tuning and optimization and  teaching. We focus on the display of data in CLP executions where representation for  constrained variables and for the constrains themselves are seeked. Two tools VIFID and  TRIFID exemplifying the devised depictions have been implemented and are used to  showcase the usefulness of the visualizations developed.,10.1.1.1.3401,Logic Programming Constraint Logic Programming Visualization Debugging Performance Abstraction of Visual Representations,?
Frances L. Johnson (flj@cse.buffalo.edu),Stuart Shapiro Shapiro Frances L. Johnson,?,Introduction and Background  If a knowledge representation and reasoning (KRR) system gains new information that in hindsight might have altered the outcome of an earlier belief change decision the earlier decision should be re-examined. We call this operation reconsideration  (Johnson  Shapiro 2004) and the result is an optimal belief base regardless of the order of previous belief change operations. This is similar to how discussion in a jury room can help jurors to optimize their interpretation of the evidence in a trial regardless of the order in which that evidence was presented.  To simplify our example we assume a global decision function is used in the belief change operations and it will favor retaining the most preferred beliefs as determined by a preference ordering (#) that is irreflexive anti-symmetric and transitive. Any base can be represented as a sequence of beliefs in order of decending preference: B = p 1  p 2  . . .  p n  where p i is preferred over p ,10.1.1.1.3402,?,?
Solar System Velocity from Muon Flux Anisotropy,Monstein Wiesenstrasse Freienbach C. Monstein,2001,reference and it provides evidence against relativity theories. The measured value of the absolute velocity of the solar system after subtracting off the velocity due to the general Milky-Way galactic rotation and translation might provide an indication of dark neighbors to the solar system. Observations continued over the years might provide additional information. Bradley stellar aberration due to the absolute uniform motion of the solar system produces a small ( v c o ~10  3 -  ) fixed distorted or astigmatic view of the position of stars and planets (Wesley 1991a). To obtain accurate predictions based upon classical celestial mechanics observations should be corrected for this aberration. For example an adequate prediction of the precession of the perihelion of Mercury requires this correction using a reasonably accurate value of the absolute velocity of the solar system. The present measurement sheds light upon the long-standing important question: What velocity should be use,10.1.1.1.3403,?,?
HYDROLOGIC AND CHEMICAL WATERSHED MONITORING DATA By Carey Andrew Johnston,Virginia Polytechnic Institute Dr. Adil Godrej Carey Andrew Johnston Carey Andrew Johnston Dr. Thomas Grizzard Chairman,?,Watershed monitoring programs generally do not have perfect data collection success rates due to a variety of field and laboratory factors. A major source of error in many stream-gaging records is lost or missing data caused by malfunctioning stream-side equipment. Studies estimate that between 5 and 20 percent of stream-gaging data may be marked as missing for one reason or another. Reconstructing or infilling missing data methods generate larger sets of data. These larger data sets generally generate better estimates of the sampled parameter and permit practical applications of the data in hydrologic or water quality calculations. This study utilizes data from a watershed monitoring program operating in the Northern Virginia area to: (1) identify and summarize the major reasons for the occurrence of missing data (2) provide recommendations for reducing the occurrence of missing data (3) describe methods for infilling missing chemical data (4) develop and evaluate methods for infilling values to replace missing chemical data and (5) recommend different infilling methods for various conditions. An evaluation of different infilling methods for chemical data over a variety of factors (e.g. amount of annual rainfall whether the missing chemical parameter is strongly correlated with flow amount of missing data) is performed using Monte Carlo modeling. Using the results of the Monte Carlo modeling a Decision Support System (DSS) is developed for easy application of the most appropriate infilling method. iii  ACKNOWLEDGMENTS  Dr. Thomas Grizzard Virginia Tech provided the initial concept for this thesis project and direction and guidance during its development. Dr. Adil Godrej Virginia Tech provided comments during development. Mr. Harold Post Occoquan Watershed ...,10.1.1.1.3404,direction and guidance during its development. Dr. Adil Godre,?
The Twin Paradox in Special Relativity and in Lorentz Ether Theory,Alexander L. Kholmetskii Earth Star,2003,Introduction  Since the appearance of the special relativity theory (SRT) the twin paradox has been discussed in many papers and textbooks. One of the most interesting papers on the subject was recently published in Apeiron [1]. This publication prompts me to continue a discussion about this paradox. Section 2 analyses the problems to be found in [1] in more detail. Section 3 presents a variety of twin paradox where the motional trajectories of two twins are not definite but may be realized with some probability. Finally Section 4 explains the twin paradox in LET as well as in any other possible ether theory which adopts a Galilean metric of absolute space. The subsection 4.1 develops a mathematical apparatus for LET.  2. The Twin paradox as presented by Tom  Van Flandern  In ref. [1] the twin paradox was considered with an imaginary Global Positioning System filling space between Earth and a star. The results obtained in [1] can also be presented at a schematic level as will be,10.1.1.1.3405,twin paradox special theory of relativity Lorentz ether theory © 2003 C. Roy Keys Inc,?
Automatically Generated High-Performance Code for Discrete Wavelet Transforms, Aca Ga?i?   Markus Püschel  José M. F. Moura,?,A growing number of performance-critical DSP application use the discrete wavelet transform (DWT) thus prompting the need for highly efficient DWT software implementations. Unfortunately the rapid evolution of computing platforms and compiler technology makes carefully hand-tuned code obsolete almost as fast as it is written. In this paper we describe our work on the automatic generation of DWT implementations that are tuned to a given platform. Our approach captures the various DWT algorithms in a concise mathematical framework that enables the integration of DWTs into the SPIRAL code generation system. Experiments show the quality of our automatically generated code and provide interesting insights for example the fastest code differs between platforms and is usually based on a non-obvious combination of DWT algorithms.,10.1.1.1.3406,?,?
Understanding Interactions Between Networks Controlling Distinct Behaviours: Escape and Swimming in Larval Zebrafish,P. Dwight Kuo  Chris Eliasmith,2004,Spinal neural networks in larval zebrafish generate a variety of movements  such as escape struggling and swimming. There have been a number of untested  proposals regarding possible mechanisms at both the network and neural levels  to account for switches between these behaviours. However there are currently  no detailed demonstrations of such mechanisms so it is not possible to determine  which are plausible and which are not. Here we propose a detailed biologically  plausible model of the interactions between the swimming and escape networks in  the larval zebrafish. This model shows how distinct behaviours can be controlled  by anatomically overlapping networks. More generally this paper demonstrates  a method for constructing spiking networks consistent with both high-level behavioural  descriptions and available neural data.,10.1.1.1.3407,CPG,?
Video Text Recognition Using Feature Compensation as Category-Dependent Feature Extraction,Minoru Mori,2003,When recognizing multiple fonts geometric features such as the directional information of strokes are generally robust against deformation but are weak against degradation. This paper describes a category-dependent feature extraction method that uses a feature compensation technique to overcome this weakness. Our proposed method estimates the degree of degradation of an input pattern by comparing the input pattern and the template of each category. This estimation enables us to compensate the degradation in feature values. We apply the proposed method to the recognition of video text suffering from degradation and deformation. Recognition experiments using characters extracted from videos show that the proposed method is superior to the conventional alternatives in resisting degradation.,10.1.1.1.3408,?,?
Classification of Access Network Types: Ethernet,Wireless Lan Adsl Wei Wei Bing Wang Chun Zhang Jim Kurose Don Towsley,2005,Ethernet wireless LAN ADSL cable modem and dialup are common access networks but have dramatically different characteristics. Fast and accurate classification of access network type can improve protocol or application performance significantly. In this paper we propose a simple and efficient end-end scheme to classify the type of an access network using packet pairs. Our scheme is based on the intrinsic characteristics of the various access networks and utilizes the median and entropy of the packet pair inter-arrival times. Extensive experiments show that our scheme obtains accurate classification results in a very short time (10 to 100 seconds).,10.1.1.1.3409,?,?
Chapter 3 A New Crawling Model and Architecture,New Crawling Model,?,logical representation on the Web graph.  The typical crawling algorithm comes from the early days of the World Wide Web and it is given by Algorithm 1. We consider that this algorithm can be improved because during crawling it is not necessary to add the newly found URLs to Q each and every time a Web page is parsed. The new URLs can be added in groups or batches because:  Indexing is done in batches. The crawling process adds information to a collection that will be indexed. The indexing process is done in batch many megabytes of text at a time and with current algorithms it is very inefficient to do it one document at a time unless you can achieve an exact balance between the incoming stream of documents and the processing speed of the index [TLNJ01] and in this case Algorithm 1 Typical crawling algorithm  Require: p 1  p 2  ... p n starting URLs  1: Q = {p 1  p 2  ... p n } queue of URLs to visit.  2: V = / 0 visited URLs.  3: while Q #= / 0 do  4: Dequeue p # Q ,10.1.1.1.3410,?,?
From a UML Platform Independent Component Model to Platform Specific Component Models,Tewfik Ziadi Tewfik Ziadi Bruno Traverson Bruno Traverson  Jean-Marc Jezequel Jean-marc Jézéquel,2002,In this paper we propose a set of UML extensions to describe a  platform independent model for software components. We use UML extensions  to define software component concepts (components ports and connectors).,10.1.1.1.3411,?,?
 A Recurrent Neural Network That Learns to Count,Paul Rodriguez Janet Wiles Jeffrey L. Elman,1999,?,10.1.1.1.3412,Recurrent neural network dynamical systems context-free languages,?
Robust Incentive Techniques for Peer-to-Peer Networks,Michal Feldman Kevin Lai  Ion Stoica  John Chuang,2004,Lack of cooperation (free riding) is one of the key problems that confronts todays P2P systems. What makes this problem particularly difficult is the unique set of challenges that P2P systems pose: large populations high turnover asymmetry of interest collusion zero-cost identities and traitors. To tackle these challenges we model the P2P system using the Generalized Prisoners Dilemma (GPD) and propose the Reciprocative decision function as the basis of a family of incentives techniques. These techniques are fully distributed and include: discriminating server selection maxflowbased subjective reputation and adaptive stranger policies. Through simulation we show that these techniques can drive a system of strategic users to nearly optimal levels of cooperation.,10.1.1.1.3415,C.2.4 [Computer-Communication Networks Distributed Systems J.4 [Social And Behavioral Sciences Economics General Terms Design Economics Keywords Incentives peer-to-peer free-riding reputation collusion cheap pseudonyms whitewash,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson Gary Gang Jing W. David Kelton José C. Arantes Ali A. Houshmand,?,Simulation with Arena is used to analyze a controlled conveyor network with merging configuration (CNMC). We use simulation to realize the logic in a queueingtheoretic model (QTM) and to analyze the behavior of CNMCs under various conditions. We also examine the performance of QTM while keeping or violating the QTM assumptions and constraints. Simulation experiments are designed for the special features of CNMC operations. Various situations are investigated to identify the behavior of CNMCs as well as the robustness of QTM. A case study is reported where mainline and induction-line speeds change proportionally.,10.1.1.1.3416,?,?
Comprehensive Summaries of Uppsala Dissertations,From The Faculty Daniel Noreland,?,this paper is to develop a hybrid method in which the computational domain is partitioned in two di#erent regions each of which is treated independently with a suitable numerical method. One of the method is formulated in the frequency domain whereas the other method is formulated in the time domain,10.1.1.1.3417,?,?
Impact of Access to Credit on Income and Food Security in Malawi,Aliou Diagne,?,The paper departs from the standard practice that takes the estimated marginal effects of either the amount of credit received or membership in a credit program as measures of the impact of access to credit on household welfare. The marginal effects of the formal credit limit variable on household welfare controlling for the credit limit from informal sources as well as the credit demanded from both sources measure the marginal effects of access to formal credit. The main finding of the paper is that access to formal credit by enabling households to reduce their borrowing from informal sources has marginally beneficial effects on household annual income. However these effects are very small and do not cause any significant difference between the per capita incomes food security and nutritional status of credit program members and noncurrent members. Moreover the beneficial substitution effect reflects only the fact that reduced borrowing from informal sources makes informal loans play a lesser role in the negative impact that borrowing (from formal or informal sources) has on net crop incomes. The marginal effects on household farm and nonfarm incomes resulting from mere access to formal credit (without necessarily borrowing) are positive and quite sizable but not statistically significant. Land scarcity and unfavorable terms of trade for the smallholders farm products remain by far the factors that most constrain per capita household income growth in Malawi. The paper concludes that the necessary complementary resources and economic environment are not yet in place for access to formal credit to realize its full benefits for Malawis rural population. CONTENTS  Acknowledgments ................................................... viii 1. ,10.1.1.1.3419,CONTENTS Acknowledgments................................................... viii,?
Constraint Handling in Manufacturing Planning Systems,Heimo Adelsberger Klaus-Peter Klaus-peter A. Keilmann,?,This paper deals with constraint handling in manufacturing. It starts with a basic de#nition of the constraint satisfaction problem followed by a description of consistency enforcing and constraint guided search. Constraint handling in scheduling problems is the main topic of the paper also presenting di#erent types of schedule construction methods and explaining the use of temporal constraints. Special attention is given to the task of mid-term production planning. First production planning in ordinary MRP II-based systems is introduced followed by the presentation of the master production scheduling leitstand #MPSL# a research and development activity of a #Forschungsschwerpunkt  at the University GH Essen.,10.1.1.1.3420,?,?
Oriented Particle Spray: Probabilistic Contour Tracing with Directional Information,Francois Pitie Anil C. Kokaram  Rozenn Dahyot,2004,Contour following is a standard activity in rotoscoping in the digital post production domain. An artist might need to cut out or edit an object separately from its background and it is left to the artist to manually create the cut out. Techniques for automatically tracing the edges of the object exist but these operate with heavy manual intervention. The most recent technique called JetStream is a considerable advance on manual or semi-automatic tracing but suffers from a lack of direction information in the image. This paper considers the incorporation of this information and so reworks the principle of density propagation for contour following. The approach is more robust than previous methods although inevitably needs user intervention to incorporate image semantics.,10.1.1.1.3421,Particle Filter Contour tracking Rotoscoping Bayesian Inference Sequential Importance Resampling Directional Filters Steerable Filtering,?
Towards an Integration of Different Specification Methods by Using the Viewpoint Framework,Bettina E. Enders Michael Goedicke Torsten Heverhagen Rudolf Tracht Peter Tröpfner,2002,In industrial interdisciplinary projects where engineers of different sorts have to work together a framework is necessary in order to support such an interdisciplinary development process. For example the design information created by the production automation engineer has to be set into relation to the software architecture the software designer has to produce which will control the automation plant. Such requirements result in the need to correctly and consistently integrate various specification methods and development processes applied during the development. This contribution focusses on...,10.1.1.1.3422,?,?
Searching And Language Classification,Anthony Aristar Wayne,2002,This paper will describe on-going work on language classification being carried out by the Wayne State University and Eastern Michigan University contingent of E-MELD. First in section 2 it will explain why a single and consistent language classification is important what the requirements of such a system are and why current standards are inadequate. Section 3 will propose a better system one that is in line with the `best practices advocated by Bird and Simons (2002). Section 4 will discuss a related problem of classifying (competing) language families and a solution in the form of a relational database design will be offered. Finally section 5 will show preliminary user interfaces to demonstrate what approaches are being taken in user-friendliness. 2. RELATING LANGUAGES TO DATA  When users type a language name into a search engine its often unclear whether what is returned will really be what they want. There are many reasons for this. For example a language may have several different names (Welsh is `Cymraeg to speakers of the language) and the search will not bring up any resources that are classified by a name different to that given to the search engine. The opposite problem also exists: two different and unrelated languages may have the same name (for example there is a Turkic language called Ainu spoken in Central Asia and another entirely unrelated Ainu spoken in northern Japan and the Kuril Islands) this would bring up irrelevant (i.e. too many) search results. The standard way of dealing with this problem has been to assign to a language and all its variant names a single language code. A search engine (or rather the database it searches) converts the language into the code and searches on the code instead. The existing standards ISO 63...,10.1.1.1.3423,?,?
Modelling the Evolution of Information Systems,J. L. H. Oei     H. A. Proper  E. D. Falkenberg,1992,In this article we discuss the need for information systems capable of evolving to the same extent as  organisation systems do. A set of requirements for evolving information systems is presented implying  the importance of the time concept in these systems. On the basis of these requirements an architecture  and a conceptual framework for evolving information systems is proposed. In our,10.1.1.1.3424,?,?
Using Multiple Memory Access Instructions for Reducing Code Size,Neil Johnson Alan Mycroft,2004,An important issue in embedded systems design is the size  of programs. As computing devices decrease in size yet with more and  more functions better code size optimizations are in greater demand. For an,10.1.1.1.3425,?,?
A Flexible Approach to Exception Handling in Open Multiagent Systems,Nazaraf H Shah Kuo-ming Chao Rachid Anane Nick Godwin,2003,Exception handling in multi-agent systems (MAS) is a complex issue due to distributed and decentralized nature of data and control in such systems. Autonomous agents representing different organizations need to implement a set of behaviors in addition to their problem solving behaviors in order to facilitate the coordinated exception handling processes across organizational boundaries. In this paper we review the limitations of the current domain independent exception handling approaches and propose a flexible approach to exception handling in MAS. The approach works by incorporating the exception handling services provided by the MAS infrastructure owner and local exception handling mechanism of individual agents. It allows the agent to use system provided exception handling service for all of its protocol related (social) exceptions or use its local exception handling mechanism to deal with a subset of these exceptions. It is claimed that this provides flexibility in exception handling. This work provides way of how to increase the reliability and availability of open agent system in exceptional situations.,10.1.1.1.3426,Robustness Multi-agent Systems,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,We discuss rare-event simulation methodology for computing tail probabilities for infinite-server queues. Our theoretical discussion also offers some new simulation insights into the change-of-measure associated with the Grtner-Ellis theorem of large deviations.,10.1.1.1.3427,?,?
Alias Annotations for Program Understanding,Jonathan Aldrich Valentin Kostadinov Craig Chambers,2002,One of the primary challenges in building and evolving large object-oriented systems is dealing with aliasing between objects. Unexpected aliasing can lead to broken invariants mistaken assumptions security holes and surprising side effects all of which may lead to software defects and complicate software evolution.,10.1.1.1.3428,?,ACM Press
Measurement-Based Multicast on Overlay Architecture,Tuna Güven Richard J. La Mark A. Shayman Bobby Bhattacharjee,2004,We propose a measurement-based routing algorithm to load balance intradomain  tra#c along multiple paths for multiple multicast sources. Multiple paths  are established using application-layer overlaying. The proposed algorithm is able  to converge under di#erent network models where each model reflects a di#erent  set of assumptions about the multicasting capabilities of the network. The algorithm  is derived from simultaneous perturbation stochastic approximation and  does not assume that the gradient of an analytical cost function is known to the  algorithm but rather relies on noisy estimates from measurements. Using the analytical  model presented in the paper we prove the convergence of the algorithm to  the corresponding optimal solution under each network model. Simulation results  are presented to demonstrate the additional benefits obtained by incrementally increasing  the multicasting capabilities. We also provide a comparative study with  the well-known IP multicast algorithm DVMRP.,10.1.1.1.3429,?,Online]. Available: http://www.cs.umd.edu/Library/TRs/CS-TR-4603/CS-TR-4603.pdf
Interpreting XML via an RDF Schema,Michel Kle In,?,One of the major problems in the realization of the vision of the Semantic Web is the transformation of existing web data into sources that can be processed and used by machines. This paper presents a procedure that can be used to turn XML documents into knowledge structures by interpreting them as RDF data via an RDF-Schema specification. This allows semantic annotation of XML documents via external RDF-Schema specifications. This procedure could potentially multiply the availability of semantically annotated data.,10.1.1.1.3430,?,?
An Object Based Algebra for Specifying a Fault Tolerant Software Architecture,Nicola Dragoni  Mauro Gaspari,2003,In this paper we present an algebra of actors extended with mechanisms to model crash failures and their detection. We show how this extended algebra of actors can be successfully used to specify distributed software architectures. The main components of a software architecture can be specified following an object-oriented style and then they can be composed using asynchronous message passing or more complex interaction patterns. We illustrate this process by means of a case study: the specification of a software architecture for intelligent agents which supports a fault tolerant anonymous interaction protocol.,10.1.1.1.3431,2002-10 Towards Self-Organizing Self-Repairing and Resilient Distributed Systems Montresor A Babaoglu O,?
Max-Min Overlay Multicast: Rate Allocation and Tree Construction,Yi Cui Yuan Xue Klara Nahrstedt,2004,Although initially proposed as the deployable alternative to IP multicast overlay multicast actually offers us great flexibilities on QoS-aware resource allocation for network applications. For example in overlay multicast streaming (1) the streaming rate of each client can be diversified to better accommodate network heterogeneity through various end-toend streaming adaptation techniques and (2) one can freely organize the overlay session by rearranging the multicast tree for the purpose of better resource utilization and fairness among all clients. The goal of this paper is to find the max-min rate allocation in overlay multicast which is pareto-optimal in terms of network resource utilization and max-min fair. We approach this goal in two steps. First we present a distributed algorithm which is able to return the max-min rate allocation for any given overlay multicast tree. Second we study the problem of finding the optimal tree whose max-min rate allocation is optimal among all trees. After proving its NP-hardness we propose a heuristic algorithm of overlay multicast tree construction. A variation of the heuristic is also designed to handle the dynamic client join/departure. Both of them have approximation bound of 1/2 to the optimal value. Experimental results show that they achieve high average throughput almost saturate link utilization and consistent min-favorability.,10.1.1.1.3432,?,?
Is Fair Allocation Always Inefficient,Ao Tang  Jiantao Wang Steven H. Low,2004,No.,10.1.1.1.3433,?,?
Audio-Visual Speaker Tracking with Importance Particle Filters,Daniel Gatica-perez Guillaume Lathoud  Iain McCowan Jean-marc Odobez  Darren Moore,2003,We present a probabilistic method for audio-visual (AV) speaker tracking using an uncalibrated wide-angle camera and a microphone array. The algorithm fuses 2-D object shape and audio information via importance particle filters (I-PFs) allowing for the asymmetrical integration of AV information in a way that efficiently exploits the complementary features of each modality. Audio localization information is used to generate an importance sampling (IS) function which guides the random search process of a particle filter towards regions of the configuration space likely to contain the true configuration (a speaker). The measurement process integrates contour-based and audio observations which results in reliable head tracking in realistic scenarios. We show that imperfect single modalities can be combined into an algorithm that automatically initializes and tracks a speaker switches between multiple speakers tolerates visual clutter and recovers from total AV object occlusion in the context of a multimodal meeting room. 1. ,10.1.1.1.3434,?,?
High Dimensional Radial Barrier Options,N. P. Firth J. N. Dewynne,2004,Pricing high dimensional American options is a di#cult problem in mathematical finance. Many simulation methods have been proposed but Monte Carlo is numerically intensive and therefore slow. We derive an analytic expression for a new type of multi-asset barrier option using Laplace transform methods. The solution is assumed to be radially symmetric in the normalized non dimensional variables hence the name Radial Barrier Options. In the single-asset case our results reduce to published results for American binary barrier options.,10.1.1.1.3435,?,?
Content Exchange Appliances,Dejan Milojicic  John Ankcorn  Larry Rudolph Himanshu Raj Rich Gossweiler  Sonia Garg  Franklin Reynolds  Rajnish Kumar Rich Gossweiler Jim Rowson Jim Rowson,2003,WWW and current Information Technology have made it easy to display a wide variety of content on  desktops and personal devices. Unfortunately little progress has been made for access to the content in  public areas. Some technologies such as Internet Kiosks and narrowcast enable content access (primarily  viewing) but not exchange. There is a growing need to access adapt and exchange desired information  with public displays for improved user experience.,10.1.1.1.3436,?,?
Measurement of Latency in Interactive Multimedia Art,Yoichi Nagashima,2004,In this paper I would like to introduce my experimental study of multimedia psychology. My initial focus of investigation is the interaction between perceptions of auditory and visual beats. When the musical and graphical beats are completely synchronized with each other as in a music video for promotional purposes the audience feels that they are natural and comforting. My initial experiment has proved that the actual tempos of music and images are a little different. If a slight time lag exists between the musical and pictorial beats the audience tries to keep them in synchronization by unconsciously changing the interpretation of the timebased beat points. As the lag increases over time the audience seems to perceive that the beat synchronization has changed from being more downbeat to more upbeat and continues enjoying it. I have developed an experiment system that can generate and control out-of-phase visual and auditory beats in real time and have tested many subjects with it. This paper describes the measurement of time lags generated in the experiment system as part of my psychological experiment.,10.1.1.1.3437,?,?
Fusion or Integration: Whats the difference?,Mark Oxley Steven Steven N. Thorsen,?,The U. S. Air Force    uses the term fusion in a very specific manner. For example the U.S. Air Force Research Laboratories have defined fusion on different objects like sensors data and classifiers. Yet there is ambiguity in some instances as to what is meant by it usage. Other Air Force research and acquisitions groups use the term integration to describe the process of combining data knowledge command control intelligence surveillance and reconnaissance. Even the U.S. Defense Advanced Research Program Agency (DARPA) has a program called Integrated Sensing and Processing (ISP) that aims to open the next paradigm for application of mathematics to the design and (co)operation of DoD sensor/exploitation systems and networks of such systems. The program hopes to develop mathematical tools that enable the design and global optimization of systems that interactively combine traditionally independent functions of sensing signal processing communication and exploitation. On the surface it appears that integration is the same as fusion. In this paper we define fusion and integration using the language of category theory. These definitions are in agreement with their usage in the Air Force. Using category theory we show the difference (and similarities) between fusion and integration.,10.1.1.1.3438,Fusion integration category theory graph theory,?
Shape and Appearance Models of Talking Faces for Model-Based Tracking,M. Odisio G. Bailly,2003,This paper presents a system that can recover and track the 3D speech movements of a speakers face for each image of a monocular sequence. A speaker-specific face model is used for tracking: model parameters are extracted from each image by an analysis-by-synthesis loop. To handle both the individual specificities of the speakers articulation and the complexity of the facial deformations during speech speaker-specific models of the face 3D geometry and appearance are built from real data. The geometric model is linearly controlled by only six articulatory parameters. Appearance is seen either as a classical texture map or through local appearance of a relevant subset of 3D points. We compare several appearance models: they are either constant or depend linearly on the articulatory parameters. We evaluate these different appearance models with ground truth data.,10.1.1.1.3439,?,?
How to Build a Foundational Ontology -- The Object-Centered High-level Reference Ontology OCHRE,Luc Schneider,2003,Foundational ontologies are axiomatic accounts of high-level  domain-independent categories about the real world. They constitute  toolboxes of reusable information modeling primitives for building application  ontologies in specific domains. As such they enhance semantic  interoperability between agents by specifying descriptively adequate  shared conceptualisations. The design of foundational ontologies gives  rise to completely new challenges in respect of their content as well  as their formalisation. Indeed their underlying modeling options correspond  to the ontological choices discussed in classical metaphysics as  well as in the research on qualitative reasoning. Building a foundational  ontology is thus an eminently interdisciplinary task. As a case study  this article sketches the formalisation of the Object-Centered High-level  REference ontology OCHRE emphasising in particular the problem of  achieving formal simplicity within the limits of descriptive adequacy.,10.1.1.1.3440,?,Springer
Ad-Hoc Localization Using Ranging and Sectoring,Krishna Kant Chintalapudi Amit Dhariwal Ramesh Govindan Gaurav Sukhatme,2004,Ad-hoc localization systems enable nodes in a sensor network to fix their positions in a global coordinate system using a relatively small number of anchor nodes that know their position through external means (e.g. GPS). Because location information provides context to sensed data such systems are a critical component of many sensor networks and have therefore received a fair amount of recent attention in the sensor networks literature. The efficacy of these systems is a function of the density of deployment and of anchor nodes as well as the error in distance estimation (ranging) between nodes.,10.1.1.1.3441,?,?
On the Security of PKCS ,Jolyon Clulow,2003,Public Key Cryptography Standards (PKCS)  has gained wide acceptance within the cryptographic security device community and has become the interface of choice for many applications. The high esteem in which PKCS  is held is evidenced by the fact that it has been selected by a large number of companies as the API for their own devices. In this paper we analyse the security of the PKCS  standard as an interface (e.g. an application-programming interface (API)) for a security device. We show that PKCS  is vulnerable to a number of known and new API attacks and exhibits a number of design weaknesses that raise questions as to its suitability for this role. Finally we present some design solutions.,10.1.1.1.3442,?,Springer-Verlag
Scalable and Accurate Identification of AS-Level Forwarding Paths,Z. Morley Mao  David Johnson  Jennifer Rexford  Jia Wang Mao David Johnson Jennifer Rexford Jia  Randy Katz,2004,Traceroute is used heavily by network operators and researchers to identify the IP forwarding path from a source to a destination. In practice knowing the Autonomous System (AS) associated with each hop in the path is also quite valuable. In previous work we showed that the IP-to-AS mapping extracted from BGP routing tables is not sufficient for determining the ASlevel forwarding paths [1]. By comparing BGP and traceroute AS paths from multiple vantage points [1] proposed heuristics that identify the root causes of the mismatches and fix the inaccurate IP-to-AS mappings. These heuristics though effective are laborintensive and mostly ad hoc. This paper proposes a systematic way to construct accurate IP-to-AS mappings using dynamic programming and iterative improvement. Our algorithm reduces the initial mismatch ratio of 15% between BGP and traceroute AS paths to 5% while changing only 2.9% of the assignments in the initial IP-to-AS mappings. This is in contrast to the results of [1] where 10% of the assignments were modified and the mismatch ratio was only reduced to 9%. We show that our algorithm is robust and can yield near-optimal results even when the initial mapping is corrupted or when the number of probing sources or destinations is reduced. Our work is a key step towards building a scalable and accurate AS-level traceroute tool.,10.1.1.1.3443,?,?
On-line Signature Verification Using Local Shape Analysis,Mingfu Zou Jianjun Tong Changping Liu Zhengliang Lou,2003,This paper presents a novel approach to the on-line signature verification using local shape Analysis. First segment the input signature into several segments using HMM (Hidden Markov Model). Then combine two adjacent segments to form a long segment and get its spectral and tremor information using FFT (Fast Fourier Transformation). At last accept it or reject it based on the similarity between the spectral and its prototype. In addition we proposed a novel initialization algorithm to avoid the local optimal of the HMMs reestimation and a novel algorithm to avoid losing the important information at cusps in preprocessing. Combining the local shape analysis with the local timebased comparison we get promising experimental results.,10.1.1.1.3444,signature Verification Hidden Markov Model Segmentation Biometric authentication Shape,?
On-line learning for Web query generation: finding documents matching a minority concept on the Web ,Rayid Ghani Rosie Jones Dunja Mladenic,?,This paper describes an approach for learning to generate  web-search queries for collecting documents matching a minority concept. As a,10.1.1.1.3445,?,?
Towards a Unified Theory of Cooperative Breeding: the role of ecology and life history re-examined,Ido Pen  Franz J. Weissing,2000,We present quantitative models that unify several adaptive hypotheses...,10.1.1.1.3446,?,?
Application-Level Graphic Streaming Channel,Patricio Inostroza Dpto Patricio Inostroza Jacques Lemordant,?,Scene Graph APIs are used to interact at the application level with a 2D or 3D scene. Examples of such APIs are the External Authoring Interface for VRML scenes or the MPEG-J scene graph API for MPEG-4 scenes. In the practice the application is running in the scene player as an applet or MPEGlet. This paper shows how a remote scene graph API can be implemented by defining a new graphic streaming channel at the application level. We describe a simple and compact communication protocol corresponding to this streaming channel and give an example of use of this channel. 1 ,10.1.1.1.3447,?,?
Performance Analysis and Constituent Code Design for Space-Time Turbo Coded Modulation over Fading Channels,Djordje Tujkovic  Ian Oppermann,2003,Recent advances in space-time coding and array processing have lead to substantial improvements in broadband wireless access  systems. A design method for constituent recursive space-time trellis codes (Rec-STTrCs) and parallel concatenated space-time  turbo coded modulation (STTuCM) was introduced recently as a new framework for building low complexity large equivalent  constraint-length STTrCs. In this paper STTuCM is analyzed in terms of the two-dimensional distance spectrum (DS) the truncated  union bound (UB) and the iterative decoding convergence. The derived bounds appeared to be tight over fast fading channels  but rather optimistic over quasi-static fading channels. Nevertheless the rank deficient part of the DS has been well enumerated  which turned out to be crucial for the accurate design of the full transmit diversity STTuCM in the second half of the paper.,10.1.1.1.3448,Index Terms,?
A Key Management Scheme for Wireless Sensor Networks Using Deployment Knowledge,Wenliang Du  Jing Deng  Yunghsiang Han Shigang Chen Pramod K. Varshney,2004,To achieve security in wireless sensor networks it is important to be able to encrypt messages sent among sensor nodes. Keys for encryption purposes must be agreed upon by communicating nodes. Due to resource constraints achieving such key agreement in wireless sensor networks is non-trivial. Many key agreement schemes used in general networks such as Diffie-Hellman and public-key based schemes are not suitable for wireless sensor networks. Pre-distribution of secret keys for all pairs of nodes is not viable due to the large amount of memory used when the network size is large. Recently a random key predistribution scheme and its improvements have been proposed.,10.1.1.1.3449,?,?
Cyclic Codes And Their Duals Over Z_m,Taher Abualrub,1999,In this paper we study the cyclic codes over Zm as being Zm -submodules of ZmG and we find their minimal generating sets. We also study the dual codes of cyclic codes and find their generators as being ideals in ZmG. Throughout this paper we assume m = q    q is a prime number and (n q)=1. 1. ,10.1.1.1.3450,?,?
Rencon 2004: Turing Test for Musical Expression,Rumi Hiraga Roberto Bresin  Keiji Hirata Royal Inst Of Technology Drottning Kristinas V,2004,Rencon is an annual international event that started in 2002. It has roles of (1) pursuing evaluation methods for systems whose output includes subjective issues and (2) providing a forum for researches of several fields related to musical expression. In the past Rencon was held as a workshop associated with a musical contest that provided a forum for presenting and discussing the latest research in automatic performance rendering. This year we introduce new evaluation methods of performance expression to Rencon: a Turing Test and a Gnirut Test which is a reverse Turing Test for performance expression. We have opened a section of the contests to any instruments and genre of music including synthesized human voices.,10.1.1.1.3452,Turing Test Musical Expression Performance Rendering,?
Towards a Quantitative Platform-Independent Analysis of Knowledge Systems,Noah S. Friedland  Paul G. Allen  Michael Witbrock Gavin Matthews  Nancy Salay Pierluigi Miraglia Jurgen Angele  Steffen Staab David Israel Vinay Chaudhri  Bruce Porter Ken Barker Peter Clark,2004,The Halo Pilot a six-month effort to evaluate the state-ofthe  -art in applied Knowledge Representation and  Reasoning (KRR) systems collaboratively developed a  taxonomy of failures with the goal of creating a common  framework of metrics against which we could measure  inter- and intra- system failure characteristics of each of the  three Halo knowledge applications. This platform  independent taxonomy was designed with the intent of  maximizing its coverage of potential failure types  providing the necessary granularity and precision to enable  clear categorization of failure types and providing a  productive framework for short and longer term corrective  action.,10.1.1.1.3453,?,AAAI Press
Energy Efficient Distributed JPEG2000 Image Compression in Multihop Wireless Networks,Huaming Wu Alhussein A. Abouzeid,2004,The problem of energy efficient image transmission over a resource constrained multi-hop wireless network is considered. Two methods of data exchange in distributed wavelet transform are proposed and investigated with respect to energy consumption and image quality. An energy-balancing distributed JPEG2000 image compression scheme which uses a combination of tiling of images and load balancing by nodes rotation is proposed. Simulation results show that the proposed scheme prolongs the system lifetime by up to 4 times and has a normalized total energy consumption comparable to centralized image compression.,10.1.1.1.3454,?,?
Using Organizational Modeling to Evaluate Health Care IS/IT Projects,André Vasconcelos   Ricardo Mendes José Tribolet,2004,This paper presents a research project that aims at creating a methodology for evaluating IS/IT Projects in the Portuguese Health Care System. This project is being jointly developed by the Center for Organizational Engineering and a task force from Sade XXI the Portuguese Health Operational Program. In order to create a framework on which to base project evaluation the project team developed a model of the Portuguese Health System using the CEO Framework. The CEO Framework is an UML-based organizational modeling framework that uses business process and information systems modeling techniques to represent monitor and simulate organizational behavior. The model created reflects the reality of the Portuguese Health Care System including the entities involved the inter and intra-organizational processes that are executed the current Information Systems Architecture and the in force Information Systems Strategy. Based on the created Organizational Model the project team created a tool that facilitates the evaluation of IS/IT projects by measuring (1) the support to the current processes (2) the conformance to the IS Architecture and Strategy (3) the relation with other past or current projects. This paper describes the organizational modeling process that was executed the developed evaluation methodologies and tools and the preliminary results regarding ongoing project evaluation.,10.1.1.1.3455,Organizational Modeling Information Systems Architecture UML Health Information Systems Project Evaluation CEO framework,?
 Better group behaviors using rule-based roadmaps,O. Burchan Bayazit Jyh-Ming Lien Nancy M. Amato,2002,  While techniques exist for simulating group behaviors these methods usually only provide simplistic navigation and planning capabilities. In this work we explore the benefits of integrating roadmap-based path planning methods with flocking techniques. We show how group behaviors such as exploring can be facilitated by using dynamic roadmaps (e.g. modifying edge weights) as an implicit means of communication between flock members. Extending ideas from cognitive modeling we embed behavior rules in individual flock members and in the roadmap. These behavior rules enable the flock members to modify their actions based on their current location and state. We propose new techniques for three distinct group behaviors: homing exploring (covering and goal searching) and passing through narrow areas. Animations of these behaviors can be viewed at,10.1.1.1.3458,?,?
A Problem Solving Environment for Modelling Stony Coral Morphogenesis,Roeland Merks Alfons Hoekstra Jaap Kaandorp Peter Sloot,2003,Apart from experimental and theoretical approaches computer  simulation is an important tool in testing hypotheses about stony  coral growth. However the construction and use of such simulation tools  needs extensive computational skills and knowledge that is not available  to most research biologists. Problem solving environments (PSEs) aim  to provide a framework that hides implementation details and allows the  user to formulate and analyse a problem in the language of the subject  area. We have developed a prototypical PSE to study the morphogenesis  of corals using a multi-model approach. In this paper we describe the design  and implementation of this PSE in which simulations of the corals  shape and its environment have been combined. We will discuss the relevance  of our results for the future development of PSEs for studying  biological growth and morphogenesis.,10.1.1.1.3459,?,?
REDUCING CHILD UNDERNUTRITION: HOW FAR DOES INCOME GROWTH TAKE US?,Lawrence Haddad Lawrence Haddad Harold Alderman Harold Alderman Lina Song Lina Song Yisehac Yohannes Yisehac Yohannes,?,How rapidly will child undernutrition respond to income growth? This study  explores that question using household survey data from 12 countries. In addition data  on the undernutrition rates since the 1970s available from a cross-section of countries are  employed in this investigation. Both forms of analysis yield similar results. Income  increases at household and national levels imply similar rates of reduction in  undernutrition. Using these estimates and better-than-historical income growth rates we  find that the Millennium Development Goal (MDG) of halving the levels of child  underweight by 2015 is unlikely to be met through income growth alone. What is needed  is a balanced strategy of income growth and investment in more direct interventions to  accelerate reductions in undernutrition.    iv       v CONTENTS  Acknowledgments .........................................................................................................vii    1. ,10.1.1.1.3460,CONTENTS,?
Wireless Bandwidth in the Making,Sergio Verdu,2000,Several emerging communication technologies hold the key to approaching the information theoretic limits of wireless multiple access channels. This article offers a brief review of those technologies and their promise to meet future demand for wireless data rate.,10.1.1.1.3461,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,Process oriented views are widely recognized as very useful for modeling but difficult to implement efficiently in a simulation system as compared to event oriented views. In particular the complexity and run-time overheads of the implementation have prevented the widespread use of process oriented views in optimistic parallel simulations. Here we review the conventional approaches to implementing process-oriented views and outline some of the sources of problems in those approaches. We also identify an approach that we call stack reconstruction which is most suited for portably and efficiently supporting optimistic process-oriented views. Benchmark simulations using our preliminary implementation which is incorporated in the TeD modeling and simulation system confirms the low overheads of this approach and demonstrates its capability to simulate over one million processes in a process-oriented model.,10.1.1.1.3464,?,?
P-systems: A structural model for kinship studies ,Frank Harary Douglas R. White,1997, Several mathematical models have been proposed for kinship studies. We propose an alternate structural model designed to be so simple logically and intuitively that it can be understood and used by anyone with a minimum of complication. It is called a P-system which is short for parental system. The P-system incorporates the best features of each of the previous models of kinship: a single relation of parentage graphs embedded within the nodes of other graphs and segregation of higher level descent and marriage structure from nuclear family structure. The latter is also the key conceptual distinction used by Lévi-Strauss (1969) in the theory of marriage alliance. While a P-system is used to represent a concrete network of kinship and marriage relationships this network also constitutes a system in the sense that it contains multiple levels where each level is a graph in which each node contains another graph structure. In sum the connections between the nodes at the outer level in a P-system are especially useful in the analysis of marriage and descent while at inner level we can describe how individuals are embedded in the kinship structure.,10.1.1.1.3465,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson Young H. Park,?,This article presents the results of research to develop a descriptive model of firm-level productivity that will allow a myriad of factor interactions to be directly accounted for. The model is a linked set of equations that attempt to capture how changes in one-factor influences the level of another factor and ultimately bottom-line performance. The model is coded in SIMAN. It is used to determine the best use of an infusion of funds -- should they go for additional automation or training etc. An application of the model to U.S. industry is presented based on parameter values obtained through a national survey.,10.1.1.1.3467,?,?
Stratum Approaches to Temporal DBMS Implementation,  Kristian Torp Christian S. Jensen Richard T. Snodgrass,1997,Previous approaches to temporal databases have assumed that a temporal database management  system (temporal DBMS) must be implemented from scratch as an integrated architecture to yield  adequate performance and to use new temporal implementation techniques such as temporal indexes  and join algorithms. However this is a very large and time-consuming task. In this,10.1.1.1.3468,?,?
Segmentation and Quantification of Brain Tumor,Chunyan Jiang Xinhua Zhang  Wanjun Huang Christoph Meinel,2004,Nowadays the inside situation could be obtained by medical machines such as Computed Tomography (CT) Magnetic Resonance Imaging (MRI) scanner etc. These noninvasive diagnosis means increase the precision of the diagnoses at the same time decrease the pain of the patients. Brain tumor diagnoses benefits from these devises very much. In the brain MR image the tumor is shown clearly. For the treatment the physician also needs the quantification of the tumor area. This requires the abnormal part in the image to be segmented accurately afterward the segmented area can be measured. This task could not be handled by hands totally. The computer can give great help during this procedure.,10.1.1.1.3470,segmentation level-set quantification DICOM,?
Simulation-Driven Architecture in the,Engineering Of Real-Time Trevor W. Pearce,2003,The Simulation-Driven Engineering (SDE) research project aims to improve real-time embedded system development by integrating the use of modeling and simulation as a fundamental cornerstone in all development stages. Shortterm goals are to simplify the reuse of engineering work products and to develop a discrete-event based simulation architecture suitable for target products. The long-term goals include supporting ambitious simulation applications such as simulation- based acquisition. SDE is a new initiative and this paper introduces the motivation for the research the initial decisions that have shaped the current directions and progress.,10.1.1.1.3471,?,?
Genome Informatics 14: 524--525 (2003) Genome Scale Classification of Extended Proteins,Predictor Sosuidumbbell Nobuyuki Nobuyuki Uchikoga Ke Rungcong Fumitsugu Akazawa Masashi Sonoyama Shigeki Mitaku,?,Introduction  Accurate classification of proteins from amino acid sequences is very helpful for the analysis of genome information. There are many novel genes in genomes which are mainly annotated on the basis of sequence homology. However many genes in genomes are not homologous to any other genes in the sequence level. Among various bioinformatic methods the use of physicochemical parameters of amino acid sequences for the classification of proteins has advantages in the analysis of functional unknown sequences [1] because its algorism is not dependent on the sequence homology with any other proteins and understandable in terms of the physical processes of folding.  We have already developed protein classification tools SOSUI and SOSUIdumbbell [4] which are the predictors of membrane proteins and soluble extended proteins respectively [3]. We have many data of membrane proteins for testing the accuracy of the methods and several performance tests have already been reported [2],10.1.1.1.3473,proteome gene classification extended protein DNA binding protein,?
Security Pitfalls of an efficient remote user authentication scheme using smart cards,Manoj Kumar,2004,In 2004 W. C. Ku and S. M. Chen proposed an efficient remote user authentication scheme using smart cards to solve the security problems of Chien et al.s scheme. Recently Hsu and Yoon et al. pointed out the security weakness of the Ku and Chens scheme Furthermore Yoon et al.s scheme also proposed a new efficient remote user authentication scheme using smart cards. This paper analyzes the security pitfalls of Yoon et als scheme and aims to show that the Yoon et al.s scheme is still vulnerable to the password guessing attack and the insider attack    .,10.1.1.1.3475,Index Terms — Cryptography Authentication Smart cards Password Check digit,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes David Goldsman Sebastien Pernet,?,of transportation systems. In particular we demonstrate a number of implementation tricks that are designed to make the modeling and coding processes more efficient and transparent. We present examples involving the simulation of commercial airline and military sealift operations.,10.1.1.1.3476,?,?
Instructions to Authors,Apeiron Is Scientific Wen-xiu Li Rediscovers Paradoxes,2001,In its function as a medium in which light is transmitted at constant velocity c it is evident that space in this mode is homogeneous and has no markers against which the velocity of a moving body can be registered. Any attempt to relate the velocity of a moving body on the one hand to light transit time in space on the other is therefore doomed to failure. For this reason the Michelson-Morley and similar experiments where the observer is situated at the eye-piece of the apparatus and comoving with it must give a null result.  The issue cannot be evaded by the assumption that light travels at speeds c v +    or c v -    as a result of the motion of the rocket relative to the Earth thus allowing earthbound calculators to claim that they have derived simultaneity of the clocks because if the same rule of light emission by a source in motion is applied within the rocket the clocks will then read differently (and the workers in the laboratory will also observe obscure Doppler effect,10.1.1.1.3478,?,?
Non-failure Analysis and Granularity Control in Parallel Execution of Logic Programs,Pedro Lopez Garcia,2000,Logic Programming Languages offer an excellent framework for the application of automatic parallelization techniques. On the other hand there are theoretical results that ensure when parallel(ized) programs are correct (i.e. obtain the same results as their corresponding sequential ones) and when execution of parallel (ized) programs do not take longer than that of the sequential ones. However such results do not take into account a number of overheads which appear in practice such as process creation and scheduling which can induce a slow-down or at least limit speedup if they are not controlled in some way. In this dissertation we have developed (an integrated in an advanced system for program analysis debugging and optimization) a complete automatic granularity control system for logic programs whereby the granularity of parallel tasks i.e. the work needed for their complete execution is efficiently estimated and used to limit parallelism so that the effect of the mentioned overheads is controlled. The system is based on a program analysis and transformation scheme where as much work is done at compile time as possible in order to avoid the introduction of runtime overheads. For this purpose we have developed some program transformation techniques so that transformed programs perform an efficient granularity control at runtime and also have developed some program analysis techniques able to infer the information needed for the program transformation phase such as (lower bounds on) cost of procedures which calls will not fail (non-failure analysis) etc.,10.1.1.1.3479,?,?
A Decentralized Algorithm for Erasure-Coded Virtual Disks,Svend Frølund Arif Merchant Yasushi Saito Susan Spence  Alistair Veitch,2004,A Federated Array of Bricks is a scalable distributed storage system composed from inexpensive storage bricks. It achieves high reliability with low cost by using erasure  coding across the bricks to maintain data reliability in the face of brick failures. Erasure coding generates n encoded blocks from m data blocks (n  m) and permits the data blocks to be reconstructed from any m of these encoded blocks. We present a new fully decentralized erasurecoding algorithm for an asynchronous distributed system. Our algorithm provides fully linearizable read-write access to erasure-coded data and supports concurrent I/O controllers that may crash and recover. Our algorithm relies on a novel quorum construction where any two quorums intersect in m processes.,10.1.1.1.3481,?,IEEE
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Lance Champagne R. Greg Carl,?,To date most search theory study has focused either on analytical models of specific situations requiring rigid assumptions or as in the case of search and rescue operational experiments aimed at obtaining detection probabilities for a variety of scenarios. Analytical search theory results provide bounds on empirical results. This research introduces an agent-based simulation approach to the subject of offensive search operations in combat. Generally the value of a combat simulation is measured in terms of insights gained through experimentation. Agent-based simulation enables insights with regards to the emergent behavior of the individual combatants groups of combatants or the system as a whole. Emergent behavior for the purposes of this research is system behavior not explicitly programmed arising from local interactions between agents. Such behavior with respect to search effectiveness is investigated within the context of a historical case study involving offensive search.,10.1.1.1.3482,?,?
Machine Learning Techniques in Spam Filtering,Konstantin Tretyakov,2004,The article gives an overview of some of the most popular machine learning methods (Bayesian classification k-NN ANNs SVMs) and of their applicability to the problem of spam-filtering. Brief descriptions of the algorithms are presented which are meant to be understandable by a reader not familiar with them before. A most trivial sample implementation of the named techniques was made by the author and the comparison of their performance on the PU1 spam corpus is presented.,10.1.1.1.3483,?,?
A Taxonomy of Wireless Micro-Sensor Network Models,Sameer Tilak  Nael B. Abu-Ghazaleh Wendi Heinzelman,2002,... This paper examines this emerging field to classify wireless micro-sensor networks according to different communication functions data delivery models and network dynamics. This taxonomy will aid in defining appropriate communication infrastructures for different sensor network application sub-spaces allowing network designers to choose the protocol architecture that best matches the goals of their application. In addition this taxonomy will enable new sensor network models to be defined for use in further research in this area.,10.1.1.1.3484,?,?
OntoMap: Ontologies for Lexical Semantics,Atanas Kiryakov And Atanas K. Kiryakov Kiril Iv. Simov Marin Dimitrov Ontotext Lab,?,The upper-level ontologies are theories that capture  the most common concepts relevant to  many tasks. These ontologies are used to represent  the skeleton of the human common-sense in  such a formal way that covers as many aspects  of the knowledge as possible. The result often  is a complex and abstract philosophic theory.,10.1.1.1.3485,?,?
Push Technology Personalizatiom Through Event Correlation,Asaf Adi David David Botzer Opher Etzion Tali Yatzkar-haham,2000,Push Technology stands for the ability to transfer information as a reaction to event occurrence. This demonstration proposal describes Amit a middleware framework that resolves a major problem in this area: the gap that exists between events that are reported by various channels and the actual cases in which the user needs to react to hereby called reactive situations. These situations are composition of events or other situations (for example when atleast four events of the same type occurred) or content filtering on events (for example only events that relate to IBM stocks) or both (when atleast four purchases of more than 50000 shares have been performed on IBM stocks in a single week). This paper describes the generic application development tool the middleware architecture and framework and describes the demo.,10.1.1.1.3486,?,?
The 115 GeV signal from nuclear physics.,Alejandro Rivero July Alejandro Rivero,?,According standard models of nuclei steepest variations of binding energy at the  drip lines should happen for nuclear masses of 45 68 92 115 175 and 246 GeV.,10.1.1.1.3487,?,?
EPTD DISCUSSION PAPER NO. 62 THE EFFECTS OF THE U.S. PLANT VARIETY PROTECTION ACT ON WHEAT GENETIC IMPROVEMENT,Julian M. Alston Raymond J. Venner,?,The U.S. Plant Variety Protection Act (PVPA) of 1970 was meant to strengthen intellectual property protection for plant breeders. A model of investment under partial excludability is developed leading to the hypotheses that any increase in excludability or appropriability of the returns to invention attributable to the PVPA would lead to increases in investment or efficiency gains in varietal RD improved varietal quality and enhanced royalties. These hypotheses are tested in an economic analysis of the effects of the PVPA on wheat genetic improvement. The PVPA appears to have contributed to increases in public expenditures on wheat variety improvement but private-sector investment in wheat breeding does not appear to have increased. Moreover econometric analyses indicate that the PVPA has not caused any increase in experimental or commercial wheat yields. However the share of U.S. wheat acreage sown to private varieties has increased--from 3 percent in 1970 to 30 percent in the 1990s. These findings indicate that the PVPA has served primarily as a marketing tool with little impact on excludability or appropriability. Key Words: Intellectual property rights wheat genetic improvement i  CONTENTS 1. ,10.1.1.1.3488,Key Words Intellectual property rights wheat genetic improvement CONTENTS,?
Preferred temperature of juvenile Atlantic cod Gadus morhua with different haemoglobin genotypes at normoxia and moderate hypoxia,And Hbi Such Maria Faldborg Petersen John Fleng Steffensen,2003,this paper (www.ferret.noaa.gov). Financial support was provided by the Carlsberg Foundation Danish Natural Sciences Research Council NARP (Nordic Arctic Research Program) and the E.  K. Petersen Foundation,10.1.1.1.3489,?,?
Autonomous Vehicle Technologies for Small Fixed Wing UAVs,Derek Kingston  Randal Beard  Timothy McLain Michael Larsen  Wei Ren,2003,Autonomous unmanned air vehicle flight control systems require robust path generation to account for terrain obstructions weather and moving threats such as radar jammers and unfriendly aircraft. In this paper we outline a feasible hierarchal approach for real-time motion planning of small autonomous fixed-wing UAVs. The approach divides the trajectory generation into four tasks: waypoint path planning dynamic trajectory smoothing trajectory tracking and low-level autopilot compensation. The waypoint path planner determines the vehicle s route without regard for the dynamic constraints of the vehicle. This results in a significant reduction in the path search space enabling the generation of complicated paths that account for pop-up and dynamically moving threats. Kinematic constraints are satisfied using a trajectory smoother which has the same kinematic structure as the physical vehicle. The third step of the approach uses a novel tracking algorithm to generate a feasible state trajectory that can be followed by a standard autopilot. Monte-Carlo simulations were done to analyze the performance and feasibility of the approach and determine real-time computation requirements. A planar version of the algorithm has also been implemented and tested in a low-cost micro-controller. The paper describes a custom UAV built to test the algorithms.,10.1.1.1.3490,?,?
Can Astronomers Observe a Difference between a,Doppler Effect And Jacques Moret-bailly,2001,Introduction  In a previous paper [Moret-Bailly (1996)] we have shown that Raman scattering in a very low-pressure gas is coherent so that the colour of an image is changed without any blur. But problems remained which prevented us from saying that the entire shift observed in galaxies is a Raman shift: in the usual observation a Raman shift corresponds to a transitions between two levels so that the shift of frequency is quantized to make this quantized disappear it is necessary to consider very small (unobservable) Raman shifts. If a lot of such small shifts are added by a transmission of a light beam through a thick gas a large shift may be obtained but it is a diffusion of the shifts so that if there is a spectrum in the light beam the lines fade.  There are two types of interactions between light and matter:  1. the first used in photoelectric cells is a quantum effect it was long the best known because it dominates when monochromatic light is used.  2. the second is th,10.1.1.1.3491,?,?
 Formal Semantics and Analysis Methods for Simulink Stateflow Models ,A. Tiwari,?,Embedded control systems typically comprise continuous control laws combined with discrete mode logic. The Simulink graphical environment of MathWorks tool suite is a popular choice for modeling and designing embedded controllers. Mode logic in Simulink models is described in terms of hierarchical state machines specified in a variant of Statecharts called Stateflow. The semantics of Stateflow is quite complex and it is valuable if these designs can be formally analyzed for both early error detection and positive assurance.,10.1.1.1.3492,?,?
EXACT: An Explicit Rate-based Flow Control Framework In MANET,n.n.,?,Flow control in mobile ad hoc network (MANET) must face many new challenges such as frequent re-routing and bandwidth fluctuation of wireless links. Implicit flow control such as AIMD performs poorly in this environment because its additive bandwidth probing and multiplicative congestion avoidance strategy often cannot keep up with the dynamics of the network. In this paper . . . ,10.1.1.1.3493,?,?
Model-based service creation in the Friends project,W. B. Teeuw D. A. C. Quartel,2001,This paperpresen a model-based approach to servicecreation We observe that the complexity of software servicesinces To man this complexityan to quickly create specific servicesin an efficien an cost-effective wayupon user request models are used goin towards `higher-level programmin A servicecreation ention is developed that supports the modellin of services at successive abstraction levels the an of service models their actualimplemen an the testin an deploymen of serviceimplemen Services are assumed to be developed from existin orn ewly developed software compon Compon are modelled by describin their extern behaviour ratherthan their inr on This providesaddition design ingnon facilitatin a systematic approach to servicecreation This paper shows how we model services a n their con compon an how we use these models.,10.1.1.1.3495,?,?
Workflow Management Systems and ERP Systems: Differences Commonalities and Applications,Jorge Cardoso Robert P. Bostrom  Amit Sheth Contact Information Amit Sheth,2004,Two important classes of information systems Workflow Management Systems (WfMSs) and Enterprise Resource Planning (ERP) systems have been used to support ebusiness process redesign integration and management. While both technologies can help with business process automation data transfer and information sharing the technological approach and features of solutions provided by WfMS and ERP are different. Currently there is a lack of understanding of these two classes of information systems in the industry and academia thus hindering their effective applications. In this paper we present a comprehensive comparison  between these two classes of systems. We discuss how the two types of systems can be used  independently or together to develop intra- and inter-organizational application solutions. In particular we also explore the roles of WfMS and ERP in the next generation of IT architecture based on web services. Our findings should help businesses make better decisions in the adoption of both WfMS and ERP in their e-business strategies.,10.1.1.1.3496,Application Integration Business Process Management. 2,?
MSSD Discussion Paper No. 35,Markets And Structural Garth Holloway Charles Nicholson Chris Delgado Contact Diana Flores,1999,ii  1. ,10.1.1.1.3497,2. TRANSACTIONS COSTS COOPERATIVES AND MILK-MARKET,?
An Extensible Business Communication Language,Hans Weigand  Wilhelm Hasselbring,2001,A main problem for electronic commerce particularly for business-to-business applications lies in the need for the involved information systems  to meaningfully exchange information. Domain-specific standards may be used  to define the semantics of common terms. However in practice it is not easy to  find those domain-specific standards that are detailed and stable enough to allow  for real interoperability. Therefore we propose an architecture that allows for incremental  construction of a shared repository including a multilingual thesaurus  which is used in a business communication language. Communicating information  systems then refer to the common thesaurus while exchanging messages. Our  emphasis is be on separating semantics (in the thesaurus) and syntax (in XML). Therefore our,10.1.1.1.3498,?,?
Addressing Preservice Teachers Conceptions Of Motivation,Jill D. Salisbury-glennon Robert J. Stevens,1999,Preservice teachers prior knowledge about teaching and learning may di!er substantially from the theories and ideas presented in their education courses. In the present study a refutational (conceptual change) text on motivation was used in an e!ort to address preservice teachers conceptions of motivation. Results indicated that preservice teachers who read the refutational text performed signicantly better on a posttest and demonstrated more of a change in their knowledge. Further results indicated that in the absence of this text self-regulated learning strategies enabled preservice teachers to undergo a change in their knowledge from the pretest to the posttest. # 1999 Elsevier Science Ltd. All rights reserved. 1. ,10.1.1.1.3499,?,?
A Component Meta Model for Reused-Based System Engineering,Frdrick Seyler Philippe Place Paul Bert,2002,The domain of research of our team crosses system engineering based on reuse component paradigm an interoperability. Our goal is to provide the integration of existing heterogeneous distributed components. This integration must be plat-form independent in order to face the problem of middleware proliferation. First we position our approach with regard to Model Driven Architecture. We briefly present a new component meta model which rests on the principle of de-coupling between components and supports  the separation between the data flow and the control flow. Then we present a reuse process based on MDA.,10.1.1.1.3500,Component Model Reuse and Integration Model Driven Architecture UML Profile Abstract The domain of research of our team crosses system engineering based on reuse component,?
The Selective Tuning Model for Visual Attention,John Tsotsos,?,INTRODUCTION  Complexity analysis leads to the conclusion that if attention tunes the visual processing architecture task-directed processing is enabled and a solution to signal interference otherwise present in the converging feedforward pathways is provided. Selective tuning takes two forms: spatial selection is realized by inhibition of irrelevant  connections and feature selection is realized by inhibition of the units which compute irrelevant features. Only a very brief summary is presented here (a more detailed account is in Tsotsos et al.    ).  One role of attention in the image domain is to localize a stimulus in retinotopic as well as feature space in such a way so that any interfering or corrupting signals are  minimized. In doing so attention also seeks to increase the discriminability of a particular  image subset. The search process that localizes the image subset is as follows. The visual  processing architecture is assumed to be pyramidal in structure with units with,10.1.1.1.3501,?,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson Edward J. Williams,?,This study details the synergistic application of ergonomic analysis discrete-process simulation and statistical analysis to the problems of determining the optimum design for a final engine drop assembly work station. The study comprised attention to analysis of facilities and tooling systems material-handling systems and ergonomic workplace design. The results of the study supported a cost-effective increase in jobs per hour concurrent with implementation of ergonomically sound production processes.,10.1.1.1.3502,?,?
Optimization Flow Control with Estimation Error,Mortada Mehyar  Demetri Spanos  Steven H. Low,2004,We analyze the effects of price estimation error in a dual-gradient optimization flow control scheme and characterize the performance of the algorithm in this case. By treating estimation error as inexactness of the gradient we utilize sufficient conditions for convergence subject to bounded error to characterize the long-term dynamics of the link utilization in terms of a region which the trajectory enters in finite time. We explicitly find bounds for this region under a particular quantization error model and provide simulation results to verify the predicted behavior of the system. Finally we analyze the effects of the stepsize on the convergence of the algorithm and provide analytical and numerical results which suggest a particular choice for this parameter.,10.1.1.1.3503,?,?
A Stochastic Model of TCP/IP with Stationary Random Losses,Eitan Altman Konstantin Avrachenkov Chadi Barakat,2000,In this paper we present a model for TCP/IP congestion control mechanism. The rate at which data is transmitted increases linearly in time until a packet loss is detected. At this point the transmission rate is divided by a constant factor. Losses are generated by some exogenous random process which is assumed to be stationary ergodic. This allows us to account for any correlation and any distribution of inter-loss times. We obtain an explicit expression for the throughput of a TCP connection and bounds on the throughput when there is a limit on the window size. In addition we study the effect of the Timeout mechanism on the throughput. A set of experiments is conducted over the real Internet and a comparison is provided with other models that make simple assumptions on the inter-loss time process. The comparison shows that our model approximates well the throughput of TCP for many distributions of inter-loss times.,10.1.1.1.3504,?,?
A Discrete Global Minimization Algorithm for Continuous Variational Problems,Danil Kirsanov  Steven Gortler,2004,In this paper we apply the ideas from combinatorial optimization to find globally optimal solutions to  continuous variational problems. At the heart of our method is an algorithm to solve for globally optimal  discrete minimal surfaces. This discrete surface problem is a natural generalization of the planar-graph  shortest path problem.,10.1.1.1.3505,?,?
Track to Track Fusion Method Applied to Road Obstacle Detection,C. Blanc Blanc Trassoudaine Le Y. Le Guilloux R. Moreira,?,This paper presents a data fusion Kalman based method applied to obstacle detection in road situations. We describe the principle and the implementation of fusion process. It is based on tracks produced separately by single sensors. Results with Infrared and Radar sensors are shown proving the benefit of this dual approach. Another application with Radar and LIDAR is also illustrated.,10.1.1.1.3506,Intelligent vehicles data fusion tracking situation analysis obstacle detection Infrared Radar LIDAR,?
Memory Management for High-Performance Applications,Emery David Berger,2002,?,10.1.1.1.3507,?,?
Genome Informatics 14: 526--527 (2003) A New Method for Characterizing,Functionally-Unknown Proteins Using Kosuke Fujishima Jun Imoto Akio Kanai Masaru Tomita,2003,Introduction  Complete DNA sequences of over 100 species are determined and more are to be read. In spite of these results functional prediction at the proteome level is still in di#culty because homology-dependant analysis has been the major stream in proteome analysis. In the present study we developed a new method which identifies a possible protein function based on computational calculation of specific amino acid frequency and periodicity. Using this method proteins of a hyperthermophilic archaeon Pyrococcus furiosus were classified into several groups by plotting their hydrophobicity score on a graph. As a result DNA/RNA-binding proteins ribosomal proteins and membrane proteins were categorized into individual groups. Then by using clustering software new candidates were chosen for DNA/RNA-binding and ribosomal proteins due to the co-visualization of functionally-known proteins. Moreover we have cloned the genes for the selected RNA-binding proteins and made the recombi,10.1.1.1.3508,?,?
Real-Time Model-Checking: Parameters Everywhere,Veronique Bruyère  Jean-Francois Raskin,2003,In this paper    we study the model-checking and parameter synthesis problems of the logic TCTL over timed automata where parameters are allowed both in the model (timed automaton) and in the property (temporal formula). Our results are as follows. On the negative side we show that the model-checking problem of TCTL extended with parameters is undecidable over timed automata with only one parametric clock. The undecidability result needs equality in the logic. On the positive side we show that when equality is not allowed in the logic the model-checking and the parameter synthesis problems become decidable. Our method is based on automata theoretic principles and an extension of our method to express duration of runs in timed automata using Presburger arithmetic. 1 ,10.1.1.1.3509,?,?
Phonotactic and word accent cues for speech segmentation in Swedish one-year-olds,Eeva Koponen,2001,Two experiments were designed to examine 12-month-old Swedish-learning infants ability to use phonotactic and word accent cues to word boundaries. Twenty-five infants were tested using the so-called Visual Preference Procedure. The stimuli were CVC.CVC (experiment 1) and CVC.CVCCVC nonsense words (experiment 2). The word accent of the stimuli signalled either a single word-like unit or two separate units. Also the cross-syllabic C.C clusters of the stimuli were either typically occurring within words or across word boundaries. The infants looking times at images of objects presented along the nonsense words were measured. Compared with results of similar experiments on English-learning infants the results of the present study were not clear-cut: the infants did not specifically respond to word boundary cues. Instead a preference for accent 2 stimuli and stimuli with typical word internal phonotactics was found.,10.1.1.1.3510,?,?
Towards Real-Scale Business Transaction Workflow Modelling,A. P. Barros A. H. M. ter Hofstede H. A. Proper,1997,While the specification languages of workflow management systems focus on process execution  semantics the successful development of workflows relies on a fuller conceptualisation of  business processing including process semantics. For this a wellspring of modelling techniques  paradigms and informal-formal method extensions which address the analysis of organisational  processing structures (enterprise modelling) and communication (based on speech-act theory) is  available. However the characterisations - indeed the cognition - of workflows still appears coarse. In this paper,10.1.1.1.3511,?,?
SEKT: Semantically Enabled Knowledge Technologies,Web Site And Thomas Gabel York Sure Johanna Voelker Sekt//d. /v Ipswich Ip Re Contactperson John Davies Contactperson Marko Grobelnik Contactperson Hamish Cunningham Contactperson Richard Benjamins Ontoprise Gmbh Contactperson Hans-peter Schnurr,?,Deliverable D12.1.1. (WP12.1)  This document accompanies the SEKT web site and mailing lists. Important features of the web  site which consists of a public and a private part as well as open issues are being described. A  brief overview summarizes the existing mailing lists available for SEKT and some subscription  details are presented. Both web site and mailing lists are up-and-running from the beginning of  the project and are subject to continuous improvement.,10.1.1.1.3512,web site mailing list Document Id. Project,?
Some Results on the Combination of Linear,Transforms With Order-Statistic,2004,Since the most e#cient waveform coding methods use linear transforms  before quantization and entropy coding the methods designed to allow random  access to compressed data normally have to deal with the result of these  transforms. However in some specialized technical applications the information  needed is the result of non-linear operations. For instance it is useful to  have fast access to the minimum and maximum values in the compression of  elevation maps. In this document we show that some linear transforms have  the property of preserving order if certain conditions are satisfied. We provide  a proof that this property can be used not only for maximum and minimum  but also for the very general class of non-linear order-statistic filters (which  includes median filters). We show that this result is valid for a set of commonly  used transforms including the discrete cosine Walsh-Hadamard and dyadic  Haar transforms and also valid for any type of order-statistic filter output.,10.1.1.1.3513,Amir Said,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Xiaoping Xiong,?,We study the convergence and asymptotic normality of a generalized form of stochastic approximation algorithm with deterministic perturbation sequences. Both one-simulation and two-simulation methods are considered. Assuming a special structure of deterministic sequence we establish sufficient condition on the noise sequence for a.s. convergence of the algorithm. Construction of such a special structure of deterministic sequence follows the discussion of asymptotic normality. Finally we discuss ideas on further research in analysis and design of the deterministic perturbation sequences.,10.1.1.1.3514,?,?
The Conceptualization and Empirical Validation of Web Site User Satisfaction,Steve Muylle  Rudy Moenaert  Marc Despontin,2004,This article addresses the concern for effective web site design by means of the conceptualization and empirical validation of a web site user satisfaction construct. Based on IS success theory hypermedia design theory a qualitative exploratory pilot study and a quantitative online critical incident technique we introduce and define the construct of web site user satisfaction explore its dimensionality provide empirical validation of the construct and its underlying dimensionality develop a standardized instrument with desirable psychometric properties for measuring WUS and explore the measures theoretical and practical application.,10.1.1.1.3515,User satisfaction Web design Scale development,?
Self-regulated learning: where are we today,Monique Boekaerts,1999,Self-regulated learning has emerged as an important new construct in education. Our understanding of self-regulated learning has been informed by three schools of thought: (1) research on learning styles (2) research on metacognition and regulation styles and (3) theories of the self including goal-directed behavior. Based on these schools of thought a three-layer model is presented. The innermost layer pertains to regulation of the processing modes. The middle layer represents regulation of the learning process. The outermost layer concerns regulation of the self. Educators and researchers would benefit from an integration of these three frames of reference into a comprehensive model of self-regulated learning. ,10.1.1.1.3516,?,?
Lexical Postcorrection of OCR-Results: The Web as a Dynamic Secondary Dictionary?,Christian Strohmaier  Christoph Ringlstetter  Klaus U. Schulz  Stoyan Mihov,2003,Postcorrection of OCR-results for text documents is usually based on electronic dictionaries. When scanning texts from a specific thematic area conventional dictionaries often miss a considerable number of tokens. Furthermore if word frequencies are stored with the entries these frequencies will not properly reflect the frequencies found in the given thematic area. Correction adequacy suffers from these two shortcomings. We report on a series of experiments where we compare (1) the use of fixed static largescale dictionaries (including proper names and abbreviations) with (2) the use of dynamic dictionaries retrieved via an automated analysis of the vocabulary of web pages from a given domain and (3) the use of mixed dictionaries. Our experiments which address English and German document collections from a variety of fields show that dynamic dictionaries of the above mentioned form can improve the coverage for the given thematic area in a significant way and help to improve the quality of lexical postcorrection methods. 1. ,10.1.1.1.3517,?,?
Towards Increasingly Update Efficient Moving-Object Indexing,Christian S. Jensen  Simonas Saltenis,2002,Current moving-object indexing concentrates on point-objects capable of continuous movement in one- two- and three-dimensional Euclidean spaces and most approaches are based on well-known conventional spatial indices. Approaches that aim at indexing the current and anticipated future positions of moving objects generally must contend with very large update loads because of the agility of the objects indexed. At the same time conventional spatial indices were often originally proposed in settings characterized by few updates and focus on query performance. In this paper we characterize the challenge of moving-object indexing and discuss a range of techniques the use of which may lead to better update performance.,10.1.1.1.3518,?,?
Design and Evaluation of a Spoken-Feedback Keyboard,Andr Campos Pedro Pedro Branco Joaquim A. Jorge,?,Speech recognition technologies have come a long way in the past generation. Indeed they are becoming ever  more pervasive in our day-to-day lives especially in the form of voice-activated menus so prevalent in many  automated answering systems. However speech technologies are still of limited usefulness for large-vocabulary  speaker-independent applications in noisy environments especially where relatively limited computing resources  are available as in present-day personal digital assistants (PDAs). Given the popularity of digital cellular  phones and text-messaging systems we describe a generic interface that can be used by any application that  need text input by visually-impaired users on this kind of devices. Given the shortcomings of present-day speech  recognition technology we opted to develop three types of keyboards two predictive with vocal feedback. This  paper describes the interface development and the usability evaluation results with target users. Our prototype  testing scenario included composing short text messages (SMS) and sending them via digital cellular networks  (GSM) making it accessible to visually-impaired people.,10.1.1.1.3519,text-entry PDA SMS predictive keyboards Short Messaging Service,?
A Solution to the NKR Problem in End-to-end Bandwidth Reservation,Jun Wang  Klara Nahrstedt,2001,With up-coming Quality of Service (QoS) requirements raised by a wide range of communication-intensive real-time multimedia applications resource reservation is one of the approaches to satisfy requested QoS. Resource ReSerVation Protocol (RSVP) is a well-known signaling protocol for bandwidth reservation in the Internet. However the current reservation protocols like RSVP do not present the maximum flow acceptance rate solution. The problem of finding the maximum reserved flow acceptance rate and minimizing the effects of crank-back procedure is called the New Killer Reservation Problem (NKR Section II- B). In this paper we study the NKR problem and answer two questions: (1) under what scenarios does the NKR problem become a serious problem and (2) how can we solve this problem. We introduce the Marginable Bandwidth Reservation Protocol (MBR) as a solution to the NKR problem. The results show that MBR protocol yields the desired improvement of flow acceptance rate at a low cost.,10.1.1.1.3520,?,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice Holger Vogt,?,Analytical simulation is thus limited to special cases with high abstraction. Discrete-event simulation (Fishman 2001) is the method of choice to describe the whole factory. Semiconductor fabrication factories are large enterprises with many toolsets each having multiple production machines. The process flow is highly reentrant therefore modeling is best done by discrete-event simulation. To describe such a fab the author has developed a new discrete event simulator called FabSim. It is written in C++. As the simulation engine it uses SystemC a C++ class library originally developed for modeling Systems on a Chip. The factory with its machines and lots traveling and in process is mapped onto SystemC like a hardware description during RTL (register transfer) modeling. The resulting simulator is compact fast and efficient. In a special configuration as a MS Windows dynamic link library the simulator is fully interactive. At any time you may define a stop in the simulation flow retrieve the state of the whole system change parameters add lots or even enter a new state and continue with the simulation.,10.1.1.1.3521,?,?
On Half Gapped Seed,Wei Chen Wing-kin Sung,2003,In this paper we proposed a new type of seed for Blast-like homology search tools called half  seed. This new seed is better than the consecutive seed used by the original Blast tools in both  sensitivity and e#ciency. When compared with the gapped seed which is proposed together with  a new Blast-like searching tool PatternHunter this new seed o#ers a much wider range of choices  for performing tradeo# between sensitivity and e#ciency. This property is especially useful when  some searching applications want to get more precise results with limitation on hardware resources  or vice versa.,10.1.1.1.3522,‘half match,?
Snoopy A New Calendar Queue Structure,Tan Kah Leong,?,Discrete event simulations need a priority queue to schedule events according to their timestamp. Up to 40% of the time may be spent on the management of the pending event set. Thus the choice of a efficient data structure is vital to the performance of discrete event simulations. A conventional Calendar Queue (CQ) and Dynamic Calendar Queue (DCQ) are two data structures that promises O(1) time complexity regardless of the size of the pending event set. CQ however performs poorly over skewed event distributions or changes in the event distribution. DCQ improves on the CQ by adding a mechanism to detect the two scenarios above and redistribute events when necessary. Both of these data structures determine their operating parameter (bucket width) by sampling of events. Sampling sometimes fails to provide a good estimate for an optimum bucket width to use. This paper proposes a novel approach to determine the optimum operating parameter of a calendar queue based on its performance statistics and guarantees O(1) performance. Henceforth we named our calendar queue adopting this mechanism Statistically eNhanced with Optimum Operating Parameter Calendar Queue (SNOOPy CQ). Our experiment results showed that SNOOPy CQ offers a consistent O(1) performance and in certain scenarios executes up to 100 times faster than DCQ and CQ.,10.1.1.1.3523,?,?
Genetic Versus Phenotypic Models Of Selection: Can Genetics Be Neglected In A Long-Term Perspective?,Franz J. Weissing,1996,Game theoretical concepts in evolutionary biology have been criticized by populations geneticists because they neglect such crucial aspects as the mating system or the mode of inheritance. In fact the dynamics of natural selection does not necessarily lead to a fitness maximum or an ESS if genetic constraints are taken into account. Yet it may be premature to conclude that game theoretical concepts do not have a dynamical justification. The new paradigm of long-term evolution postulates that genetic constraints which may be dominant in a short-term perspective will in the long run disappear in the face of the ongoing influx of mutations. Two basic results (see Hammerstein this issue) seem to reconcile the dynamical approach of long-term population genetics with the static approach of evolutionary game theory: (1) only populations at local fitness optima (Nash strategies) can be long-term stable and (2) in monomorphic populations evolutionary stability is necessary and su#cient to ensure long-term dynamic stability. The present paper has a double purpose. On the one hand it is demonstrated by fairly general arguments that the scope of the results mentioned above extends to non-linear frequency dependent selection to multiple loci and to quite general mating systems. On the other hand some limitations of the theory of long-term evolution will also be stressed: (1) there is little hope for a game theoretical characterization of stability in polymorphic populations (2) many interesting systems do not admit long-term stable equilibria and (3) even if a long-term stable equilibrium exists it is not at all clear whether and how it is attainable by a series of gene substitution events.,10.1.1.1.3524,Phenotypic stability — Optimization,?
Collaborative Environments and Scientific Visualization in,Grid Gilson Giraldi Gilson A. Giraldi Jauvane C. De Oliveira Bruno Schulze Rodrigo L. S. Silva,?,In this paper we focus on two aspects: (1)the application of grid technology  to allow a group of geographically disperse users to accomplish a given  task collaboratively (2) distributed scientific visualization through grid. Henceforth  we firstly describe some collaborative environments. Then visualization  techniques that can be implemented in grids are focused. These techniques can  be integrated in a collaborative visualization system through grid technology.,10.1.1.1.3525,?,?
Tele-Direction: A New Framework for,Collaborative Telepresence The,2001,We propose a new framework for Internet-based telepresence in which the participants collaboratively experience and effect events at a remote site.. The system combines a remote agent (the Tele-Actor) with distributed audience control (the Tele-Directors). This framework allows the remote group of Tele-Directors not only to view but to vote on commands and thereby to participate in the Tele-Actors environment. In this technical sketch we describe the Tele-Direction framework and some of the key human interface issues.,10.1.1.1.3526,Teleconferencing collaborative control telerobotics Tele-Actor Tele-Director,?
Inference of Sequential Association Rules Guided by Context-Free Grammars,Cláudia M. Antunes Arlindo L. Oliveira,2002,One of the main unresolved problems in data mining is related with  the treatment of data that is inherently sequential. Algorithms for the inference  of association rules that manipulate sequential data have been proposed and  used to some extent but are ineffective in some cases because too many  candidate rules are extracted and filtering the relevant ones is difficult and  inefficient. In this work we present a method and algorithm for the inference of  sequential association rules that uses context-free grammars to guide the  discovery process in order to filter in an efficient and effective way the  associations discovered by the algorithm.,10.1.1.1.3527,?,Springer
Interactive Transmission Line Computer Program for Undergraduate Teaching,Christopher W. Trueman,2000,Distributed-circuit analysis using transmission lines is a standard topic in undergraduate education in electrical engineering and computer engineering. This paper presents a simple menu-driven program that students can use to explore the behavior of transmission line circuits and as a computational laboratory for verifying their solutions to homework problems. At the introductory level the program demonstrates traveling waves and standing waves. Smith-chart calculations of impedance and reflection coefficient can be associated with the standing-wave pattern on the transmission line. A branching circuit can be solved including impedance matching with a quarter-wave transformer. At the intermediate level students can use the program to test their designs for two- and three-step Chebyshev transformers and for impedance matching using single double and triple-stub circuits. The program makes easy the calculation of the bandwidth of a design by displaying the return loss or transmission loss as a function of frequency. Low-pass and bandstop filters can be solved. The program encourages students to explore the behavior of the voltages and currents on the lines as the frequency is changed to gain insight into the operation of transformers matching schemes and filters.,10.1.1.1.3528,?,?
QoS Extension to BGP,Li Xiao King-shan Lui Jun Wang Klara Nahrstedt,2002,To enable the end-to-end Quality of Service (QoS) guarantees in the Internet based on the Border Gateway Protocol (BGP) inter-domain QoS advertising and routing are important. However little research has been done in this area so far. Two major challenges scalability and heterogeneity make the QoS extension to BGP difficult. Two existing approaches the Link Capacity Routing (LCR) and the Available Bandwidth Routing (ABR) address QoS advertising and routing in BGP with respect to bandwidth metric. But neither of them can solve the two challenges well.,10.1.1.1.3529,?,?
Slotted Aloha as a game with partial information,Eitan Altman  Rachid El Azouzi  Tania Jiménez,2004,This paper studies distributed choice of retransmission probabilities in slotted ALOHA. Both the cooperative team problem as well as the noncooperative game problem are considered. Unlike some previous work we assume that mobiles do not know the number of backlogged packets at other nodes. A Markov chain analysis is used to obtain optimal and equilibrium retransmission probabilities and throughput. We then investigate the impact of adding retransmission costs (which may represent the disutility for power consumption) on the equilibrium and show how this pricing can be used to make the equilibrium throughput coincide with the optimal team throughput.,10.1.1.1.3530,Slotted Aloha Nash equilibrium Markov chain Pricing,?
Top-Down Enterprise Application Integration with Reference Models,Willem-Jan van den Heuvel Wilhelm Hasselbring Mike Papazoglou,2000,For Enterprise Resource Planning (ERP) systems such as SAP R/3 or  IBM SanFrancisco the tailoring of reference models for customizing the ERP  systems to specific organizational contexts is an established approach. In this paper  we present a methodology that uses such reference models as a starting point  for a top-down integration of enterprise applications. The re-engineered models  of legacy systems are individually linked via cross-mapping specifications  to the forward-engineered reference models specification. The actual linking of  reference and legacy models is done with a methodology for connecting (new)  business objects with (old) legacy systems.,10.1.1.1.3531,?,?
Culture Wars in the Classroom: Prospective Teachers Question Science,Karen Sullenger  Steve Turner Hart Caplan  Joe Crummey  Rick Cuming  Cynthia Charron Beth Corey,2000,Does studying about the nature(s) of science contribute to a prospective teachers effectiveness as a science teacher? This research grew out of a course created by a science educator and historian of science who believed prospective teachers needed more complex understandings of the cultural wars surrounding science. The research team consisted of five prospective teachers who participated in the course as well as the two instructors. This paper describes the experience of participating in the course from both perspectives. We argue that studying the cultural wars over science contributes to prospective teachers professional growth as much because the course elicits tacit beliefs about school science as it introduces more complex understandings of science. We found that prospective teachers tacit beliefs about school science were their greatest barrier to developing more complex understandings about the nature(s) of science. We contend that willingness to grapple with complexity and developing a professional identity by locating oneself in the conversations about the nature(s) of science are better criteria for determining the professional growth of prospective teachers than knowledge measures. Finally we argue that prospective teachers should be viewed as professionals who are responsible for finding their own voice making their own decisions and considering the consequences of their beliefs on their practice. This study raises questions critical to teacher education programs for prospective teachers and teacher-educators alike.,10.1.1.1.3532,?,?
Golay Sequences for DS CDMA Applications,J. Seberry  T.A. Wysocki T. A. Wysocki,?,Golay complementary sequences often referred to as Golay pairs are characterised by the property that the sum of their aperiodic autocorrelation functions equals to zero except for the zero shift. Because of this property Golay complementary sequences can be utilised to construct Hadamard matrices defining sets of orthogonal spreading sequences for DS CDMA systems of the lengths not necessary being a power of 2. In the paper we present an evaluation from the viewpoint of DS CDMA applications of some sets of spreading sequences based on Golay complementary sequences. We then modify those sets of sequences to enhance their correlation properties for asynchronous operation and simulate a multi-user DS CDMA system utilising the modified sequences.,10.1.1.1.3533,?,?
Isis: Intelligent Scalability For Interoperable Services,P. Gioia A. Cotarmanach  K. Kamyab et al.,?,?,10.1.1.1.3536,?,?
Memory Overflow Protection for Embedded Systems using Run-time Checks Reuse and Compression,Surupa Biswas Surupa,2004,Out-of-memory errors are a serious source of unreliability in most embedded systems. Applications run out of main memory because of the frequent difficulty of estimating the memory requirement before deployment either because it depends on input data or because certain language features prevent estimation. The typical lack of disks and virtual memory in embedded systems has two serious consequences when an out-of-memory error occurs. First there is no swap space for the application to grow into and the system crashes. Second since protection from virtual memory is usually absent the fact that a segment has exceeded its bounds is not even detected and hence no pre-crash remedial action is possible.,10.1.1.1.3537,Categories and Subject Descriptors D.3.4 [Programming Languages Processors D.4.5 [Operating Systems Reliability D.4.2 [Operating Systems Storage Management C.3 [Special-Purpose And Application-Based Systems Real-time and embedded systems,ACM Press
Set-Sharing is not always redundant for Pair-Sharing,Francisco Bueno  Maria Garcia de la Banda,?,Sharing among program variables is vital information when  analyzing logic programs. This information is often expressed either as  sets or as pairs of program variables that (may) share. That is either  as set-sharing or as pair-sharing. It has been recently argued that (a)  set-sharing is interesting not as an observable property in itself but as  an encoding for accurate pair-sharing and that (b) such an encoding is  in fact redundant and can be significantly simplified without loss of pairsharing  accuracy. We show that this is not the case when set-sharing is  combined with other kinds of information such as the popular freeness.,10.1.1.1.3538,?,?
A Distributed Monitoring System for large heterogeneous WLANs,Daniel Grob,2003,The goal of this thesis was the design and implementation of a monitoring system for large Wireless LANs (WLANs) composed by Access Points (AP) from different manufacturers. Furthermore the monitoring system should consider WLAN specific data. The,10.1.1.1.3539,?,?
A Meta-protocol and Type system for the Dynamic Coupling of Binary Components,Ralf H. Reussner Dirk Heuzeroth,1999,We introduce a new type system where the type of a component consists of two protocols --- a call and a use protocol. We model these protocols by finite automata and show how those reflect component enhancement and adaption. Coupling is controlled by a meta-protocol which calls the adaption and enhancement algorithms. These algorithms require type information of the components involved. This type information is provided by the meta-protocol using reflection. This mechanism allows automatic adaption of components in changing environments.,10.1.1.1.3540,?,?
Modular Verification of Global Module Invariants in Object-Oriented Programs,K. Rustan M. Leino  Peter Müller,2004,Modules and objects both contain variables whose values may be constrained by invariants. For example in the object-oriented languages Java and C# a module is a class and its static fields and an object is an instance of a class and its instance variables. The invariants of modules work differently both from the invariants of objects alone and from the invariants of modules in a procedural language. This paper presents a methodology for module invariants in an objectoriented setting. The methodology is sound prescribes an initialization order of a programs modules supports the dynamic loading of modules and classes and is amenable to static modular checking.,10.1.1.1.3541,?,?
Recognition of Handwriting . . . ,Nicholas E. Matsakis,1999,In recent years the recognition of handwritten mathematical expressions has recieved an increasing amount of attention in pattern recognition research. The diversity of approaches to the problem and the lack of a commercially viable system however indicate that there is still much research to be done in this area. In this thesis I will describe an on-line approach for converting a handwritten mathematical expression into an equivalent expression in a typesetting command language such as TEX or MathML as well as a feedback-oriented user interface which can make errors more tolerable to the end user since they can be quickly corrected. The three,10.1.1.1.3542,?,?
Trust-Based Security In Web Services,Christian Platzer,2004,In the course of this thesis SimOffice an environment with trust-based access control for Web services was developed. Web services are gaining,10.1.1.1.3543,?,?
Augmenting Conversations Using Dual-Purpose Speech,Kent Lyons Christopher Skeels Thad Starner Cornelis M. Snoeck Benjamin A. Wong Daniel Ashbrook,2004,In this paper we explore the concept of dual--purpose speech: speech that is socially appropriate in the context of a human-- to--human conversation which also provides meaningful input to a computer. We motivate the use of dual--purpose speech and explore issues of privacy and technological challenges related to mobile speech recognition. We present three applications that utilize dual--purpose speech to assist a user in conversational tasks: the Calendar Navigator Agent DialogTabs and Speech Courier. The Calendar Navigator Agent navigates a users calendar based on socially appropriate speech used while scheduling appointments. DialogTabs allows a user to postpone cognitive processing of conversational material by proving short--term capture of transient information. Finally Speech Courier allows asynchronous delivery of relevant conversational information to a third party. Additional Keywords and Phrases: Speech user interfaces dual--purpose speech mobile computing  1 ,10.1.1.1.3544,?,?
The Mathematical Semantic Web,Massimo Marchiori,2003,How can Mathematics and the Semantic Web effectively join? In this paper we provide an account of the key standard technologies that can foster the integration of Mathematical representation into the Semantic Web.,10.1.1.1.3545,?,?
IFAC Nonlinear Control Systems Design Symp. Enschede The Netherlands,Praly And Jiang D. Bestle M. Zeitz Z. P. Jiang Y. Tan Z. Jiang L. Praly L. Praly I. Kanellakopoulos I. Kanellakopoulos,?,For a large class of robustness problems with uncertain parameter vector confined to a box  there are many papers providing results along the following lines. The desired performance specification is robustly satisfied for all if and only if it is satisfied at each vertex of . Since the number of vertices of explodes combinatorically with the dimension of  the computation associated with the implementation of such results is often intractable. The main point of this note is to introduce a new approach to such problems aimed at alleviation of this computational complexity problem. To this end the notion of approximate feasibility is introduced and the theory which follows from this definition is vertex-free.,10.1.1.1.3546,?,?
Analogical Path Planning,Saul Simhon Gregory,?,We present a probabilistic method for path planning that considers trajectories constrained by both the environment and an ensemble of restrictions or preferences on preferred motions for a moving robot. Our system learns constraints and preference biases on a robots motion from examples and then synthesizes behaviors that satisfy these constraints. This behavior can encompass motions that satisfy diverse requirements such as a sweep pattern for floor coverage or in particular in our experiments satisfy restrictions on the robots physical capabilities such as restrictions on its turning radius. Given an approximate path that may not satisfy the required conditions our system computes a refined path that satisfies the constraints and also avoids obstacles. Our approach is based on a Bayesian framework for combining a prior probability distribution on the trajectory with environmental constraints. The prior distribution is generated by decoding a Hidden Markov Model which is itself is trained over a particular set of preferred motions. Environmental constraints are modeled using a potential field over the configuration space.,10.1.1.1.3547,?,?
Relativistic Interpretation (with Non-Zero Photon Mass) of the Small Ether Drift Velocity Detected by Michelson Morley and Miller,J. P. Vigier,2001,this report from the observations made at Mount Wilson. The two circles on this chart show the magnitude of drift actually obtained by Michelson and Morley for the noon and evening observations indicating a result wholly consistent with the later work at Mount Wilson,10.1.1.1.3548,?,?
On the Sublinear Behavior of MIMO Channel Capacity at Low SNR,Siddharth Ray Muriel Médard Lizhong Zheng Jinane Abounadi,2004,We consider wideband wireless communication over a multiple-input multiple-output (MIMO) Rayleigh fading channel where the transmitter has no channel state information (CSI). We study the channel with perfect receiver CSI (coherent channel) versus the channel with no CSI at the receiver (non-coherent channel). A channel with partial CSI at the receiver has a capacity between the coherent and non-coherent channels and in this paper we study the two extremes.,10.1.1.1.3549,?,?
Deadline Analysis of Interrupt-driven Software,Dennis Brylow   Jens Palsberg,2003,Real-time reactive and embedded systems are widely used throughout society (e.g. flight control railway signaling vehicle management medical devices and many others). For real-time interrupt-driven software timely interrupt handling is part of correctness. It is vital for software verification in such systems to check that all specified deadlines for interrupt handling will be met. Such verification is a daunting task because of the large number of di#erent possible interrupt arrival scenarios. For example for a Z86-based microcontroller there can be up to six interrupt sources and each interrupt can arrive during any clock cycle. Verification of such systems has traditionally relied upon lengthy and tedious testing even under the best of circumstances testing is likely to cover only a fraction of the state space in interrupt-driven systems. This paper,10.1.1.1.3550,General Terms Algorithms Measurement Reliability Keywords Real time,?
DUMAS - Adaptation and Robust Information Processing for Mobile Speech Interfaces,Kristiina Jokinen Björn Gambäck,2004,In this paper we present the EU-IST project DUMAS (Dynamic Universal Mobility for Adaptive Speech  Interfaces) and discuss adaptation and robust information processing as realized in AthosMail a speechbased  multilingual email application developed within the project. One of the goals of the research  conducted in the project has been to develop a spoken interactive mail system with components that would  make the users interaction with the system more flexible and natural. AthosMail allows users to read and  manipulate their mailbox via a mobile phone and it adapts its responses according to the users expected  expertise level. This paper gives an overview of the project as well as the AthosMail components that  support adaptation in the system architecture and in its external functionality.,10.1.1.1.3551,?,?
Explicit Fusions,Lucian Wischik  Philippa Gardner,2000,We introduce explicit fusions of names. An explicit fusion  is a process that exists concurrently with the rest of the system and  enables two names to be used interchangeably. Explicit fusions provide  a small-step account of reaction in process calculi such as the pi calculus  and the fusion calculus. In this respect they are similar to the explicit  substitutions of Abadi Cardelli and Curien which do the same for the  lambda calculus. In this paper we give a technical foundation for explicit  fusions. We present the pi-F calculus a simple process calculus with  explicit fusions and define a strong bisimulation congruence. We study  the embeddings of the fusion calculus and the pi calculus. The former is  fully abstract with respect to bisimulation.,10.1.1.1.3552,?,?
Ezstrobe - General-Purpose Simulation System Based On Activity Cycle Diagrams,Julio C. Martinez D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,1998,This paper introduces EZStrobe a very simple but powerful general-purpose simulation system. Although designed for modeling construction operations EZStrobe is domain independent and useful for modeling a wide variety of systems in any discipline. EZStrobe is based on Activity Cycle Diagrams and employs the Three-Phase Activity Scanning paradigm. It is therefore naturally adept for complex systems where many resources collaborate to carry out tasks as is typical in construction. The paper describes the basic system concepts. The paper also presents and explains several examples of increasing complexity to illustrate the range of modeling capabilities.,10.1.1.1.3553,for construction (e.g Halpin 1992 Martinez 1996). These,?
A Separation Principle for Non-UCO Systems: The Jet Engine Stall and Surge Example,Manfredi Maggiore Kevin Passino,?,The problem of controlling surge and stall in jet engine compressors is of fundamental importance in preventing damage and lengthening the life of these components. In this theoretical study we illustrate the application of a novel output feedback control technique to the Moore-Greitzer mathematical model for these two instabilities assuming that the plenum pressure rise is measurable. This problem is particularly challenging since the system is not uniformly completely observable and hence none of the output feedback control techniques found in the literature can be applied to recover the performance of a full state feedback controller. 1 ,10.1.1.1.3554,?,?
Genome Informatics 14: 611--612 (2003) 611 Deterministic and Stochastic Models Analyze the,Robustness Of Circadian Yoshiyuki Sumida Fumitaka Ohnishi Hiroyuki Kurata,?,this paper we aim at understanding how critical the values of parameters is for producing the robust oscillator using a deterministic model and how the probabilistic fluctuations involve the stable oscillation using a stochastic model [5]. In the deterministic model we classified the various parameter combinations that produced the cycle of 24 hours. The robust properties depended on the values of the parameters. In the stochastic model the proper use of fluctuation could make stable oscillations. 2 Method  2.1 Deterministic Model  The analysis for the deterministic model consists of mathematical modeling numerical simulation clustering the solutions and sensitivity analysis. The CADLIVE system [3 4] parsed the regulatorreaction equations for the Drosophila circadian clock into the mathematical model and simulated it numerically. The genetic algorithms with random searches were employed to explore the kinetic parameters that fit the simulated results to the experimental data. We classified the parameter combinations according to the similarity of the parameter values using the class average method in the statistic analysis software of SAS. The sensitivity analysis was carried out by calculating the changes in the period or in the amplitudes with respect to the variations in the parameters,10.1.1.1.3555,simulation simulator two-phase partition method circadian rhythms gene regulatory networks,?
Application of Aboutness to Functional Benchmarking in Information Retrieval,Kam-fai Wong Dawei Song Peter Bruza Chun-hung Cheng,2001,this article we propose to use inductive evaluation for functional benchmarking of IR models as a complement of the traditional experiment-based performance benchmarking. We define a functional benchmark suite in two stages: the evaluation criteria based on the notion of aboutness and the formal evaluation methodology using the criteria. The proposed benchmark has been successfully applied to evaluate various well-known classical and logic-based IR models. The functional benchmarking results allow us to compare and analyze the functionality of the different IR models,10.1.1.1.3557,General Terms Measurement Performance Theory Additional Key Words and Phrases Aboutness functional benchmarking inductive evaluation logic-based information retrieval,?
Applying Aspect-Orientation in Designing Security Systems: A Case Study,Shu Gao  Yi Deng Huiqun Yu Xudong He Konstantin Beznosov  Kendra Cooper ,2004,As a security policy model evolves the design of security systems using that model could become increasingly complicated. It is necessary to come up with an approach to guide the development reuse and evolution of the design. In this paper we propose an aspect-oriented design approach to designing flexible and extensible security systems. A case study demonstrates that such an approach has multifold benefits and is worth further exploration.,10.1.1.1.3558,?,?
Updating the Parameters of a Threshold Scheme by Minimal Broadcast,S. G. Barwick  Wen-Ai Jackson Keith M. Martin,2004,Threshold schemes allow secret data to be protected amongst a set of participants  in such a way that only a pre-specified threshold of participants can reconstruct the secret  from private information (shares) distributed to them on system setup using secure  channels. We consider the general problem of designing unconditionally secure threshold  schemes whose defining parameters (the threshold and the number of participants) can  later be changed by using only public channel broadcast messages. In this paper we are  interested in the e#ciency of such threshold schemes and seek to minimise storage costs  (size of shares) as well as optimise performance in low bandwidth environments by minimising  the size of necessary broadcast messages. We prove a number of lower bounds on  the smallest size of broadcast message necessary to make general changes to the parameters  of a threshold scheme in which each participant already holds shares of minimal size.,10.1.1.1.3559,?,?
An Identity-based Non-interactive Authentication Framework for,Computational Grids Trusted Wenbo Mao Wenbo Mao,2004,We examine the authentication framework for Globus Security Infrastructure (GSI  the current grid security standard) and identify a weakness of poor scalability due to  heavy interactions between a user-side client and many resource contribution sites. We  propose an alternative authentication framework for GSI using authenticated session  keys which are shared between two parties without any interactions between them.,10.1.1.1.3560,?,?
Gesture Segmentation in Complex Motion Sequences,Kanav Kahol Kanav Kahol,2003,Complex human motion sequences (such as dances) are typically analyzed by  segmenting them into shorter motion sequences called gestures. However this  segmentation process is subjective and varies considerably from one human  observer to another. This leads to a lack of a ground truth in the segmentation  process that is used to encode expert knowledge about segmentation as  provided by pioneers of modern dance. It is hypothesised that by building  theories of human motion on the foundation of knowledge possessed by modern  dance and its pioneers (who understand the segmentation process) it is possible to develop a strong theoretical model of gesture segmentation. Modern dance  experts can also provide a ground truth in regards to what constitutes a gesture  within a continuous motion sequence. This is a very specialized task and  computer scientists need such a ground truth to test models of human gesture  segmentation. The gesture segmentation algorithm proposed in this thesis  employs a dynamic hierarchical layered structure to represent the human  anatomy and uses low-level motion parameters to characterize motion in the  various layers of this hierarchy which correspond to different physical segments  of the human body. A nave Bayesian classifier is then used to learn the criteria  for gesture segmentation that is estimated from empirical data provided by  experts and to create a profile for each expert. Then those profiles are used to  predict how each expert will segment gestures in other motion sequences. When  the predictions made by the algorithm were tested with a library of 3D motion  iv  capture sequences (which were created by 2 choreographers) they were found  to be reasonably accurate. The proposed algorithm was also extended to find  and to quan...,10.1.1.1.3563,?,?
Multiresolution Analysis of Arbitrary Meshes,Matthias Eck   Tony DeRose Tom Duchamp Hugues Hoppe Michael Lounsbery Werner Stuetzle,1995,In computer graphics and geometric modeling shapes are often represented by triangular meshes. With the advent of laser scanning systems meshes of extreme complexity are rapidly becoming commonplace. Such meshes are notoriously expensive to store transmit render and are awkward to edit. Multiresolution analysis offers a simple unified and theoretically sound approach to dealing with these problems. Lounsbery et al. have recently developed a technique for creating multiresolution representations for a restricted class of meshes with subdivision connectivity. Unfortunately meshes encountered in practice typically do not meet this requirement. In this paper we present a method for overcoming the subdivision connectivity restriction meaning that completely arbitrary meshes can now be converted to multiresolution form. The method is based on the approximation of an arbitrary initial mesh M by a mesh M    that has subdivision connectivity and is guaranteed to be within a specified tolerance. The key,10.1.1.1.3564,CAD G.1.2 [Approximation Spline Approximation. Additional Keywords Geometric modeling subdivision surfaces wavelets,?
Proceedings of the 2003 Winter Simulation Conference,Chick Snchez Ferrin S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,?,This paper intends to examine the interoperation of simulation models from the viewpoint of a simulation engineer who uses standard tools and methods to create these models. The paper will look at the models in the context of COTS (Commercially available Off-The Shelf) simulation packages with a view to applying Distributed Simulation (DS) theory to the subject. By studying current methods employed which enable COTS simulation packages to interoperate this paper will discuss the tools currently used and examine their appropriateness. The paper will also suggest how an example COTS simulation package could be modified to provide the necessary functions and interoperability required to allow full distributed simulation.,10.1.1.1.3565,?,?
SyncSim: A Synchronous Simple Optimistic Simulation Technique Based on . . .,Sushil Prasad  Zhiyong Cao S. Chick P. J. Sánchez D. Ferrin D. J. Morrice,2003,We developed and implemented two highly optimized optimistic discrete event simulation techniques based on an efficient and scalable Parallel Heap data structure as a global event queue. The primary results are (i) the design of an optimistic simulation algorithm namely SyncSim which does not rely on traditional state and message saving data structures but employs only one backup state per state variable (ii) a demonstration through implementation of SyncSim of an optimistic technique which overcomes the two main mutually conflicting and unbounded overheads of the existing optimistic simulation algorithms: SyncSim bounds the additional space requirements to just one copy per state variable and drastically limits the number of rollbacks encountered. Furthermore SyncSim beats the highly optimized traditional simulator simglobal on a wide variety of large networks on an Origin-2000 computer. The algorithm SyncSim could form a basis for a good parallelizing engine attachable relatively easily to an existing serial simulator.,10.1.1.1.3566,?,?
Rapid Automated Tracing and Feature Extraction from Retinal Fundus Images Using Direct Exploratory Algorithms,Ali Can  Hong Shen James N. Turner  Howard L. Tanenbaum Badrinath Roysam,1999,Algorithms are presented for rapid automatic robust adaptive and accurate tracing of retinal vasculature and analysis of intersections and crossovers. This method improves upon prior work in several ways: 1) automatic adaptation from frame to frame without manual initialization/adjustment with few tunable parameters 2) robust operation on image sequences exhibiting natural variability poor and varying imaging conditions including over/under-exposure low contrast and artifacts such as glare 3) does not require the vasculature to be connected so it can handle partial views and 4) operation is efficient enough for use on unspecialized hardware and amenable to deadline-driven computing being able to produce a rapidly and monotonically improving sequence of usable partial results. Increased computation can be traded for superior tracing performance. Its efficiency comes from direct processing on gray-level data without any preprocessing and from processing only a minimally necessary fraction of pixels in an exploratory manner avoiding low-level image-wide operations such as thresholding edge detection and morphological processing. These properties make the algorithm suited to real-time on-line (live) processing and is being applied to computer-assisted laser retinal surgery.,10.1.1.1.3567,?,?
Self-Organized Learning in Multi-Layer Networks,Rüdiger W. Brause,?,We present a framework for the self-organized formation of high level learning by a statistical preprocessing of features. The paper focuses first on the formation of the features in the context of layers of feature processing units as a kind of resource-restricted associative multiresolution learning We clame that such an architecture must reach maturity by basic statistical proportions optimizing the information processing capabilities of each layer. The final symbolic output is learned by pure association of features of different levels and kind of sensorial input. Finally we also show that common error-correction learning for motor skills can be accomplished also by non-specific associative learning.,10.1.1.1.3568,feedforward network layers maximal information gain restricted Hebbian learning cellular neural nets evolutionary associative,?
EPTD DISCUSSION PAPER NO. 47 IMPACT ON FOOD SECURITY AND RURAL DEVELOPMENT OF REALLOCATING WATER FROM AGRICULTURE,Mark W. Rosegrant Claudia Ringler,?,The competition for limited water resources between agriculture and more highly valued domestic and industrial water uses is rapidly increasing and will likely require the transfer of water out of agriculture. This paper reviews and synthesizes the available evidence of the effects of water transfers from agricultural to urban and industrial areas on local and regional rural economies and analyzes the potential impacts of a large reallocation on global food supply and demand. It concludes with a discussion on the potential for water policy reform and demand management to minimize adverse impacts when water is reallocated from agriculture. It is argued that comprehensive reforms are required to mitigate the potentially adverse impacts of water transfers for local communities and to sustain crop yield and output growth to meet rising food demands at the global level. Key policy reforms include the establishment of secure water rights to users the decentralization and privatization of water management functions to appropriate levels the use of incentives including pricing reform especially in urban contexts and markets in tradable property rights and the introduction of appropriate water-saving technologies. Keywords: Water transfers Water scarcity Agricultural production Projections of food supply and demand Demand management. i  CONTENTS Abstract .............................................................1 1. ,10.1.1.1.3569,Water transfers Water scarcity Agricultural production Projections of food supply and demand Demand management. CONTENTS,?
Bias-Minimizing Filters for Motion Estimation,Dirk Robinson  Peyman Milanfar,?,motion vector fields perhaps the most popular and methods. A critical step in the gradient-based estimation process is the estimation of image gradients using derivative filters. It is well known that the gradientbased estimators contain significant deterministic bias relating the gradient calculation. In this paper we describe the fundamental relationship between estimator bias and derivative filters. From this we suggest an image adaptive method addressing the design of biasminimizing gradient filters. Simulations validate the superior performance of such filters for the many variants of gradient-based estimation including the widely used multiscale iterative methods.,10.1.1.1.3571,?,?
Language Identification Using Gaussian Mixture Model Tokenization,Pedro A. Torres-carrasquillo Douglas A. Reynolds  J.R. Deller  Jr.,?,Phone tokenization followed by n-gram language modeling has consistently provided good results for the task of language identification. In this paper this technique is generalized by using Gaussian mixture models as the basis for tokenizing. Performance results are presented for a system employing a GMM tokenizer in conjunction with multiple language processing and score combination techniques. On the 1996 CallFriend LID evaluation set a 12-way closed set error rate of 17% was obtained.,10.1.1.1.3572,?,?
Sensor Coverage Using Mobile Robots and Stationary Nodes,Maxim A. Batalin  Gaurav S. Sukhatme,2002,We consider the dynamic sensor coverage problem in the absence of global localization information. In the regime where few sensors are available compared to the size of the space being explored a successful strategy must e#ectively mobilize the sensors by mounting them on mobile robots. We present here an approach where mobile robots explore an uncharted environment by deploying small communication beacons. These beacons act as local markers for preferred directions of further exploration. The robots never acquire a map of their surroundings nor are localized however they ensure timely coverage of all regions of the space by relying on the local instructions disseminated by the stationary communication beacons. Preliminary data from experiments suggest that our algorithm produces exploratory patrol-like behavior resulting in good spatial sensor coverage over time.,10.1.1.1.3573,Sensor network static network mobile network mobile robots coverage exploration patrolling,?
What Can Boolean Networks Learn?,Arlindo L. Oliveira  Alberto Sangiovanni-Vincentelli,1992,We study the generalization abilities of networks that are composed of boolean nodes i.e. nodes that implement only basic boolean functions: and or and not.,10.1.1.1.3574,?,?
Performance of Group Communication over Ad-Hoc Networks,Marc Mosko And,2002,We study the performance of reliable and unreliable allnode broadcast over ad-hoc networks that use contentionbased channel access. To obtain analytical results while preserving hidden-terminal and node clustering characteristics of ah-hoc networks we introduce a novel differentialequation fluid model for information flow through a network of cluster trees where a spanning tree joins groups of fully connected nodes. Through numerical analysis and simulations in GloMoSim we show throughput goodput and loss rates for reliable and unreliable networks. For reliable broadcast we also find NAK rates NAK loss rates and retransmission rates. We show that using end-to-end sequence numbers which are common in reliable multicast for NAK generation in ad-hoc networks creates substantial unnecessary traffic.,10.1.1.1.3575,?,?
TSAT++: an Open Platform for Satisfiability Modulo Theories,Alessandro Armando Claudio Castellini Enrico Giunchiglia  Massimo Idini  Marco Maratea,2004,This paper describes TSAT++ an open platform which realizes the lazy SATbased approach to Satisfiability Modulo Theories (SMT). SMT is the problem of determining satisfiability of a propositional combination of T -literals where T is a first-order theory for which a satisfiability procedure for a set of ground atoms is known. TSAT++ enjoys a modular design in which an enumerator and a theoryspecific  satisfiability checker cooperate in order to solve SMT. Modularity allows both di#erent enumerators and satisfiability checkers for di#erent theories (or combinations of theories) to be plugged in as far as they comply to a simple and well-defined interface. A number of optimization techniques are also implemented in TSAT++ which are independent of the modules used (and of the corresponding theory). Some experimental results are presented showing that TSAT++ instantiated for Separation Logic is competitive with or faster than state-of-the-art solvers for that very logic.,10.1.1.1.3576,Key words Boolean Satisfiability Ground Decision Procedures Separation Logic Hardware Verification Formal Methods,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Russell R. Barton (panelist,?,This panel has been put together to promote the use of simulation as a teaching tool to expedite the learning and more importantly the understanding of probability theory. In a nutshell the thesis upon which this panel is based is that the simulation approach is more effective than a mathematical approach on a stand-alone basis. It also dominates any statistical approach as a pedagogical tool.,10.1.1.1.3577,SESSION 1 WORDS,?
March 2000 CSTR-00-004,University Of Bristol Edward Ross Edward Ross,2000,Computers are extremely e#ective information processors. However  for current highly interactive usage computers can only be as e#ectiveas  the interface which is used to communicate with them. This report #rst  examines the development of the user interface to place the intelligent  interface in historical context. Following this is a survey of intelligent  interface paradigms and techniques. These showhow new interfaces can  improve communication between humans and machines when the interface  technology makes the leap from a passive tool-set to a pro-active assistant.,10.1.1.1.3578,?,?
Fusion Of Face Recognition Algorithms For Video-Based Surveillance Systems,Gian Luca Marcialis Fabio Roli,2003,It is widely acknowledged that face recognition could play an important role in advanced video-based surveillance systems mainly because it is non-intrusive and does not require people cooperation. Unfortunately face recognition algorithms showed to suffer a lot from the high variability of environmental conditions (e.g. variations of lighting face pose and scale). This currently limits their application to real video-surveillance tasks. Recently fusion of multiple face recognisers has been proposed to improve the robustness of face recognition systems to environmental conditions variability. In this chapter fusion of two well-known face recognition algorithms namely PCA and LDA is proposed. Experimental results that confirm the benefits of fusing PCA and LDA allow drawing some preliminary conclusions about the role of the fusion of face recognition algorithms in video-based surveillance applications.,10.1.1.1.3579,Key words Video Surveillance Biometrics Face Recognition Fusion of Multiple Classifiers,Kluwer Academic Publishers
Techniques for Multi-Channel Real-Time Spatial Distribution,Using Frequency-Domain Processing Ryan H. Torchia,?,The authors have developed several methods for spatially distributing spectral material in real-time using frequency-domain processing. Applying spectral spatialization techniques to more than two channels introduces a few obstacles particularly with controllers visualization and the manipulation of large amounts of control data. Various interfaces are presented which address these issues. We also discuss 3D cube controllers and visualizations which go a long way in aiding usability. A range of implementations were realized each with its own interface automation and output characteristics. We also explore a number of novel techniques. For example a sounds spectral components can be mapped in space based on its own components energy or the energy of another signals components (a kind of spatial cross-synthesis). Finally we address aesthetic concerns such as perceptual and sonic coherency which arise when sounds have been spectrally dissected and scattered across a multichannel spatial field in 64 128 or more spectral bands.,10.1.1.1.3580,?,?
A Novel Approach to FPGA-Based Hardware Fault Modeling and Simulation,Abílio Parreira J. P. Teixeira Marcelino Santos,2003,The purpose of this work is to present a Hardware Fault Simulation  (HFS) methodology and tool (f    s) using partial reconfiguration suitable for  efficient fault modeling and simulation in FPGAs. The methodology is  particularly useful for BIST effectiveness evaluation and for applications in  which multiple fault injection is mandatory such as in safety-critical  applications. A novel (CSA -- Combination Stuck-At) fault model is proposed  which leads to better test quality estimates than the classic (LSA -- Line StuckAt)  model at the LUTs terminals. Fault injection is performed using only local  reconfiguration with small binary files. The efficiency of Software and FPGAbased  HFS with and without partial reconfiguration are compared using  ISCAS89 sequential benchmarks showing the usefulness of the proposed  methodology.,10.1.1.1.3581,?,?
Physical Field Models for Pattern Classification,Dymitr Ruta  Bogdan Gabrys,?,this paper we propose an example of such a novel classifier that performs well individually and can be shown diverse with respect to other commonly used classifiers. In designing the new classifier we exploit a notion of a static field generated by a set of samples treated as physical particles. Our approach is closely related to the idea of an information field recently emerging from the studies in information theory where increasingly deep analogies are drawn with the physical world [14] [4]. Shannon entropy representing probabilistic interpretation of information content is an example of a direct counterpart to the thermodynamic entropy related to physical particles. Information or its uncertainty is quite often compared to energy with all its aspects [4]. The latest findings led even to the formulation of the quantum information theory based on well-developed quantum physics [14]. The mathematical concept of a field so commonly observed in nature has hardly been exploited for pattern recognition purposes. In [3] Hochreiter and Mozer use electric field metaphor to Independent Component Analysis (ICA) problem where joint and factorial density estimates are treated as a distribution of positive and negative charges. In [6] Principe et al introduces the concept of information potentials and forces employing unconventional definition of mutual information based on Renyis entropy. Torkkola [12] used further these concepts for linear [12] and non-linear [13] transformations of the data maximising their mutual information,10.1.1.1.3582,?,?
Hybrid Diagnosis with Unknown Behavioral Modes,Michael W. Hofbaur   Brian C. Williams,2002,A novel capability of discrete model-based diagnosis methods is the ability to handle unknown modes where no assumption is made about the behavior of one or several components of the system. This paper incorporates this novel capability of model-based diagnosis into a hybrid estimation scheme by calculating partial filters. The filters are based on causal and structural analysis of the specified components and their interconnection within the hybrid automaton model. Incorporating unknown modes provides a robust estimation scheme that can cope unlike other hybrid estimation and multi-model estimation schemes with unmodeled situations and partial information.,10.1.1.1.3583,?,?
The Need for Media Access Control in Optical CDMA Networks ,Purushotham Kamath Joseph D. Touch Joseph A. Bannister,2004,Optical CDMA Local Area Networks allow shared access to a broadcast medium. Every node on the network is assigned an Optical Orthogonal Codeword (OOC) to transmit or receive on. OOCs are designed to be pseudo-orthogonal i.e. the correlation (and therefore the interference) between pairs of codewords is constrained. This paper demonstrates that the use of optical CDMA does not preclude the need for a media access control (MAC) layer protocol to resolve contention for the shared media. OOCs have,10.1.1.1.3584,System design,?
RDF Query Languages Need Support for Graph Properties,Renzo Angles  Claudio Gutierrez Jonathan Hayes,2004,This short paper discusses the need to include into RDF  query languages the ability to directly query graph properties from RDF  data. We study the support that current RDF query languages give to  these features to conclude that they are currently not supported. We  propose a set of basic graph properties that should be added to RDF  query languages and provide evidence for this view.,10.1.1.1.3586,?,?
A Framework for Differential Frame-Based Matching Algorithms In . . . ,Andrea Bianco Paolo Giaccone Emilio Leonardi Fabio Neri,2004,We propose a novel framework to solve the problem of scheduling packets in high-speed input-queued switches with frame-based control. Our approach is based on the application of game theory concepts. We define a flexible scheduling policy named SSB (Slot Sell and Buy): the existence of a unique Nash equilibrium for the policy is proved together with properties of convergence of these equilibria. These findings allows us to state that our SSB scheduling policy achieves 100% throughput both in isolated input-queued switches and in networks of input-queued switches. Simulation results are used to further validate the approach and to show its flexibility in dealing with differentiated QoS guarantees.,10.1.1.1.3587,?,?
Peer-to-Peer Support for Massively Multiplayer Games,Björn Knutsson Honghui Lu Wei Xu  Bryan Hopkins,2004,We present an approach to support massively multi-player games on peer-to-peer overlays. Our approach exploits the fact that players in MMGs display locality of interest and therefore can form self-organizing groups based on their locations in the virtual world. To this end we have designed scalable mechanisms to distribute the game state to the participating players and to maintain consistency in the face of node failures. The resulting system dynamically scales with the number of online players. It is more flexible and has a lower deployment cost than centralized games servers. We have implemented a simple game we call SimMud and experimented with up to 4000 players to demonstrate the applicability of this approach.,10.1.1.1.3588,?,?
An Algorithmic Approach to Identifying Link Failures,Mohit Lad  Akash Nanavati  Dan Massey  Lixia Zhang,2004,Due to the Internets sheer size complexity and various routing policies it is difficult if not impossible to locate the causes of large volumes of BGP update messages that occur from time to time. To provide dependable global data delivery we need diagnostic tools that can pinpoint the exact connectivity changes. In this paper we describe an algorithm called MVSChange that can pin down the origin of routing changes due to any single link failure or link restoration. Using a simplified model of BGP called Simple Path Vector Protocol (SPVP) and a graph model of the Internet MVSChange takes as input the SPVP update messages collected from multiple vantage points and accurately locates the link that initiated the routing changes. We provide theoretical proof for the the correctness of the design. Fault Tolerant Algorithms Fault Diagnosis Routing and Graph Theory  1. ,10.1.1.1.3589,Fault Tolerant Algorithms Fault Diagnosis Routing and Graph Theory,?
Canonical Graph Shapes,Arend Rensink,2004,Graphs are an intuitive model for states of a (software) system  that include pointer structures --- for instance object-oriented programs.,10.1.1.1.3590,?,Springer-Verlag
Integrating the Physical World with the Web to Enable Context-Enhanced Services,Philippe Debaty Patrick Goddi Patrick Goddi Alex Vorbau Alex Vorbau,2003,In Cooltown we believe that the integration of our physical world with the  Web offers unique opportunities to enable ubiquitous computing applications. This p aper  describes our latest results in building a model and a software arch itecture called the  Web presence manager (WPM) to support this physical-virtual integration. This software  layer implements and specifies the services and information provided by Web  representations of physical entities such as people places or things. We detail an  extensive context-enhanced media-oriented application built on top of our platform. Our  application enables mobile and context-aware access to personal contents and rendering  on local appliances in a variety of ubiquitous computing enviro nments.,10.1.1.1.3591,?,?
New Frontiers for an Artificial Immune System,Julie Greensmith Julie Greensmith Julie Greensmith Msc Multidisciplinary Informatics,2003,AIRS a resource limited artificial immune classifier system has performed well on various classification tasks including data clustering. This thesis proposes the use of this system for the complex task of multi-class document classification. Initially the AIRS system is validated using a standard machine learning dataset which has not been used previously with this classifier. The use of AIRS for the purpose of document classification was then examined. This includes the pre-processing of HTML documents and the extraction selection and representation of features for the purpose of feature vector compilation. AIRS was used to classify various Internet documents using a variety of datasets. Comparisons were made where the amount of documents amount of classes and amount of features were varied independently. Additionally AIRS was compared with another text classification package as a benchmarking exercise. On completion of this we are confident that AIRS is a suitable candidate for increasingly more complex tasks such as hierarchical document classification and multiple taxonomic mappings.,10.1.1.1.3592,?,?
A pilot study: 3D stereo photogrammetric image superimposition on to 3D CT scan images - the future of orthognathic surgery,Balvinder Khambay  Jean-Christophe Nebel  Janet Bowman  Ashraf Ayoub  Frasier Walker Donald  Donald Hadley,2002,deformity. The most commonly used method of planning is to cut up profile photographs magnified to the  same size as the standardized lateral skull radiograph. These are then superimposed over the cephalographs.,10.1.1.1.3593,?,?
Anytime Algorithms for Multiagent Decision Making Using Coordination Graphs,N. Vlassis R. Elhorst J. R. Kok,2004,Coordination graphs provide a tractable framework for cooperative multiagent decision making by decomposing the global payoff function into a sum of local terms. In this paper we review some distributed algorithms for action selection in a coordination graph and discuss their pros and cons. For real-time decision making we emphasize the need for anytime algorithms for action selection: these are algorithms that improve the quality of the solution over time. We describe variable elimination coordinate ascent and the max-plus algorithm the latter being an instance of the belief propagation algorithm in Bayesian networks. We discuss some interesting open problems related to the use of the maxplus algorithm in real-time multiagent decision making.,10.1.1.1.3595,ascent max-plus,?
Adaptive and Predictive Downlink Resource Management In Next . . . ,Xin Wang et al.,2004,Guard channels have been proposed to minimize handoff call dropping when mobile hosts move from one cell to another. CDMA systems are power- and interference-limited. Therefore guard capacity in CDMA networks is soft that is a given capacity corresponds to variable number of connections. Thus it is essential to adjust the guard capacity in response to changes in traffic conditions and user mobility. We propose two schemes for managing downlink CDMA radio resources: Guard Capacity Adaptation Based on Dropping (GAD) and Guard Capacity Adaptation Based on Prediction and Dropping (GAPD). In both schemes the guard capacity of a cell is dynamically adjusted so as to maintain the handoff dropping rate at a target level. In the second scheme there is an additional frequent adjustment component where guard capacity is adjusted based on soft handoff prediction. We show through extensive simulations that GAD and GAPD control the handoff dropping rate effectively under varying traffic conditions and system parameters. We also find that GAPD is more robust than GAD to temporal traffic variations and changes in control parameters.  ,10.1.1.1.3596,?,?
Genome Informatics 14: 516--517 (2003) Protein Classification via Kernel Matrix Completion,Taishin Kin Tsuyoshi Tsuyoshi Kato Koji Tsuda Kiyoshi Asai,?,Introduction  Although 3D structure of a protein is valuable to predict its function it is still far more di#cult and costly to measure coordinates of atoms in a protein than sequencing its amino acids. We often do not know the 3D structures of all the proteins at hand. Let us consider a kernel matrix that consists of kernel values representing protein similarities in terms of their 3D structures where some of the entries are missing because structure information of some proteins are unavailable whereas their amino acid sequences are readily available. We proposes to estimate the missing entries by means of another kernel matrix derived from amino acid sequences. Basically a parametric model is created from the sequence kernel matrix and the missing entries of the structure kernel matrix are estimated by fitting this model to existing entries. For model fitting we adopt two algorithms: e-projection and em algorithm based on the information geometry of kernel matrices. We performed p,10.1.1.1.3597,information geometry kernel matrix incomplete matrix protein structure,?
Working Papers 49 (2001) 30–33 Modeling the Talking Tongue,Olov Engwall,2001,Electromagnetic articulography (EMA) and Electropalatography (EPG) data has been used to adjust the shape and the movement of a three-dimensional tongue model to follow the articulations of the reference subject. The EMA data was used to control the dynamics of the parameters of a three-dimensional tongue model whereas the EPG data was used to tune the six articulatory parameters to replicate the subjects linguopalatal contact patterns. A 3D model has been generated of the palate and the jaw and an algorithm for handling boundary collisions between the tongue and the inner structures has been implemented.,10.1.1.1.3599,?,?
Lie Group Methods for Optimization with Orthogonality Constraints,Mark D. Plumbley,2004,Optimization of a cost function J(W) under an orthogonality  constraint WW    = I is a common requirement for ICA methods.,10.1.1.1.3600,?,Springer
Can Agreement and Case Morphology Serve as Cues for Comprehension in Agrammatism?,Study Of German Frank Burchert Naama Friedmann Ria De Bleser,2003,Introduction: Agrammatism in Brocas aphasia is a language disorder that is characterized by a selective syntactic deficit often in comprehension as well as in speech production. According to the Trace Deletion Hypothesis (TDH Grodzinsky 1990 1995 2000) the deficit in comprehension in agrammatic aphasia is attributed to impaired representation of structures with non-canonical word order derived by syntactic movement.  The central research question of our study was whether this generalisation holds in languages that have richer morphology than English. The generalisability of the TDH to morphologically rich languages is not obvious given that case or gender morphology can provide explicit cues to the detection of the Agent in a sentence and thus might help the agrammatic individual to decide notwithstanding syntactic problems who is doing what to whom in a sentence comprehension task. Our previous studies have shown that an impairment in movement-derived structures is evident in ,10.1.1.1.3601,?,?
Virtual Modality: a Framework for Testing and Building Multimodal Applications,Peter Pal Boda Péter Pál Boda Edward Filisko,2004,This paper introduces a method that generates  simulated multimodal input to be used in testing  multimodal system implementations as  well as to build statistically motivated multimodal  integration modules. The generation of  such data is inspired by the fact that true multimodal  data recorded from real usage scenarios  is difficult and costly to obtain in large  amounts. On the other hand thanks to operational  speech-only dialogue system applications  a wide selection of speech/text data (in  the form of transcriptions recognizer outputs  parse results etc.) is available. Taking the textual  transcriptions and converting them into  multimodal inputs in order to assist multimodal  system development is the underlying idea  of the paper. A conceptual framework is established  which utilizes two input channels:  the original speech channel and an additional  channel called Virtual Modality. This additional  channel provides a certain level of abstraction  to represent non-speech user inputs  (e.g. gestures or sketches). From the transcriptions  of the speech modality pre-defined  semantic items (e.g. nominal location references)  are identified removed and replaced  with deictic references (e.g. here there). The  deleted semantic items are then placed into the  Virtual Modality channel and according to  external parameters (such as a pre-defined  user population with various deviations) temporal  shifts relative to the instant of each corresponding  deictic reference are issued. The  paper explains the procedure followed to create  Virtual Modality data the details of the  speech-only database and results based on a  multimodal city information and navigation  application.,10.1.1.1.3602,?,?
Symbols Recognition by Global-Local Structural Approaches Based on the Scenarios Use and with a XML Representation of Data,Mathieu Delalandre  Stephane Nicolas  Eric Trupin  Jean-Marc Ogier,2003,symbols on the documents. We have based our system on a combination of local and global structural approaches. The global approach groups the connected components together according to some closeness and connection constraints. The local approach splits up each connected component into a graph of geometrical objects (vectors arcs curves). The extracted graphs are matched thanks to a structural classifier which permits graph-subgraph and exact-inexact matching. The system adaptability is obtained thanks to the scenarios use. A XML data representation is used allowing the data manipulations and the graphic representations of results.,10.1.1.1.3603,?,?
Advanced Implementation Techniques for Scientific Data Warehouses,Torben Bach Pedersen  Christian S. Jensen,2000,Data warehouses using a multidimensional view of data have become very popular in both business  and science in recent years. Data warehouses for scientific purposes such as medicine and  bio-chemistry    pose several great challenges to existing data warehouse technology. Data warehouses  usually use pre-aggregated data to ensure fast query response. However pre-aggregation  cannot be used in practice if the dimension structures or the relationships between facts and dimensions  are irregular. A technique for overcoming this limitation and some experimental  results are presented. Queries over scientific data warehouses often need to reference data that  is external to the data warehouse e.g. data that is too complex to be handled by current data  warehouse technology data that is owned by other organizations or data that is updated frequently. An example,10.1.1.1.3604,?,?
Procedural Authoring Of Solid Models,Julie Dorsey Leonard Mcmillan Arthur C. Smith Barbara M. Cutler Barbara M. Cutler,2003,This thesis investigates the creation representation and manipulation of volumetric  geometry suitable for computer graphics applications. In order to capture and reproduce  the appearance and behavior of many objects it is necessary to model the  internal structures and materials and how they change over time. However producing  real-world effects with standard surface modeling techniques can be extremely  challenging.,10.1.1.1.3605,?,?
Vivaldi: A Decentralized Network Coordinate System,Frank Dabek Russ Cox Frans Kaashoek Robert Morris,2004,Large-scale Internet applications can benefit from an ability to predict round-trip times to other hosts without having to contact them first. Explicit measurements are often unattractive because the cost of measurement can outweigh the benefits of exploiting proximity information. Vivaldi is a simple light-weight algorithm that assigns synthetic coordinates to hosts such that the distance between the coordinates of two hosts accurately predicts the communication latency between the hosts.,10.1.1.1.3606,Algorithms Measurement Performance Design Experimentation Keywords Vivaldi network coordinates Internet topology,?
Is There An Intrahousehold `flypaper Effect? Evidence From A School Feeding Program,Fcnd Discussion Paper Hanan Jacoby,?,Are public transfers targeted toward children largely neutralized by the household as the theory of altruism implies or is there an intrahousehold flypaper effect whereby such transfers stick to the child? This paper studies the impact of a school feeding program on child caloric intake in the Philippines. Because children are interviewed on school days and nonschool days and because some schools offer a feeding program and others do not the dietary impact of the program is identified under mild restrictions. The empirical results confirm an intrahousehold flypaper effect indeed they indicate virtually no intrahousehold reallocation of calories in response to the feeding program. In poorer households however childrens gains from the program appear to be taxed more heavily. CONTENTS  Acknowledgments ..................................................... v 1. ,10.1.1.1.3607,CONTENTS Acknowledgments..................................................... v,?
Comparing Cpu Performance Between And Within Processor,Families Lee Butler Lee A. Butler Travis Atkison Ethan Miller,?,Our study compares CPU performance on RISC and CISC uni and multiprocessors of varying speeds and shows that the Instruction Set Architecture (ISA) style no longer matters. Our study ran the BRL-CAD benchmark on over a dozen computers with several different ISAs. We discuss the performance similarities and differences both between ISAs and within each ISA family. We found that the two dominant factors in CPU performance for our program were clock speed and the number of functional units the complexity of the instruction set made little difference.,10.1.1.1.3608,?,?
Proceedings of the 2001 Winter Simulation Conference,Peters Smith Medeiros B. A. Peters J. S. Smith D. J. Medeiros M. W. Rohrer William B. Nordgren,?,Taylor Enterprise Dynamics (Taylor ED) is an objectoriented software system used to model simulate visualize and monitor dynamic-flow process activities and systems. Atoms are Taylor EDs smart objects and model building resources. In addition to Taylor EDs standard atom libraries users can create new atoms themselves. Taylor EDs object-oriented architecture provides users with the ability to enhance and increase the functionality of the Taylor ED software system. It also provides simulation experts with a platform on which to create new simulation software programs for specific industries or for specific applications. Historically Taylor ED has been used to model manufacturing warehousing and material handling processes. The software is being used more and more to model simulate and visualize service and data flow processes. In addition to these traditional uses Taylor ED is also used to monitor flow processes in real-time. This paper briefly describes the uses and benefits of Taylor ED.,10.1.1.1.3609,1 TAYLOR ED – MODELING SIMULATING VISUALIZING AND MONITORING DYNAMIC FLOW SYSTEMS,?
Submitted to the Department of Physics,In Partial Fulfillment Szymon M. Rusinkiewicz Szymon M. Rusinkiewicz,?,It is possible to compare the masses of single ions with an accuracy of one  part in 10  11  (an order of magnitude better than the current state of the art) by  comparing the cyclotron frequencies of two ions of different species confined  simultaneously in a Penning trap. Computer simulations were used to study  the motion of two simultaneously trapped ions in a trap with predicted partially  controllable imperfections the results were checked against theoretical  predictions for ideal Penning traps. Attention was devoted to schemes that offer  high precision by placing both ions in the same orbit.,10.1.1.1.3610,?,?
Comparing Weighting Models for Monolingual Information Retrieval,Gianni Amati Claudio Carpineto Giovanni Romano,2003,Motivated by the hypothesis that the retrieval performance  of a weighting model is independent of the language in which queries  and collection are expressed we compared the retrieval performance of  three weighting models i.e. Okapi statistical language modeling (SLM)  and deviation from randomness (DFR) on three monolingual test collections  i.e. French Italian and Spanish. The DFR model was found  to consistently achieve better results than both Okapi and SLM whose  performance was comparable. We also evaluated whether the use of retrieval  feedback improved retrieval performance retrieval feedback was  beneficial for DFR and Okapi and detrimental for SLM. Besides relative  performance DFR with retrieval feedback achieved excellent absolute  results: best run for Italian and Spanish third run for French.,10.1.1.1.3612,?,?
Testing High-Speed SoCs Using LowSpeed ATEs,Mehrdad Nourani,2002,We present a test meth847 ogy to allow testingh igh6 peed circuits with low-speed ATEs. Th basic strategy is adding an interface circuit to partially supply test data coordinate sending th test patterns and collecting th signatures. An ILP formulation is presented to globally optimize such coordination in terms of th overall test time and th eh2 dware cost.,10.1.1.1.3613,?,?
Multidimensional Data Modeling For Location-Based Services,Christian S. Jensen  Augustas Kligys  Torben Bach Pedersen Igor Timko,2004,With the recent and continuing advances in areas such as wireless communications and positioning technologies mobile location-based services are becoming possible.,10.1.1.1.3614,?,?
Interactive Query Formulation using Point to Point Queries,H.A. Proper,1994,Effective information disclosure in the context of databases with a large conceptual  schema is known to be a non-trivial problem. In particular the formulation  of ad-hoc queries is a major problem in such contexts. Existing approaches for  tackling this problem include graphical query interfaces query by navigation and  query by construction. In this article we propose the point to point query mechanism   that can be combined with the existing mechanism into an unprecedented  computer supported query formulation mechanism.,10.1.1.1.3616,?,?
Kin Discrimination and Sex Ratios in a Parasitoid Wasp,Reece Shuker Pen S. E. Reece D. M. Shuker I. Pen A. B. Duncan A. Choudhary C. M. Batchelor,?,Sex ratio theory provides a clear and simple way to test if nonsocial haplodiploid wasps can discriminate between kin and nonkin. Specifically if females can discriminate siblings from nonrelatives then they are expected to produce a higher proportion of daughters if they mate with a sibling. This prediction arises because in haplodiploids inbreeding (sib-mating) causes a mother to be relatively more related to her daughters than her sons. Here we formally model this prediction for when multiple females lay eggs in a patch and test it with the parasitoid wasp Nasonia vitripennis. Our results show that females do not adjust their sex ratio behaviour dependent upon whether they mate with a sibling or nonrelative in response to either direct genetic or a range of indirect environmental cues. This suggests that females of N. vitripennis cannot discriminate between kin and nonkin. The implications of our results for the understanding of sex ratio and social evolution are discussed.,10.1.1.1.3618,?,?
Analysis Of The Prewhitened Constant Modulus Cost Function,Roberto Opez-Valcarce And Roberto López-valcarce O Pérez-gonzález,1999,We provide an analysis of the constant modulus (CM) cost function under the assumption of a white equalizer input. This can be achieved by means of an adaptive prewhitening all-pole filter and has been suggested in previous works as a means for both MSE improvement and DFE cold start-up. For white inputs it is seen that CM-optimizing the spherical component of the equalizer parameter vector is equivalent to minimizing the fourth moment of its output regardless of the value of the radial component. This leads to an eigenvector interpretation of prewhitened CM receivers and to a blind initialization procedure from an eigenvector of the quadricovariance matrix of the whitened data. Connections with iterative eigenvector-based schemes are also explored. 1. ,10.1.1.1.3619,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,An Australian automotive component company plans to assemble and deliver seats to customer on just-in-time basis. It plans to assemble various seat types on one assembly line. Mixed-Model sequencing is very important if a company has to assemble seats in just-in-time environment. Toyota Motor Companys goal chasing algorithm I and a user defined algorithm are used sequence seats on assembly line. Discrete event simulation software is used to model the assembly operations of seat plant. Both algorithms are programmed to generate a sequence for the seat plant. Model results show both algorithms can sequence seats on the assembly line and each algorithm has its advantages and disadvantages.,10.1.1.1.3620,?,?
Cluster-based Routing Overhead,In Networks With,?,While several cluster based routing algorithms have been proposed for ad hoc networks there is a lack of formal mathematical analysis of these algorithms. Specifically there is no published investigation of the relation between routing overhead on one hand and route request pattern (traffic) on the other. This paper provides a mathematical framework for quantifying the overhead of a cluster-based routing protocol. We explicitly model the application-level traffic in terms of the statistical description of the number of hops between a source and a destination. The network topology is modelled by a regular two-dimensional grid of unreliable nodes and expressions for various components of the routing overhead are derived. The results show that clustering does not change the traffic requirement for infinite scalability compared to flat protocols but reduces the overhead by a factor of O(1/M) where M is the cluster size. The analytic results are validated against simulations of random network topologies running a well known (D-hop Max-min) clustering algorithm.,10.1.1.1.3621,?,?
Xcalibur: A Vertical Takeoff Tsto,Rlv Concept With J. E. Bradford A. Charania J. R. Olds M. Graham John E. Bradford A. C. Charania John R. Olds Matthew Graham,?,A new 3    generation two-stage-to-orbit (TSTO) reusable launch vehicle (RLV) has been designed. The Xcalibur concept represents a novel approach due to its integration method for the upperstage element of the system. The vertical-takeoff booster which is powered by rocket-based combined-cycle (RBCC) engines carries the upperstage internally in the aft section of the airframe to a Mach 15.5 staging condition. The upperstage is released from the booster and carries the 20 Klbs of payload to low earth orbit (LEO) using its high energy density matter (HEDM) propulsion system. The booster element is capable of returning to the original launch site in a ramjet-cruise propulsion mode. Both the booster and the upperstage utilize advanced technologies including: graphiteepoxy tanks metal-matrix composites UHTC TPS materials electro-mechanical actuators (EMAs) and lightweight subsystems (avionics power distribution etc.). Details of the concept design including external and internal configuration mass properties engine performance trajectory analysis aeroheating results and economics assessment are given. Highlights of the distributed collaborative design approach analysis tools and a summary of a payload trade study are also provided.,10.1.1.1.3622,?,?
Developing a UML Profile for Modelling Knowledge Based Systems,Mohd Syazwan Abdullah  Andy Evans Ian Benest  Chris Kimble,2004,Knowledge engineers have favoured a diagrammatic approach for  developing knowledge-based systems by adopting those used in software  engineering. However these modelling techniques tend to be used in an ad hoc  way and are highly dependent on the modelling experience of the engineers  involved. This paper focuses on the use of the Unified Modeling Language  (UML) Profiles for knowledge modelling. It identifies the short-comings of  current approaches in adopting UML and discusses the need to have an  extension to UML through the profile mechanism. A work-in-progress on  creating such a profile is also presented.,10.1.1.1.3623,?,?
Combining Topic Models and Social Networks for Chat Data Mining,Ville Tuulos  Henry Tirri,2004,Informal chat-room conversations have intrinsically different properties from regular static document collections. Noise concise expressions and dynamic changing and interleaving nature of discussions make chat data ill-suited for analysis with an off-the-shelf text mining method. On the other hand interactive human communication has some implicit features which may be used to enhance the results.,10.1.1.1.3624,?,?
A New Approach to Image Feature Detection With Applications,B. S. Manjunath C. Shekhar R. Chellappa,1996,Image feature detection is a fundamental issue in many intermediate level vision problems such as stereo motion correspondence image registration and object recognition. In this paper we present an approach to feature detection based on a scale-interaction model. This feature detector is responsive to short lines line endings corners and other such sharp changes in curvature. We provide extensive experimental results to demonstrate its potential applications to several image analysis problems.,10.1.1.1.3625,?,?
Deep Packet Filter with Dedicated Logic and Read Only Memories,Young H. Cho   William H. Mangione-Smith,2004,Searching for multiple string patterns in a stream of data is a computationally expensive task. The speed of the search pattern module determines the overall performance of deep packet inspection firewalls intrusion detection systems (IDS) and intrusion prevention systems (IPS). For example one open source IDS configured for 845 patterns can sustain a throughput of only 50 Mbps running on a dual 1-GHz Pentium III system. Using such systems would not be practical for filtering high speed networks with over 1 Gbps traffic. Some of these systems are implemented with field programmable gate arrays (FPGA) so that they are fast and programmable. However such FPGA filters tend to be too large to be mapped on to a single FPGA. By sharing the common sub-logic in the design we can effectively shrink the footprint of the filter. Then for a large subset of the patterns the logic area can be further reduced by using a memory based architecture. These design methods allow our filter for 2064 attack patterns to map onto a single Xilinx Spartan 3 - XC3S2000 FPGA with a filtering rate of over 3 Gbps of network traffic.,10.1.1.1.3626,?,?
Visualizing Association Mining Results through Hierarchical Clusters,Steven Noel Center Steven Noel,2001,We propose a new methodology for visualizing association mining results. Inter-item distances are computed from combinations of itemset supports. The new distances retain a simple pairwise structure and are consistent with important frequently occurring itemsets. Thus standard tools of visualization e.g. hierarchical clustering dendrograms can still be applied while the distance information upon which they are based is richer. Our approach is applicable to general association mining applications as well as applications involving information spaces modeled by directed graphs e.g. the Web. In the context of collections of hypertext documents the inter-document distances capture the information inherent in a collections link structure a form of link mining. We demonstrate our methodology with document sets extracted from the Science Citation Index applying a metric that measures consistency between clusters and frequent itemsets.,10.1.1.1.3627,?,?
Finite Difference Approximations for Fractional Advection-Dispersion Flow Equations,Mark M. Meerschaert Charles Tadjeran,2004,Fractional advection-dispersion equations are used in groundwater hydrology tomqU- the transport of passive tracers carried by fluid flow in a porous mrousq In this paper we develop practical numtical mumti to solve one dimUEBDqyU fractional advection-dispersion equations with variable coefficients on a finite domeqV The practical application of these results is illustrated by mqUEIB# a radial flow problem Use of the fractional derivative allows the model equations to capture the early arrival of tracer observed at a field site.,10.1.1.1.3628,Finite di erence approximation Stability Backward Euler method Implicit Euler method Radial dispersion,?
Design of a Low-Boom Supersonic Business Jet Using Evolutionary Algorithms and an Adaptive Unstructured Mesh Method,Seongim Choi Seongim Choi Juan J. Alonso Juan J. Alonso Hyoung S. Chung Hyoung S. Chung,2004,this paper. The estimated model of Equation (2) is given as   y =  # + r    (x)R -1 (y    f  #) (5) where y is the column vector of response data and f is a column vector of length n s which is filled with ones. R in Equation (3) is the correlation matrix which can be obtained by computing R(x      ) the correlation function between any two sampled data points. This correlation function is specified by the user. In this work we use a Gaussian exponential correlation function of the form provided by Giunta et al,10.1.1.1.3629,?,?
Adaptive Sex Allocation in Birds: The Complexities of Linking Theory and Practice,Jan Komdeur  Ido Pen,2002,INTRODUCTION  Modern empirical sex ratio research began when Hamilton (1967) observed that many insects and mites have highly female-biased sex ratios and that this trait is associated with high levels of brother--sister matings. This could not be explained by the dominant theory at the time Fishers (1930) theory of equal allocation to the sexes. Hamilton solved the problem by marrying his theory of kin selection (Hamilton 1964) to sex ratio theory. He showed that the sex with more severe kin competition is less ef# cient than the opposite sex in exporting parental genes. Hamiltons work greatly boosted further empirical and theoretical research into invertebrate sex ratios. The result is that today we have an excellent understanding of the selective forces that shape sex allocation in invertebrates (review in Godfray  Werren 1996).  Sex allocation in birds on the other hand is still far from being well understood (Sheldon 1998 Pen 2000). We review some recent empirical and theor,10.1.1.1.3630,sex ratio parental care life history sex determination sexual selection ? tness,?
Identifying Most Predictive Items,Daniel Keim Markus Wawryniuk,2004,Frequent itemsets and association rules are generally accepted  concepts in analyzing item-based databases. The Apriori-framework  was developed for analyzing categorical data. However many data  include numerical values. Therefore most existing techniques transform  numerical values to categorical values. The transformation is done such  that the rules are optimal with respect to support or confidence.,10.1.1.1.3631,?,?
Automatic Blocking of QR and LU Factorizations for Locality,Qing Yi Ken Kennedy  Haihang You Keith Seymour Jack Dongarra,2004,ojps5#?tbhrs^547*/21#268eF5#/2681I?0\u^`14 t0W*?H\_W35/_26 0S:c!dW*2683W?Q/=5/26  Y868?HW5#x54Y84Wf0=5v71I3d0.0/=5/26  t0W*?H\_W35/_26 0S:c!dW*2683W?Q/=5/26  5#dHd0Y Q/268zH7 28890-32250  d0.0/=5/26  t0W*?H\_W35/_26 0S:c!dW*2683W?Q/=5/26  31t!W*2?7143dH.!/2W*2\]H/2[0W^547}/214268eF5#/26814?54Y841426Z/2[H3\ ?HWWtb/21fW f0Y81Q7}gWtCyv[0W?C1IdW}=5#/268?H1I?Y 4268eF5#/26814?54Y841426Z/2[H3\ ?HWWtb/21fW d0Y81I6Z/:/2[HWt!WWd7F547=[HW[068W*=5#27=[QXd!2W454Y8W?Q/V68?/21t05FXL \V7143dH.0/2W} 3W*314_X\X!\/2W3\TmW7F5#.H\_Wwf1#/2[ojpfH54\_WFt|1I?bu1I.0\_W[H14Yt!W* /_=5#?H\^`14235#/26814?H\=|5#?thr^5#7*/214268eF5/26 1I?bu1I.0\_W[H14Yt!W* 28930-270 7*1I3dHY8W*cY81Q14d\/_2.H7*/2.!2W\]^W*y7143dH68Y8W*2\w7F54?^.0Y H14Yt!W* 28930 - /2[0Wf0Y81Q7}g68?H14^x/2[HW*\_Wn54Y841426Z/2[H3\{[H1I.0I[Y868?HWF5q54Y8IW*f0=5|Y86Z f!=5#268W\ \_.H7=[C54\ hi-j9L- kmld0216t!W\v354?.5#Y8Y8Xf0Y ?HWF5q54Y8IW*f0= 3W*?/=5/2681I?H\V1#^/2[HW\_W54Y8I1#268/2[03\]QfQX54.0/21435#/2687F5#Y 4Y8IW*f0=5|Y86Z 289 f0Y81Q7}gWtGW*2\_6814?H\q14^/2[0Wn7143dH.0/=5/2681I?H\]3142WnfW*?HW*z0/w7F54?fW I5468?HWt\_.H7=[54\54.!/21I35/26 143dH.0/=5/2681I?H\]3142WnfW*?HW*z0/w7F54?fW 2 \/_=5/2WI68W\{[H68\d5#dW*t!W31I?0\/_=5#/2W\n[01Fy/215#dHdHYZX5#?5#4 #2W\_\_68WY81Q1Id/_=5#?H\^1#235#/2681I?/2W7}[0?H6 1Fy/215#dHdHYZX5#?5#4 28980-186 68?00]Q/21wd021t!.H7W W*U7*6 ^1#235#/2681I?/2W7}[0?H6 1Fy/215#dHdHYZX5#?5#4 dH5#_/26 ryv68/2[ 28800-16570  1#235#/2681I?/2W7}[0?H6 1Fy/215#dHdHYZX5#?5#4 28980-1 /2[H5#/7F5#?fW4W?HW}=5#/2WFtfX14.014d0/268368eW*5#?t7*1I3d52W|/2[0W dW}_^14235#?H7W14^5#.0/21#Nf0Y81Q7}...,10.1.1.1.3632,?,?
Auction-based spectrum sharing,Jianwei Huang Randall Berry Michael L. Honig,2004,Abstract. We study auction-based mechanisms for sharing spectrum among a group of users subject to a constraint on the interference temperature at collocated receivers. The users access the channel using spread spectrum signaling and thus generate interference with each other. Each user receives a utility that is a function of the received signal-tointerference plus noise ratio. We propose two auction mechanisms for allocating the received power. The first is an SINR-based auction which when combined with logarithmic utilities leads to a weighted max-min fair SINR allocation. The second is a power-based auction that maximizes the total utility when the bandwidth is large enough. Both auction mechanisms achieve social optimality in a large system limit where bandwidth power and the number of users are increased in a fixed proportion. We also give sufficient conditions for global convergence of a distributed updating algorithm and discuss the convergence speed. 1,10.1.1.1.3633,?,?
Robust Probabilistic Inference in Distributed Systems ,Mark A. Paskin Carlos Guestrin,2004,Probabilistic inference problems arise naturally in  distributed systems such as sensor networks and  teams of mobile robots. Inference algorithms that use  message passing are a natural fit for distributed systems  but they must be robust to the failure situations  that arise in real-world settings such as unreliable  communication and node failures. Unfortunately the  popular sum--product algorithm can yield very poor  estimates in these settings because the nodes beliefs  before convergence can be arbitrarily different from  the correct posteriors. In this paper we present a new  message passing algorithm for probabilistic inference  which provides several crucial guarantees that the  standard sum--product algorithm does not. Not only  does it converge to the correct posteriors but it is also  guaranteed to yield a principled approximation at any  point before convergence. In addition the computational  complexity of the message passing updates  depends only upon the model and is independent of  the network topology of the distributed system. We  demonstrate the approach with detailed experimental  results on a distributed sensor calibration task using  data from an actual sensor network deployment.,10.1.1.1.3634,?,?
Parameterized Object Sensitivity for Points-to Analysis for Java,Ana Milanova  Atanas Rountev  Barbara G. Ryder,2002,The goal of points-to analysis for Java is to determine the set of objects pointed to by a reference variable or a reference object field. We present object sensitivity a new form of context sensitivity for flow-insensitive points-to analysis for Java. The key idea of our approach is to analyze a method separately for each of the object names that represent runtime objects on which this method may be invoked. To ensure flexibility and practicality we propose a parameterization framework that allows analysis designers to control the tradeo#s between cost and precision in the object-sensitive analysis.,10.1.1.1.3636,?,?
Preference Construction and Persistence,In Digital Marketplaces Gerald Häubl Kyle B. Murray,2003,This article examines the role of electronic recommendation agents in connection with consumers  constructionof multiattributepreferences.We propose that such digital agentshave the  potential to influence consumers preferences in a systematic fashion. Our key hypothesis is  that everything else being equal the inclusion of an attribute in a recommendation agent renders  this attributemore prominent in consumerspurchasedecisions.The results of a controlled  agent-assisted shopping experiment provide strong support for this hypothesis. We also demonstrate  that this preference-construction effect may persist beyond the initial shoppingexperience  and into subsequent choice settings in which no recommendation agent is available,10.1.1.1.3637,?,?
Winnowing Wheat from Chaff: The Chunking GA,Hal Stringer And Hal Stringer Annie S. Wu,2004,In this work we investigate the ability of a Chunking GA (ChGA) to  reduce the size of variable length chromosomes and control bloat. The ChGA  consists of a standard genetic algorithm augmented by a communal building  block memory system and associated memory chromosomes and operators. A  new mxn MaxSum fitness function used for this work is also described. Results  show that a ChGA equipped with memory capacity equal to or greater than the  minimal size of an optimal solution naturally eliminates unexpressed genes.,10.1.1.1.3638,?,Springer
Feature Space Optimization Prior to Fuzzy Image Classification,François Leduc,?,This paper presents a method for features space optimization in a context of fuzzy image classification. Based on membership functions intersections the method allows to select the most appropriate features for objects discrimination. Comparison of the eCognition nearest neighbor algorithms and fuzzy classification is provided with the use of un-optimized and optimized features sets.,10.1.1.1.3639,feature space optimization dimensionality reduction,?
The Design of A Distributed Rating Scheme for Peer-To-Peer Systems,Debojyoti Dutta Ashish Goel Ramesh Govindan Hui Zhang,2003,There exist many successful examples of online reputation (or rating) systems such as on-line markets and e-tailer ratings. However for peer-to-peer applications an explicit ratings subsystem has often been ignored in system design because of the implicit assumption of trust and altruism among P2P users. This assumption might be true (or might not matter) when a P2P network is still in its infancy and is relatively small in size. But the assumption might break down with increase in the size and diversity of the P2P network. In this paper we discuss issues in the design of rating schemes for P2P systems. In keeping with the design philosophy of many of these system we consider the design of distributed rating systems. As a case study we illustrate two different approaches to a distributed rating system aimed at tackling the free-rider problem in P2P networks. A key challenge in designing such rating schemes is to make them collusion-proof: we discuss our efforts in this direction.  ,10.1.1.1.3640,?,?
Dynamic Restart Policies,Henry Kautz Kautz Eric Horvitz,2002,We describe theoretical results and empirical study of  context-sensitive restart policies for randomized search procedures.,10.1.1.1.3641,?,?
Fusion of Multi-Sensor Imagery for Night Vision: Color Visualization Target Learning and Search,D.A. Fay A. M. Waxman M. Aguilar  D.B. Ireland  J.P. Racamato  W.D. Ross W. W. Streilein M. I. Braun,2000,We present methods and results for fusion of imagery from multiple sensors to create a color night  vision capability. The fusion system architectures are based on biological models of the spatial and opponentcolor processes in the human retina and visual cortex implemented as shunting center-surround feed-forward neural networks. Real-time implementation of the dualsensor  fusion system combines imagery from either a low-light CCD camera or a short-wave infrared camera with thermal long-wave infrared imagery. Results are also shown for extensions of this fusion architecture to include imagery from all three of these sensors Visible/SWIR/LWIR as well as a four sensor system using Visible/SWIR/MWIR/LWIR cameras. We also demonstrate how results from these multi-sensor fusion systems are used as inputs to an interactive tool for target designation learning and search based on a  Fuzzy ARTMAP neural network.,10.1.1.1.3642,Sensor fusion image fusion night vision real-time processing,?
Quantum-like Chaos in Prime Number Distribution and in Turbulent Fluid Flows,A. M. Selvam,2001,re applied to derive the following  results for the observed association between prime number  distribution and quantum-like chaos. (i) Number theoretical  concepts are intrinsically related to the quantitative description  of dynamical systems. (ii) Continuous periodogram analyses  of different sets of adjacent prime number spacing intervals  show that the power spectra follow the model predicted  universal inverse power-law form of the statistical normal  distribution. The prime number distribution therefore exhibits  self-organized criticality which is a signature of quantum-like  chaos. (iii) The continuum real number field contains unique  structures namely prime numbers which are analogous to the  dominant eddies in the eddy continuum in turbulent fluid  flows.  Keywords: quantum-like chaos in prime numbers fractal  structure of primes quantification of prime number  distribution prime numbers and fluid flows  1. Introduction  he continuum real number field (infinite numbe,10.1.1.1.3643,?,Statistics McGraw-Hill
And Interpersonal Distance,William Ickinger Tulane William J. Ickinger Sandra Morris,?,Locus of control and Mach IV scores are found to be correlated with standing interpersonal distancing behavior in a behavioral game. Correlations between interpersonal distance and factors of these scales suggest that interpersonal distance is not generally manipulated actively to influence others but that greater distance is used as a defense against perceived negative characteristics of others. Scores on Vandos (1969) Reducer Augmentor scale predict distancing behavior with specific individuals (research confederates) but the direction of the correlation varies among individuals. @ Copyright William J. Ickinger Jr. 2001 ALL RIGHTS RESERVED 2  LITERATURE REVIEW  Hayduk (1983) reviewed personality as a determinant of differences in interpersonal distancing behavior. He concluded that there was insufficient evidence to provide dependable personality explanations for spatial preferences unless psychological disorders are considered extreme personality differences in which case stronger relationships appear. One of the major problems in interpreting the findings on personality characteristics and interpersonal distance is the difficulty of comparing results obtained using several different methodologies. One of the more basic differences is that some studies use standing subjects while in others subjects are seated. In a review of the literature research which used standing subjects showed a greater frequency of significant findings than research using seated subjects. Results of both types of studies are summarized below. Results obtained using methodologies where subjects have been asked to project themselves into simulated situations are not included because of the serious questions about the validity of these approaches most recently raised by Hayduk (1983) and e...,10.1.1.1.3644,?,?
Towards Supporting Psychologically Plausible Variability in Agent-Based Human Modelling,In Agent-based Human Modelling  Frank E. Ritter Emma Norling,2004,We describe the initial steps in developing an agentbased cognitive architecture designed to support psychologically plausible human variability. The new architecture COJACK is based on JACK a BDI-based agent language. It will constrain the agents to reason and act in a psychologically plausible manner. Their information processing will be adjusted by a set of parameters that moderate the agents reasoning and actions combined with a set of guidelines for developing plans and beliefs for the agents. This set of parameters will also support varying the agents performance both in terms of differences across agents as well as differences that arise within an individual due to internal and external factors. We conclude that other architectures will want to include a similar set including representing a body its interaction with the environment and the passage of time.,10.1.1.1.3645,?,?
Frequency Domain Testing Of Waveform Digitizers,Dario Petri Dario Petri,2001,An easy to use robust and accurate frequency-domain procedure for estimating the spectral performance of waveform digitizers is considered in this paper. Its properties are analyzed and almost unbiased estimators are proposed along with simple but accurate expressions for their variances. Experimental results are presented to validate the proposed analysis. Directions and criteria useful for the design of the test procedure are also included. Keywords: Analog-digital conversion quantization frequency domain analysis discrete Fourier transform. I. ,10.1.1.1.3647,?,?
JavaSymphony: Extensions for Explicit Control of Locality Parallelism and Load Balancing for Cluster and Grid-Computing,Thomas Fahringer  Alexandru Jugravu Ru Jugravu,2002,There has been an increasing research interest in using Java for performance-oriented distributed applications. Many approaches tend towards automatic management of locality parallelism and load balancing which is mostly under the exclusive control of a runtime system. However the programmer is commonly disabled to provide crucial information about the application structure (e.g. locality relationships or affinities between data and tasks) to the compiler or runtime system which frequently results in critical performance problems. In previous work we described JavaSymphony to substantially mitigate this problem. JavaSymphony is a Java class library that allows to control parallelism load balancing and locality at a high level. Objects can be explicitly distributed based on virtual architectures which impose a virtual hierarchy on a distributed system of physical computing nodes. The concept of remote method invocation is used to exchange data among distributed objects and to process work by remote objects.,10.1.1.1.3649,?,?
Variational Based Analysis and Modelling using B-splines,Peter Sherar P. A. Sherar,2004,The use of energy methods and variational principles is widespread in many fields of engineering of which structural mechanics and curve and surface design are two prominent examples. In principle many different types of function can be used as possible trial solutions to a given variational problem but where piecewise polynomial behaviour and user controlled cross segment continuity is either required or desirable B-splines serve as a natural choice. Although there are many examples of the use of B-splines in such situations there is no common thread running through existing formulations that generalises from the one dimensional case through to two and three dimensions. We develop a unified approach to the representation of the minimisation equations for Bspline based functionals in tensor product form and apply these results to solving specific problems in geometric smoothing and finite element analysis using the Rayleigh-Ritz method. We focus on the development of algorithms for the exact computation of the minimisation matrices generated by finding stationary values of functionals involving integrals of squares and products of derivatives and then use these to seek new variational based solutions to problems in the above fields. By using tensor notation we are able to generalise the methods and the algorithms from curves through to surfaces and volumes. The algorithms developed can be applied to other fields where a variational form of the problem exists and where such tensor product B-spline functions can be specified as potential solutions. ii Contents 1,10.1.1.1.3650,Contents,?
Turning wine into water: Can ordinary speech be artificially nasalized,Erik Eriksson Jan Van Doorn Kirk P. H. Sullivan,2003,this paper was to test whether perceptually nasalized speech could be produced by modifying the spectral features of the vowels to resemble nasalized vowels,10.1.1.1.3651,?,?
Wideband Communication System Sensitivity to Quantization Noise,Antonio Moschitta Antonio Moschitta Dario Petri Dario Petri,?,The performances of A/D converters are usually characterized in their granular region by adopting amplitude limited sine-wave testing signals. However some applications like digital telecommunication systems often require the conversion of signals which noticeably differ from sine-waves and may introduce ADC overloading phenomena. In this paper the A/D conversion of Gaussian distributed signal is investigated both for PCM and Sigma-Delta converters. Then the effects of quantization noise upon the behavior of a Digital Communication System are considered. By extending previous results a model is introduced which describes the BER performance of an OFDM system also in presence of overloading quantization noise both for PCM and Sigma-Delta A/D converters.,10.1.1.1.3652,Testing Direct Digital Modulation Orthogonal Frequency Division Multiplexing,?
Pricing and Rate Adaptation in a Non-Cooperative Environment,Xinran Wu Peter  Marbach,2003,We consider a price-based rate control scheme that has been proposed by Kelly et al.. However rather than assuming that users adapt their transmission rates by mandate we study the situation where users choose transmission rates to maximize their net benefit at each time step. Extending a result obtained by Ganesh et al. we show that in the single link case the system again converges to the equilibrium bandwidth allocation of Kelly et al.. This result suggests that price-based rate control scheme proposed by Kelly et al. is also effective when users behave in a selfish manner.,10.1.1.1.3653,?,?
The Geometry of Knowledge,Johan van Benthem  Darko Sarenac,2004,The most widely used attractive logical account of knowledge uses  standard epistemic models i.e. graphs whose edges are indistinguishability  relations for agents. In this paper we discuss more general topological models  for a multi-agent epistemic language whose main uses so far have been in  reasoning about space. We show that this more geometrical perspective affords  greater powers of distinction in the study of common knowledge defining new  collective agents and merging information for groups of agents.,10.1.1.1.3654,?,?
Finite Difference Approximations For Two-Sided Space-Fractional Partial Differential Equations,Mark M. Meerschaert Charles Tadjeran,2006,Fractional order partial differential equations are generalizations of classical partial differential equations. Increasingly these models are used in applications such as fluid flow finance and others. In this paper we examine some practical numerical methods to solve a class of initialboundary value fractional partial differential equations with variable coefficients on a finite domain. We examine the case when a left-handed or a right-handed fractional spatial derivative may be present in the partial differential equation. Stability consistency and (therefore) convergence of the methods are discussed. The stability (and convergence) results in the fractional PDE unify the corresponding results for the classical parabolic and hyperbolic cases into a single condition. A numerical example using a finite difference method for a two-sided fractional PDE is also presented and compared with the exact analytical solution.,10.1.1.1.3655,fractional flow fractional derivative fractional PDE numerical fractional PDE,?
Proceedings of the 1998 Winter Simulation Conference,Medeiros Watson Carson D. J. Medeiros E. F. Watson J. S. Carson M. S. Manivannan,?,Traditional methods of dealing with variability in simulation input data are mainly stochastic. This is most often the best method to use if the factors affecting the variation or the nature of the relationships between the factors and the outputs can not be easily identified.,10.1.1.1.3656,?,?
Transform Coefficient Thresholding and Lagrangian Optimization for H.264 Video Coding,X Examensarbete Pontus Carlsson Pontus Carlsson Pontus Carlsson,2004,this report we propose two methods for improving the coding performance while remaining fully compliant to the standard. After transformation and quantization the transform coefficients are usually entropy coded and embedded in the bitstream. However some of them might be beneficial to discard if the number of saved bits are sufficiently large. This is usually referred to as coefficient thresholding and is investigated in the scope of H.264 in this report. Lagrangian optimization for video compression has proven to yield substantial improvements in perceived quality and the H.264 Reference Software has been designed around this concept. When performing Lagrangian optimization lambda is a crucial parameter that determines the tradeoff between rate and distortion. We propose a new method to select lambda and the quantization parameter for non-reference frames in H.264. The two methods are shown to achieve significant improvements. When combined they reduce the bitrate around 12% while preserving the video quality in terms of average PSNR. To aid development of H.264 a software tool has been created to visualize the coding process and present statistics. This tool is capable of displaying information such as bit distribution motion vectors predicted pictures and motion compensated block sizes.,10.1.1.1.3657,ISSN,?
The Caring Personal Agent,Susan Bull Jim Greer Gord McCalla,2003,Self (1999) argues that the essence of having a computer-based learning system that cares about its learners is that the system model its learners so as to be able to adapt to their needs. In this paper we discuss the notion of personal agents who care for their owners by representing the owners interests in the learning system. We contextualise this discussion by showing how such personal agents are used in I-Help a system that promotes caring and sharing by encouraging learners to help one another. In I-Help personal agents themselves care for their learners by helping them to discover useful information and/or to find ready willing and able peer learners who can aid them in overcoming problems.,10.1.1.1.3658,?,?
Toward Feedback Stabilization of Faulty Software Systems:,Case Study Stephen Stephen Waydo William B. Dunbar Eric Klavins,?,Software systems generally suffer from a certain fragility in the face of disturbances such as bugs unforeseen user input unmodeled interactions with other software components and so on. A single such disturbance can make the machine on which the software is executing hang or crash. We postulate that what is required to address this fragility is a general means of using feedback to robustly stabilize these systems. In this paper we develop a model of an iterative software process specifically a nondeterministic faulty list sorter. Feedback is introduced into the process to achieve robust stability with respect to incorrect sorting operations. To keep the computational requirements of the controllers low randomization and approximation are used. Methods by which software robustness can be enhanced by distributing a task between nodes each of which are capable of selecting the best input to process are also explored. The particular case of a sorting system consisting of a network of partial sorters some of which may be buggy or even malicious is examined.,10.1.1.1.3659,?,?
Omnidirectional Vision for an Autonomous Helicopter,Stefan Hrabar Gaurav S. Sukhatme,2003,We present the design and implementation of an omnidirectional vision system used for sideways-looking sensing on an autonomous helicopter. To demonstrate the capabilities of the system a visual servoing task was designed which required the helicopter to locate and move towards the centroid of a number of visual targets. Results are presented showing that the task was successfully completed by a Pioneer ground robot equipped with the same omnidirectional vision system and preliminary test flight results show that the system can generate appropriate control commands for the helicopter.,10.1.1.1.3660,?,?
Barrier Boosting,Gunnar Rätsch  Manfred Warmuth  Sebastian Mika  Takashi Onoda  Steven Lemm  Klaus-Robert Müller,?,Boosting algorithms like AdaBoost and Arc-GV  are iterative strategies to minimize a constrained  objective function equivalent to Barrier algorithms.,10.1.1.1.3661,?,?
The Drug Ontology Project for Elsevier - An RDF Architecture Enabling Thesaurus-Driven Data Integration,J. Broekstra C. Fluit  A. Kampman F. Van Harmelen H. Stuckenschmidt  R. Bhogal  A. Scerri  A. de Waard  E. van Mulligen,2004,The DOPE project (Drug Ontology Project for Elsevier) is driven by the need to access multiple information sources through a single interface. In this paper we describe how DOPE allows thesaurus-driven access to heterogeneous and distributed data based on the RDF data model. The architecture allows for the easy addition of thesauri and data sources and can facilitate explorations in ontology mapping and data integration.,10.1.1.1.3662,?,?
Cooley-Tukey FFT Like Algorithm for the Discrete Triangle Transform,Markus Püschel  Martin Rötteler,?,The discrete triangle transform (DTT) was recently introduced [1] as an example of a non-separable transform for signal processing on a two-dimensional triangular grid. The DTT is built from Chebyshev polynomials in two variables in the same way as the DCT type III is built from Chebyshev polynomials in one variable. We show that as a consequence the DTT has as the DCT type III a Cooley-Tukey FFT type fast algorithm. We derive this algorithm and an upper bound for the number of complex operations it requires. Similar to most separable two-dimensional transforms the operations count of this algorithm is O(n    log(n)) for an input of size n    n.,10.1.1.1.3663,?,?
Decentralized Scheme for Spacecraft Formation Flying via the Virtual Structure Approach,Wei Ren  Randal W. Beard Al W. Beard,2003,this paper. Following a decentralized  coordination architecture via the virtual structure approach decentralized formation control strategies are  introduced which are appropriate when a large number of spacecraft are involved and/or stringent inter-spacecraft  communication limitations are exerted. The e#ectiveness of the proposed control strategies is demonstrated  through simulation results,10.1.1.1.3664,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,This paper describes an extension to the existing BSP Time Warp dynamic load-balancing algorithm to allow the management of interruption from external workload. Experiments carried out on a manufacturing simulation model using different partition strategies with and without interruption from external workload show that significant performance improvement can be achieved with external workload management.,10.1.1.1.3665,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes,?,Most discrete event simulation environments are based on a process-oriented and therefore multi-threaded paradigm. This results in simulation environments that are very hard to distribute over more computers and not easy to integrate with scattered external information sources. The architecture presented here is based on the event-based DES paradigm which is implemented by scheduled method invocation. Objects used in the simulation environment interact with remote a-synchronous subscribed clients in order to produce representations of the simulated system. The environment which is implemented in Java consists of a simulation and representation library and is integrated with several statistical libraries.,10.1.1.1.3666,?,?
TranScaling: A Video Coding and Multicasting Framework for Wireless IP Multimedia Services,Hayder Radha,2001,The convergence of the Internet with new wireless and  mobile networks is creating a whole new level of heterogeneity  in multimedia communications. This increased level of  heterogeneity emphasizes the need for scalable and adaptive  video solutions both for coding and transmission purposes.,10.1.1.1.3667,analog modems cable modems DSL LAN etc,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Sgouris P. Sgouridis,?,The continuing growth of marine container transport as well as the complexity in the analysis of terminal port operations has created an ideal area for applying computer simulation. This paper focuses on the handling of incoming containers transported on trucks in an All-StraddleCarrier  system. All major processes are reproduced by the simulation model. Input data includes parameters of space speed and arrival frequency in a generic format so that the model is adjustable to any situation. Analyzing the model for periods of model time ranging from a day to a week can give insight to the service level provided by any given port configuration. The simulated system can be used as a planning and a process improvement tool. In the development of the simulation model an object-oriented environment is used. It proves quite effective resulting in a reliable and adjustable model.,10.1.1.1.3668,?,?
Achieving Food Security in a Cost Effective Way: Implications of Domestic . . .,S. Jha Shikha Jha Shikha Jha P. V. Srinivasan P. V. Srinivasan Chris Delgado Paul Dorosh Eleni Gabre-madhin Nurul Islam Hans Löfgren,2004,this report we interchangeably refer to States/ Union Territories as states.    8   Table 2.1Safety Net ProgramsInterventions Financing Arrangements and  Coverage      Program/Scheme Volume of Food-Based Transfer Program Interventions  A. Targeted Public  Distribution System   BPL/ APL: 35 kg rice and wheat/  family/ month  Price subsidies on rice wheat sugar edible  oils.  1. Antyodaya Anna  Yojna  35 kg of rice and wheat per family  classified as poorest of the poor  A higher price subsidy on rice and wheat  than BPL rates  2. Annapurna Scheme 10 kg/ month/indigent senior citizen Free grain to indigent senior citizens   B. Food grain Price  Stabilization    Food grain procurement and price support  rice and wheat buffer stocks and open market  sales at below market prices Controls on  private storage movement access to credit  rice milling external trade   C. Food for Work   1.Jawahar Gram  Samriddhi Yojana  1 kg of rice or wheat/workday Employment in lean agricultural season for  rural workers below poverty line  2. Employment  Assurance Scheme  1 kg of rice or wheat/workday 100 days employment during lean  agricultural season up to 2 members/family  3. Swarnjayanti Gram  Swarozgar Yojana  Up to 5 kg grains per person per day Employment at minimum wage partly paid  in kind  4. Food-for-Work Food grains up to 5 kg per man-day Employment in natural calamity areas   D. Mid-Day Meals  Scheme   3 kg rice or wheat/child/month for  10 mos. Or cooked meal  (100gm/day) for 200 days  Cooked meal or distribution of food grains to  primary schools   E. Nutrition Schemes  with Food  Supplementation   1. Integrated Child  Development Services  Scheme/ Tamil Nadu  Integrated Nutrition   0 to 6 yrs: 300 calories (ready to eat   food) + 8-10 gm protein for 300   Malnourish...,10.1.1.1.3669,in,?
 Inaccessibility and undecidability in computation geometry and dynamical systems, Asaki Saito  Kunihiko Kaneko,2001,Non-self-similar sets defined by a decision procedure are numerically investigated by introducing the notion of inaccessibility to (ideal) decision procedure that is connected with undecidability. A halting set of a universal Turing machine (UTM) the Mandelbrot set and a riddled basin are mainly investigated as non-self-similar sets with a decision procedure. By encoding a symbol sequence to a point in a Euclidean space a halting set of a UTM is shown to be geometrically represented as a non-self-similar set having different patterns and different fine structures on arbitrarily small scales. The boundary dimension of this set is shown to be equal to the space dimension implying that the ideal decision procedure is inaccessible in the presence of error. This property is shown to be invariant under application of “fractal ” code transformations. Thus a characterization of undecidability is given by the inaccessibility to the ideal decision procedure and its invariance against the code transformations. It is also shown that the distribution of halting time of the UTM decays with a power law (or slower) and that this characteristic is also unchanged under code transformation. The Mandelbrot set is shown to have these features including the invariance against the code transformation in common and is connected with undecidable sets. In contrast although a riddled basin as a geometric representation of a certain context-free language has the boundary dimension equal to the space dimension and a power law halting time distribution these properties are not invariant against the code transformation. Thus the riddled basin is ranked as middle between an ordinary fractal and a halting set of a UTM or the Mandelbrot set. Last we,10.1.1.1.3670,?,Elsevier
Design Activity within Immersive Design Environments,Mr Sam Bucolo,2004,The introduction of digital design tools such as CAD Visualisations Shared Virtual Spaces and Immersive Projection Systems into the industrial design process has offered designers numerous benefits -- primarily related to a reduction in development time and cost. However the use of digital design media changes both the kind of activities and interactions that produce the designs and those used to probe and further the designs in design reviews within an educational context. This paper presents research of user interactions and experiences in design review sessions. Reviews using both traditional media and digital (Virtual Reality) media are studied. The study examines design conversations design reflections and the nature of the use of design media in both cases. The study has identified that the use of digital media for design reviews alters the nature of the design review process and its impact should be considered before adopting such an approach.,10.1.1.1.3671,Industrial Design Collocated interaction Virtual Reality Conceptual Design Reviews and Interaction Design,?
Do We Think and Communicate in Quantum Ways? On the Presence of Quantum Structures in Language,Diederik Aerts  Marek Czachor  Bart DHooge,2004,... this article is to show the presence of genuine quantum structures in human language. More in particular we will point out the violation of Bells inequalities in specific situations encountered in language. The first sections of this article explain why the violation of Bells inequalities is proof of the presence of genuine quantum structures and how over the past decades this insight has increasingly made itself felt in the foundations of quantum mechanics research. This article also contains an overview of earlier work of ours discussing the detection of quantum structures in other domains than the micro-world.  ,10.1.1.1.3672,?,?
A Neural Network Based Approach for ESM/Radar Track,Yifeng Zhou Jim,?,In this paper a neural network based ESM/radar track association algorithm is presented. The algorithm consists of a feed-forward neural network and a probability combiner. The neural network classifier is trained using the radar bearing measurements as well as their time stamps to approximate the a posteriori probabilities. The ESM bearing measurements along with their time stamps are fed to the trained network to provide a sequence of a posteriori probabilities. The probability combiner combines the local a posteriori probabilities to provide the global a posteriori probabilities that an ESM track belongs to each individual radar track. The track association logic associates the ESM track with the radar track that has the maximum a posteriori probability. The approach is able to eliminate the complex track time alignment process that is required by other techniques. It also alleviates the requirement for the Gaussian assumption about the measurements. Computer simulations are used to demonstrate the performance and effectiveness of the proposed algorithm.,10.1.1.1.3673,track association sensor fusion ESM radar neural networks,?
FCND DP No. 97 FCND DISCUSSION PAPER NO. 97 SOCIOECONOMIC DIFFERENTIALS IN CHILD STUNTING ARE CONSISTENTLY LARGER IN URBAN THAN IN RURAL AREAS,Purnima Menon Marie T. Ruel Saul S. Morris,?,Urban-rural comparisons of childhood undernutrition suggest that urban populations are better-off than rural populations. However these comparisons could mask the large differentials that exist among socioeconomic groups in urban areas. Data from the Demographic and Health Surveys (DHS) for 11 countries from three regions were used to test the hypothesis that intra-urban differentials in child stunting were greater than intra-rural differentials and that the prevalence of stunting among the urban and the rural poor was equally high. A socioeconomic status (SES) index based on household assets housing quality and availability of services was created separately for rural and urban areas of each country using principal components analysis. Odds ratios (OR) were computed to estimate the magnitude of differentials in stunting (height-for-age Z-scores  -2) between urban and rural areas and between the lowest and highest SES quintiles within areas. The prevalence of stunting was lower in urban than in rural areas for all countries but rural-urban ORs were relatively small ( 3.3). As hypothesized the gap between low and high SES was markedly larger in urban (median OR = 4) than rural (median OR = 1.8) areas and differences were statistically significant (interaction between area and SES in logistic regression) in all but three countries. Within-urban ORs as high as 10 were found in Peru and the Dominican Republic whereas within-rural ORs were smaller than 3.5 except in Brazil. In most countries stunting in the poorest urban quintile was almost on par with that of poor rural dwellers. Thus malnutrition in urban areas continues to be of concern and effective targeting of nutrition programs to the poorest segments of the urban population will be critical to their su...,10.1.1.1.3674,?,?
C. Roy Keys Inc.,Adic Properties Of Oscar Sotolongo-costa Jesus San-martin,?,this paper we explore the application of ultrametricity in linking the Bernoulli map with a branching structure which will reveal the possibilities of assigning an ultrametric measure to processes that to all appearances are not linked with a given metric (e.g. minority game and related problems) so that an adequate understanding of the ultrametric properties of a given process may lead to deeper understanding [5]. As any nontrivial norm is equivalent to the Euclidean or any of the p-adics (Ostrowskis theorem [1]) it would be convenient to measure the distance between points in Bakers map with a p-adic metric,10.1.1.1.3675,?,?
Architecture-Based Program Compaction,Chris Ler Andr Chris Lüer André Hoek,2003,this paper we propose a new approach to program compaction for applications that contain reused components. We call our approach architecturebased since it makes use of designers understanding of the architecture of an application that consists out of reused components,10.1.1.1.3677,?,?
 Causal Coherence and The Availability of Locations and Objects during . . . ,Brian A. Sundermeier Paul van den Broek Rolf A. Zwaan,?,The aim of this study was to examine whether locations of objects are encoded and available to the reader at different points in a narrative depending on their causal relevance. Participants in five experiments read narratives in which the spatial relation between an object and its location either did or did not provide a causal explanation for a later critical event. Object and location target words were presented to participants immediately before or after the critical event. Speeded-recognition response times to target words demonstrated that both locations and objects were re-activated but only after they became causally relevant. The results suggest that the causal structure of a text can influence the availability of spatial information and that at least some spatial relations are encoded during reading and are available to the reader when needed to build coherence.  ,10.1.1.1.3678,?,?
Project ref. no. IST-1999 10354,Project Title Alert Author(s R. Amaral I. Trancoso (inesc C. Barras E. Bilinski J. L. Gauvain L. Lamel Y. Y. Lo U. Iurgel A. Kosmala (unidu,?,for dissemination)  This document overviews the work carried out in the ALERT  project concerning the detection of topics in audiovisual data using  the output of a speech recognizer. The objectives of this workpackage  are two-fold: to automatically divide the audio stream into  topically homogeneous segments and associate one or more topics  with each audio segment. The emphasis is to develop statistical  methods for topic detection comparing the performance of different  techniques in the presence of speech recognition errors.,10.1.1.1.3679,IST-1999 ALERT Deliverable D4.1 Contents,?
Resource-Aware Stream Management with the Customizable dproc Distributed,Monitoring Mechanisms Sandip Ip Agarwala Christian Poellabauer Jiantao Kong Karsten Schwan Matthew Wolf,2003,Monitoring the resources of distributed systems is essential to the successful deployment and execution of grid applications particularly when such applications have welldefined QoS requirements. The dproc system-level monitoring mechanisms implemented for standard Linux kernels have several key components. First utilizing the familiar /proc filesystem dproc extends this interface with resource information collected from both local and remote hosts. Second to predictably capture and distribute monitoring information dproc uses a kernel-level group communication facility termed KECho which is based on events and event channels. Third and the focus of this paper is dprocs run-time customizability for resource monitoring which includes the generation and deployment of monitoring functionality within remote operating system kernels. Using dproc we show that (a) data streams can be customized according to a clients resource availabilities (dynamic stream management) (b) by dynamically varying distributed monitoring (dynamic filtering of monitoring information) appropriate balance can be maintained between monitoring overheads and application quality and (c) by performing monitoring at kernel-level the information captured enables decision making that takes into account the multiple resources used by applications.,10.1.1.1.3680,?,?
Dissimilarity Representation of Images for Relevance,Feedback In Content-Based Giorgio Giacinto Fabio Roli,?,Relevance feedback mechanisms are adopted to refine image-based  queries by asking users to mark the set of retrieved images as being relevant or  not. In this paper a relevance feedback technique based on the dissimilarity  representation of images is proposed. Each image is represented by a vector  whose components are the similarity values between the image itself and a  representation set made up of the images retrieved so far. A relevance score is  then assigned to each image according to its distances from the sets of relevant  and non-relevant images. Three techniques to compute such relevance scores  are described. Reported results on three image databases show that the proposed  relevance feedback mechanism allows attaining large improvements in retrieval  precision after each retrieval iteration. It also outperforms other techniques  proposed in the literature.,10.1.1.1.3681,?,?
Some Remarks on Factor Graphs,Hans-andrea Loeliger,2003,The paper is a collection of remarks some rather plain on various issues with factor graphs. In particular it is pointed out that powerful signal processing techniques such as gradient methods Kalman filtering and the particle filter can be used and combined in factor graphs.,10.1.1.1.3682,factor graphs turbo signal processing,?
Global Value Numbering using Random Interpretation,Sumit Gulwani George C. Necula,2004,We present a polynomial time randomized algorithm for global value numbering. Our algorithm is complete when conditionals are treated as non-deterministic and all operators are treated as uninterpreted functions. We are not aware of any complete polynomialtime deterministic algorithm for the same problem. The algorithm does not require symbolic manipulations and hence is simpler to implement than the deterministic symbolic algorithms. The price for these benefits is that there is a probability that the algorithm can report a false equality. We prove that this probability can be made arbitrarily small by controlling various parameters of the algorithm. Our algorithm is based on the idea of random interpretation which relies on executing a program on a number of random inputs and discovering relationships from the computed values. The computations are done by giving random linear interpretations to the operators in the program. Both branches of a conditional are executed. At join points the program states are combined using a random affine combination. We discuss ways in which this algorithm can be made more precise by using more accurate interpretations for the linear arithmetic operators and other language constructs.,10.1.1.1.3683,Categories and Subject Descriptors D.2.4 [Software Engineering Software/Program Verification F.3.1 [Logics and Meanings of Programs Specifying and Verifying,?
Implement role based access control with attribute certificates,Wei Zhou Christoph Meinel,2004,over the Internet. But as more people are involved in the transaction circle security and authorization control becomes one of the biggest concerns. Hence We are motivated by the need to manage and to enforce a strong authorization mechanism in largescale web-environment. Role based access control (RBAC) provides some flexibility to security management. Public key infrastructure (PKI) can provide a strong authentication. Privilege management infrastructure (PMI) as a new technology can provide strong authorization. In order to satisfy mentioned security requirements we have established a role based access control infrastructure and developed a prototype that uses X.509 public key certificates (PKCs) and attribute certificates (ACs). Access control is performed by access control policies that are written in XML. Policies and roles are stored in ACs. PKCs and ACs are all stored in LDAP servers. A new solution for policy management is described. The main components of the prototype are administration tool and access control engine. The access control engine provides a service that mediates the data between the users and the resources which is also responsible for authentication and authorization. The administration tool can create key pairs PKCs and ACs manage users information and so on.,10.1.1.1.3685,infrastructure,?
Scenario-based Assessment of Software Architecture Usability,Eelke Folmer   Jilles van Gurp Jan Bosch,2003,Over the years the software engineering community has increasingly realized the important role software architecture plays in fulfilling the quality requirements of a system. The quality attributes of a software system are to a large extent determined by the systems software architecture .Usability is an essential part of software quality. The usability of software has traditionally been evaluated on completed systems. Evaluating usability at completion introduces a great risk of wasting effort on software products that are not usable. A scenario based assessment approach has proven to be successful for assessing quality attributes such as modifiability and maintainability [12]. It is our conjecture that scenario based assessment can also be applied for usability assessment. This paper presents and describes a scenario based assessment method to evaluate whether a given software architecture (provided usability) meets the usability requirements (required usability). The Scenariobased Architecture Level UsabiliTy Assessment (SALUTA) method consists of five main steps goal selection usage profile creation software architecture description scenario evaluation and interpretation   ,10.1.1.1.3686,?,?
Publishedoblis,May Recoveryafte Mass Ricard V. Solé José M. Montoya Douglas H. Erwin,?,this paper we analyse the similarities and differences  between ecological succession and evolutionary recovery to provide a preliminary ecological theory of  recoveries. A simple evolutionary model with three trophic levels is presented and its properties (closely  resembling those observed in the fossil record) are compared with characteristic patterns of ecological  response to disturbances in continuous models of three-level ecosystems,10.1.1.1.3687,biodiversity recoveries assembly dynamics mass extinctions food web structure,?
Learning to Read Between the Lines: The Aspect Bernoulli Model,A. Kaban  E. Bingham  T. Hirsimäki,2004,We present a novel probabilistic multiple cause model for binary observations. In contrast to other approaches the model is linear and it infers reasons behind both observed and unobserved attributes with the aid of an explanatory variable. We exploit this distinctive feature of the method to automatically distinguish between attributes that are `o# by content and those that are missing. Results on artificially corrupted binary images as well as the expansion of short text documents are given by way of demonstration.,10.1.1.1.3688,?,?
Location-Based Services for Mobile Telephony: a Study of Users Privacy Concerns,Louise Barkhuus  Anind Dey,2003,Context-aware computing often involves tracking peoples location. Many studies and applications highlight the importance of keeping peoples location information private. We discuss two types of locationbased services location-tracking services that are based on other parties tracking the users location and  position-aware services that rely on the devices knowledge of its own location. We present an experimental case study that examines peoples concern for location privacy and compare this to the use of location-based services.,10.1.1.1.3689,?,?
METIORE: A Personalized Information Retrieval System,David Bueno Amos A. David,2001,The idea of personalizing the interactions of a system is not new.,10.1.1.1.3690,?,Springer
Using Non-Primitive Concept Definitions for Improving DL-Based Knowledge Bases,Ronald Cornet Ameen Abu-Hanna,2004,Medical Terminological Knowledge Bases contain a large number of primitive  concept definitions. This is due to the large number of natural kinds that  are represented and due to the limits of expressiveness of the Description Logic  used. The utility of classification is reduced by these primitive definitions hindering  the knowledge modeling process. To better exploit the classification utility  we devise a method in which definitions are assumed to be non-primitive in the  modeling process. This method aims at the detection of: duplicate concept definitions  underspecification and actual limits of a DL-based representation. This  provides the following advantages: duplicate definitions can be found the limits  of expressiveness of the logic can be made more clearly and tacit knowledge is  identified which can be expressed by defining additional concept properties. Two  case studies demonstrate the feasibility of this approach.,10.1.1.1.3691,?,?
Scalable Application-Level Anycast for Highly Dynamic Groups,Miguel Castro Peter Druschel  Anne-Marie Kermarrec  Antony Rowstron,2003,We present an application-level implementation of anycast  for highly dynamic groups. The implementation can handle group sizes  varying from one to the whole Internet and membership maintenance  is e#cient enough to allow members to join for the purpose of receiving  a single message. Key to this e#ciency is the use of a proximity-aware  peer-to-peer overlay network for decentralized lightweight group maintenance  nodes join the overlay once and can join and leave many groups  many times to amortize the cost of maintaining the overlay. An anycast  implementation with these properties provides a key building block  for distributed applications. In particular it enables management and  location of dynamic resources in large scale peer-to-peer systems. We  present several resource management applications that are enabled by  our implementation.,10.1.1.1.3692,?,?
A Model for the Structural Functional and Deontic Specification of Organizations in Multiagent Systems,Jomi Fred Hübner Jaime Simão Sichman Olivier Boissier,2002,A Multiagent System (MAS) that explicitly represents its organization  normally focuses either on the functioning or the structure of this organization. However addressing,10.1.1.1.3693,?,Springer
Lip gestures in Danish vowels: Articulation and coarticulation,Gert Foget Hansen,2003,This paper presents the results of a pilot experiment on measuring lip  gestures for the vowels of one Danish speaker (the author) including data on  anticipatory lip rounding over a gradually shortened sequence of consonants  in conjunction with a word boundary. The results may have implications for  theories concerning coarticulation,10.1.1.1.3695,?,?
A Bilingual OCR for Hindi-Telugu Documents and its Applications,Jawahar Pavan Kumar C. V. Jawahar S. S. Ravi Kiran,2002,This paper describes the character recognition process from printed documents containing Hindi and Telugu text. Hindi and Telugu are among the most popular languages in India. The bilingual recognizer is based on Principal Component Analysis followed by support vector classification. This attains an overall accuracy of approximately 96.7%. Extensive experimentation is carried out on an independent test set of approximately 200000 characters. Applications based on this OCR are sketched.,10.1.1.1.3696,?,?
FCNDP No. 175,Fcnd Discussion Paper Sarah Harrower John Hoddinott,?,This paper explores risk sharing in the Zone Lacustre Mali as viewed through  the lens of consumption smoothing. We find that idiosyncratic shocks appear to have  little impact on consumption and that households respond to these shocks in a variety of  ways. In general nonpoor households are more likely to enter into new incomegenerating activities while poor households are more likely to engage in credit or gift  exchange or to ration consumption. When we construct a stronger test for consumption  smoothing we find that changes in household income lead to modest changes in  consumption. Covariant shocks as measured by village/round dummies always lead to  changes in consumption. These results are robust to concerns regarding bias resulting  from measurement error or endogeneity of changes in income. Lastly we find that  households with access to improved water control infrastructure are less vulnerable than  those that rely on rainfall or the flooding of the Niger River.  iii Contents   Acknowledgments............................................................................................................... v    1. ,10.1.1.1.3697,1. Introduction.....................................................................................,?
Lessons In The Development And Deployment Of,Automated It Skills Stewart Long Nr Tj,2000,Assessment software is currently being deployed by a UK Examination Board to largely replace human assessment for the accreditation of word processing skills for one of its most popular awards. This paper is intended to outline some of the key lessons learned concerning assessment software development and deployment which have been instrumental in the projects success.,10.1.1.1.3698,?,?
Models and Methods for Analyzing Internet Congestion Control Algorithms,R Srikant,2004,this paper is organized in follows. In Section 2 we present a simple model for Jacobsons algorithm that was introduced in [27] and analyze its local stability in the presence of feedback delay. We summarize the results in [27 25] which show that TCP-Reno is not stable when the capacity per user is large or if the feedback delay is large. In Section 3 we introduce the Kelly resource allocation model [11] and the associated congestion control algorithms [13 20]. A stability analysis of the congestion control algorithm in the presence of feedback delays is presented in Section 4. This stability result was obtained in [32] using Razumikhin theorem. A related result has also been obtained in [18] using di#erent techniques. In Section 5 we present the connection-level model introduced in [26] and present a stability result using a drift analysis. This result which was first established in [4] using fluid limits and a special case of this result was presented earlier in [6]. Finally concluding remarks are presented in Section 6. The survey presented here covers only a small portion of the considerable research on Internet Congestion Control that has taken place over the last few years. For a more comprehensive survey we refer the reader to [27],10.1.1.1.3699,?,SpringerVerlag
Prototyping Advanced Warfare Gaming Capabilities For The 21st Century Warfighter,Curtis L. Blais For The St Century Warfighter,1998,The United States Marine Corps has a unique role in development of the next-generation warfare gaming system for command staff training. This system titled the Joint Simulation System (JSIMS) is under development by the Department of Defense through a Joint Program Office acting to coordinate the activities of multiple DoD agencies and military services. The nature of operations conducted by the USMC requires modeling and simulation across all JSIMS domains -- Land Air/Space Maritime Intelligence and Command and Control. The Marine Corps requires the broadest reach across these domains to provide battlespace representations that will support staff training from Marine Expeditionary Unit through multiple Marine Expeditionary Force operations.,10.1.1.1.3701,Control Communications Computers and Intelligence,?
LandTrees and Women,Evolution Of Landtenure Agnes R. Quisumbing Keijiro Otsuka S. Suyanto J. B. Aidoo E. Payongayong Sumatra Agnes R. Quisumbing,?,this report may be reproduced without the express permission  of but with acknowledgment to the International Food Policy Research Institute,10.1.1.1.3702,Figures vii,?
Optimal Sensor Trajectories in Bearings-Only Tracking,Marcel Hernandez,2004,We consider the problem of determining sensor trajectories in the bearings-only tracking of an uncertain target. This work differs from previous research in that we allow the target dynamics to be both uncertain and random and also consider multi-sensor scenarios. The basis of our technique is to control a measure of estimation error based on the Posterior Cram er-Rao lower bound (PCRLB) and we present both single-step and multi-step planning approaches. We also introduce an efficient search technique that allows us to quickly perform the necessary optimisation (s). Sensor trajectories are shown to be almost identical to those obtained by performing an enumerative search but the computational load is reduced by several orders of magnitude. Simulation results are presented for 1 2 and 3 sensor scenarios and compare the single-step and twostep approaches. The performance (in terms of both the PCRLB and particle filter estimation errors) improves both with two-step planning and as sensor numbers increase as one would expect.,10.1.1.1.3703,resource management target,?
Typed Memory Management in a Calculus of Capabilities,David Walker Karl Crary  Greg Morrisett,2000,Region-based memory management is an alternative to standard tracing garbage collection that  makes potentially dangerous operations such as memory deallocation explicit but verifiably safe. In  this article we present a new compiler intermediate language called the Capability Calculus that  supports region-based memory management and enjoys a provably safe type system. Unlike previous  region-based type systems region lifetimes need not be lexically scoped and yet the language may  be checked for safety without complex analyses. Therefore our type system may be deployed in  settings such as extensible operating systems where both the performance and safety of untrusted  code is important.,10.1.1.1.3704,?,ACM Press
Computer Aided Improvement of Human-Centered Design Processes,E. Metzker  M. Offergeld,?,With the increasing relevancy of usability as a software quality factor a growing demand for tools that support the special activities of HCD (human-centered design) processes within the industrial software development community is expected to arise. To elicit initial requirements for tool support we analyzed the real tasks of  developers of four major companies engaged in the development of highly interactive systems the problems  incurred and the burning support issues. Inspired by the results of this survey we developed REUSE a system that facilitates the elicitation organization and effective reuse of best practices and artifacts concerning HCD activities and makes their performance more efficient. An initial formative evaluation with future users showed that REUSE is able to improve the utilization of HCD methods within the development process of interactive systems and overcomes some limitations of related approaches.,10.1.1.1.3705,?,?
Measurement Based Optimal Multi-path Routing,Tuna Güven  Chris Kommareddy Richard J. La Mark A. Shayman Bobby Bhattacharjee,2004,We propose a new architecture for efficient network monitoring and measurements in a traditional IP network. This new architecture enables establishment of multiple paths (tunnels) between source-destination pairs without having to modify the underlying routing protocol(s). Based on the proposed architecture we propose a measurement-based multi-path routing algorithm derived from simultaneous perturbation stochastic approximation. The proposed algorithm does not assume that the gradient of analytical cost function is known to the algorithm but rather relies on noisy estimates from measurements. Using the analytical model presented in the paper we prove the convergence of the algorithm to the optimal solution. Simulation results are presented to demonstrate the advantages of the proposed algorithm under a variety of network scenarios. A comparative study with an existing optimal routing algorithm MATE is also provided.,10.1.1.1.3706,Simulations,?
Automatic Implementation and Simulation of Dynamic Qualitative,Systems Using Fuzzy,?,This paper presents the overview of an ongoing project which goal is to obtain and simulate the dynamics of qualitative systems through the combination of the properties of Fuzzy Boolean Networks and Fuzzy Rule Based Cognitive Maps.,10.1.1.1.3707,?,?
Proceedings of the 2002 Winter Simulation Conference,Ycesan Chen Snowdon E. Yücesan C. -h. Chen J. L. Snowdon J. M. Charnes Jai Thomas Jayesh Todi Asif Paranjpe,?,The project was conducted in a high quality steel wire manufacturing company with the production capacity of over 120000 tones/annum. The wire drawn from the high speed wire drawing (KOCH) machine is fed as the raw material for BEKEART (zinc coating galvanization) furnace. The problem faced by the company is the variability in the amount of input to the furnace which results from the breakdowns occurring on the KOCH machine resulting in low production. Apart from its speed KOCH machines have other advantages due to their automation by which they can be set as per the requirements and different parameters of the company. From figure1 it can be concluded that any downtime in the process occurring at the KOCH machine adversely affects the productivity of the BEKEART furnace as a result of which the total production on this line suffers and hence the profits of the company. Simulation study was done with the objective of increasing the throughput and ensuring smooth product flow through the system by finding the optimum arrival batch size.,10.1.1.1.3708,?,?
A network intrusion detection system on IXP1200 network processors with support for large rule sets,Herbert Bos Kaiming Huang,2004,In this paper we describe an network intrusion detection system implemented on the IXP1200 network processor. It is aimed at detecting worms at high speeds by matching the payload of network packets against worm signatures at the lowest possible levels of the processing hierarchy (the microengines of an IXP1200 network processor). The solution employs the AhoCorasick algorithm in a parallel fashion where each microengine processes a subset of the network traffic. To allow for large patterns as well as a large number of rules the signatures are stored in off-chip memory. Using an old version of the IXP network processors (the IXP1200) the system is capable of handling close to 200 Mbps with full content scan for realistic threats.,10.1.1.1.3709,?,?
Efficiency Loss in a Cournot Mechanism for Network Resource Allocation,Ramesh Johari  John N. Tsitsiklis,?,We consider a resource allocation problem where individual users wish to send data across a network to maximize their utility and a cost is incurred at each link dependent on the total rate sent on that link. We analyze a model where users choose the rates at which they want to send along available paths and each link sets a price equal to the marginal cost of the rate through it. As long as users do not anticipate the effect of their actions on prices such a scheme can maximize the sum of users utilities minus the sum of the links costs (called aggregate surplus). Continuing previous efforts to quantify the effects of selfish behavior in network pricing mechanisms our research considers the possibility that users may anticipate the effect of their actions on the link price. While the efficiency loss is generally arbitrarily high we establish bounds for several special cases. In particular if each link has an affine marginal cost function we establish that the aggregate surplus is at least 2/3 of the optimal aggregate surplus even for general networks thus the efficiency loss when users are selfish is no more than approximately 33%. I. ,10.1.1.1.3711,?,?
Adding 3D Graphics Support to PLX,Xiao Yang  Ruby Lee,?,This paper adds floating-point instructions to PLX  for 3D graphics processing which is essential for applications  such as games and digital content creation. Based on an analysis  of the 3D graphics pipeline from an ISA point of view we show  the operations and data types needed. We present the FP ISA  and demonstrate its use and performance with code examples  from the 3D graphics pipeline.   Keywordsprocessor architecture instruction-set architecture  (ISA) floating-point multimedia 3D graphics   I.# ,10.1.1.1.3712,?,?
MetaFluxNet a Program Package for Metabolic Pathway Construction and Analysis and Its Use in Large-Scale Metabolic Flux Analysis of Escherichia coli, Dong-Yup Lee Dong-yup Lee Soon Ho Hong  Tae Yong Kim  Hongsoek Yun  Young-Gyun Oh  Sunwon Park,2003,We have developed MetaFluxNet which is a stand-alone program package for the management  of metabolic reaction information and quantitative metabolic flux analysis. It allows users to interpret  and examine metabolic behavior in response to genetic and/or environmental modifications.,10.1.1.1.3713,metabolic flux analysis MetaFluxNet Escherichia coli in silico simulation,?
Evaluating cfengines Immunity Model of Site Maintenance,Mark Burgess,2000,this paper is to take a critical review of the success of the immunity model computer management. What are the criteria for judging a mechanism for maintenance ? What aspects of system administration are not covered in this model? Can the immunity model be judged to be superior or inferior to other approaches to system management ?  2 Analytical system administration  In spite of USENIX/SAGE efforts system administration is not yet a continuing research dialog but more a cycle of reinvention of one-off solutions. If one is to avoid such reinvention and advance the state of the field more introspection and criticism of the technologies at hand is needed,10.1.1.1.3714,?,?
Efficient Quantization for Overcomplete Expansions in R^N,Baltasar Beferull-lozano Antonio Ortega,2003,In this paper we study construction of structured regular quantizers for overcomplete expansions in . Our goal is to design structured quantizers which allow simple reconstruction algorithms with low complexity and which have good performance in terms of accuracy. Most related work to date in quantized redundant expansions has assumed that the same uniform scalar quantizer was used on all the expansion coefficients. Several approaches have been proposed to improve the reconstruction accuracy with some of these methods having significant complexity. Instead we consider the joint design of the overcomplete expansion and the scalar quantizers (allowing different step sizes) in such a way as to produce an equivalent vector quantizer (EVQ) with periodic structure. The construction of a periodic quantizer is based on lattices in and the concept of geometrically scaled-similar sublattices. The periodicity makes it possible to achieve good accuracy using simple reconstruction algorithms (e.g. linear reconstruction or a small lookup table).,10.1.1.1.3715,?,?
Evaluating Example-based Search Tools,Pearl H. Z. Pu Pratyush Kumar,2004,?,10.1.1.1.3716,example-based interface e-commerce decision tradeoff product,?
Discovering Internet Topology,Siamwalla Sharma Ands,?,In large and constantly evolving networks it is difficult to determine how the network is actually laid out. Yet this information is invaluable for network management simulation and server siting. Traditional topology discovery algorithms are based on SNMP which is not universally deployed. We describe several heuristics and algorithms to discover both intra-domain and Internet backbone topology while making as few assumptions about the network as possible. We quantitatively evaluate their performance and also present a new technique for visualizing Internet backbone topology.,10.1.1.1.3717,?,?
Adaptive Wavelet Thresholding for Image Denoising and Compression,S. Grace Chang Bin Yu Martin Vetterli,2000,The first part of this paper proposes an adaptive data-driven threshold for image denoising via wavelet soft-thresholding. The threshold is derived in a Bayesian framework and the prior used on the wavelet coefficients is the generalized Gaussian distribution (GGD) widely used in image processing applications. The proposed threshold is simple and closed-form and it is adaptive to each subband because it depends on data-driven estimates of the parameters. Experimental results show that the proposed method called BayesShrink is typically within 5% of the MSE of the best soft-thresholding benchmark with the image assumed known. It also outperforms Donoho and Johnstones SureShrink most of the time. The second part,10.1.1.1.3718,?,?
